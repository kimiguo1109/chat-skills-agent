"""
Google Gemini API æœåŠ¡å°è£…

æä¾›ç»Ÿä¸€çš„ LLM API è°ƒç”¨æ¥å£ï¼Œæ”¯æŒï¼š
- æ–‡æœ¬ç”Ÿæˆ
- JSON æ ¼å¼åŒ–è¾“å‡º
- é”™è¯¯å¤„ç†å’Œé‡è¯•
- Token é™åˆ¶
"""
import logging
import json
import time
from typing import Optional, Dict, Any, List
from google import genai  # æ¢å¤ Geminiï¼Œç”¨äºå¿«é€Ÿå‹ç¼©ä»»åŠ¡
from google.genai import types

from ..config import settings

logger = logging.getLogger(__name__)


class GeminiClient:
    """Gemini API å®¢æˆ·ç«¯å°è£…ï¼ˆä½¿ç”¨æœ€æ–° SDKï¼‰"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gemini-2.5-flash"):
        """
        åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯
        
        Args:
            api_key: Gemini API Keyï¼Œå¦‚æœä¸æä¾›åˆ™ä» settings è¯»å–
            model: é»˜è®¤æ¨¡å‹åç§°
        """
        self.api_key = api_key or settings.GEMINI_API_KEY
        self.model = model  # ğŸ”§ æ·»åŠ  model å±æ€§ï¼Œä¸ KimiClient ä¿æŒä¸€è‡´
        
        # åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨æœ€æ–° SDKï¼‰
        self.client = genai.Client(api_key=self.api_key)
        self.async_client = self.client.aio
        
        logger.info(f"âœ… Gemini client initialized with model: {self.model}")
    
    async def generate_stream(
        self,
        prompt: str,
        model: str = "gemini-2.5-flash",
        max_tokens: int = 2000,
        temperature: float = 0.7,
        thinking_budget: Optional[int] = 1024,
        return_thinking: bool = True,
        buffer_size: int = 1  # å…¼å®¹å‚æ•°ï¼ŒGemini ä¸ä½¿ç”¨
    ):
        """
        æµå¼ç”Ÿæˆå†…å®¹ï¼ˆç”¨äºå®æ—¶å±•ç¤ºæ€è€ƒè¿‡ç¨‹ï¼‰
        
        Args:
            prompt: æç¤ºè¯
            model: æ¨¡å‹åç§°
            max_tokens: æœ€å¤§tokenæ•°
            temperature: æ¸©åº¦å‚æ•°
            thinking_budget: æ€è€ƒé¢„ç®—
            return_thinking: æ˜¯å¦è¿”å›æ€è€ƒè¿‡ç¨‹
            
        Yields:
            Dict: åŒ…å« type (thinking/content) å’Œ text çš„å­—å…¸
        """
        config_kwargs = {
            "temperature": temperature,
            "max_output_tokens": max_tokens,
            "response_modalities": ["TEXT"],
        }
        
        # âš ï¸ æ€è€ƒé…ç½®ä»…æ”¯æŒ Gemini 2.5 Flash (Thinking)ï¼Œ2.0 Flash Exp ä¸æ”¯æŒ
        # ä¸ºä¿æŒå…¼å®¹æ€§ï¼Œæš‚æ—¶å…³é—­æ€è€ƒé…ç½®
        # æœªæ¥å¯æ ¹æ® model åç§°åˆ¤æ–­æ˜¯å¦æ”¯æŒ thinking
        # if thinking_budget is not None and thinking_budget > 0 and "thinking" in model.lower():
        #     config_kwargs["thinkingConfig"] = types.ThinkingConfig(
        #         thinkingBudget=thinking_budget,
        #         includeThoughts=return_thinking
        #     )
        
        config = types.GenerateContentConfig(**config_kwargs)
        
        try:
            logger.info(f"ğŸŒŠ Starting streaming generation: model={model}")
            
            # ä½¿ç”¨æµå¼ API
            stream = await self.async_client.models.generate_content_stream(
                model=model,
                contents=prompt,
                config=config
            )
            
            thinking_accumulated = []
            content_accumulated = []
            usage_metadata = {}  # ğŸ†• æ”¶é›† usage å…ƒæ•°æ®
            
            async for chunk in stream:
                logger.debug(f"ğŸ” Received chunk: {type(chunk)}")
                
                # ğŸ†• æ•è· usage metadataï¼ˆé€šå¸¸åœ¨æœ€åä¸€ä¸ª chunkï¼‰
                if hasattr(chunk, 'usage_metadata') and chunk.usage_metadata:
                    um = chunk.usage_metadata
                    usage_metadata = {
                        "prompt_tokens": getattr(um, 'prompt_token_count', 0),
                        "completion_tokens": getattr(um, 'candidates_token_count', 0),
                        "total_tokens": getattr(um, 'total_token_count', 0),
                        "thoughts_tokens": getattr(um, 'thoughts_token_count', 0) if hasattr(um, 'thoughts_token_count') else 0
                    }
                    logger.info(f"ğŸ“Š Gemini usage captured: {usage_metadata}")
                
                if hasattr(chunk, 'candidates') and chunk.candidates:
                    candidate = chunk.candidates[0]
                    logger.debug(f"ğŸ” Candidate has content: {hasattr(candidate, 'content')}")
                    
                    if hasattr(candidate, 'content') and candidate.content:
                        has_parts = hasattr(candidate.content, 'parts')
                        parts_count = len(candidate.content.parts) if has_parts and candidate.content.parts else 0
                        logger.debug(f"ğŸ” Content has {parts_count} parts")
                        
                        if not has_parts or not candidate.content.parts:
                            # ğŸ”§ ä¿®å¤ï¼šæœ€åä¸€ä¸ªchunkå¯èƒ½æ²¡æœ‰partsï¼Œè¿™æ˜¯æ­£å¸¸çš„
                            # å®ƒåªåŒ…å«metadataï¼ˆusageç­‰ï¼‰ï¼Œç»§ç»­ç­‰å¾…streamå®Œæˆ
                            logger.debug(f"â„¹ï¸  Chunk has no parts (likely final metadata chunk), skipping")
                            continue
                            
                        for part in candidate.content.parts:
                            # ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®åŒºåˆ†thinkingå’Œcontent
                            # Gemini API: å½“æœ‰thoughtå±æ€§æ—¶ï¼Œè¡¨ç¤ºè¿™æ˜¯thinkingéƒ¨åˆ†
                            has_thought_attr = hasattr(part, 'thought')
                            
                            # ğŸ”§ å…³é”®ä¿®å¤ï¼šå½“thought=Trueæ—¶ï¼Œè¡¨ç¤ºè¿™æ˜¯å¸¦thinkingçš„å¸¸è§„å†…å®¹
                            # åªæœ‰thoughtæ˜¯éç©ºå­—ç¬¦ä¸²æ—¶æ‰æ˜¯çº¯thinkingéƒ¨åˆ†
                            thought = getattr(part, 'thought', None)
                            text = getattr(part, 'text', None)
                            
                            # ğŸ” è°ƒè¯•æ—¥å¿—
                            logger.debug(f"ğŸ” Part - has_thought: {has_thought_attr}, thought type: {type(thought)}, thought value: {thought}, text preview: {text[:50] if text else None}")
                            
                            if isinstance(thought, str) and thought:
                                # thoughtæ˜¯éç©ºå­—ç¬¦ä¸²ï¼Œè¿™æ˜¯çº¯thinkingå†…å®¹
                                logger.info(f"ğŸ§  Thinking chunk: {len(thought)} chars, preview: {thought[:50]}")
                                thinking_accumulated.append(thought)
                                
                                # ğŸ”¥ æµå¼å‘é€ thinkingï¼ˆæ”¯æŒå®æ—¶æ˜¾ç¤ºï¼‰
                                import asyncio
                                chunk_size = 30
                                for i in range(0, len(thought), chunk_size):
                                    mini_chunk = thought[i:i+chunk_size]
                                    yield {
                                        "type": "thinking",
                                        "content": mini_chunk,  # ğŸ”§ ç»Ÿä¸€ä½¿ç”¨ "content"
                                        "accumulated": "".join(thinking_accumulated)
                                    }
                                    await asyncio.sleep(0.02)  # ğŸ†• æ‰“å­—æœºæ•ˆæœ
                            elif text:
                                # ğŸ” æ£€æŸ¥textæ˜¯å¦æ˜¯markdown thinkingï¼ˆä»¥**å¼€å¤´ï¼‰
                                if text.strip().startswith('**') and not text.strip().startswith('```'):
                                    # è¿™æ˜¯markdownæ ¼å¼çš„thinkingå†…å®¹
                                    logger.info(f"ğŸ§  Thinking chunk (from text): {len(text)} chars, preview: {text[:50]}")
                                    thinking_accumulated.append(text)
                                    
                                    # ğŸ”¥ æµå¼å‘é€ thinkingï¼ˆå¸¦å»¶è¿Ÿï¼‰
                                    import asyncio
                                    chunk_size = 30
                                    for i in range(0, len(text), chunk_size):
                                        mini_chunk = text[i:i+chunk_size]
                                        yield {
                                            "type": "thinking",
                                            "content": mini_chunk,  # ğŸ”§ ç»Ÿä¸€ä½¿ç”¨ "content"
                                            "accumulated": "".join(thinking_accumulated)
                                        }
                                        await asyncio.sleep(0.02)  # ğŸ†• æ‰“å­—æœºæ•ˆæœ
                                else:
                                    # æœ‰textå†…å®¹ï¼Œè¿™æ˜¯å®é™…è¾“å‡º
                                    logger.info(f"ğŸ“ Content chunk: {len(text)} chars, preview: {text[:50]}")
                                    content_accumulated.append(text)
                                    
                                    # ğŸ”¥ æµå¼å‘é€ contentï¼ˆå¸¦æ‰“å­—æœºå»¶è¿Ÿæ•ˆæœï¼‰
                                    import asyncio
                                    chunk_size = 30  # æ¯æ¬¡å‘é€çš„å­—ç¬¦æ•°
                                    for i in range(0, len(text), chunk_size):
                                        mini_chunk = text[i:i+chunk_size]
                                        yield {
                                            "type": "content",
                                            "content": mini_chunk,  # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ "content" è€Œä¸æ˜¯ "text"
                                            "accumulated": "".join(content_accumulated)
                                        }
                                        # ğŸ†• æ·»åŠ å°å»¶è¿Ÿå®ç°æ‰“å­—æœºæ•ˆæœ (çº¦ 30ms)
                                        await asyncio.sleep(0.03)
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿ done äº‹ä»¶ä¸€å®šä¼šå‘é€
            logger.info(f"ğŸ Stream loop completed, sending done event")
            logger.info(f"ğŸ“Š Final accumulated - thinking: {len(''.join(thinking_accumulated))} chars, content: {len(''.join(content_accumulated))} chars")
            
            # ğŸ†• å‘é€ usage äº‹ä»¶ï¼ˆä¸ Kimi æ ¼å¼ç»Ÿä¸€ï¼‰
            final_thinking = "".join(thinking_accumulated)
            final_content = "".join(content_accumulated)
            
            # ä½¿ç”¨å®é™…çš„ usage metadataï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå¦åˆ™ä» chars ä¼°ç®—
            if usage_metadata:
                yield {
                    "type": "usage",
                    "usage": {
                        "prompt_tokens": usage_metadata.get("prompt_tokens", 0),
                        "completion_tokens": usage_metadata.get("completion_tokens", 0),
                        "total_tokens": usage_metadata.get("total_tokens", 0),
                        "thinking_chars": len(final_thinking),
                        "content_chars": len(final_content),
                        "model": model,
                        "source": "api"  # æ ‡è®°ä¸º API ç²¾ç¡®æ•°æ®
                    }
                }
                logger.info(f"ğŸ“Š Token Usage (Gemini Stream - EXACT)")
                logger.info(f"   â€¢ Input:  {usage_metadata.get('prompt_tokens', 0):,} tokens")
                logger.info(f"   â€¢ Output: {usage_metadata.get('completion_tokens', 0):,} tokens")
                logger.info(f"   â€¢ Total:  {usage_metadata.get('total_tokens', 0):,} tokens")
            else:
                # Fallback: ä» chars ä¼°ç®— tokensï¼ˆä¸­æ–‡çº¦ 0.5 token/charï¼‰
                estimated_output = int((len(final_thinking) + len(final_content)) * 0.5)
                yield {
                    "type": "usage",
                    "usage": {
                        "prompt_tokens": 0,  # æ— æ³•ä¼°ç®—
                        "completion_tokens": estimated_output,
                        "total_tokens": estimated_output,
                        "thinking_chars": len(final_thinking),
                        "content_chars": len(final_content),
                        "model": model,
                        "source": "estimated"
                    }
                }
                logger.info(f"ğŸ“Š Token Usage (Gemini Stream - ESTIMATED from {len(final_content)} chars)")
                logger.info(f"   â€¢ Output: ~{estimated_output:,} tokens (estimated)")
            
            # å®Œæˆæ ‡è®°
            yield {
                "type": "done",
                "thinking": final_thinking,
                "content": final_content
            }
            
            logger.info(f"âœ… Streaming generation complete")
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ Streaming generation error: {e}")
            
            # æ£€æµ‹503é”™è¯¯ï¼ˆAPIè¿‡è½½ï¼‰
            if "503" in error_msg or "overloaded" in error_msg.lower():
                yield {
                    "type": "error",
                    "error": "AIæœåŠ¡æš‚æ—¶è¿‡è½½ï¼Œè¯·ç­‰å¾…å‡ ç§’åé‡è¯• (503 Service Overloaded)",
                    "code": 503
                }
            else:
                yield {
                    "type": "error",
                    "error": error_msg,
                    "code": 500
                }
    
    async def generate(
        self,
        prompt: str,
        model: str = "gemini-2.5-flash",  # ğŸ†• ä½¿ç”¨ 2.5 Flash æ”¯æŒæ€è€ƒæ¨¡å‹
        response_format: str = "text",
        max_tokens: int = 2000,
        temperature: float = 0.7,
        max_retries: int = 3,
        thinking_budget: Optional[int] = 1024,  # ğŸ†• æ€è€ƒé¢„ç®—ï¼Œé»˜è®¤ 1024 tokens
        return_thinking: bool = True,  # ğŸ†• æ˜¯å¦è¿”å›æ€è€ƒè¿‡ç¨‹
        file_uris: Optional[List[str]] = None  # ğŸ†• æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ï¼ˆå›¾ç‰‡/æ–‡æ¡£ URIï¼‰
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ–‡æœ¬å†…å®¹ï¼ˆå¼‚æ­¥ï¼‰- ğŸ†• æ”¯æŒæ€è€ƒæ¨¡å‹å’Œå¤šæ¨¡æ€è¾“å…¥
        
        Args:
            prompt: æç¤ºè¯
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ gemini-2.5-flash ï¼ˆ2.0 Flash Expï¼‰
            response_format: å“åº”æ ¼å¼ï¼Œ"text" æˆ– "json"
            max_tokens: æœ€å¤§ token æ•°
            temperature: æ¸©åº¦å‚æ•°ï¼ˆ0-1ï¼‰ï¼Œè¶Šé«˜è¶Šéšæœº
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            thinking_budget: æ€è€ƒé¢„ç®—ï¼ˆtokensï¼‰ï¼Œ0 = æ— æ€è€ƒï¼Œ1024 = ä¸­ç­‰ï¼Œæœ€å¤§ 24576
            return_thinking: æ˜¯å¦è¿”å›æ€è€ƒè¿‡ç¨‹
            file_uris: GCS æ–‡ä»¶ URI åˆ—è¡¨ï¼Œæ”¯æŒå›¾ç‰‡å’Œæ–‡æ¡£
        
        Returns:
            Dict[str, Any]: åŒ…å«ä»¥ä¸‹é”®ï¼š
                - "content": ç”Ÿæˆçš„æ–‡æœ¬æˆ– JSON å­—ç¬¦ä¸²
                - "thinking": æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
                - "usage": Token ä½¿ç”¨ç»Ÿè®¡
        
        Raises:
            Exception: API è°ƒç”¨å¤±è´¥
        """
        # å¦‚æœè¯·æ±‚ JSON æ ¼å¼ï¼Œåœ¨ prompt ä¸­æ˜ç¡®è¯´æ˜
        if response_format == "json":
            prompt = self._enhance_json_prompt(prompt)
        
        # é…ç½®ç”Ÿæˆå‚æ•°
        config_kwargs = {
            "temperature": temperature,
            "max_output_tokens": max_tokens,
        }
        
        # ğŸ†• æ€è€ƒé…ç½®ï¼šå½“ thinking_budget=0 æ—¶ç¦ç”¨æ€è€ƒæ¨¡å¼
        # è¿™å¯¹äºéœ€è¦æ›´å¤šè¾“å‡º tokens çš„åœºæ™¯å¾ˆé‡è¦ï¼ˆå¦‚å¤æ‚æ•°å­¦é¢˜è§£ç­”ï¼‰
        if "2.5" in model and thinking_budget is not None:
            try:
                if thinking_budget == 0:
                    # ç¦ç”¨æ€è€ƒæ¨¡å¼
                    config_kwargs["thinking_config"] = types.ThinkingConfig(
                        thinking_budget=0
                    )
                    logger.info(f"ğŸ§  Thinking disabled (budget=0)")
                elif thinking_budget > 0:
                    # å¯ç”¨æ€è€ƒæ¨¡å¼å¹¶è®¾ç½®é¢„ç®—
                    config_kwargs["thinking_config"] = types.ThinkingConfig(
                        thinking_budget=thinking_budget
                    )
                    logger.info(f"ğŸ§  Thinking enabled (budget={thinking_budget})")
            except Exception as e:
                logger.warning(f"âš ï¸ ThinkingConfig not supported in this SDK version: {e}")
        
        config = types.GenerateContentConfig(**config_kwargs)
        
        # ğŸ†• æ„å»ºå¤šæ¨¡æ€å†…å®¹ï¼ˆæ”¯æŒå›¾ç‰‡/æ–‡æ¡£ + æ–‡å­—ï¼‰
        contents = self._build_multimodal_contents(prompt, file_uris)
        
        # é‡è¯•é€»è¾‘
        for attempt in range(max_retries):
            try:
                if file_uris:
                    logger.info(f"ğŸ¤– Calling Gemini API: model={model}, tokens<={max_tokens}, files={len(file_uris)}")
                else:
                    logger.info(f"ğŸ¤– Calling Gemini API: model={model}, tokens<={max_tokens}")
                start_time = time.time()
                
                # ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯è°ƒç”¨ APIï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
                response = await self.async_client.models.generate_content(
                    model=model,
                    contents=contents,
                    config=config
                )
                
                # ğŸ†• æ”¹è¿›çš„å“åº”æ£€æŸ¥
                raw_text = getattr(response, 'text', None) or ""
                
                if not raw_text or not raw_text.strip():
                    # ğŸ†• ç©ºå“åº”æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ candidates
                    if hasattr(response, 'candidates') and response.candidates:
                        # å°è¯•ä» candidates æå–å†…å®¹
                        for candidate in response.candidates:
                            if hasattr(candidate, 'content') and candidate.content:
                                parts = getattr(candidate.content, 'parts', [])
                                for part in parts:
                                    if hasattr(part, 'text') and part.text:
                                        raw_text = part.text
                                        break
                    
                    if not raw_text or not raw_text.strip():
                        logger.warning(f"âš ï¸ Empty response from Gemini (attempt {attempt + 1}/{max_retries})")
                        if attempt < max_retries - 1:
                            time.sleep(2)
                            continue  # é‡è¯•
                        raise ValueError("Empty response from Gemini API after all retries")
                
                result = raw_text.strip()
                elapsed = time.time() - start_time
                
                # ğŸ†• æå–æ€è€ƒè¿‡ç¨‹
                thinking_process = None
                if return_thinking:
                    thinking_process = self._extract_thinking(response)
                
                # ============= Token ä½¿ç”¨ç»Ÿè®¡ =============
                usage_metadata = getattr(response, 'usage_metadata', None)
                usage_stats = {}
                
                if usage_metadata:
                    # ğŸ”§ ä½¿ç”¨ `or 0` ç¡®ä¿å€¼ä¸ä¸º Noneï¼ˆAPI æœ‰æ—¶è¿”å› None è€Œé 0ï¼‰
                    input_tokens = getattr(usage_metadata, 'prompt_token_count', 0) or 0
                    output_tokens = getattr(usage_metadata, 'candidates_token_count', 0) or 0
                    total_tokens = getattr(usage_metadata, 'total_token_count', 0) or 0
                    thoughts_tokens = getattr(usage_metadata, 'thoughts_token_count', 0) or 0  # ğŸ†• æ€è€ƒ tokens
                    
                    usage_stats = {
                        "input_tokens": input_tokens,
                        "output_tokens": output_tokens,
                        "thoughts_tokens": thoughts_tokens,
                        "total_tokens": total_tokens
                    }
                    
                    log_msg = (
                        f"ğŸ“Š Token Usage | Input: {input_tokens:,} | Output: {output_tokens:,}"
                    )
                    if thoughts_tokens > 0:
                        log_msg += f" | Thoughts: {thoughts_tokens:,} ğŸ§ "
                    log_msg += f" | Total: {total_tokens:,} | Time: {elapsed:.2f}s | Model: {model}"
                    
                    logger.info(log_msg)
                else:
                    logger.info(f"âœ… Gemini response received in {elapsed:.2f}s, length={len(result)}")
                
                # å¦‚æœæ˜¯ JSON æ ¼å¼ï¼Œå°è¯•è§£æéªŒè¯
                if response_format == "json":
                    # ğŸ†• å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºç©º
                    if not result or not result.strip():
                        logger.warning(f"âš ï¸ Empty result before JSON extraction (attempt {attempt + 1}/{max_retries})")
                        if attempt < max_retries - 1:
                            time.sleep(2)
                            continue  # é‡è¯•
                        raise ValueError("Empty response cannot be parsed as JSON")
                    
                    result = self._extract_json(result)
                    
                    # ğŸ†• æå–åå†æ¬¡æ£€æŸ¥
                    if not result or not result.strip():
                        logger.warning(f"âš ï¸ Empty result after JSON extraction (attempt {attempt + 1}/{max_retries})")
                        if attempt < max_retries - 1:
                            time.sleep(2)
                            continue  # é‡è¯•
                        raise ValueError("No valid JSON found in response")
                    
                    try:
                        # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆ JSON
                        json.loads(result)
                        # âœ… éªŒè¯æˆåŠŸï¼Œç»§ç»­åˆ°æœ€åè¿”å›å­—å…¸æ ¼å¼
                    except json.JSONDecodeError as json_err:
                        # JSONè§£æå¤±è´¥ï¼Œè®°å½•åŸå§‹å“åº”
                        logger.warning(f"âš ï¸ JSON parsing failed (attempt {attempt + 1}/{max_retries}): {json_err}")
                        logger.warning(f"ğŸ“ Raw response ({len(result)} chars): {repr(result[:100])}")
                        
                        # ğŸ”§ é¦–å…ˆå°è¯•ä¿®å¤ JSONï¼ˆå¤„ç†æ— æ•ˆè½¬ä¹‰å­—ç¬¦ç­‰é—®é¢˜ï¼‰
                        try:
                            fixed_result = self._try_fix_json(result)
                            json.loads(fixed_result)
                            logger.info(f"âœ… JSON auto-fixed successfully (invalid escape chars etc.)")
                            result = fixed_result
                            # ä¿®å¤æˆåŠŸï¼Œè·³è¿‡åç»­çš„åƒåœ¾å“åº”æ£€æµ‹
                        except Exception as fix_err:
                            logger.warning(f"âš ï¸ JSON fix attempt failed: {fix_err}")
                            
                            # ğŸ†• æ£€æµ‹åƒåœ¾å“åº”ï¼ˆæ›´å®½æ¾çš„æ£€æµ‹é€»è¾‘ï¼‰
                            is_garbage = (
                                len(result.strip()) < 15 or  # å¤ªçŸ­
                                result.strip().count('{') != result.strip().count('}')  # æ‹¬å·ä¸åŒ¹é…
                                # ç§»é™¤å­—æ®µæ£€æµ‹ï¼Œå› ä¸ºä¸åŒçš„ skill æœ‰ä¸åŒçš„å­—æ®µ
                            )
                            
                            if is_garbage:
                                logger.warning(f"ğŸ—‘ï¸ Detected garbage response (len={len(result)}), using fallback directly")
                                logger.debug(f"ğŸ“ Garbage content: {repr(result[:50])}")
                                
                                # ğŸ†• å¯¹äºåƒåœ¾å“åº”ï¼Œå®‰å…¨åœ°è¿”å› 'other' æ„å›¾
                                result = json.dumps({
                                    "intent": "other",
                                    "topic": None,
                                    "confidence": 0.70,
                                    "note": "Fallback due to garbage LLM response"
                                })
                                logger.info(f"âœ… Using fallback intent: other (garbage response)")
                                return {
                                    "content": result,
                                    "thinking": thinking_process if 'thinking_process' in dir() else None,
                                    "usage": usage_stats if 'usage_stats' in dir() else {}
                                }
                            
                            # ä¸æ˜¯åƒåœ¾å“åº”ï¼Œç»§ç»­é‡è¯•
                            if attempt < max_retries - 1:
                                time.sleep(2)
                                continue
                        
                        if attempt == max_retries - 1:
                            logger.warning(f"âš ï¸ Final attempt: trying to fix JSON...")
                            try:
                                fixed_result = self._try_fix_json(result)
                                json.loads(fixed_result)
                                logger.info(f"âœ… JSON auto-fixed successfully")
                                result = fixed_result
                            except Exception as fix_err:
                                logger.error(f"âŒ Failed to fix JSON: {fix_err}")
                                # ğŸ†• æœ€åä¸€æ‹›ï¼šè¿”å›ä¸€ä¸ªé»˜è®¤çš„ JSON ç»“æ„
                                logger.warning(f"âš ï¸ Returning fallback JSON response")
                                result = json.dumps({
                                    "intent": "other",
                                    "topic": None,
                                    "confidence": 0.70,  # ğŸ†• è¶³å¤Ÿé«˜çš„ç½®ä¿¡åº¦ï¼Œé¿å…è§¦å‘ clarification
                                    "error": "JSON parsing failed"
                                })
                        else:
                            time.sleep(2)
                            continue  # é‡è¯•
                
                # ğŸ†• è¿”å›å­—å…¸æ ¼å¼ï¼ˆåŒ…å«æ€è€ƒè¿‡ç¨‹ï¼‰
                return {
                    "content": result,
                    "thinking": thinking_process,
                    "usage": usage_stats
                }
                
            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸ JSON parsing failed (attempt {attempt + 1}/{max_retries}): {e}")
                logger.debug(f"Raw result (last 200 chars): ...{result[-200:]}")
                if attempt == max_retries - 1:
                    logger.error("âŒ Failed to parse JSON after all retries")
                    raise ValueError(f"Invalid JSON response: {str(e)}")
                time.sleep(2 * (attempt + 1))  # æŒ‡æ•°é€€é¿
                
            except Exception as e:
                logger.error(f"âŒ Gemini API error (attempt {attempt + 1}/{max_retries}): {type(e).__name__}: {e}")
                if attempt == max_retries - 1:
                    raise
                
                # æŒ‡æ•°é€€é¿
                wait_time = 2 ** attempt
                logger.info(f"â³ Retrying in {wait_time}s...")
                time.sleep(wait_time)
        
        raise Exception("Failed to generate content after all retries")
    
    def _download_file(self, uri: str) -> Optional[bytes]:
        """
        ğŸ†• ç»Ÿä¸€çš„æ–‡ä»¶ä¸‹è½½æ–¹æ³•ï¼ˆè‡ªåŠ¨è¯†åˆ« HTTP URL æˆ– GCS URIï¼‰
        
        Args:
            uri: æ–‡ä»¶ URL æˆ– GCS URI
        
        Returns:
            æ–‡ä»¶äºŒè¿›åˆ¶æ•°æ®æˆ– None
        """
        # æ£€æµ‹ URI ç±»å‹
        if uri.startswith(("http://", "https://")):
            # HTTP/HTTPS URLï¼ˆå¦‚ StudyX OSSï¼‰
            return self._download_from_url(uri)
        elif uri.startswith("gs://"):
            # GCS URI
            return self._download_file_from_gcs(uri)
        else:
            logger.warning(f"âš ï¸ Unknown URI scheme: {uri}")
            return None
    
    def _build_multimodal_contents(self, prompt: str, file_uris: Optional[List[str]] = None) -> Any:
        """
        ğŸ†• æ„å»ºå¤šæ¨¡æ€å†…å®¹ï¼ˆæ”¯æŒå›¾ç‰‡/æ–‡æ¡£ + æ–‡å­—ï¼‰
        
        æ”¯æŒçš„ URI ç±»å‹ï¼š
        - HTTP/HTTPS URL (å¦‚ https://media2.studyxapp.com/xxx.png)
        - GCS URI (å¦‚ gs://bucket/path/file.jpg)
        
        Args:
            prompt: æ–‡å­—æç¤º
            file_uris: æ–‡ä»¶ URL/URI åˆ—è¡¨
        
        Returns:
            å†…å®¹åˆ—è¡¨æˆ–çº¯æ–‡å­—
        """
        if not file_uris:
            return prompt
        
        # æ„å»ºå¤šæ¨¡æ€å†…å®¹
        parts = []
        
        for uri in file_uris:
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®š MIME ç±»å‹
            mime_type = self._get_mime_type(uri)
            
            if mime_type and mime_type.startswith("image/"):
                try:
                    # ğŸ†• ä½¿ç”¨ç»Ÿä¸€ä¸‹è½½æ–¹æ³•ï¼ˆè‡ªåŠ¨è¯†åˆ« HTTP æˆ– GCSï¼‰
                    image_data = self._download_file(uri)
                    if image_data:
                        # ä½¿ç”¨ PIL Image æˆ–ç›´æ¥ç”¨ bytes
                        part = types.Part.from_bytes(data=image_data, mime_type=mime_type)
                        parts.append(part)
                        logger.info(f"ğŸ“ Added image to multimodal content: {uri[:60]}... ({mime_type}, {len(image_data)} bytes)")
                    else:
                        logger.warning(f"âš ï¸ Failed to download image: {uri}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to add image {uri}: {e}")
            elif mime_type and mime_type == "application/pdf":
                # ğŸ†• æ”¯æŒ PDF æ–‡ä»¶
                try:
                    pdf_data = self._download_file(uri)
                    if pdf_data:
                        part = types.Part.from_bytes(data=pdf_data, mime_type=mime_type)
                        parts.append(part)
                        logger.info(f"ğŸ“ Added PDF to multimodal content: {uri[:60]}... ({mime_type}, {len(pdf_data)} bytes)")
                    else:
                        logger.warning(f"âš ï¸ Failed to download PDF: {uri}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to add PDF {uri}: {e}")
            elif mime_type and mime_type in ["text/plain", "application/msword", 
                                              "application/vnd.openxmlformats-officedocument.wordprocessingml.document"]:
                # ğŸ†• æ”¯æŒæ–‡æœ¬æ–‡ä»¶å’Œ Word æ–‡æ¡£
                try:
                    file_data = self._download_file(uri)  # ğŸ”§ ä½¿ç”¨ç»Ÿä¸€ä¸‹è½½æ–¹æ³•
                    if file_data:
                        # å¯¹äºæ–‡æœ¬æ–‡ä»¶ï¼Œå°è¯•è§£ç å¹¶ä½œä¸ºæ–‡æœ¬æ·»åŠ 
                        if mime_type == "text/plain":
                            try:
                                text_content = file_data.decode('utf-8')
                                parts.append(f"[æ–‡ä»¶å†…å®¹ - {uri.split('/')[-1]}]:\n{text_content}")
                                logger.info(f"ğŸ“ Added text file to content: {uri[:60]}... ({len(text_content)} chars)")
                            except:
                                part = types.Part.from_bytes(data=file_data, mime_type=mime_type)
                                parts.append(part)
                                logger.info(f"ğŸ“ Added text file as binary: {uri[:60]}...")
                        else:
                            # Word æ–‡æ¡£ä½œä¸ºäºŒè¿›åˆ¶å¤„ç†
                            part = types.Part.from_bytes(data=file_data, mime_type=mime_type)
                            parts.append(part)
                            logger.info(f"ğŸ“ Added document to multimodal content: {uri[:60]}... ({mime_type}, {len(file_data)} bytes)")
                    else:
                        logger.warning(f"âš ï¸ Failed to download file: {uri}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to add file {uri}: {e}")
            elif mime_type:
                # å…¶ä»–æ–‡ä»¶ç±»å‹ - å°è¯•é€šç”¨å¤„ç†
                try:
                    file_data = self._download_file(uri)  # ğŸ”§ ä½¿ç”¨ç»Ÿä¸€ä¸‹è½½æ–¹æ³•
                    if file_data:
                        part = types.Part.from_bytes(data=file_data, mime_type=mime_type)
                        parts.append(part)
                        logger.info(f"ğŸ“ Added file to multimodal content: {uri[:60]}... ({mime_type}, {len(file_data)} bytes)")
                    else:
                        logger.warning(f"âš ï¸ Failed to download file: {uri}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to add file {uri}: {e}")
            else:
                logger.warning(f"âš ï¸ Unsupported file type: {uri}")
        
        # æ·»åŠ æ–‡å­—æç¤º
        parts.append(prompt)
        
        return parts
    
    def _convert_gcs_to_https(self, gcs_uri: str) -> Optional[str]:
        """
        å°† GCS URI è½¬æ¢ä¸º HTTPS URL
        
        Args:
            gcs_uri: GCS URI (gs://studyx_test/temp/xxx/yyy.jpg)
        
        Returns:
            HTTPS URL (https://files.istudyx.com/temp/xxx/yyy.jpg)
        """
        if not gcs_uri.startswith("gs://"):
            return None
        
        # gs://studyx_test/temp/8c77f68a/xxx.jpg -> temp/8c77f68a/xxx.jpg
        path = gcs_uri[5:]  # å»æ‰ "gs://"
        parts = path.split("/", 1)
        if len(parts) < 2:
            return None
        
        bucket_name = parts[0]
        blob_path = parts[1]
        
        # ğŸ†• ç‰¹æ®Šå¤„ç† studyx_test bucket -> files.istudyx.com
        if bucket_name == "studyx_test":
            return f"https://files.istudyx.com/{blob_path}"
        
        # å…¶ä»– bucket ä½¿ç”¨ Google Cloud Storage å…¬å¼€ URL
        return f"https://storage.googleapis.com/{bucket_name}/{blob_path}"
    
    def _download_from_url(self, url: str) -> Optional[bytes]:
        """
        ğŸ†• ä» HTTP/HTTPS URL ä¸‹è½½æ–‡ä»¶ï¼ˆæ”¯æŒ StudyX OSS ç­‰å¤–éƒ¨ URLï¼‰
        
        Args:
            url: HTTP/HTTPS URL (å¦‚ https://media2.studyxapp.com/temp/xxx.png)
        
        Returns:
            æ–‡ä»¶äºŒè¿›åˆ¶æ•°æ®æˆ– None
        """
        import requests
        
        try:
            logger.info(f"ğŸ“¥ Downloading from HTTP URL: {url[:80]}...")
            response = requests.get(url, timeout=60, headers={
                "User-Agent": "Mozilla/5.0 (compatible; SkillAgent/1.0)"
            })
            if response.status_code == 200:
                file_data = response.content
                logger.info(f"âœ… Downloaded file from URL: {url[:50]}... ({len(file_data)} bytes)")
                return file_data
            else:
                logger.warning(f"âš ï¸ HTTP download failed ({response.status_code}): {url}")
                return None
        except Exception as e:
            logger.error(f"âŒ Failed to download from URL: {url}, error: {e}")
            return None
    
    def _download_file_from_gcs(self, gcs_uri: str) -> Optional[bytes]:
        """
        ä» GCS ä¸‹è½½æ–‡ä»¶ï¼ˆä¼˜å…ˆä½¿ç”¨ HTTPS URLï¼Œæ— éœ€è®¤è¯ï¼‰
        æ”¯æŒå›¾ç‰‡ã€PDFã€æ–‡æ¡£ç­‰å„ç§æ–‡ä»¶ç±»å‹
        
        Args:
            gcs_uri: GCS URI (gs://bucket/path/to/file)
        
        Returns:
            æ–‡ä»¶äºŒè¿›åˆ¶æ•°æ®æˆ– None
        """
        import requests
        
        try:
            # ğŸ†• ä¼˜å…ˆè½¬æ¢ä¸º HTTPS URL ä¸‹è½½ï¼ˆæ— éœ€ GCS è®¤è¯ï¼‰
            https_url = self._convert_gcs_to_https(gcs_uri)
            if https_url:
                logger.info(f"ğŸ”„ Converting GCS URI to HTTPS: {gcs_uri} -> {https_url}")
                response = requests.get(https_url, timeout=60)  # æ–‡ä»¶å¯èƒ½è¾ƒå¤§ï¼Œå¢åŠ è¶…æ—¶
                if response.status_code == 200:
                    file_data = response.content
                    logger.info(f"âœ… Downloaded file via HTTPS: {https_url} ({len(file_data)} bytes)")
                    return file_data
                else:
                    logger.warning(f"âš ï¸ HTTPS download failed ({response.status_code}), trying GCS client...")
            
            # Fallback: ä½¿ç”¨ GCS å®¢æˆ·ç«¯ï¼ˆéœ€è¦è®¤è¯ï¼‰
            from google.cloud import storage
            
            # è§£æ GCS URI
            if not gcs_uri.startswith("gs://"):
                logger.error(f"âŒ Invalid GCS URI: {gcs_uri}")
                return None
            
            path = gcs_uri[5:]  # å»æ‰ "gs://"
            parts = path.split("/", 1)
            if len(parts) < 2:
                logger.error(f"âŒ Invalid GCS path: {gcs_uri}")
                return None
            
            bucket_name = parts[0]
            blob_name = parts[1]
            
            # ä¸‹è½½æ–‡ä»¶
            client = storage.Client()
            bucket = client.bucket(bucket_name)
            blob = bucket.blob(blob_name)
            
            file_data = blob.download_as_bytes()
            logger.info(f"âœ… Downloaded file from GCS: {gcs_uri} ({len(file_data)} bytes)")
            return file_data
            
        except Exception as e:
            logger.error(f"âŒ Failed to download file: {gcs_uri}, error: {e}")
            return None
    
    def _download_gcs_image(self, gcs_uri: str) -> Optional[bytes]:
        """
        ä» GCS ä¸‹è½½å›¾ç‰‡ï¼ˆè°ƒç”¨é€šç”¨æ–‡ä»¶ä¸‹è½½æ–¹æ³•ï¼‰
        
        Args:
            gcs_uri: GCS URI (gs://bucket/path/to/image.jpg)
        
        Returns:
            å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®æˆ– None
        """
        return self._download_file_from_gcs(gcs_uri)
    
    def _get_mime_type(self, uri: str) -> Optional[str]:
        """
        æ ¹æ®æ–‡ä»¶ URI è·å– MIME ç±»å‹
        
        Args:
            uri: æ–‡ä»¶ URI
        
        Returns:
            MIME ç±»å‹æˆ– None
        """
        uri_lower = uri.lower()
        
        # å›¾ç‰‡ç±»å‹
        if uri_lower.endswith('.jpg') or uri_lower.endswith('.jpeg'):
            return "image/jpeg"
        elif uri_lower.endswith('.png'):
            return "image/png"
        elif uri_lower.endswith('.gif'):
            return "image/gif"
        elif uri_lower.endswith('.webp'):
            return "image/webp"
        
        # æ–‡æ¡£ç±»å‹
        elif uri_lower.endswith('.pdf'):
            return "application/pdf"
        elif uri_lower.endswith('.txt'):
            return "text/plain"
        
        # æœªçŸ¥ç±»å‹ - å°è¯•ä½œä¸ºæ–‡æœ¬å¤„ç†
        else:
            logger.warning(f"âš ï¸ Unknown file type for {uri}, treating as text/plain")
            return "text/plain"
    
    def _enhance_json_prompt(self, prompt: str) -> str:
        """
        å¢å¼º prompt ä»¥è·å¾— JSON æ ¼å¼è¾“å‡º
        
        Args:
            prompt: åŸå§‹ prompt
        
        Returns:
            str: å¢å¼ºåçš„ prompt
        """
        if "JSON" in prompt.upper() or "json" in prompt:
            # å·²ç»åŒ…å« JSON æŒ‡ç¤º
            return prompt
        
        return f"""{prompt}

IMPORTANT: You must respond with valid JSON only. Do not include any text before or after the JSON object.
Example format: {{"key": "value"}}

Your JSON response:"""
    
    def _try_fix_json(self, text: str) -> str:
        """
        å°è¯•ä¿®å¤å¸¸è§çš„ JSON é”™è¯¯ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        å¤„ç†çš„é”™è¯¯ç±»å‹ï¼š
        1. Markdown ä»£ç å—
        2. æ³¨é‡Š (// å’Œ /* */)
        3. å°¾éšé€—å·
        4. å•å¼•å·
        5. æœªç»ˆæ­¢çš„å­—ç¬¦ä¸² (Unterminated string)
        6. ä¸å®Œæ•´çš„ JSON
        7. ğŸ†• æ— æ•ˆçš„è½¬ä¹‰å­—ç¬¦ (Invalid \escape)
        """
        import re
        
        original_text = text  # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨äºè°ƒè¯•
        
        # ğŸ†• ä¿®å¤æ— æ•ˆçš„è½¬ä¹‰å­—ç¬¦ (Invalid \escape)
        # JSON åªå…è®¸: \", \\, \/, \b, \f, \n, \r, \t, \uXXXX
        # å…¶ä»–çš„ \x éœ€è¦è½¬æ¢ä¸º \\x æˆ–ç›´æ¥ç§»é™¤åæ–œæ 
        def fix_invalid_escapes(s):
            """ä¿®å¤ JSON å­—ç¬¦ä¸²ä¸­çš„æ— æ•ˆè½¬ä¹‰å­—ç¬¦"""
            result = []
            i = 0
            while i < len(s):
                if s[i] == '\\' and i + 1 < len(s):
                    next_char = s[i + 1]
                    # æœ‰æ•ˆçš„è½¬ä¹‰å­—ç¬¦
                    if next_char in '"\\\/bfnrt':
                        result.append(s[i:i+2])
                        i += 2
                    # Unicode è½¬ä¹‰
                    elif next_char == 'u' and i + 5 < len(s):
                        result.append(s[i:i+6])
                        i += 6
                    else:
                        # æ— æ•ˆçš„è½¬ä¹‰å­—ç¬¦ï¼Œç§»é™¤åæ–œæ æˆ–è½¬æ¢ä¸ºåŒåæ–œæ 
                        # ç›´æ¥ä¿ç•™åŸå­—ç¬¦ï¼Œç§»é™¤åæ–œæ 
                        result.append(next_char)
                        i += 2
                        logger.debug(f"ğŸ”§ Fixed invalid escape: \\{next_char} -> {next_char}")
                else:
                    result.append(s[i])
                    i += 1
            return ''.join(result)
        
        text = fix_invalid_escapes(text)
        
        # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—
        text = text.strip()
        if text.startswith("```json"):
            text = text[7:]
        if text.startswith("```"):
            text = text[3:]
        if text.endswith("```"):
            text = text[:-3]
        text = text.strip()
        
        # å°è¯•ç§»é™¤ JSON ä¸­çš„æ³¨é‡Šï¼ˆ// å’Œ /* */ï¼‰
        # ç§»é™¤å•è¡Œæ³¨é‡Š
        text = re.sub(r'//[^\n]*\n', '\n', text)
        # ç§»é™¤å¤šè¡Œæ³¨é‡Š
        text = re.sub(r'/\*.*?\*/', '', text, flags=re.DOTALL)
        
        # ç§»é™¤å°¾éšé€—å·ï¼ˆJSON ä¸­æœ€å¸¸è§çš„é”™è¯¯ï¼‰
        # 1. å¯¹è±¡ä¸­çš„å°¾éšé€—å·: , }
        text = re.sub(r',(\s*})', r'\1', text)
        # 2. æ•°ç»„ä¸­çš„å°¾éšé€—å·: , ]
        text = re.sub(r',(\s*\])', r'\1', text)
        
        # ä¿®å¤å•å¼•å·ä¸ºåŒå¼•å·ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        # ä½†è¦å°å¿ƒä¸è¦æ”¹å˜å­—ç¬¦ä¸²å†…éƒ¨çš„å•å¼•å·
        # ç®€å•ç­–ç•¥ï¼šåªæ›¿æ¢é”®åçš„å•å¼•å·
        text = re.sub(r"'([^']*)'(\s*):", r'"\1"\2:', text)
        
        # ğŸ†• å¤„ç† Unterminated string é”™è¯¯
        # å¸¸è§æƒ…å†µï¼šJSON è¢«æˆªæ–­ï¼Œå­—ç¬¦ä¸²æ²¡æœ‰ç»“æŸå¼•å·
        # å°è¯•åœ¨åˆé€‚çš„ä½ç½®è¡¥å……å¼•å·å’Œæ‹¬å·
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªé—­åˆçš„å­—ç¬¦ä¸²
        in_string = False
        escape_next = False
        last_quote_pos = -1
        
        for i, char in enumerate(text):
            if escape_next:
                escape_next = False
                continue
            if char == '\\':
                escape_next = True
                continue
            if char == '"':
                in_string = not in_string
                if in_string:
                    last_quote_pos = i
        
        # å¦‚æœå­—ç¬¦ä¸²æœªé—­åˆï¼Œå°è¯•ä¿®å¤
        if in_string and last_quote_pos >= 0:
            # æ‰¾åˆ°æœ€åä¸€ä¸ªæœ‰æ•ˆçš„ä½ç½®ï¼ˆéè½¬ä¹‰å­—ç¬¦ï¼‰
            # åœ¨å­—ç¬¦ä¸²æœ«å°¾æ·»åŠ å¼•å·
            text = text.rstrip()
            # ç§»é™¤æœ«å°¾å¯èƒ½çš„ä¸å®Œæ•´è½¬ä¹‰å­—ç¬¦
            while text.endswith('\\'):
                text = text[:-1]
            text += '"'
            logger.debug(f"ğŸ”§ Fixed unterminated string by adding closing quote")
        
        # å°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡æˆ–æ•°ç»„
        # ä»åå¾€å‰æ‰¾æœ€åä¸€ä¸ª } æˆ– ]
        last_brace = text.rfind('}')
        last_bracket = text.rfind(']')
        
        if last_brace > last_bracket:
            # å¯¹è±¡
            text = text[:last_brace + 1]
        elif last_bracket > last_brace:
            # æ•°ç»„
            text = text[:last_bracket + 1]
        else:
            # ğŸ†• æ²¡æœ‰æ‰¾åˆ°å®Œæ•´çš„æ‹¬å·ï¼Œå°è¯•è¡¥å……
            # æ£€æŸ¥å¼€å§‹æ˜¯å¯¹è±¡è¿˜æ˜¯æ•°ç»„
            first_brace = text.find('{')
            first_bracket = text.find('[')
            
            if first_brace >= 0 and (first_bracket < 0 or first_brace < first_bracket):
                # æ˜¯å¯¹è±¡ï¼Œè®¡ç®—éœ€è¦è¡¥å……çš„ }
                open_count = text.count('{') - text.count('}')
                if open_count > 0:
                    text += '}' * open_count
                    logger.debug(f"ğŸ”§ Added {open_count} closing braces")
            elif first_bracket >= 0:
                # æ˜¯æ•°ç»„ï¼Œè®¡ç®—éœ€è¦è¡¥å……çš„ ]
                open_count = text.count('[') - text.count(']')
                if open_count > 0:
                    text += ']' * open_count
                    logger.debug(f"ğŸ”§ Added {open_count} closing brackets")
        
        # ğŸ†• ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœæ–‡æœ¬éå¸¸çŸ­ä¸”åƒæ˜¯è¢«æˆªæ–­çš„ intent å“åº”
        # ç›´æ¥æ„é€ ä¸€ä¸ªé»˜è®¤å“åº”
        if len(text) < 20 and '{' not in text:
            logger.warning(f"âš ï¸ Text too short to be valid JSON: {text[:50]}")
            # å°è¯•ä»åŸå§‹æ–‡æœ¬ä¸­æå–å¯èƒ½çš„ intent å…³é”®è¯
            text_lower = original_text.lower()
            if 'quiz' in text_lower or 'é¢˜' in original_text:
                return '{"intent": "quiz_request", "topic": null, "confidence": 0.6}'
            elif 'flashcard' in text_lower or 'é—ªå¡' in original_text or 'å¡ç‰‡' in original_text:
                return '{"intent": "flashcard_request", "topic": null, "confidence": 0.6}'
            elif 'explain' in text_lower or 'è®²è§£' in original_text or 'è§£é‡Š' in original_text:
                return '{"intent": "explain_request", "topic": null, "confidence": 0.6}'
            else:
                return '{"intent": "other", "topic": null, "confidence": 0.5}'
        
        return text
    
    def _extract_json(self, text: str) -> str:
        """
        ä»æ–‡æœ¬ä¸­æå– JSON å†…å®¹ï¼ˆæ”¹è¿›ç‰ˆï¼Œå¤„ç†å¤šä½™å†…å®¹ï¼‰
        
        Args:
            text: å¯èƒ½åŒ…å« JSON çš„æ–‡æœ¬
        
        Returns:
            str: æå–çš„ JSON å­—ç¬¦ä¸²
        """
        text = text.strip()
        
        # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
        if text.startswith("```json"):
            text = text[7:]
        if text.startswith("```"):
            text = text[3:]
        if text.endswith("```"):
            text = text[:-3]
        
        text = text.strip()
        
        # å°è¯•æ‰¾åˆ°å®Œæ•´çš„ JSON å¯¹è±¡æˆ–æ•°ç»„
        # ä½¿ç”¨ç®€å•çš„æ‹¬å·åŒ¹é…æ¥æ‰¾åˆ°å®Œæ•´çš„ JSON
        
        # ä¼˜å…ˆæ£€æŸ¥å¯¹è±¡
        if "{" in text:
            start = text.find("{")
            depth = 0
            in_string = False
            escape_next = False
            
            for i in range(start, len(text)):
                char = text[i]
                
                # å¤„ç†å­—ç¬¦ä¸²ä¸­çš„å¼•å·
                if char == '"' and not escape_next:
                    in_string = not in_string
                elif char == '\\' and not escape_next:
                    escape_next = True
                    continue
                
                if not in_string:
                    if char == '{':
                        depth += 1
                    elif char == '}':
                        depth -= 1
                        if depth == 0:
                            # æ‰¾åˆ°å®Œæ•´çš„ JSON å¯¹è±¡
                            return text[start:i+1]
                
                escape_next = False
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹è±¡ï¼Œæ£€æŸ¥æ•°ç»„
        if "[" in text:
            start = text.find("[")
            depth = 0
            in_string = False
            escape_next = False
            
            for i in range(start, len(text)):
                char = text[i]
                
                if char == '"' and not escape_next:
                    in_string = not in_string
                elif char == '\\' and not escape_next:
                    escape_next = True
                    continue
                
                if not in_string:
                    if char == '[':
                        depth += 1
                    elif char == ']':
                        depth -= 1
                        if depth == 0:
                            # æ‰¾åˆ°å®Œæ•´çš„ JSON æ•°ç»„
                            return text[start:i+1]
                
                escape_next = False
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸå§‹æ–‡æœ¬
        return text
    
    async def generate_json(
        self,
        prompt: str,
        model: str = "gemini-2.5-flash",
        max_tokens: int = 2000,
        temperature: float = 0.7,
        max_retries: int = 3
    ) -> str:
        """
        ç”Ÿæˆ JSON æ ¼å¼å†…å®¹ï¼ˆå¿«æ·æ–¹æ³•ï¼‰
        
        Args:
            prompt: æç¤ºè¯
            model: æ¨¡å‹åç§°
            max_tokens: æœ€å¤§ token æ•°
            temperature: æ¸©åº¦å‚æ•°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        
        Returns:
            str: JSON å­—ç¬¦ä¸²
        """
        return await self.generate(
            prompt=prompt,
            model=model,
            response_format="json",
            max_tokens=max_tokens,
            temperature=temperature,
            max_retries=max_retries
        )
    
    async def generate_batch(
        self,
        prompts: List[str],
        model: str = "gemini-2.5-flash",
        **kwargs
    ) -> List[str]:
        """
        æ‰¹é‡ç”Ÿæˆï¼ˆä¸²è¡Œæ‰§è¡Œï¼‰
        
        Args:
            prompts: prompt åˆ—è¡¨
            model: æ¨¡å‹åç§°
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            List[str]: ç”Ÿæˆç»“æœåˆ—è¡¨
        """
        results = []
        for i, prompt in enumerate(prompts):
            logger.info(f"ğŸ“ Processing batch {i + 1}/{len(prompts)}")
            result = await self.generate(prompt, model=model, **kwargs)
            results.append(result)
        
        return results
    
    def get_model_info(self, model_name: str = "gemini-2.5-flash") -> Dict[str, Any]:
        """
        è·å–æ¨¡å‹ä¿¡æ¯
        
        Args:
            model_name: æ¨¡å‹åç§°
        
        Returns:
            Dict: æ¨¡å‹ä¿¡æ¯
        """
        try:
            # ä½¿ç”¨æ–° SDK çš„æ–¹å¼
            return {
                "name": model_name,
                "status": "available",
                "note": "Using new google.genai SDK"
            }
        except Exception as e:
            logger.error(f"âŒ Failed to get model info: {e}")
            return {"error": str(e)}
    
    def _extract_thinking(self, response) -> Optional[str]:
        """
        ä» Gemini å“åº”ä¸­æå–æ€è€ƒè¿‡ç¨‹
        
        Args:
            response: Gemini API å“åº”å¯¹è±¡
        
        Returns:
            Optional[str]: æ€è€ƒè¿‡ç¨‹æ–‡æœ¬ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å› None
        """
        try:
            # å°è¯•ä»å“åº”ä¸­æå– candidates
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                
                # æ£€æŸ¥ content.parts
                if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                    for part in candidate.content.parts:
                        # æŸ¥æ‰¾ thought å±æ€§ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å¸ƒå°”ï¼‰
                        if hasattr(part, 'thought'):
                            thought = part.thought
                            # æ£€æŸ¥æ˜¯å¦ä¸ºå­—ç¬¦ä¸²ç±»å‹
                            if isinstance(thought, str) and thought:
                                logger.info(f"ğŸ§  Thinking process found: {len(thought)} chars")
                                return thought
                            # å¦‚æœæ˜¯å¸ƒå°”å€¼ Trueï¼ŒæŸ¥æ‰¾ text
                            elif thought is True and hasattr(part, 'text'):
                                text = part.text
                                if text:
                                    logger.info(f"ğŸ§  Thinking process found (via text): {len(text)} chars")
                                    return text
                        
                        # å¤‡é€‰æ–¹æ¡ˆï¼šæ£€æŸ¥ part çš„å…¶ä»–å±æ€§
                        if hasattr(part, 'text') and part.text:
                            # å¦‚æœ text åŒ…å«æ€è€ƒæ ‡è®°
                            text = part.text
                            if text.startswith("<thinking>") or text.startswith("æ€è€ƒè¿‡ç¨‹:"):
                                logger.info(f"ğŸ§  Thinking process found in text: {len(text)} chars")
                                return text
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å› None
            logger.debug("â„¹ï¸  No thinking process found in response")
            return None
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to extract thinking process: {e}")
            return None
    
    async def close(self):
        """å…³é—­å¼‚æ­¥å®¢æˆ·ç«¯"""
        try:
            if hasattr(self, 'async_client') and hasattr(self.async_client, 'aclose'):
                await self.async_client.aclose()
                logger.info("âœ… Async client closed")
            else:
                logger.info("â„¹ï¸  Async client does not require explicit close")
        except Exception as e:
            logger.warning(f"âš ï¸ Error closing async client: {e}")
