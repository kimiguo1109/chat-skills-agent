"""
Plan Skill Executor - è®¡åˆ’æŠ€èƒ½æ‰§è¡Œå™¨

è´Ÿè´£æ‰§è¡Œ Plan Skill çš„ä¸²è”è°ƒç”¨é€»è¾‘ï¼š
1. è§£ææ‰§è¡Œè®¡åˆ’
2. ä¸²è”è°ƒç”¨å¤šä¸ª skills
3. ç®¡ç†ä¸Šä¸‹æ–‡ä¼ é€’
4. èšåˆæœ€ç»ˆç»“æœ
"""
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
import json

logger = logging.getLogger(__name__)


class PlanSkillExecutor:
    """
    Plan Skill æ‰§è¡Œå™¨
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    - ä¸²è”æ‰§è¡Œå¤šä¸ª skills
    - ä¸Šä¸‹æ–‡æå–å’Œæ³¨å…¥
    - Token æˆæœ¬æ§åˆ¶
    - é”™è¯¯å¤„ç†å’Œå›é€€
    """
    
    def __init__(self, skill_orchestrator):
        """
        åˆå§‹åŒ– Plan Skill æ‰§è¡Œå™¨
        
        Args:
            skill_orchestrator: SkillOrchestrator å®ä¾‹ï¼ˆç”¨äºè°ƒç”¨å­ skillsï¼‰
        """
        self.skill_orchestrator = skill_orchestrator
        self.execution_log = []
        self.token_usage = {
            "total": 0,
            "per_step": {}
        }
    
    async def execute_plan(
        self,
        plan_config: Dict[str, Any],
        user_input: Dict[str, Any],
        user_profile: Any,
        session_context: Any
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„ Plan
        
        Args:
            plan_config: Plan Skill çš„ YAML é…ç½®
            user_input: ç”¨æˆ·è¾“å…¥å‚æ•°
            user_profile: ç”¨æˆ·å­¦ä¹ ç”»åƒ
            session_context: ä¼šè¯ä¸Šä¸‹æ–‡
        
        Returns:
            èšåˆåçš„å­¦ä¹ åŒ…
        """
        execution_plan = plan_config["execution_plan"]
        steps = execution_plan["steps"]
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ¯ å¼€å§‹æ‰§è¡Œ Plan Skill: {plan_config['display_name']}")
        logger.info(f"ğŸ“‹ æ€»æ­¥éª¤æ•°: {len(steps)}")
        logger.info(f"ğŸ“ ä¸»é¢˜: {user_input.get('topic', 'Unknown')}")
        logger.info(f"{'='*60}\n")
        
        # æ‰§è¡Œç»“æœå­˜å‚¨
        step_results = {}
        step_contexts = {}  # å­˜å‚¨æ¯ä¸ª step æå–çš„ä¸Šä¸‹æ–‡
        
        # ä¸²è”æ‰§è¡Œæ‰€æœ‰ steps
        for step in steps:
            step_id = step["step_id"]
            step_name = step["display_name"]
            skill_id = step["skill_id"]
            
            logger.info(f"\n{'â”€'*60}")
            logger.info(f"ğŸ“ Step {step['order']}: {step_name}")
            logger.info(f"ğŸ”§ Skill: {skill_id}")
            logger.info(f"ğŸ“¦ ä¾èµ–: {step['depends_on'] or 'æ— '}")
            
            try:
                # 1. æ„å»º step è¾“å…¥
                step_input = self._build_step_input(
                    step=step,
                    user_input=user_input,
                    step_contexts=step_contexts
                )
                logger.info(f"âœ… è¾“å…¥å‚æ•°æ„å»ºå®Œæˆ")
                
                # 2. æ‰§è¡Œ skill
                result = await self._execute_step(
                    skill_id=skill_id,
                    input_params=step_input,
                    user_profile=user_profile,
                    session_context=session_context
                )
                logger.info(f"âœ… Skill æ‰§è¡ŒæˆåŠŸ")
                
                # 3. æå–ä¸Šä¸‹æ–‡ï¼ˆç”¨äºä¸‹æ¸¸ stepsï¼‰
                extracted_context = self._extract_context(
                    result=result,
                    extraction_config=step.get("context_extraction", {})
                )
                
                # 4. å­˜å‚¨ç»“æœ
                step_results[step_id] = result
                step_contexts[step_id] = extracted_context
                
                # 5. Token ç»Ÿè®¡
                tokens_used = self._estimate_tokens(result)
                self.token_usage["per_step"][step_id] = tokens_used
                self.token_usage["total"] += tokens_used
                
                logger.info(f"ğŸ’¾ ä¸Šä¸‹æ–‡æå–: {len(str(extracted_context))} å­—ç¬¦")
                logger.info(f"ğŸ’° Token æ¶ˆè€—: ~{tokens_used}")
                logger.info(f"ğŸ“Š ç´¯è®¡ Token: ~{self.token_usage['total']}")
                logger.info(f"âœ… Step {step_id} å®Œæˆ")
                
            except Exception as e:
                logger.error(f"âŒ Step {step_id} å¤±è´¥: {e}")
                logger.exception(e)
                
                # é”™è¯¯å¤„ç†
                error_config = plan_config.get("error_handling", {})
                strategy = error_config.get("on_step_failure", {}).get("strategy", "skip_and_continue")
                
                if strategy == "skip_and_continue":
                    logger.info(f"â­ï¸  è·³è¿‡ Step {step_id}ï¼Œç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥")
                    continue
                elif strategy == "abort":
                    logger.error(f"ğŸš« Plan æ‰§è¡Œä¸­æ­¢")
                    raise
                else:
                    # é»˜è®¤ï¼šè·³è¿‡
                    logger.info(f"â­ï¸  è·³è¿‡ Step {step_id}ï¼Œç»§ç»­æ‰§è¡Œ")
                    continue
        
        logger.info(f"\n{'â”€'*60}")
        logger.info(f"ğŸ“¦ æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæˆ")
        logger.info(f"âœ… æˆåŠŸ: {len(step_results)}/{len(steps)} ä¸ªæ­¥éª¤")
        logger.info(f"ğŸ’° æ€» Token æ¶ˆè€—: ~{self.token_usage['total']}")
        
        # æ£€æŸ¥æœ€å°æˆåŠŸæ­¥éª¤æ•°
        min_required = plan_config.get("error_handling", {}).get("min_required_steps", 1)
        if len(step_results) < min_required:
            error_msg = plan_config.get("error_handling", {}).get("fallback", {}).get("on_total_failure", {}).get("message", "å­¦ä¹ åŒ…ç”Ÿæˆå¤±è´¥")
            logger.error(f"âŒ æˆåŠŸæ­¥éª¤ä¸è¶³: {len(step_results)} < {min_required}")
            raise Exception(error_msg)
        
        # èšåˆç»“æœ
        bundle = self._aggregate_results(
            step_results=step_results,
            aggregation_config=plan_config["aggregation"],
            user_input=user_input
        )
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸŠ Plan Skill æ‰§è¡Œå®Œæˆï¼")
        logger.info(f"ğŸ“¦ å­¦ä¹ åŒ… ID: {bundle.get('bundle_id')}")
        logger.info(f"ğŸ“š åŒ…å«ç»„ä»¶: {len(bundle.get('components', []))}")
        logger.info(f"â±ï¸  é¢„è®¡å­¦ä¹ æ—¶é—´: {bundle.get('estimated_time_minutes')} åˆ†é’Ÿ")
        logger.info(f"{'='*60}\n")
        
        return bundle
    
    async def execute_plan_stream(
        self,
        plan_config: Dict[str, Any],
        user_input: Dict[str, Any],
        user_profile: Any,
        session_context: Any
    ):
        """
        ğŸ†• æµå¼æ‰§è¡Œå®Œæ•´çš„ Planï¼ˆå®æ—¶å±•ç¤ºæ¯ä¸ªæ­¥éª¤çš„thinkingå’Œè¿›åº¦ï¼‰
        
        Args:
            plan_config: Plan Skill çš„ YAML é…ç½®
            user_input: ç”¨æˆ·è¾“å…¥å‚æ•°
            user_profile: ç”¨æˆ·å­¦ä¹ ç”»åƒ
            session_context: ä¼šè¯ä¸Šä¸‹æ–‡
        
        Yields:
            Dict: æµå¼äº‹ä»¶ {"type": "plan_progress|thinking|content|step_done|done", ...}
        """
        execution_plan = plan_config["execution_plan"]
        steps = execution_plan["steps"]
        total_steps = len(steps)
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸŒŠ å¼€å§‹æµå¼æ‰§è¡Œ Plan Skill: {plan_config['display_name']}")
        logger.info(f"ğŸ“‹ æ€»æ­¥éª¤æ•°: {total_steps}")
        logger.info(f"ğŸ“ ä¸»é¢˜: {user_input.get('topic', 'Unknown')}")
        logger.info(f"{'='*60}\n")
        
        # ğŸ†• å‡†å¤‡æ­¥éª¤é¢„è§ˆä¿¡æ¯
        steps_preview = []
        for idx, step in enumerate(steps, 1):
            steps_preview.append({
                "step_order": idx,
                "step_name": step.get("name", f"æ­¥éª¤ {idx}"),
                "step_description": step.get("description", ""),
                "skill_id": step["skill_id"]
            })
        
        # å‘é€Planå¼€å§‹çŠ¶æ€ï¼ˆåŒ…å«æ­¥éª¤é¢„è§ˆï¼‰
        yield {
            "type": "plan_start",
            "total_steps": total_steps,
            "topic": user_input.get('topic'),
            "subject": user_input.get('subject'),
            "steps_preview": steps_preview  # ğŸ†• å®Œæ•´æ­¥éª¤åˆ—è¡¨
        }
        
        # æ‰§è¡Œç»“æœå­˜å‚¨
        step_results = {}
        step_contexts = {}
        
        # ä¸²è”æ‰§è¡Œæ‰€æœ‰ stepsï¼ˆæµå¼ï¼‰
        for step in steps:
            step_id = step["step_id"]
            step_name = step["display_name"]
            skill_id = step["skill_id"]
            step_order = step["order"]
            
            logger.info(f"\n{'â”€'*60}")
            logger.info(f"ğŸ“ Step {step_order}/{total_steps}: {step_name}")
            logger.info(f"ğŸ”§ Skill: {skill_id}")
            
            # ğŸ†• å‘é€æ­¥éª¤å¼€å§‹çŠ¶æ€
            yield {
                "type": "step_start",
                "step_order": step_order,
                "total_steps": total_steps,
                "step_name": step_name,
                "skill_id": skill_id
            }
            
            try:
                # 1. æ„å»º step è¾“å…¥
                step_input = self._build_step_input(
                    step=step,
                    user_input=user_input,
                    step_contexts=step_contexts
                )
                logger.info(f"âœ… è¾“å…¥å‚æ•°æ„å»ºå®Œæˆ")
                
                # 2. ğŸ†• æµå¼æ‰§è¡Œ skill
                async for chunk in self._execute_step_stream(
                    skill_id=skill_id,
                    input_params=step_input,
                    user_profile=user_profile,
                    session_context=session_context,
                    step_info={
                        "step_order": step_order,
                        "total_steps": total_steps,
                        "step_name": step_name
                    }
                ):
                    # è½¬å‘thinkingå’Œcontent chunks
                    if chunk["type"] in ["thinking", "content"]:
                        yield chunk
                    elif chunk["type"] == "done":
                        # Stepå®Œæˆï¼Œä¿å­˜ç»“æœ
                        result = chunk.get("data", {})
                        step_results[step_id] = result
                        
                        # 3. æå–ä¸Šä¸‹æ–‡
                        extracted_context = self._extract_context(
                            result=result,
                            extraction_config=step.get("context_extraction", {})
                        )
                        step_contexts[step_id] = extracted_context
                        
                        # 4. ğŸ†• è¯¦ç»†Tokenç»Ÿè®¡
                        tokens_used = self._estimate_tokens(result)
                        
                        # å°è¯•ä»resultè·å–å®é™…çš„usageä¿¡æ¯
                        actual_usage = result.get("_usage", {})
                        
                        # æ„å»ºè¯¦ç»†çš„tokenç»Ÿè®¡
                        step_token_info = {
                            "estimated_tokens": tokens_used,
                            "actual_usage": actual_usage,
                            "step_name": step_name,
                            "skill_id": skill_id
                        }
                        
                        self.token_usage["per_step"][step_id] = step_token_info
                        self.token_usage["total"] += tokens_used
                        
                        # ğŸ†• è¯¦ç»†æ—¥å¿—è¾“å‡º
                        logger.info(f"")
                        logger.info(f"{'â”€'*60}")
                        logger.info(f"âœ… Step {step_order}/{total_steps} å®Œæˆ: {step_name}")
                        logger.info(f"{'â”€'*60}")
                        
                        if actual_usage:
                            logger.info(f"ğŸ’° Tokenæ¶ˆè€—è¯¦æƒ…:")
                            logger.info(f"   â”œâ”€ Prompt Tokens:     {actual_usage.get('prompt_tokens', 'N/A')}")
                            logger.info(f"   â”œâ”€ Completion Tokens: {actual_usage.get('completion_tokens', 'N/A')}")
                            logger.info(f"   â”œâ”€ Total Tokens:      {actual_usage.get('total_tokens', 'N/A')}")
                            if "reasoning_tokens" in actual_usage and actual_usage.get("reasoning_tokens", 0) > 0:
                                logger.info(f"   â””â”€ Reasoning Tokens:  {actual_usage.get('reasoning_tokens', 0)}")
                        else:
                            logger.info(f"ğŸ’° Tokenæ¶ˆè€—ä¼°ç®—: ~{tokens_used} tokens")
                        
                        logger.info(f"ğŸ“Š ç´¯è®¡Tokenæ¶ˆè€—: ~{self.token_usage['total']} tokens")
                        logger.info(f"{'â”€'*60}")
                        
                        # ğŸ†• å‘é€æ­¥éª¤å®ŒæˆçŠ¶æ€ï¼ˆåŒ…å«resultç”¨äºå‰ç«¯å³æ—¶æ˜¾ç¤ºï¼‰
                        yield {
                            "type": "step_done",
                            "step_order": step_order,
                            "total_steps": total_steps,
                            "step_name": step_name,
                            "skill_id": skill_id,
                            "tokens_used": tokens_used,
                            "result": result  # ğŸ†• åŒ…å«å®Œæ•´ç»“æœä¾›å‰ç«¯æ¸²æŸ“
                        }
                    elif chunk["type"] == "error":
                        # Stepå¤±è´¥
                        raise Exception(chunk.get("message", "Step execution failed"))
                
            except Exception as e:
                logger.error(f"âŒ Step {step_id} å¤±è´¥: {e}")
                logger.exception(e)
                
                # é”™è¯¯å¤„ç†
                error_config = plan_config.get("error_handling", {})
                strategy = error_config.get("on_step_failure", {}).get("strategy", "skip_and_continue")
                
                # ğŸ†• å‘é€æ­¥éª¤é”™è¯¯çŠ¶æ€
                yield {
                    "type": "step_error",
                    "step_order": step_order,
                    "step_name": step_name,
                    "error": str(e),
                    "strategy": strategy
                }
                
                if strategy == "skip_and_continue":
                    logger.info(f"â­ï¸  è·³è¿‡ Step {step_id}ï¼Œç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥")
                    continue
                elif strategy == "abort":
                    logger.error(f"ğŸš« Plan æ‰§è¡Œä¸­æ­¢")
                    yield {
                        "type": "error",
                        "message": f"Planæ‰§è¡Œä¸­æ­¢äºStep {step_order}: {str(e)}"
                    }
                    return
        
        # ğŸ†• ç”Ÿæˆè¯¦ç»†çš„Tokenç»Ÿè®¡æŠ¥å‘Š
        logger.info(f"\n{'â”'*60}")
        logger.info(f"ğŸ“¦ Plan Skill æ‰§è¡Œå®Œæˆç»Ÿè®¡")
        logger.info(f"{'â”'*60}")
        logger.info(f"âœ… æˆåŠŸæ­¥éª¤: {len(step_results)}/{total_steps}")
        logger.info(f"")
        logger.info(f"ğŸ’° Tokenæ¶ˆè€—è¯¦æƒ…:")
        logger.info(f"{'â”€'*60}")
        
        total_prompt_tokens = 0
        total_completion_tokens = 0
        total_reasoning_tokens = 0
        
        for step_id, token_info in self.token_usage["per_step"].items():
            step_name = token_info.get("step_name", step_id)
            actual_usage = token_info.get("actual_usage", {})
            
            logger.info(f"")
            logger.info(f"ğŸ“ {step_name} ({token_info.get('skill_id', 'unknown')})")
            
            if actual_usage:
                prompt_t = actual_usage.get('prompt_tokens', 0)
                completion_t = actual_usage.get('completion_tokens', 0)
                reasoning_t = actual_usage.get('reasoning_tokens', 0)
                total_t = actual_usage.get('total_tokens', 0)
                
                total_prompt_tokens += prompt_t
                total_completion_tokens += completion_t
                total_reasoning_tokens += reasoning_t
                
                logger.info(f"   â”œâ”€ Prompt:     {prompt_t:>6} tokens")
                logger.info(f"   â”œâ”€ Completion: {completion_t:>6} tokens")
                if reasoning_t > 0:
                    logger.info(f"   â”œâ”€ Reasoning:  {reasoning_t:>6} tokens")
                logger.info(f"   â””â”€ Total:      {total_t:>6} tokens")
            else:
                estimated = token_info.get("estimated_tokens", 0)
                logger.info(f"   â””â”€ ä¼°ç®—:       ~{estimated:>6} tokens")
        
        logger.info(f"")
        logger.info(f"{'â”€'*60}")
        logger.info(f"ğŸ“Š æ€»è®¡:")
        
        if total_prompt_tokens > 0 or total_completion_tokens > 0:
            logger.info(f"   â”œâ”€ Prompt Tokens:     {total_prompt_tokens:>8}")
            logger.info(f"   â”œâ”€ Completion Tokens: {total_completion_tokens:>8}")
            if total_reasoning_tokens > 0:
                logger.info(f"   â”œâ”€ Reasoning Tokens:  {total_reasoning_tokens:>8}")
            logger.info(f"   â””â”€ Total Tokens:      {total_prompt_tokens + total_completion_tokens:>8}")
        else:
            logger.info(f"   â””â”€ ä¼°ç®—æ€»è®¡:          ~{self.token_usage['total']:>8} tokens")
        
        logger.info(f"{'â”€'*60}")
        
        # æ£€æŸ¥æœ€å°æˆåŠŸæ­¥éª¤æ•°
        min_required = plan_config.get("error_handling", {}).get("min_required_steps", 1)
        if len(step_results) < min_required:
            error_msg = f"å­¦ä¹ åŒ…ç”Ÿæˆå¤±è´¥ï¼šæˆåŠŸæ­¥éª¤ä¸è¶³ ({len(step_results)}/{min_required})"
            logger.error(f"âŒ {error_msg}")
            yield {
                "type": "error",
                "message": error_msg
            }
            return
        
        # èšåˆç»“æœ
        bundle = self._aggregate_results(
            step_results=step_results,
            aggregation_config=plan_config["aggregation"],
            user_input=user_input
        )
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸŠ Plan Skill æ‰§è¡Œå®Œæˆï¼")
        logger.info(f"ğŸ“¦ å­¦ä¹ åŒ… ID: {bundle.get('bundle_id')}")
        logger.info(f"ğŸ“š åŒ…å«ç»„ä»¶: {len(bundle.get('components', []))}")
        logger.info(f"â±ï¸  é¢„è®¡å­¦ä¹ æ—¶é—´: {bundle.get('estimated_time_minutes')} åˆ†é’Ÿ")
        logger.info(f"{'='*60}\n")
        
        # ğŸ†• å‘é€Planå®ŒæˆçŠ¶æ€
        yield {
            "type": "done",
            "content": bundle,
            "content_type": "learning_bundle"
        }
    
    async def _execute_step_stream(
        self,
        skill_id: str,
        input_params: Dict[str, Any],
        user_profile: Any,
        session_context: Any,
        step_info: Dict[str, Any]
    ):
        """
        ğŸ†• æµå¼æ‰§è¡Œå•ä¸ª skillï¼ˆè½¬å‘thinkingå’Œcontentï¼‰
        
        Args:
            skill_id: Skill ID
            input_params: è¾“å…¥å‚æ•°
            user_profile: ç”¨æˆ·ç”»åƒ
            session_context: ä¼šè¯ä¸Šä¸‹æ–‡
            step_info: æ­¥éª¤ä¿¡æ¯ï¼ˆç”¨äºæ˜¾ç¤ºè¿›åº¦ï¼‰
        
        Yields:
            Dict: æµå¼äº‹ä»¶
        """
        # è°ƒç”¨ SkillOrchestrator çš„æµå¼æ‰§è¡Œæ–¹æ³•
        async for chunk in self.skill_orchestrator._execute_single_skill_stream(
            skill_id=skill_id,
            input_params=input_params,
            user_profile=user_profile,
            session_context=session_context
        ):
            # è½¬å‘æ‰€æœ‰chunks
            yield chunk
    
    def _build_step_input(
        self,
        step: Dict[str, Any],
        user_input: Dict[str, Any],
        step_contexts: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ„å»º step çš„è¾“å…¥å‚æ•°
        
        æ”¯æŒæ¨¡æ¿å˜é‡ï¼š
        - {input.field}: ä»ç”¨æˆ·è¾“å…¥æå–
        - {context.step_id.field}: ä»ä¸Šæ¸¸ step ä¸Šä¸‹æ–‡æå–
        
        Args:
            step: Step é…ç½®
            user_input: ç”¨æˆ·è¾“å…¥
            step_contexts: å·²æ‰§è¡Œ steps çš„ä¸Šä¸‹æ–‡
        
        Returns:
            Step è¾“å…¥å‚æ•°å­—å…¸
        """
        step_input = {}
        
        for key, value_template in step["input_mapping"].items():
            if isinstance(value_template, str) and "{" in value_template:
                # è§£ææ¨¡æ¿å˜é‡
                if value_template.startswith("{input."):
                    # ä»ç”¨æˆ·è¾“å…¥æå–: {input.topic}
                    field = value_template[7:-1]
                    step_input[key] = user_input.get(field)
                
                elif value_template.startswith("{context."):
                    # ä»ä¸Šæ¸¸ step ä¸Šä¸‹æ–‡æå–: {context.explain.key_terms}
                    parts = value_template[9:-1].split(".", 1)
                    step_id = parts[0]
                    field_path = parts[1] if len(parts) > 1 else None
                    
                    if step_id in step_contexts:
                        if field_path:
                            step_input[key] = self._get_nested_value(step_contexts[step_id], field_path)
                        else:
                            step_input[key] = step_contexts[step_id]
                    else:
                        logger.warning(f"âš ï¸  ä¾èµ–çš„ step {step_id} ä¸å­˜åœ¨æˆ–æœªæ‰§è¡Œ")
            else:
                # ç›´æ¥å€¼
                step_input[key] = value_template
        
        return step_input
    
    async def _execute_step(
        self,
        skill_id: str,
        input_params: Dict[str, Any],
        user_profile: Any,
        session_context: Any
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ª skill
        
        Args:
            skill_id: Skill ID
            input_params: è¾“å…¥å‚æ•°
            user_profile: ç”¨æˆ·ç”»åƒ
            session_context: ä¼šè¯ä¸Šä¸‹æ–‡
        
        Returns:
            Skill æ‰§è¡Œç»“æœ
        """
        # è°ƒç”¨ SkillOrchestrator æ‰§è¡Œ skill
        result = await self.skill_orchestrator._execute_single_skill(
            skill_id=skill_id,
            input_params=input_params,
            user_profile=user_profile,
            session_context=session_context
        )
        
        return result
    
    def _extract_context(
        self,
        result: Dict[str, Any],
        extraction_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ä» step ç»“æœä¸­æå–ä¸Šä¸‹æ–‡
        
        å®ç°ä¸Šä¸‹æ–‡å¸è½½ï¼ˆContext Pruningï¼‰ï¼š
        - åªæå–å…³é”®ä¿¡æ¯
        - å‹ç¼©æ•°æ®é‡
        - å‡å°‘ä¸‹æ¸¸ token æ¶ˆè€—
        
        Args:
            result: Step æ‰§è¡Œç»“æœ
            extraction_config: æå–é…ç½®
        
        Returns:
            æå–çš„ä¸Šä¸‹æ–‡å­—å…¸
        """
        if not extraction_config:
            return {}
        
        strategy = extraction_config.get("strategy", "key_points")
        fields = extraction_config.get("fields", [])
        max_tokens = extraction_config.get("max_tokens", 500)
        
        extracted = {}
        
        if strategy == "key_points":
            # æå–æŒ‡å®šå­—æ®µ
            for field in fields:
                value = self._get_nested_value(result, field)
                if value:
                    extracted[field] = value
        
        elif strategy == "summary":
            # ç”Ÿæˆæ‘˜è¦ï¼ˆæå–å…³é”®ä¿¡æ¯ï¼‰
            for field in fields:
                value = self._get_nested_value(result, field)
                if value:
                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œåªä¿ç•™æ•°é‡ä¿¡æ¯
                    if isinstance(value, list):
                        extracted[field] = f"{len(value)} items"
                    else:
                        extracted[field] = value
        
        elif strategy == "full_content":
            # ğŸ†• ä¼ é€’å®Œæ•´å†…å®¹ï¼ˆç¡®ä¿ä¸‹æ¸¸æ­¥éª¤å†…å®¹è¿è´¯æ€§ï¼‰
            # æå–æ‰€æœ‰æŒ‡å®šå­—æ®µçš„å®Œæ•´å†…å®¹ï¼Œä¸åšä»»ä½•å‹ç¼©
            for field in fields:
                value = self._get_nested_value(result, field)
                if value:
                    extracted[field] = value
            
            logger.info(f"ğŸ“¦ [full_contentç­–ç•¥] æå–äº† {len(extracted)} ä¸ªå­—æ®µçš„å®Œæ•´å†…å®¹")
            logger.info(f"ğŸ“Š æå–å­—æ®µ: {list(extracted.keys())}")
        
        # Token é™åˆ¶æ£€æŸ¥
        extracted_str = json.dumps(extracted, ensure_ascii=False)
        estimated_tokens = len(extracted_str) // 4
        
        if estimated_tokens > max_tokens:
            logger.warning(f"âš ï¸  æå–çš„ä¸Šä¸‹æ–‡è¶…è¿‡é™åˆ¶: {estimated_tokens} > {max_tokens}")
            # è¿›ä¸€æ­¥å‹ç¼©ï¼ˆç®€å•å®ç°ï¼šæˆªæ–­ï¼‰
            extracted = self._compress_context(extracted, max_tokens)
        
        logger.debug(f"ğŸ” ä¸Šä¸‹æ–‡æå–: {strategy} | {len(extracted_str)} chars | ~{estimated_tokens} tokens")
        
        return extracted
    
    def _aggregate_results(
        self,
        step_results: Dict[str, Dict[str, Any]],
        aggregation_config: Dict[str, Any],
        user_input: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        èšåˆæ‰€æœ‰ step çš„ç»“æœä¸ºå®Œæ•´å­¦ä¹ åŒ…
        
        Args:
            step_results: å„ step çš„æ‰§è¡Œç»“æœ
            aggregation_config: èšåˆé…ç½®
            user_input: ç”¨æˆ·è¾“å…¥
        
        Returns:
            å®Œæ•´çš„å­¦ä¹ åŒ…
        """
        components = []
        total_time = 0
        
        # ç»„è£… components
        for component_config in aggregation_config["assembly"]["components"]:
            step_id = component_config["step_id"]
            
            if step_id in step_results:
                result = step_results[step_id]
                
                components.append({
                    "component_type": component_config["component_type"],
                    "skill_id": result.get("skill_id", "unknown"),
                    "content": result
                })
                
                # ç´¯åŠ æ—¶é—´
                if "estimated_time_minutes" in result:
                    total_time += result.get("estimated_time_minutes", 0)
        
        # ç”Ÿæˆå­¦ä¹ è·¯å¾„
        learning_path = aggregation_config["assembly"]["learning_path_template"]
        
        # ç”Ÿæˆ bundle_id
        timestamp = int(datetime.now().timestamp())
        bundle_id = f"bundle_{user_input.get('subject', 'general')}_{user_input.get('topic', 'topic')}_{timestamp}"
        
        bundle = {
            "bundle_id": bundle_id,
            "subject": user_input.get("subject", "é€šç”¨"),
            "topic": user_input.get("topic"),
            "components": components,
            "estimated_time_minutes": total_time if total_time > 0 else 45,  # é»˜è®¤ 45 åˆ†é’Ÿ
            "learning_path": learning_path,
            "execution_summary": {
                "plan_skill_version": "2.0",
                "total_steps": len(step_results),
                "successful_components": len(components),
                "token_usage": self.token_usage
            }
        }
        
        return bundle
    
    def _get_nested_value(self, data: Any, path: str) -> Any:
        """
        è·å–åµŒå¥—å­—å…¸/å¯¹è±¡çš„å€¼
        
        æ”¯æŒè·¯å¾„: 'field1.field2.field3'
        """
        if not path:
            return data
        
        keys = path.split(".")
        value = data
        
        for key in keys:
            if isinstance(value, dict):
                value = value.get(key)
            elif hasattr(value, key):
                value = getattr(value, key)
            else:
                return None
            
            if value is None:
                return None
        
        return value
    
    def _compress_context(self, context: Dict[str, Any], max_tokens: int) -> Dict[str, Any]:
        """å‹ç¼©ä¸Šä¸‹æ–‡åˆ°æŒ‡å®š token é™åˆ¶"""
        # ç®€å•å®ç°ï¼šä¿ç•™æœ€é‡è¦çš„å­—æ®µ
        compressed = {}
        current_tokens = 0
        
        for key, value in context.items():
            value_str = json.dumps(value, ensure_ascii=False)
            value_tokens = len(value_str) // 4
            
            if current_tokens + value_tokens <= max_tokens:
                compressed[key] = value
                current_tokens += value_tokens
            else:
                break
        
        return compressed
    
    def _estimate_tokens(self, result: Dict[str, Any]) -> int:
        """ä¼°ç®—ç»“æœçš„ token æ•°é‡ï¼ˆç®€å•ä¼°ç®—ï¼šå­—ç¬¦æ•° / 4ï¼‰"""
        result_str = json.dumps(result, ensure_ascii=False)
        return len(result_str) // 4

