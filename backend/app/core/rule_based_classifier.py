"""
è§„åˆ™å¼•æ“æ„å›¾åˆ†ç±»å™¨ (Rule-Based Intent Classifier)

ç”¨äºå¿«é€Ÿè¯†åˆ«æ˜ç¡®çš„ç”¨æˆ·æ„å›¾ï¼Œæ— éœ€æ¶ˆè€— LLM tokensã€‚
åªæœ‰æ¨¡ç³Šè¯·æ±‚æ‰ä¼šå›é€€åˆ° LLM Intent Routerã€‚

è®¾è®¡ç†å¿µï¼š
- 70% çš„ç”¨æˆ·è¯·æ±‚æ˜¯æ˜ç¡®çš„ï¼ˆå¦‚"ç»™æˆ‘5é“é¢˜"ã€"è§£é‡Šç‰›é¡¿å®šå¾‹"ï¼‰
- è¿™äº›æ˜ç¡®è¯·æ±‚å¯ä»¥ç”¨ç®€å•è§„åˆ™è¯†åˆ«ï¼Œæ— éœ€ LLM
- åªæœ‰æ¨¡ç³Šè¯·æ±‚æ‰éœ€è¦ LLM çš„è¯­ä¹‰ç†è§£èƒ½åŠ›

Token ä¼˜åŒ–ï¼š
- è§„åˆ™å¼•æ“: 0 tokens (çº¯ä»£ç )
- å¹³å‡èŠ‚çœ: 86% tokens (3,132 â†’ 450)
"""
import re
import logging
from typing import Optional, Dict, Any, Tuple

logger = logging.getLogger(__name__)


class RuleBasedIntentClassifier:
    """åŸºäºè§„åˆ™çš„æ„å›¾åˆ†ç±»å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è§„åˆ™å¼•æ“"""
        # æ„å›¾å…³é”®è¯æ˜ å°„
        self.intent_keywords = {
            "quiz": {
                "keywords": ["quiz", "é¢˜", "ç»ƒä¹ é¢˜", "æµ‹è¯•", "æµ‹éªŒ", "é—®é¢˜", "è€ƒé¢˜", "åˆ·é¢˜"],
                "intent": "quiz_request",
                "confidence": 0.95
            },
            "explain": {
                "keywords": ["explain", "è®²è§£", "è§£é‡Š", "ä»€ä¹ˆæ˜¯", "æ˜¯ä»€ä¹ˆ", "å¸®æˆ‘ç†è§£", "ç†è§£", "ä»‹ç»ä¸€ä¸‹", "ç§‘æ™®"],
                "intent": "explain_request",
                "confidence": 0.95
            },
            "flashcard": {
                "keywords": ["flashcard", "é—ªå¡", "å¡ç‰‡", "è®°å¿†å¡", "å•è¯å¡", "èƒŒè¯µå¡"],
                "intent": "flashcard_request",
                "confidence": 0.95
            },
            "notes": {
                "keywords": ["notes", "ç¬”è®°", "è®°å½•", "æ•´ç†", "æ€»ç»“", "å½’çº³", "æ¢³ç†"],
                "intent": "notes",
                "confidence": 0.95
            },
            "mindmap": {
                "keywords": ["mindmap", "æ€ç»´å¯¼å›¾", "çŸ¥è¯†å›¾è°±", "è„‘å›¾", "mind map", "ç”»ä¸ªå›¾"],
                "intent": "mindmap",
                "confidence": 0.95
            },
            "learning_bundle": {
                "keywords": [
                    # ç›´æ¥è¯·æ±‚å­¦ä¹ åŒ…
                    "å­¦ä¹ åŒ…", "å­¦ä¹ èµ„æ–™", "å­¦ä¹ ææ–™", "å­¦ä¹ å†…å®¹",
                    # ç»¼åˆå­¦ä¹ ç±»
                    "å…¨é¢å­¦ä¹ ", "ä¸€ç«™å¼å­¦ä¹ ", "ç»¼åˆå­¦ä¹ ", "å®Œæ•´å­¦ä¹ ", "ç³»ç»Ÿå­¦ä¹ ",
                    # å­¦ä¹ å¥—é¤ç±»
                    "å­¦ä¹ å¥—é¤", "å­¦ä¹ æ–¹æ¡ˆ", "å­¦ä¹ è®¡åˆ’", "å­¦ä¹ æ”»ç•¥",
                    # è‹±æ–‡è¡¨è¾¾
                    "learning bundle", "study package", "learning package",
                    # å£è¯­åŒ–è¡¨è¾¾
                    "ç»™æˆ‘å…¨å¥—", "æ¥ä¸ªå…¨å¥—", "å…¨éƒ¨èµ„æ–™", "æ‰€æœ‰ææ–™", "å®Œæ•´èµ„æ–™",
                    "å¸®æˆ‘å‡†å¤‡", "å…¨é¢å‡†å¤‡"
                ],
                "intent": "learning_bundle",
                "confidence": 0.95
            },
            "help": {
                "keywords": ["help", "å¸®åŠ©", "åŠŸèƒ½", "èƒ½åšä»€ä¹ˆ", "æœ‰å“ªäº›åŠŸèƒ½", "æ€ä¹ˆç”¨", "ä½¿ç”¨æ–¹æ³•"],
                "intent": "help",
                "confidence": 0.98
            }
        }
        
        # æ•°é‡æå–æ­£åˆ™è¡¨è¾¾å¼
        self.quantity_patterns = [
            r'(\d+)\s*é“',     # "5é“é¢˜"
            r'(\d+)\s*ä¸ª',     # "3ä¸ªé—®é¢˜"
            r'(\d+)\s*å¼ ',     # "10å¼ é—ªå¡"
            r'(\d+)\s*ä»½',     # "2ä»½èµ„æ–™"
        ]
        
        logger.info("âœ… RuleBasedIntentClassifier initialized")
    
    def classify(
        self,
        message: str,
        memory_summary: Optional[str] = None
    ) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨è§„åˆ™åˆ†ç±»ç”¨æˆ·æ„å›¾
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            memory_summary: è®°å¿†æ‘˜è¦ï¼ˆç”¨äºåå¥½æ¨æ–­ï¼‰
        
        Returns:
            åˆ†ç±»ç»“æœå­—å…¸ï¼Œå¦‚æœæ— æ³•åˆ†ç±»åˆ™è¿”å› None
        """
        message_lower = message.lower().strip()
        
        # 1. å°è¯•å…³é”®è¯åŒ¹é…
        matched_intent = self._match_keywords(message_lower)
        
        if matched_intent:
            intent_type = matched_intent["intent"]
            confidence = matched_intent["confidence"]
            
            # 2. æå–ä¸»é¢˜
            topic = self._extract_topic(message)
            
            # 3. æå–æ•°é‡å‚æ•°
            quantity = self._extract_quantity(message)
            
            # 4. æ£€æµ‹ä¸Šä¸‹æ–‡å¼•ç”¨ï¼ˆå¦‚ "ç¬¬ä¸€é“é¢˜"ã€"è¿™äº›ä¾‹å­"ï¼‰
            use_last_artifact = self._detect_context_reference(message)
            
            # 5. æ„å»ºç»“æœ
            result = {
                "intent": intent_type,
                "topic": topic,
                "target_artifact": self._get_target_artifact(intent_type),
                "confidence": confidence,
                "raw_text": message,
                "parameters": {},
                "classification_method": "rule_based"  # æ ‡è®°ä¸ºè§„åˆ™å¼•æ“åˆ†ç±»
            }
            
            # æ·»åŠ æ•°é‡å‚æ•°
            if quantity:
                result["parameters"]["quantity"] = quantity
            
            # æ·»åŠ ä¸Šä¸‹æ–‡å¼•ç”¨æ ‡è®°
            if use_last_artifact:
                result["parameters"]["use_last_artifact"] = True
            
            logger.info(
                f"ğŸ¯ Rule-based classification: {intent_type} "
                f"(confidence: {confidence:.2f}, topic: {topic}, quantity: {quantity}, "
                f"use_context: {use_last_artifact})"
            )
            
            return result
        
        # æ— æ³•é€šè¿‡è§„åˆ™åˆ†ç±»
        logger.info("âš ï¸  Rule-based classification failed, will fallback to LLM")
        return None
    
    def _match_keywords(self, message: str) -> Optional[Dict[str, Any]]:
        """
        åŒ¹é…å…³é”®è¯ï¼ˆæŒ‰ä¼˜å…ˆçº§åŒ¹é…ï¼Œé¿å…å†²çªï¼‰
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯ï¼ˆå°å†™ï¼‰
        
        Returns:
            åŒ¹é…çš„æ„å›¾ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…åˆ™è¿”å› None
        """
        # å®šä¹‰åŒ¹é…ä¼˜å…ˆçº§ï¼ˆé«˜ä¼˜å…ˆçº§çš„å…ˆåŒ¹é…ï¼‰
        # ä¼˜å…ˆçº§ï¼šexplain > notes > flashcard > mindmap > learning_bundle > quiz > help
        priority_order = [
            "explain",       # "è§£é‡Šä¸€ä¸‹é¢˜" åº”è¯¥æ˜¯ explainï¼Œä¸æ˜¯ quiz
            "notes",         # "åšç¬”è®°" åº”è¯¥æ˜¯ notesï¼Œä¸æ˜¯å…¶ä»–
            "flashcard",     # "é—ªå¡"
            "mindmap",       # "æ€ç»´å¯¼å›¾"
            "learning_bundle",  # "å­¦ä¹ åŒ…"
            "help",          # "åŠŸèƒ½" ä¼˜å…ˆäºå…¶ä»–
            "quiz",          # "é¢˜" æ˜¯é€šç”¨è¯ï¼Œä¼˜å…ˆçº§æœ€ä½
        ]
        
        # æŒ‰ä¼˜å…ˆçº§é¡ºåºåŒ¹é…
        for intent_name in priority_order:
            if intent_name not in self.intent_keywords:
                continue
            
            intent_info = self.intent_keywords[intent_name]
            for keyword in intent_info["keywords"]:
                if keyword.lower() in message:
                    return intent_info
        
        return None
    
    def _extract_topic(self, message: str) -> Optional[str]:
        """
        æå–ä¸»é¢˜
        
        ç®€å•ç­–ç•¥ï¼š
        - ç§»é™¤æ„å›¾å…³é”®è¯
        - ç§»é™¤æ•°é‡è¯
        - å–å‰©ä½™çš„æ ¸å¿ƒè¯æ±‡
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
        
        Returns:
            æå–çš„ä¸»é¢˜ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å› None
        """
        # ğŸ¯ æ–°ç­–ç•¥ï¼šæç®€å¤„ç†ï¼Œé¿å…è¿‡åº¦åˆ é™¤å¯¼è‡´ä¿¡æ¯ä¸¢å¤±
        # ä¾‹å¦‚ï¼š"ç‰›é¡¿ç¬¬äºŒå®šå¾‹" ä¸åº”è¯¥å˜æˆ "ç‰›é¡¿ç¬¬å®šå¾‹"
        
        # 1. åªç§»é™¤æ˜ç¡®çš„æ„å›¾å…³é”®è¯ï¼ˆæœ€å°é›†åˆï¼‰
        intent_keywords = [
            "quiz", "é¢˜ç›®", "é¢˜", "ç»ƒä¹ ", "explain", "è®²è§£", "è§£é‡Š",
            "flashcard", "é—ªå¡", "notes", "ç¬”è®°", "mindmap", "æ€ç»´å¯¼å›¾",
            "å­¦ä¹ åŒ…", "ä»€ä¹ˆæ˜¯", "æ˜¯ä»€ä¹ˆ"
        ]
        
        cleaned = message
        for keyword in intent_keywords:
            cleaned = cleaned.replace(keyword, " ")
        
        # 2. åªç§»é™¤æ˜ç¡®çš„åŠ©è¯å’ŒåŠ¨ä½œè¯ï¼ˆæœ€å°é›†åˆï¼‰
        filler_words = ["ç»™æˆ‘", "å¸®æˆ‘", "æ¥", "ä¸€ä¸‹", "ç”Ÿæˆ", "åˆ¶ä½œ", "åˆ›å»º", "åš", "å‡º", "çš„"]
        for word in filler_words:
            cleaned = cleaned.replace(word, " ")
        
        # 3. ğŸ†• åªç§»é™¤é‡è¯ï¼Œä¸ç§»é™¤æ•°å­—ï¼
        #    ä¿ç•™"ç¬¬äºŒ"ã€"äºŒæˆ˜"ç­‰å«ä¹‰æ•°å­—
        #    åªåˆ é™¤"5é“é¢˜"ä¸­çš„"5"è¿™ç§çº¯æ•°é‡è¡¨è¾¾
        cleaned = re.sub(r'\d+\s*[ä¸ªé“å¼ ä»½æ¬¡éç‚¹]', '', cleaned)  # "5é“" â†’ ""
        cleaned = re.sub(r'[å‡ ä¸¤]+\s*[ä¸ªé“å¼ ä»½æ¬¡éç‚¹]', '', cleaned)  # "å‡ é“" â†’ ""
        
        # 4. æ¸…ç†ç©ºæ ¼
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        
        # 5. ğŸ¯ ç®€å•åˆ¤æ–­ï¼šå¦‚æœæœ‰å®è´¨æ€§å†…å®¹ï¼ˆé•¿åº¦>=3ï¼‰ï¼Œè¿”å›
        if cleaned and len(cleaned) >= 3:
            return cleaned
        
        # ğŸ†• è¿”å› None è¡¨ç¤º"æ²¡æœ‰æ˜ç¡®ä¸»é¢˜"
        return None
    
    def _extract_quantity(self, message: str) -> Optional[int]:
        """
        æå–æ•°é‡
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
        
        Returns:
            æå–çš„æ•°é‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å› None
        """
        for pattern in self.quantity_patterns:
            match = re.search(pattern, message)
            if match:
                try:
                    return int(match.group(1))
                except ValueError:
                    continue
        
        return None
    
    def _detect_context_reference(self, message: str) -> bool:
        """
        æ£€æµ‹æ¶ˆæ¯æ˜¯å¦å¼•ç”¨äº†ä¸Šä¸‹æ–‡ï¼ˆå¦‚ "ç¬¬ä¸€é“é¢˜"ã€"è¿™äº›ä¾‹å­"ï¼‰
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
        
        Returns:
            æ˜¯å¦éœ€è¦ä½¿ç”¨ä¸Šä¸€è½®çš„ artifact å†…å®¹
        """
        # åªä¿ç•™éå¸¸æ˜ç¡®çš„å¼•ç”¨å…³é”®è¯ï¼ˆç”¨äºå¿«é€Ÿæ£€æµ‹ï¼‰
        # å¤æ‚çš„å¼•ç”¨è¡¨è¾¾äº¤ç»™LLMå¤„ç†
        context_keywords = [
            # æ˜ç¡®çš„åºå·å¼•ç”¨
            "ç¬¬ä¸€é“é¢˜", "ç¬¬äºŒé“é¢˜", "ç¬¬ä¸‰é“é¢˜", "ç¬¬å››é“é¢˜", "ç¬¬äº”é“é¢˜",
            "ç¬¬ä¸€ä¸ªä¾‹å­", "ç¬¬äºŒä¸ªä¾‹å­", "ç¬¬ä¸‰ä¸ªä¾‹å­",
            "ç¬¬1é“", "ç¬¬2é“", "ç¬¬3é“", "ç¬¬4é“", "ç¬¬5é“",
            "ç¬¬1ä¸ªä¾‹å­", "ç¬¬2ä¸ªä¾‹å­", "ç¬¬3ä¸ªä¾‹å­",
        ]
        
        message_lower = message.lower()
        for keyword in context_keywords:
            if keyword in message_lower:
                logger.info(f"ğŸ”— Context reference detected: '{keyword}' in message")
                return True
        
        return False
    
    def _get_target_artifact(self, intent: str) -> Optional[str]:
        """
        æ ¹æ®æ„å›¾è·å–ç›®æ ‡äº§ç‰©ç±»å‹
        
        Args:
            intent: æ„å›¾ç±»å‹
        
        Returns:
            äº§ç‰©ç±»å‹
        """
        artifact_mapping = {
            "quiz_request": "quiz_set",
            "explain_request": "explanation",
            "flashcard_request": "flashcard_set",
            "notes": "notes",
            "mindmap": "mindmap",
            "learning_bundle": "learning_bundle",
            "help": None
        }
        
        return artifact_mapping.get(intent)
    
    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–è§„åˆ™å¼•æ“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return {
            "total_intents": len(self.intent_keywords),
            "total_keywords": sum(len(info["keywords"]) for info in self.intent_keywords.values()),
            "supported_intents": list(self.intent_keywords.keys())
        }

