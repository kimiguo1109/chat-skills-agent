"""
Skill Orchestrator - æŠ€èƒ½ç¼–æ’å™¨

è´Ÿè´£ï¼š
1. æ„å›¾åˆ°æŠ€èƒ½æ˜ å°„
2. æŠ€èƒ½é€‰æ‹©ç­–ç•¥
3. è¾“å…¥å‚æ•°æ„å»º  
4. æŠ€èƒ½æ‰§è¡Œï¼ˆè°ƒç”¨ Geminiï¼‰
5. è¾“å‡ºå°è£…
6. è®°å¿†æ›´æ–°
"""
import json
import logging
import os
from typing import Dict, Any, Optional, List
from datetime import datetime

from ..models.intent import IntentResult, MemorySummary
from ..models.memory import UserLearningProfile, SessionContext
from ..models.skill import SkillDefinition
from ..services.gemini import GeminiClient
from ..services.kimi import KimiClient  # ğŸ†• å¯¼å…¥ KimiClient
from ..config import settings  # ğŸ†• å¯¼å…¥é…ç½®
from .skill_registry import SkillRegistry, get_skill_registry
from .memory_manager import MemoryManager

logger = logging.getLogger(__name__)


class SkillOrchestrator:
    """æŠ€èƒ½ç¼–æ’å™¨ - è°ƒåº¦æ ¸å¿ƒ"""
    
    def __init__(
        self,
        skill_registry: Optional[SkillRegistry] = None,
        gemini_client: Optional[GeminiClient] = None,
        memory_manager: Optional[MemoryManager] = None
    ):
        """
        åˆå§‹åŒ– Skill Orchestrator
        
        Args:
            skill_registry: Skill Registry å®ä¾‹
            gemini_client: Gemini Client å®ä¾‹ï¼ˆå…¼å®¹å‚æ•°ï¼‰
            memory_manager: Memory Manager å®ä¾‹
        """
        self.skill_registry = skill_registry or get_skill_registry()
        
        # ğŸ”¥ æ ¹æ®é…ç½®é€‰æ‹© LLM Client
        if settings.KIMI_API_KEY and settings.KIMI_MODEL:
            self.llm_client = KimiClient()
            logger.info("âœ… Using Kimi Client for LLM operations")
        else:
            self.llm_client = gemini_client or GeminiClient()
            logger.info("âœ… Using Gemini Client for LLM operations")
        
        # ä¿æŒå‘åå…¼å®¹
        self.gemini_client = self.llm_client
        
        self.memory_manager = memory_manager or MemoryManager()
        
        # Prompt æ–‡ä»¶ç›®å½•
        self.prompts_dir = os.path.join(
            os.path.dirname(os.path.dirname(__file__)),
            "prompts"
        )
        
        logger.info("âœ… SkillOrchestrator initialized")
    
    async def execute_stream(
        self,
        intent_result: IntentResult,
        user_id: str,
        session_id: str,
        additional_params: Optional[Dict[str, Any]] = None
    ):
        """
        ğŸ†• æµå¼æ‰§è¡ŒæŠ€èƒ½ï¼ˆå®æ—¶å±•ç¤ºæ€è€ƒè¿‡ç¨‹å’Œç”Ÿæˆå†…å®¹ï¼‰
        
        Args:
            intent_result: æ„å›¾è¯†åˆ«ç»“æœ
            user_id: ç”¨æˆ· ID
            session_id: ä¼šè¯ ID
            additional_params: é¢å¤–å‚æ•°
        
        Yields:
            Dict: æµå¼äº‹ä»¶ {"type": "status|thinking|content|done", ...}
        """
        try:
            logger.info(f"ğŸŒŠ Stream orchestrating: intent={intent_result.intent}, topic={intent_result.topic}")
            
            # Step 1: é€‰æ‹©æŠ€èƒ½
            skill = self._select_skill(intent_result)  # ğŸ”§ ä¿®å¤ï¼šä¼ é€’IntentResultå¯¹è±¡
            if not skill:
                yield {
                    "type": "error",
                    "message": f"No skill found for intent: {intent_result.intent}"
                }
                return
            
            # ğŸ”§ æ£€æµ‹Plan Skill - Plan Skillä¸æ”¯æŒæµå¼ï¼ˆæš‚æ—¶å›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼ï¼‰
            logger.debug(f"ğŸ” Checking skill type: skill.id={skill.id}, skill.skill_type={skill.skill_type}")
            
            # ğŸ”§ å¢å¼ºæ£€æµ‹ï¼šæ£€æŸ¥skill_typeæˆ–skill.idï¼ˆé˜²æ­¢skill_typeæœªåŠ è½½ï¼‰
            is_plan_skill = (
                skill.skill_type == "plan" or 
                skill.id == "learning_plan_skill" or
                "plan" in skill.id.lower()
            )
            
            if is_plan_skill:
                # ğŸ†• Plan Skill æµå¼æ‰§è¡Œ
                logger.info(f"ğŸŒŠ Executing Plan Skill in streaming mode")
                
                # åŠ è½½ç”¨æˆ·ç”»åƒå’Œä¼šè¯ä¸Šä¸‹æ–‡
                user_profile = await self.memory_manager.get_user_profile(user_id)
                session_context = await self.memory_manager.get_session_context(session_id)
                
                # æ„å»ºè¾“å…¥å‚æ•°
                context = await self._build_context(skill, user_id, session_id)
                input_params = self._build_input_params(
                    skill, intent_result, context, additional_params
                )
                
                # ä½¿ç”¨PlanSkillExecutoræµå¼æ‰§è¡Œ
                from .plan_skill_executor import PlanSkillExecutor
                plan_executor = PlanSkillExecutor(skill_orchestrator=self)
                
                async for chunk in plan_executor.execute_plan_stream(
                    plan_config=skill.raw_config,
                    user_input=input_params,
                    user_profile=user_profile,
                    session_context=session_context
                ):
                    yield chunk
                
                return
            
            yield {
                "type": "status",
                "message": f"ä½¿ç”¨ {skill.display_name}"
            }
            
            # Step 2: æ„å»ºä¸Šä¸‹æ–‡
            context = await self._build_context(skill, user_id, session_id)
            
            # Step 3: æ„å»ºè¾“å…¥å‚æ•°
            params = self._build_input_params(
                skill, intent_result, context, additional_params
            )
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¾„æ¸…
            if not params.get("topic"):
                yield {
                    "type": "clarification_needed",
                    "message": "éœ€è¦æ˜ç¡®å­¦ä¹ ä¸»é¢˜"
                }
                return
            
            # Step 4: åŠ è½½ prompt
            prompt_content = self._load_prompt(skill)
            prompt = self._format_prompt(prompt_content, params, context)
            
            # Step 5: æµå¼è°ƒç”¨ LLM
            yield {
                "type": "status", 
                "message": "æ­£åœ¨ç”Ÿæˆå†…å®¹..."
            }
            
            thinking_accumulated = []
            content_accumulated = []
            
            # ğŸ”¥ ä½¿ç”¨ llm_clientï¼ˆæ”¯æŒ Kimi æˆ– Geminiï¼‰
            async for chunk in self.llm_client.generate_stream(
                prompt=prompt,
                model=skill.models.get("primary", self.llm_client.model),  # ä½¿ç”¨ llm_client çš„é»˜è®¤æ¨¡å‹
                thinking_budget=skill.thinking_budget or 64,  # âš¡âš¡âš¡ æé€Ÿæ€è€ƒï¼š64 tokensï¼ˆ~5-10ç§’ï¼‰
                buffer_size=1,  # âš¡âš¡âš¡âš¡ æé™ä¼˜åŒ–ï¼šæ¯ä¸ªå­—ç¬¦ç«‹å³å‘é€
                temperature=getattr(skill, 'temperature', 1.0)  # âš¡âš¡âš¡ æœ€å¤§åŒ–é€Ÿåº¦
            ):
                # ç´¯ç§¯æ•°æ®
                if chunk["type"] == "thinking":
                    thinking_accumulated.append(chunk.get("text", ""))
                elif chunk["type"] == "content":
                    content_accumulated.append(chunk.get("text", ""))
                
                # è½¬å‘ç»™å‰ç«¯
                yield chunk
            
            # Step 6: è§£ææœ€ç»ˆç»“æœ
            full_thinking = "".join(thinking_accumulated)
            full_content = "".join(content_accumulated)
            
            # ğŸ”¥ å¦‚æœcontentæ²¡æœ‰æµå¼å‘é€è¿‡ï¼ˆKimiä¸€æ¬¡æ€§ç”Ÿæˆï¼‰ï¼Œå¼ºåˆ¶æ‹†åˆ†æµå¼æ˜¾ç¤º
            content_chunks_sent = len(content_accumulated)
            logger.info(f"ğŸ“Š Content chunks received: {content_chunks_sent}")
            
            if content_chunks_sent == 0 and full_content:
                # å®Œå…¨æ²¡æœ‰content chunksï¼Œä½†æœ‰å®Œæ•´contentï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰
                logger.warning(f"âš ï¸  No content chunks but have full_content, forcing stream")
                # å¼ºåˆ¶æ‹†åˆ†å‘é€
                chunk_size = 50
                for i in range(0, len(full_content), chunk_size):
                    mini_chunk = full_content[i:i+chunk_size]
                    accumulated_so_far = full_content[:i+len(mini_chunk)]
                    yield {
                        "type": "content",
                        "text": mini_chunk,
                        "accumulated": accumulated_so_far
                    }
            elif content_chunks_sent > 0 and content_chunks_sent < 5:
                # Content chunkså¤ªå°‘ï¼ˆå¯èƒ½Kimiä¸€æ¬¡æ€§ç”Ÿæˆäº†å¤§å—ï¼‰ï¼Œå¼ºåˆ¶æ‹†åˆ†æœ€åä¸€å—
                logger.info(f"ğŸ“¦ Content sent in {content_chunks_sent} large chunks, forcing granular stream")
                # å¦‚æœæœ€åä¸€å—å¾ˆå¤§ï¼Œæ‹†åˆ†å®ƒ
                if len(content_accumulated) > 0:
                    last_chunk = content_accumulated[-1]
                    if len(last_chunk) > 100:  # å¦‚æœæœ€åä¸€å—è¶…è¿‡100å­—ç¬¦
                        logger.info(f"âœ‚ï¸  Splitting large final chunk ({len(last_chunk)} chars)")
                        chunk_size = 50
                        base_accumulated = "".join(content_accumulated[:-1])
                        for i in range(0, len(last_chunk), chunk_size):
                            mini_chunk = last_chunk[i:i+chunk_size]
                            accumulated_so_far = base_accumulated + last_chunk[:i+len(mini_chunk)]
                            yield {
                                "type": "content",
                                "text": mini_chunk,
                                "accumulated": accumulated_so_far
                            }
            
            # ğŸ”§ æå–JSONï¼ˆå»é™¤markdownä»£ç å—ï¼‰
            json_str = full_content
            if "```json" in json_str:
                # JSONè¢«åŒ…è£¹åœ¨```json ...```ä¸­
                try:
                    json_str = json_str.split("```json")[1].split("```")[0].strip()
                    logger.info(f"âœ‚ï¸  Extracted JSON from markdown code block")
                except:
                    logger.warning(f"âš ï¸  Failed to extract JSON from markdown")
            elif "```" in json_str:
                # JSONè¢«åŒ…è£¹åœ¨``` ...```ä¸­
                try:
                    json_str = json_str.split("```")[1].split("```")[0].strip()
                    logger.info(f"âœ‚ï¸  Extracted JSON from code block")
                except:
                    pass
            
            # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©ºï¼ˆå¯èƒ½å› APIé”™è¯¯ä¸­æ–­ï¼‰
            if not json_str or len(json_str.strip()) < 10:
                logger.error(f"âŒ Content is empty or too short, likely due to API interruption")
                yield {
                    "type": "error",
                    "message": "AIæœåŠ¡æš‚æ—¶è¿‡è½½ï¼Œè¯·ç¨åé‡è¯• (503 Service Unavailable)"
                }
                return
            
            # æ£€æŸ¥å†…å®¹æ˜¯å¦çœ‹èµ·æ¥åƒmarkdownï¼ˆè€Œä¸æ˜¯JSONï¼‰
            if json_str.strip().startswith('**') or json_str.strip().startswith('#'):
                logger.error(f"âŒ Content appears to be markdown, not JSON - API stream was interrupted")
                yield {
                    "type": "error",
                    "message": "AIæœåŠ¡ä¸­æ–­äº†ç”Ÿæˆè¿‡ç¨‹ï¼Œè¯·åˆ·æ–°é¡µé¢åé‡è¯•"
                }
                return
            
            # å°è¯•è§£æ JSON
            try:
                parsed_content = json.loads(json_str)
                logger.info(f"âœ… JSON parsed successfully")
            except json.JSONDecodeError as e:
                logger.error(f"âŒ Failed to parse JSON: {e}")
                logger.error(f"Content preview: {json_str[:200]}")
                
                # ğŸ”§ å°è¯•ä¿®å¤æˆªæ–­çš„JSON
                # ç­–ç•¥ï¼šæ·»åŠ ç¼ºå¤±çš„é—­åˆç¬¦å·
                if "Unterminated string" in str(e) or "Expecting" in str(e):
                    logger.warning(f"âš ï¸  JSON appears truncated, attempting to fix...")
                    
                    # å°è¯•æ·»åŠ ç¼ºå¤±çš„ ] å’Œ }
                    fixed_attempts = [
                        json_str + '"}]}}',  # å°è¯•1: å­—ç¬¦ä¸²+æ•°ç»„+å¯¹è±¡
                        json_str + '"]}}',    # å°è¯•2: æ•°ç»„+å¯¹è±¡
                        json_str + '}]}}',    # å°è¯•3: å¯¹è±¡+æ•°ç»„+å¯¹è±¡
                        json_str + '}}',      # å°è¯•4: å¯¹è±¡
                        json_str + ']}'       # å°è¯•5: æ•°ç»„+å¯¹è±¡
                    ]
                    
                    for i, attempt in enumerate(fixed_attempts):
                        try:
                            parsed_content = json.loads(attempt)
                            logger.info(f"âœ… JSON fixed and parsed (attempt {i+1})")
                            break
                        except:
                            continue
                    else:
                        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
                        yield {
                            "type": "error",
                            "message": "ç”Ÿæˆå†…å®¹æ ¼å¼é”™è¯¯ï¼ˆJSONæˆªæ–­ï¼‰ï¼Œè¯·é‡è¯•"
                        }
                        return
                else:
                    yield {
                        "type": "error",
                        "message": "ç”Ÿæˆå†…å®¹æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•"
                    }
                    return
            
            # Step 7: æ£€æµ‹å†…å®¹ç±»å‹ï¼ˆä½¿ç”¨å’Œä¼ ç»ŸAPIç›¸åŒçš„é€»è¾‘ï¼‰
            content_type = "unknown"
            if "quiz_set_id" in parsed_content or "questions" in parsed_content:
                content_type = "quiz_set"
            elif "concept" in parsed_content or "explanation" in parsed_content:
                content_type = "explanation"
            elif "flashcard_set_id" in parsed_content or "cards" in parsed_content:
                content_type = "flashcard_set"
            elif "notes_id" in parsed_content or "structured_notes" in parsed_content:
                content_type = "notes"
            elif "bundle_id" in parsed_content or "components" in parsed_content:
                content_type = "learning_bundle"
            elif "mindmap_id" in parsed_content or "root" in parsed_content:
                content_type = "mindmap"
            elif "error" in parsed_content:
                content_type = "error"
            
            logger.info(f"âœ… Detected content_type: {content_type}")
            
            # Step 8: æ›´æ–° memoryï¼ˆä¿å­˜ artifactï¼Œæ„å»ºç”¨æˆ·ç”»åƒï¼‰
            logger.info(f"ğŸ’¾ Saving artifact in stream mode (type: {content_type})")
            
            # ğŸ”¥ è°ƒç”¨ç»Ÿä¸€çš„ _update_memory æ–¹æ³•
            try:
                await self._update_memory(
                    user_id=user_id,
                    session_id=session_id,
                    intent_result=intent_result,
                    skill_result=parsed_content
                )
                logger.info(f"âœ… Artifact saved and memory updated in stream mode")
            except Exception as e:
                logger.error(f"âŒ Failed to save artifact in stream mode: {e}")
                # ä¸ä¸­æ–­æµç¨‹ï¼Œç»§ç»­è¿”å›ç»“æœ
            
            # Step 9: è¿½åŠ åˆ° Conversation Session MD æ–‡ä»¶
            try:
                session_mgr = self.memory_manager.get_conversation_session_manager(user_id)
                await session_mgr.start_or_continue_session(intent_result.raw_text)
                
                await session_mgr.append_turn({
                    "user_query": intent_result.raw_text,
                    "agent_response": {
                        "skill": skill.id,
                        "artifact_id": parsed_content.get("artifact_id", ""),
                        "content": parsed_content
                    },
                    "response_type": content_type,
                    "timestamp": datetime.now(),
                    "intent": intent_result.model_dump(),
                    "metadata": {
                        "thinking_tokens": len(full_thinking.split()),  # ç²—ç•¥ä¼°ç®—
                        "output_tokens": len(full_content.split()),  # ç²—ç•¥ä¼°ç®—
                        "model": skill.models.get("primary", "unknown")
                    }
                })
                logger.debug(f"ğŸ“ Appended turn to conversation session MD (stream mode)")
            except Exception as e:
                logger.error(f"âŒ Failed to append to conversation session (stream): {e}")
            
            # å®Œæˆ
            yield {
                "type": "done",
                "thinking": full_thinking,
                "content": parsed_content,
                "content_type": content_type
            }
            
            logger.info(f"âœ… Stream orchestration complete for {skill.id}")
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ Stream orchestration error: {e}")
            
            # æ£€æµ‹503é”™è¯¯ï¼ˆAPIè¿‡è½½ï¼‰
            if "503" in error_msg or "overloaded" in error_msg.lower() or "unavailable" in error_msg.lower():
                yield {
                    "type": "error",
                    "message": "ğŸ”„ AIæœåŠ¡æš‚æ—¶è¿‡è½½ï¼Œè¯·ç­‰å¾…10-30ç§’åé‡è¯•",
                    "code": 503
                }
            else:
                yield {
                    "type": "error",
                    "message": f"å‘ç”Ÿé”™è¯¯: {error_msg}",
                    "code": 500
                }
    
    async def execute(
        self,
        intent_result: IntentResult,
        user_id: str,
        session_id: str,
        additional_params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„ç¼–æ’æµç¨‹
        
        Args:
            intent_result: æ„å›¾è¯†åˆ«ç»“æœ
            user_id: ç”¨æˆ· ID
            session_id: ä¼šè¯ ID
            additional_params: é¢å¤–å‚æ•°
        
        Returns:
            æŠ€èƒ½æ‰§è¡Œç»“æœ
        """
        logger.info(f"ğŸ¯ Orchestrating: intent={intent_result.intent}, topic={intent_result.topic}, confidence={intent_result.confidence:.2f}")
        
        # ============= Phase 0: æ™ºèƒ½æ¾„æ¸…æœºåˆ¶ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰=============
        
        # ğŸ†• ç½®ä¿¡åº¦è¿‡ä½ï¼šæä¾›æ¾„æ¸…é€‰é¡¹
        if intent_result.confidence < 0.60:  # ç½®ä¿¡åº¦ < 60%
            logger.info(f"âš ï¸ Low confidence ({intent_result.confidence:.2f}), requesting clarification")
            
            session_context = await self.memory_manager.get_session_context(session_id)
            recent_intents = session_context.recent_intents[-5:] if session_context and session_context.recent_intents else []
            
            # æ„å»ºæ„å›¾é€‰é¡¹
            intent_options = []
            intent_labels = {
                "explain_request": {"label": "è§£é‡Šæ¦‚å¿µ", "icon": "ğŸ“–", "description": "è¯¦ç»†è®²è§£ä¸€ä¸ªçŸ¥è¯†ç‚¹"},
                "quiz_request": {"label": "ç»ƒä¹ é¢˜ç›®", "icon": "âœï¸", "description": "ç”Ÿæˆæµ‹è¯•é¢˜"},
                "flashcard_request": {"label": "è®°å¿†é—ªå¡", "icon": "ğŸ—‚ï¸", "description": "ç”Ÿæˆè®°å¿†å¡ç‰‡"},
                "notes": {"label": "å­¦ä¹ ç¬”è®°", "icon": "ğŸ“", "description": "ç”Ÿæˆç»“æ„åŒ–ç¬”è®°"},
                "mindmap": {"label": "æ€ç»´å¯¼å›¾", "icon": "ğŸ§ ", "description": "ç”ŸæˆçŸ¥è¯†å¯¼å›¾"},
            }
            
            # ä¼˜å…ˆæ˜¾ç¤ºæœ€è¿‘ä½¿ç”¨çš„æ„å›¾
            for intent in recent_intents:
                if intent in intent_labels and intent not in [opt["value"] for opt in intent_options]:
                    info = intent_labels[intent]
                    intent_options.append({
                        "type": "intent",
                        "label": info["label"],
                        "value": intent,
                        "icon": info["icon"],
                        "description": info["description"]
                    })
            
            # è¡¥å……å…¶ä»–å¸¸ç”¨æ„å›¾
            for intent, info in intent_labels.items():
                if intent not in [opt["value"] for opt in intent_options]:
                    intent_options.append({
                        "type": "intent",
                        "label": info["label"],
                        "value": intent,
                        "icon": info["icon"],
                        "description": info["description"]
                    })
            
            return {
                "content_type": "clarification_needed",
                "intent": "clarification",
                "response_content": {
                    "question": "æŠ±æ­‰ï¼Œæˆ‘ä¸å¤ªç¡®å®šæ‚¨æƒ³è¦ä»€ä¹ˆã€‚è¯·é€‰æ‹©ä¸€ä¸ªé€‰é¡¹ï¼š",
                    "reason": "low_confidence",
                    "confidence": intent_result.confidence,
                    "options": intent_options[:5],  # æœ€å¤š5ä¸ªé€‰é¡¹
                    "allow_custom_input": True,
                    "custom_input_placeholder": "æˆ–è€…ç”¨å…¶ä»–æ–¹å¼æè¿°æ‚¨çš„éœ€æ±‚...",
                    "original_intent": intent_result.intent,
                    "original_message": intent_result.raw_text
                }
            }
        
        # ============= Phase 0 ç»§ç»­: ä¸»é¢˜ç›¸å…³æ¾„æ¸… =============
        
        # ğŸ¯ æ¾„æ¸…æœºåˆ¶ï¼šå¯¹æ‰€æœ‰éœ€è¦æ˜ç¡®ä¸»é¢˜çš„skillsï¼Œæä¾›å¼•å¯¼æˆ–æ¾„æ¸…
        needs_clarification_intents = [
            "notes", "flashcard_request", "quiz_request", 
            "explain_request", "mindmap", "learning_bundle"
        ]
        
        if intent_result.intent in needs_clarification_intents:
            # è·å– session context
            session_context = await self.memory_manager.get_session_context(session_id)
            artifact_history = []
            
            if session_context:
                artifact_history = session_context.artifact_history or []
            
            # ğŸ¯ å…³é”®ï¼šåªæœ‰å½“topicæ— æ•ˆæ—¶æ‰éœ€è¦æ¾„æ¸…/å¼•å¯¼
            #    å¦‚æœç”¨æˆ·æ˜ç¡®è¯´äº†topicï¼ˆå¦‚"å¾®ç§¯åˆ†"ï¼‰ï¼Œç›´æ¥æ‰§è¡Œï¼Œä¸éœ€è¦å¼•å¯¼
            topic_is_valid = intent_result.topic and len(intent_result.topic) >= 3
            
            # ğŸ†• é¦–æ¬¡è®¿é—® + æ— æ˜ç¡®topicï¼šæä¾›onboardingå¼•å¯¼ï¼ˆ0 tokenæ¶ˆè€—ï¼‰
            if len(artifact_history) == 0 and not topic_is_valid:
                logger.info(f"ğŸ‘‹ First-time user detected, showing onboarding (0 tokens)")
                
                return {
                    "content_type": "onboarding",
                    "intent": intent_result.intent,
                    "response_content": {
                        "welcome": "ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ StudyX Agentï¼",
                        "message": "æˆ‘æ³¨æ„åˆ°æ‚¨è¿˜æ²¡æœ‰å¼€å§‹å­¦ä¹ ä»»ä½•ä¸»é¢˜ã€‚",
                        "suggestions": [
                            {
                                "category": "ç‰©ç†",
                                "topics": ["ç‰›é¡¿å®šå¾‹", "å…‰å­¦", "ç”µç£å­¦", "é‡å­åŠ›å­¦"],
                                "icon": "âš›ï¸"
                            },
                            {
                                "category": "æ•°å­¦",
                                "topics": ["å¾®ç§¯åˆ†", "çº¿æ€§ä»£æ•°", "æ¦‚ç‡è®º", "ç»Ÿè®¡å­¦"],
                                "icon": "ğŸ“"
                            },
                            {
                                "category": "å†å²",
                                "topics": ["äºŒæˆ˜å†å²", "æ–‡è‰ºå¤å…´", "å·¥ä¸šé©å‘½", "å¤ä»£æ–‡æ˜"],
                                "icon": "ğŸ“œ"
                            },
                            {
                                "category": "ç”Ÿç‰©",
                                "topics": ["å…‰åˆä½œç”¨", "ç»†èƒç»“æ„", "é—ä¼ å­¦", "è¿›åŒ–è®º"],
                                "icon": "ğŸ§¬"
                            },
                            {
                                "category": "è®¡ç®—æœº",
                                "topics": ["æ•°æ®ç»“æ„", "ç®—æ³•", "æœºå™¨å­¦ä¹ ", "ç½‘ç»œ"],
                                "icon": "ğŸ’»"
                            }
                        ],
                        "call_to_action": "è¯·å…ˆå‘Šè¯‰æˆ‘æ‚¨æƒ³å­¦ä¹ ä»€ä¹ˆä¸»é¢˜ï¼Œä¾‹å¦‚ï¼šã€Œè®²è®²ç‰›é¡¿ç¬¬äºŒå®šå¾‹ã€æˆ–ã€Œä»€ä¹ˆæ˜¯å…‰åˆä½œç”¨ã€"
                    }
                }
            
            # ğŸ†• å¤šä¸»é¢˜æ¾„æ¸…ï¼šå³ä½¿æœ‰ current_topicï¼Œå¦‚æœæœ‰å¤šä¸ªå†å²ä¸»é¢˜ä¹Ÿåº”è¯¢é—®
            if len(artifact_history) > 0 and not topic_is_valid:
                # æå–æœ€è¿‘çš„ä¸»é¢˜åˆ—è¡¨
                recent_topics = await self._extract_recent_topics(session_id)
                
                # å¦‚æœæœ‰å¤šä¸ªä¸»é¢˜ï¼Œæä¾›æ¾„æ¸…é€‰é¡¹
                if len(recent_topics) >= 2:
                    logger.info(f"â“ Multiple topics detected ({len(recent_topics)} topics), requesting clarification")
                    
                    return {
                        "content_type": "clarification_needed",
                        "intent": intent_result.intent,
                        "response_content": {
                            "question": "æˆ‘æ³¨æ„åˆ°æ‚¨ä¹‹å‰å­¦ä¹ äº†å¤šä¸ªä¸»é¢˜ï¼Œè¯·é—®æ‚¨æƒ³åŸºäºå“ªä¸ªä¸»é¢˜ç»§ç»­ï¼Ÿ",
                            "reason": "topic_ambiguous",
                            "options": [
                                {
                                    "type": "topic",
                                    "label": topic,
                                    "value": topic,
                                    "icon": "ğŸ“š"
                                }
                                for topic in recent_topics[:5]  # æœ€å¤š5ä¸ªé€‰é¡¹
                            ],
                            "allow_custom_input": True,
                            "custom_input_placeholder": "æˆ–è€…è¾“å…¥æ–°çš„ä¸»é¢˜...",
                            "original_intent": intent_result.intent,
                            "original_message": intent_result.raw_text
                        }
                    }
            
            # ğŸ†• å¦‚æœæ¶ˆæ¯ä¸­æ²¡æœ‰æ˜ç¡®ä¸»é¢˜ï¼Œä½†æœ‰ current_topicï¼Œæ£€æŸ¥æ˜¯å¦åº”è¯¥æ¾„æ¸…
            # ç‰¹æ®Šæƒ…å†µï¼šç”¨æˆ·åªè¯´"ç”ŸæˆXå¼ é—ªå¡"ï¼Œæœ‰å¤šä¸ªå†å²ä¸»é¢˜
            if topic_is_valid and len(artifact_history) > 0:
                recent_topics = await self._extract_recent_topics(session_id)
                # å¦‚æœæœ‰3ä¸ªæˆ–æ›´å¤šä¸åŒä¸»é¢˜ï¼Œè€ƒè™‘æ¾„æ¸…
                if len(recent_topics) >= 3:
                    # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦éå¸¸æ¨¡ç³Šï¼ˆæ²¡æœ‰æ˜ç¡®æåˆ°ä¸»é¢˜ï¼‰
                    message_lower = intent_result.raw_text.lower()
                    has_explicit_topic = any(topic in message_lower for topic in recent_topics)
                    
                    if not has_explicit_topic:
                        logger.info(f"â“ Ambiguous request with {len(recent_topics)} topics, requesting clarification")
                        
                        return {
                            "content_type": "clarification_needed",
                            "intent": intent_result.intent,
                            "response_content": {
                                "question": f"æ‚¨æƒ³åŸºäºå“ªä¸ªä¸»é¢˜ç”Ÿæˆï¼Ÿï¼ˆå½“å‰é»˜è®¤ï¼š{intent_result.topic}ï¼‰",
                                "reason": "topic_ambiguous",
                                "options": [
                                    {
                                        "type": "topic",
                                        "label": topic,
                                        "value": topic,
                                        "icon": "ğŸ“š"
                                    }
                                    for topic in recent_topics[:5]
                                ],
                                "allow_custom_input": True,
                                "custom_input_placeholder": "æˆ–è€…è¾“å…¥æ–°çš„ä¸»é¢˜...",
                                "original_intent": intent_result.intent,
                                "original_message": intent_result.raw_text
                            }
                        }
            
            # å¤šä¸»é¢˜æ¾„æ¸…ï¼šåªæœ‰å½“topicæ— æ•ˆä¸”æœ‰å¤šä¸ªä¸»é¢˜æ—¶æ‰è§¦å‘
            if not topic_is_valid and len(artifact_history) > 1:
                # æå–æ‰€æœ‰å·²å­¦ä¹ çš„ä¸»é¢˜
                learned_topics = []
                seen_topics = set()
                for artifact in reversed(artifact_history):  # æœ€æ–°çš„åœ¨å‰
                    topic_val = artifact.topic if hasattr(artifact, 'topic') else artifact.get("topic")
                    artifact_type = artifact.artifact_type if hasattr(artifact, 'artifact_type') else artifact.get("artifact_type", "unknown")
                    
                    if topic_val and topic_val not in seen_topics:
                        seen_topics.add(topic_val)
                        learned_topics.append({
                            "topic": topic_val,
                            "type": artifact_type
                        })
                
                if len(learned_topics) >= 1:
                    logger.info(f"ğŸ’¬ Clarification needed: {len(learned_topics)} topic(s) available, asking user (0 tokens)")
                    
                    # æ ¹æ®ä¸åŒintentç”Ÿæˆä¸åŒçš„é—®é¢˜
                    intent_questions = {
                        "notes": ("åšç¬”è®°", "åš{topic}çš„ç¬”è®°"),
                        "quiz_request": ("ç”Ÿæˆé¢˜ç›®", "ç”Ÿæˆ{topic}çš„é¢˜ç›®"),
                        "flashcard_request": ("ç”Ÿæˆé—ªå¡", "ç”Ÿæˆ{topic}çš„é—ªå¡"),
                        "explain_request": ("è®²è§£", "è®²è§£{topic}"),
                        "mindmap": ("ç”Ÿæˆæ€ç»´å¯¼å›¾", "ç”Ÿæˆ{topic}çš„æ€ç»´å¯¼å›¾"),
                        "learning_bundle": ("è·å–å­¦ä¹ åŒ…", "è·å–{topic}çš„å­¦ä¹ èµ„æ–™")
                    }
                    
                    action_text, example_text = intent_questions.get(
                        intent_result.intent, 
                        ("å­¦ä¹ ", "å­¦ä¹ {topic}")
                    )
                    
                    # è¿”å›æ¾„æ¸…å“åº”ï¼ˆ0 tokenæ¶ˆè€—ï¼‰
                    return {
                        "content_type": "clarification",
                        "intent": intent_result.intent,
                        "response_content": {
                            "question": f"æ‚¨æƒ³å¯¹å“ªä¸ªä¸»é¢˜{action_text}å‘¢ï¼Ÿ",
                            "learned_topics": learned_topics[:5],  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                            "suggestion": f"è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³é€‰æ‹©çš„ä¸»é¢˜ï¼Œä¾‹å¦‚ï¼šã€Œ{example_text.format(topic=learned_topics[0]['topic'])}ã€"
                        }
                    }
        
        # ============= Phase 3: å¤„ç† ambiguous/contextual æ„å›¾ =============
        
        # Step 0.1: å¤„ç†æ¨¡ç³Šæ„å›¾ (éœ€è¦åå¥½æ¨æ–­)
        if intent_result.intent == "ambiguous":
            logger.info("ğŸ”„ Processing ambiguous intent - applying user preference...")
            
            # è·å–ç”¨æˆ·åå¥½ï¼ˆä¸è°ƒç”¨ LLMï¼Œç›´æ¥æŸ¥è¯¢æ•°æ®åº“/å†…å­˜ï¼‰
            user_profile = await self.memory_manager.get_user_profile(user_id)
            
            # ä»ç”¨æˆ·åå¥½ä¸­æå– top preference
            top_preference = "explain"  # é»˜è®¤
            if user_profile and user_profile.preferences:
                # preferences æ˜¯ dict: {"preferred_artifact": "quiz", ...}
                preferred_artifact = user_profile.preferences.get("preferred_artifact")
                if preferred_artifact:
                    top_preference = preferred_artifact
            
            # æ›´æ–° intent ä¸ºç”¨æˆ·åå¥½çš„æŠ€èƒ½
            intent_result.intent = top_preference
            logger.info(f"âœ… Ambiguous intent resolved to: {top_preference} (based on user preference)")
            
            # ğŸ†• æå–å½“å‰å­¦ä¹ ä¸»é¢˜ï¼ˆå¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®štopicï¼Œä½¿ç”¨å½“å‰ä¸»é¢˜ï¼‰
            if not intent_result.topic:
                session_context = await self.memory_manager.get_session_context(session_id)
                if session_context and session_context.current_topic:
                    intent_result.topic = session_context.current_topic
                    logger.info(f"âœ… Ambiguous intent: using current topic: {session_context.current_topic}")
        
        # Step 0.2: å¤„ç†ä¸Šä¸‹æ–‡å¼•ç”¨ (éœ€è¦ä» last_artifact æå–ä¿¡æ¯)
        if intent_result.intent == "contextual":
            logger.info("ğŸ”„ Processing contextual intent - extracting from last artifact...")
            
            # è·å– session contextï¼ˆä¸è°ƒç”¨ LLMï¼Œç›´æ¥è¯»å–å†…å­˜ï¼‰
            session_context = await self.memory_manager.get_session_context(session_id)
            
            # ä» last_artifact æå– topic
            if session_context and session_context.last_artifact:
                # last_artifact æ ¼å¼: "Type: explanation | Topic: ç‰›é¡¿ç¬¬äºŒå®šå¾‹"
                last_artifact = session_context.last_artifact
                
                # ğŸ†• ä¼˜å…ˆä» last_artifact å­—ç¬¦ä¸²æå–ï¼Œå¦‚æœå¤±è´¥åˆ™ä» current_topic æå–
                if " | Topic: " in last_artifact:
                    topic = last_artifact.split(" | Topic: ")[1].strip()
                    intent_result.topic = topic
                    logger.info(f"âœ… Extracted topic from last artifact: {topic}")
                elif session_context.current_topic:
                    # Fallback: å¦‚æœ last_artifact æ²¡æœ‰ topic ä¿¡æ¯ï¼Œä½¿ç”¨ current_topic
                    intent_result.topic = session_context.current_topic
                    logger.info(f"âœ… Using current_topic as fallback: {session_context.current_topic}")
                else:
                    logger.warning("âš ï¸ No topic found in last artifact or current_topic")
                
                # æ ¹æ® last artifact ç±»å‹æ¨æ–­æ„å›¾
                # å¦‚æœä¸Šä¸€è½®æ˜¯ explainï¼Œè¿™ä¸€è½®å¯èƒ½æ˜¯ quiz æˆ– flashcard
                user_profile = await self.memory_manager.get_user_profile(user_id)
                top_preference = "quiz"  # é»˜è®¤
                if user_profile and user_profile.preferences:
                    preferred_artifact = user_profile.preferences.get("preferred_artifact")
                    if preferred_artifact:
                        top_preference = preferred_artifact
                
                intent_result.intent = top_preference
                logger.info(f"âœ… Contextual intent resolved to: {top_preference}")
                
                # æ ‡è®°éœ€è¦ä½¿ç”¨ last_artifact å†…å®¹
                if not intent_result.parameters:
                    intent_result.parameters = {}
                intent_result.parameters['use_last_artifact'] = True
            else:
                logger.warning("âš ï¸ No last artifact found for contextual intent, falling back to 'other'")
                intent_result.intent = "other"
        
        # ============= End Phase 3 Processing =============
        
        # Step 1: é€‰æ‹©æŠ€èƒ½
        skill = self._select_skill(intent_result)
        if not skill:
            return self._create_error_response(
                "no_skill_found",
                f"æœªæ‰¾åˆ°åŒ¹é…æ„å›¾ '{intent_result.intent}' çš„æŠ€èƒ½"
            )
        
        logger.info(f"ğŸ“¦ Selected skill: {skill.id} ({skill.display_name})")
        
        # ğŸ†• Step 1.5: æ£€æŸ¥æ˜¯å¦ä¸º Plan Skill
        if skill.skill_type == "plan":
            logger.info(f"ğŸ¯ Detected Plan Skill: {skill.id}")
            return await self._execute_plan_skill(
                skill=skill,
                intent_result=intent_result,
                user_id=user_id,
                session_id=session_id,
                additional_params=additional_params
            )
        
        # Step 2: è·å–ä¸Šä¸‹æ–‡
        context = await self._build_context(skill, user_id, session_id)
        
        # Step 3: æ„å»ºè¾“å…¥å‚æ•°
        params = self._build_input_params(skill, intent_result, context, additional_params)
        
        # Step 4: æ‰§è¡ŒæŠ€èƒ½
        try:
            response = await self._execute_skill(skill, params, context)
            # ğŸ†• response æ˜¯å­—å…¸: {"content": str, "thinking": str, "usage": dict}
            
            # æå–å†…å®¹
            result_json = response.get("content", response) if isinstance(response, dict) else response
            thinking = response.get("thinking") if isinstance(response, dict) else None
            usage = response.get("usage", {}) if isinstance(response, dict) else {}
            
            # è§£æ JSON
            result = json.loads(result_json) if isinstance(result_json, str) else result_json
            
            # ğŸ†• å°†æ€è€ƒè¿‡ç¨‹æ·»åŠ åˆ°ç»“æœä¸­
            if thinking:
                result["_thinking"] = thinking
                result["_usage"] = usage
                logger.info(f"ğŸ§  Thinking process included: {len(thinking)} chars")
            
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"âŒ Failed to parse skill result JSON: {e}")
            return self._create_error_response("json_parse_error", f"Invalid JSON response: {str(e)}")
        except Exception as e:
            logger.error(f"âŒ Skill execution failed: {e}")
            return self._create_error_response("execution_error", str(e))
        
        # Step 5: å°è£…è¾“å‡ºï¼ˆä¼ å…¥ intent_resultï¼‰
        output = self._wrap_output(skill, result, intent_result)
        
        # Step 6: æ›´æ–°è®°å¿†ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ï¼‰
        await self._update_memory(user_id, session_id, intent_result, result)
        
        # Step 7: è¿½åŠ åˆ° Conversation Session MD æ–‡ä»¶
        try:
            session_mgr = self.memory_manager.get_conversation_session_manager(user_id)
            await session_mgr.start_or_continue_session(intent_result.raw_text)
            
            await session_mgr.append_turn({
                "user_query": intent_result.raw_text,
                "agent_response": {
                    "skill": skill.id,
                    "artifact_id": result.get("artifact_id", ""),
                    "content": result
                },
                "response_type": output.get("content_type", "unknown"),
                "timestamp": datetime.now(),
                "intent": intent_result.model_dump(),
                "metadata": {
                    "thinking_tokens": result.get("_usage", {}).get("thinking_tokens", 0),
                    "output_tokens": result.get("_usage", {}).get("output_tokens", 0),
                    "model": skill.models.get("primary", "unknown")
                }
            })
            logger.debug(f"ğŸ“ Appended turn to conversation session MD")
        except Exception as e:
            logger.error(f"âŒ Failed to append to conversation session: {e}")
        
        logger.info(f"âœ… Orchestration complete for {skill.id}")
        return output
    
    def _select_skill(self, intent_result: IntentResult) -> Optional[SkillDefinition]:
        """
        æ ¹æ®æ„å›¾é€‰æ‹©åˆé€‚çš„æŠ€èƒ½
        
        Args:
            intent_result: æ„å›¾è¯†åˆ«ç»“æœ
        
        Returns:
            é€‰ä¸­çš„ Skill å®šä¹‰ï¼Œæˆ– None
        """
        # è·å–åŒ¹é…çš„ skills
        intent = intent_result.intent
        if isinstance(intent, list):
            intent = intent[0]  # å–ç¬¬ä¸€ä¸ªæ„å›¾
        
        matching_skills = self.skill_registry.get_skills_by_intent(intent)
        
        if not matching_skills:
            logger.warning(f"âš ï¸  No skill found for intent: {intent}")
            return None
        
        # ç®€å•ç­–ç•¥ï¼šå–ç¬¬ä¸€ä¸ª
        # TODO: å¯ä»¥å®ç°æ›´å¤æ‚çš„é€‰æ‹©ç­–ç•¥ï¼ˆåŸºäºä¸Šä¸‹æ–‡ã€ç”¨æˆ·åå¥½ç­‰ï¼‰
        return matching_skills[0]
    
    async def _build_context(
        self,
        skill: SkillDefinition,
        user_id: str,
        session_id: str
    ) -> Dict[str, Any]:
        """
        æ„å»ºæŠ€èƒ½æ‰§è¡Œæ‰€éœ€çš„ä¸Šä¸‹æ–‡
        
        åŒ…æ‹¬ï¼š
        1. ç”¨æˆ·ç”»åƒå’Œä¼šè¯ä¸Šä¸‹æ–‡
        2. æœ€è¿‘çš„ artifactsï¼ˆç”¨äºä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼‰
        3. Memory summaryï¼ˆè¡Œä¸ºæ€»ç»“ï¼‰
        
        Args:
            skill: Skill å®šä¹‰
            user_id: ç”¨æˆ· ID
            session_id: ä¼šè¯ ID
        
        Returns:
            ä¸Šä¸‹æ–‡å­—å…¸
        """
        context = {}
        
        # æ ¹æ® skill çš„ context é…ç½®è·å–å¿…è¦çš„ä¸Šä¸‹æ–‡
        if skill.context.get("need_user_memory", False):
            user_profile = await self.memory_manager.get_user_profile(user_id)
            session_context = await self.memory_manager.get_session_context(session_id)
            memory_summary = await self.memory_manager.generate_memory_summary(user_id, session_id)
            
            context["user_profile"] = user_profile.model_dump()
            context["session_context"] = session_context.model_dump()
            context["memory_summary"] = memory_summary.recent_behavior
            
            # ğŸ”¥ åŠ è½½æœ€è¿‘çš„ artifactsï¼ˆæ„å»ºä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼‰
            try:
                recent_artifacts = []
                if session_context.artifact_history:
                    # è·å–æœ€è¿‘çš„ 3 ä¸ª artifacts
                    recent_artifact_ids = session_context.artifact_history[-3:]
                    
                    for artifact_id in recent_artifact_ids:
                        artifact_content = await self.memory_manager.get_artifact(artifact_id)
                        if artifact_content:
                            recent_artifacts.append({
                                "artifact_id": artifact_id,
                                "content": artifact_content
                            })
                
                context["recent_artifacts"] = recent_artifacts
                logger.info(f"ğŸ“š Loaded {len(recent_artifacts)} recent artifacts for context")
                
            except Exception as e:
                logger.warning(f"âš ï¸  Failed to load recent artifacts: {e}")
                context["recent_artifacts"] = []
        
        # TODO: å¦‚æœéœ€è¦ content_storeï¼Œä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³å†…å®¹
        if skill.context.get("need_content_store", False):
            context["content_context"] = []  # å ä½ç¬¦
        
        return context
    
    def _build_input_params(
        self,
        skill: SkillDefinition,
        intent_result: IntentResult,
        context: Dict[str, Any],
        additional_params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ„å»ºæŠ€èƒ½çš„è¾“å…¥å‚æ•°
        
        Args:
            skill: Skill å®šä¹‰
            intent_result: æ„å›¾ç»“æœ
            context: ä¸Šä¸‹æ–‡
            additional_params: é¢å¤–å‚æ•°
        
        Returns:
            è¾“å…¥å‚æ•°å­—å…¸
        """
        params = {}
        
        # ä» intent_result æå–åŸºæœ¬å‚æ•°ï¼Œå¹¶éªŒè¯ topic æœ‰æ•ˆæ€§
        topic = intent_result.topic
        topic_is_valid = False
        
        if topic:
            # éªŒè¯ topic æ˜¯å¦æœ‰æ•ˆï¼ˆé•¿åº¦ >= 2ï¼Œä¸”ä¸æ˜¯çº¯æ•°å­—/åºæ•°è¯ï¼‰
            invalid_topics = ["ç¬¬ä¸€", "ç¬¬äºŒ", "ç¬¬ä¸‰", "è¿™", "é‚£", "å®ƒ", "è¿™ä¸ª", "é‚£ä¸ª"]
            if len(topic) >= 2 and topic not in invalid_topics and not topic.isdigit():
                params["topic"] = topic
                topic_is_valid = True
            else:
                logger.info(f"âš ï¸  Invalid topic detected: '{topic}', will use fallback")
        
        # ğŸ†• Topic Fallback ç­–ç•¥
        if not topic_is_valid:
            if "session_context" in context:
                session_ctx = context["session_context"]
                current_topic = None
                artifact_history = []
                
                if isinstance(session_ctx, dict):
                    current_topic = session_ctx.get('current_topic')
                    artifact_history = session_ctx.get('artifact_history', [])
                else:
                    current_topic = getattr(session_ctx, 'current_topic', None)
                    artifact_history = getattr(session_ctx, 'artifact_history', [])
                
                # ğŸ¯ æ³¨æ„ï¼šæ¾„æ¸…æœºåˆ¶å·²ç»åœ¨ execute() æ–¹æ³•å¼€å§‹æ—¶å¤„ç†
                #    å¦‚æœæ‰§è¡Œåˆ°è¿™é‡Œï¼Œè¯´æ˜ä¸éœ€è¦æ¾„æ¸…ï¼Œç›´æ¥ä½¿ç”¨ current_topic fallback
                
                # æ ‡å‡† fallback: ä½¿ç”¨ current_topic
                if current_topic:
                    params["topic"] = current_topic
                    logger.info(f"ğŸ“ Topic fallback: using session current_topic = {current_topic}")
                else:
                    logger.warning(f"âš ï¸  No valid topic found in intent_result or session_context for {skill.id}")
        
        # æ·»åŠ  memory_summary
        if "memory_summary" in context:
            params["memory_summary"] = context["memory_summary"]
        
        # V1.5: æ£€æŸ¥æ˜¯å¦éœ€è¦å¼•ç”¨ä¸Šä¸€è½® artifact
        if hasattr(intent_result, 'parameters') and intent_result.parameters:
            use_last_artifact = intent_result.parameters.get('use_last_artifact', False)
            if use_last_artifact and "session_context" in context:
                session_ctx = context["session_context"]
                # session_ctx å¯èƒ½æ˜¯å­—å…¸ï¼ˆmodel_dumpåï¼‰æˆ–å¯¹è±¡
                if isinstance(session_ctx, dict):
                    last_artifact_content = session_ctx.get('last_artifact_content')
                else:
                    last_artifact_content = getattr(session_ctx, 'last_artifact_content', None)
                
                if last_artifact_content:
                    # ğŸ†• æ™ºèƒ½æå–ï¼šåŸºäºIntent Routerè¯†åˆ«çš„å¼•ç”¨ç±»å‹æå–å†…å®¹
                    import json
                    
                    # ğŸ†• ä¼˜å…ˆä» artifact_history ä¸­æœç´¢ï¼ˆæ”¯æŒå¤šè½®å¼•ç”¨ï¼‰
                    artifact_history = getattr(session_ctx, 'artifact_history', []) if not isinstance(session_ctx, dict) else session_ctx.get('artifact_history', [])
                    
                    source_content = last_artifact_content
                    reference_type = intent_result.parameters.get("reference_type")
                    reference_index = intent_result.parameters.get("reference_index")
                    reference_description = intent_result.parameters.get("reference_description")
                    
                    # ğŸ” å¦‚æœæœ‰reference_descriptionï¼Œå°è¯•ä»å†å²ä¸­æœç´¢åŒ¹é…çš„artifact
                    if reference_description and artifact_history:
                        matched_artifact = self._search_artifact_history(artifact_history, reference_description)
                        if matched_artifact:
                            source_content = matched_artifact.content
                            logger.info(f"ğŸ” Found matching artifact in history: #{matched_artifact.turn_number} ({matched_artifact.artifact_type})")
                        else:
                            logger.info(f"â„¹ï¸  No match found in history for '{reference_description}', using last_artifact")
                    
                    # 1ï¸âƒ£ å¼•ç”¨ç‰¹å®šé¢˜ç›®ï¼ˆæ˜ç¡®åºå·ï¼‰
                    if reference_type == "question" and isinstance(reference_index, int):
                        if isinstance(last_artifact_content, dict) and "questions" in last_artifact_content:
                            questions = last_artifact_content["questions"]
                            if 1 <= reference_index <= len(questions):
                                specific_question = questions[reference_index - 1]
                                source_content = {
                                    "quiz_set_id": last_artifact_content.get("quiz_set_id"),
                                    "subject": last_artifact_content.get("subject"),
                                    "specific_question": specific_question,
                                    "question_number": reference_index
                                }
                                logger.info(f"âœ¨ LLM detected: Extract question #{reference_index} from quiz_set")
                    
                    # 2ï¸âƒ£ å¼•ç”¨ç‰¹å®šä¾‹å­ï¼ˆæ˜ç¡®åºå·ï¼‰
                    elif reference_type == "example" and isinstance(reference_index, int):
                        if isinstance(last_artifact_content, dict) and "examples" in last_artifact_content:
                            examples = last_artifact_content["examples"]
                            if 1 <= reference_index <= len(examples):
                                specific_example = examples[reference_index - 1]
                                source_content = {
                                    "concept": last_artifact_content.get("concept"),
                                    "subject": last_artifact_content.get("subject"),
                                    "specific_example": specific_example,
                                    "example_number": reference_index,
                                    "all_examples": examples  # ä¿ç•™ä¸Šä¸‹æ–‡
                                }
                                logger.info(f"âœ¨ LLM detected: Extract example #{reference_index} from explanation")
                    
                    # 3ï¸âƒ£ å¼•ç”¨æ‰€æœ‰ä¾‹å­
                    elif reference_type == "examples" and reference_index == "all":
                        if isinstance(last_artifact_content, dict) and "examples" in last_artifact_content:
                            source_content = {
                                "concept": last_artifact_content.get("concept"),
                                "subject": last_artifact_content.get("subject"),
                                "all_examples": last_artifact_content["examples"]
                            }
                            logger.info(f"âœ¨ LLM detected: Use all {len(last_artifact_content['examples'])} examples")
                    
                    # 4ï¸âƒ£ å¼•ç”¨ç‰¹å®šå†…å®¹ï¼ˆè¯­ä¹‰æœç´¢ï¼‰
                    elif reference_type == "content" and reference_description:
                        # ğŸ” åœ¨last_artifact_contentä¸­æœç´¢åŒ…å«reference_descriptionçš„å†…å®¹
                        extracted_content = self._semantic_search_content(
                            last_artifact_content, 
                            reference_description
                        )
                        if extracted_content:
                            source_content = extracted_content
                            logger.info(f"âœ¨ LLM detected: Extract content matching '{reference_description}'")
                        else:
                            logger.warning(f"âš ï¸  Could not find content matching '{reference_description}', using full content")
                    
                    # 5ï¸âƒ£ å¼•ç”¨æ•´ä¸ªartifactï¼ˆé»˜è®¤ï¼‰
                    elif reference_type == "last_artifact" or not reference_type:
                        logger.info(f"âœ¨ Using full last_artifact_content as source")
                    
                    # å°†å†…å®¹ä½œä¸º source_content ä¼ é€’ç»™ skill
                    if isinstance(source_content, dict):
                        params["source_content"] = json.dumps(source_content, ensure_ascii=False, indent=2)
                    else:
                        params["source_content"] = str(source_content)
                    logger.info(f"ğŸ“ Prepared source_content for {skill.id}")
        
        # ğŸ†• V1.7: æå– quantity å‚æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨å…·ä½“å‚æ•°åï¼‰
        if hasattr(intent_result, 'parameters') and intent_result.parameters:
            quantity = None
            
            # æ ¹æ®ä¸åŒçš„ skill ä¼˜å…ˆæŸ¥æ‰¾å¯¹åº”çš„å‚æ•°
            if skill.id == 'quiz_skill':
                # ä¼˜å…ˆæŸ¥æ‰¾ num_questionsï¼Œç„¶åæ˜¯ quantity
                quantity = intent_result.parameters.get('num_questions') or intent_result.parameters.get('quantity')
                if quantity is None:
                    quantity = 5  # é»˜è®¤ 5 é“é¢˜
                params['num_questions'] = quantity
                logger.info(f"ğŸ“Š Quiz quantity: {quantity}")
                
            elif skill.id == 'flashcard_skill':
                # ä¼˜å…ˆæŸ¥æ‰¾ num_cardsï¼Œç„¶åæ˜¯ quantity
                quantity = intent_result.parameters.get('num_cards') or intent_result.parameters.get('quantity')
                if quantity is None:
                    quantity = 5  # é»˜è®¤ 5 å¼ å¡
                params['num_cards'] = quantity
                logger.info(f"ğŸ“Š Flashcard quantity: {quantity}")
        
        # ğŸ”¥ åˆå¹¶æ‰€æœ‰ intent parameters (é™¤äº†å·²ç»è¢«å¤„ç†çš„)
        # è¿™ç¡®ä¿ Plan Skill å¯ä»¥æ¥æ”¶ flashcard_quantity, quiz_quantity ç­‰è‡ªå®šä¹‰å‚æ•°
        # âš ï¸  åªåˆå¹¶éç©ºå€¼ï¼Œé¿å…ä¼ é€’ None æˆ–ç©ºå­—ç¬¦ä¸²å¯¼è‡´åç»­å¤„ç†é”™è¯¯
        if hasattr(intent_result, 'parameters') and intent_result.parameters:
            for key, value in intent_result.parameters.items():
                # è¿‡æ»¤æ‰ Noneã€ç©ºå­—ç¬¦ä¸²ã€ç©ºåˆ—è¡¨ç­‰æ— æ•ˆå€¼
                if value is not None and value != "" and value != [] and key not in params:
                    params[key] = value
        
        # æ·»åŠ ç”¨æˆ·æä¾›çš„é¢å¤–å‚æ•°
        if additional_params:
            params.update(additional_params)
        
        return params
    
    def _search_artifact_history(
        self,
        artifact_history: List[Any],
        keyword: str
    ) -> Optional[Any]:
        """
        åœ¨artifact_historyä¸­æœç´¢åŒ…å«keywordçš„artifact
        
        Args:
            artifact_history: artifactå†å²è®°å½•åˆ—è¡¨
            keyword: æœç´¢å…³é”®è¯
        
        Returns:
            åŒ¹é…çš„ArtifactRecordï¼Œå¦‚æœæ²¡æ‰¾åˆ°è¿”å›None
        """
        import json
        
        keyword_lower = keyword.lower()
        
        # ä»æœ€æ–°åˆ°æœ€æ—§æœç´¢
        for artifact in reversed(artifact_history):
            # 1. æœç´¢summary
            if hasattr(artifact, 'summary') and artifact.summary:
                if keyword_lower in artifact.summary.lower():
                    logger.info(f"ğŸ¯ Keyword '{keyword}' found in artifact #{artifact.turn_number} summary")
                    return artifact
            
            # 2. æœç´¢topic
            if hasattr(artifact, 'topic') and artifact.topic:
                if keyword_lower in artifact.topic.lower():
                    logger.info(f"ğŸ¯ Keyword '{keyword}' found in artifact #{artifact.turn_number} topic")
                    return artifact
            
            # 3. æœç´¢content
            if hasattr(artifact, 'content'):
                content_str = json.dumps(artifact.content, ensure_ascii=False).lower()
                if keyword_lower in content_str:
                    logger.info(f"ğŸ¯ Keyword '{keyword}' found in artifact #{artifact.turn_number} content")
                    return artifact
        
        return None
    
    def _semantic_search_content(
        self,
        content: Dict[str, Any],
        keyword: str
    ) -> Optional[Dict[str, Any]]:
        """
        åœ¨contentä¸­æœç´¢åŒ…å«keywordçš„éƒ¨åˆ†ï¼ˆç®€å•çš„å…³é”®è¯åŒ¹é…ï¼‰
        
        Args:
            content: è¦æœç´¢çš„å†…å®¹ï¼ˆlast_artifact_contentï¼‰
            keyword: æœç´¢å…³é”®è¯ï¼ˆå¦‚ "åŒ—æå†°å·"ã€"æ¸©å®¤æ•ˆåº”"ï¼‰
        
        Returns:
            åŒ¹é…çš„å†…å®¹ï¼Œå¦‚æœæ²¡æ‰¾åˆ°è¿”å›None
        """
        import json
        
        # å°†contentè½¬ä¸ºå­—ç¬¦ä¸²ä¾¿äºæœç´¢
        content_str = json.dumps(content, ensure_ascii=False).lower()
        keyword_lower = keyword.lower()
        
        # 1. åœ¨examplesä¸­æœç´¢
        if "examples" in content and isinstance(content["examples"], list):
            for idx, example in enumerate(content["examples"]):
                example_str = json.dumps(example, ensure_ascii=False).lower()
                if keyword_lower in example_str:
                    logger.info(f"ğŸ” Found keyword '{keyword}' in example #{idx+1}")
                    return {
                        "concept": content.get("concept"),
                        "subject": content.get("subject"),
                        "specific_example": example,
                        "example_number": idx + 1,
                        "matched_keyword": keyword,
                        "all_examples": content["examples"]
                    }
        
        # 2. åœ¨questionsä¸­æœç´¢
        if "questions" in content and isinstance(content["questions"], list):
            for idx, question in enumerate(content["questions"]):
                question_str = json.dumps(question, ensure_ascii=False).lower()
                if keyword_lower in question_str:
                    logger.info(f"ğŸ” Found keyword '{keyword}' in question #{idx+1}")
                    return {
                        "quiz_set_id": content.get("quiz_set_id"),
                        "subject": content.get("subject"),
                        "specific_question": question,
                        "question_number": idx + 1,
                        "matched_keyword": keyword
                    }
        
        # 3. åœ¨flashcardsä¸­æœç´¢
        if "flashcards" in content and isinstance(content["flashcards"], list):
            matched_cards = []
            for idx, card in enumerate(content["flashcards"]):
                card_str = json.dumps(card, ensure_ascii=False).lower()
                if keyword_lower in card_str:
                    matched_cards.append(card)
            
            if matched_cards:
                logger.info(f"ğŸ” Found keyword '{keyword}' in {len(matched_cards)} flashcard(s)")
                return {
                    "flashcard_set_id": content.get("flashcard_set_id"),
                    "subject": content.get("subject"),
                    "matched_flashcards": matched_cards,
                    "matched_keyword": keyword
                }
        
        # 4. æ²¡æ‰¾åˆ°ï¼Œè¿”å›None
        logger.warning(f"âš ï¸  Keyword '{keyword}' not found in content")
        return None
    
    async def _execute_plan_skill(
        self,
        skill: SkillDefinition,
        intent_result: IntentResult,
        user_id: str,
        session_id: str,
        additional_params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œ Plan Skillï¼ˆä¸²è”è°ƒç”¨å¤šä¸ª skillsï¼‰
        
        Args:
            skill: Plan Skill å®šä¹‰
            intent_result: æ„å›¾ç»“æœ
            user_id: ç”¨æˆ· ID
            session_id: ä¼šè¯ ID
            additional_params: é¢å¤–å‚æ•°
        
        Returns:
            å­¦ä¹ åŒ…ç»“æœ
        """
        from .plan_skill_executor import PlanSkillExecutor
        
        logger.info(f"\n{'='*70}")
        logger.info(f"ğŸ¯ å¼€å§‹æ‰§è¡Œ Plan Skill: {skill.id}")
        logger.info(f"{'='*70}\n")
        
        # è·å–ç”¨æˆ·ç”»åƒå’Œä¼šè¯ä¸Šä¸‹æ–‡
        user_profile = await self.memory_manager.get_user_profile(user_id)
        session_context = await self.memory_manager.get_session_context(session_id)
        
        # ç”Ÿæˆ memory summary
        memory_summary = await self.memory_manager.generate_memory_summary(user_id, session_id)
        
        # æ„å»ºç”¨æˆ·è¾“å…¥
        user_input = {
            "subject": intent_result.parameters.get("subject") if intent_result.parameters else None,
            "topic": intent_result.topic,
            "difficulty": intent_result.parameters.get("difficulty", "medium") if intent_result.parameters else "medium",
            "memory_summary": memory_summary.recent_behavior  # ğŸ”§ ä½¿ç”¨ generate_memory_summary ç»“æœ
        }
        
        # ğŸ”¥ å°†æ‰€æœ‰ intent parameters åˆå¹¶åˆ° user_inputï¼Œç¡®ä¿ Plan Skill å¯ä»¥è®¿é—®æ‰€æœ‰æå–çš„å‚æ•°
        # (ä¾‹å¦‚ flashcard_quantity, quiz_quantity ç­‰)
        # âš ï¸  åªåˆå¹¶éç©ºå€¼ï¼Œé¿å…ä¼ é€’ None æˆ–ç©ºå­—ç¬¦ä¸²å¯¼è‡´åç»­å¤„ç†é”™è¯¯
        if intent_result.parameters:
            for key, value in intent_result.parameters.items():
                # è¿‡æ»¤æ‰ Noneã€ç©ºå­—ç¬¦ä¸²ã€ç©ºåˆ—è¡¨ç­‰æ— æ•ˆå€¼
                if value is not None and value != "" and value != [] and key not in user_input:
                    user_input[key] = value
                    logger.debug(f"ğŸ“ Merged parameter from intent: {key}={value}")
        
        # å¦‚æœ subject ä¸ºç©ºï¼Œå°è¯•ä» topic ä¸­æå–
        if not user_input.get("subject") and intent_result.topic:
            # ç®€å•æå–ï¼šå‡è®¾ topic å¯èƒ½åŒ…å«å­¦ç§‘ä¿¡æ¯
            user_input["subject"] = "é€šç”¨"
        
        # ğŸ› DEBUG: Log final user_input before executing plan
        logger.debug(f"ğŸ“¥ Final user_input for Plan Skill: {user_input}")
        
        # åˆ›å»º Plan Skill æ‰§è¡Œå™¨
        executor = PlanSkillExecutor(skill_orchestrator=self)
        
        # æ‰§è¡Œè®¡åˆ’
        try:
            bundle = await executor.execute_plan(
                plan_config=skill.raw_config,  # ğŸ†• ä½¿ç”¨åŸå§‹é…ç½®
                user_input=user_input,
                user_profile=user_profile,
                session_context=session_context
            )
            
            # å°è£…è¾“å‡º
            output = {
                "skill_id": skill.id,
                "content_type": "learning_bundle",
                "response_content": bundle,
                "intent": intent_result.intent
            }
            
            # æ›´æ–°è®°å¿†ï¼ˆä¿å­˜å­¦ä¹ åŒ…åˆ° artifact_historyï¼‰
            await self._update_memory(user_id, session_id, intent_result, bundle)
            
            logger.info(f"âœ… Plan Skill æ‰§è¡Œå®Œæˆ: {skill.id}")
            
            return output
            
        except Exception as e:
            logger.error(f"âŒ Plan Skill æ‰§è¡Œå¤±è´¥: {e}")
            logger.exception(e)
            return self._create_error_response(
                "plan_execution_error",
                f"å­¦ä¹ åŒ…ç”Ÿæˆå¤±è´¥: {str(e)}"
            )
    
    async def _execute_single_skill(
        self,
        skill_id: str,
        input_params: Dict[str, Any],
        user_profile: Any,
        session_context: Any
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ª skillï¼ˆä¾› PlanSkillExecutor è°ƒç”¨ï¼‰
        
        Args:
            skill_id: Skill ID
            input_params: è¾“å…¥å‚æ•°
            user_profile: ç”¨æˆ·ç”»åƒ
            session_context: ä¼šè¯ä¸Šä¸‹æ–‡
        
        Returns:
            Skill æ‰§è¡Œç»“æœ
        """
        # ä» registry è·å– skillï¼ˆä½¿ç”¨å…¬å…±æ–¹æ³•ï¼‰
        skill = self.skill_registry.get_skill(skill_id)
        
        if not skill:
            raise ValueError(f"Skill not found: {skill_id}")
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context = {
            "user_profile": user_profile,
            "session_context": session_context
        }
        
        # æ‰§è¡Œ skill
        response = await self._execute_skill(skill, input_params, context)
        
        # ğŸ†• response æ˜¯å­—å…¸: {"content": str, "thinking": str, "usage": dict}
        # æå–å†…å®¹
        result_json = response.get("content", response) if isinstance(response, dict) else response
        thinking = response.get("thinking") if isinstance(response, dict) else None
        usage = response.get("usage", {}) if isinstance(response, dict) else {}
        
        # è§£æç»“æœ
        result = json.loads(result_json) if isinstance(result_json, str) else result_json
        
        # ğŸ†• å°†æ€è€ƒè¿‡ç¨‹æ·»åŠ åˆ°ç»“æœä¸­
        if thinking:
            result["_thinking"] = thinking
            result["_usage"] = usage
        
        return result
    
    async def _execute_single_skill_stream(
        self,
        skill_id: str,
        input_params: Dict[str, Any],
        user_profile: Any,
        session_context: Any
    ):
        """
        ğŸ†• æµå¼æ‰§è¡Œå•ä¸ªskillï¼ˆç”¨äºPlan Skillçš„æ¯ä¸ªæ­¥éª¤ï¼‰
        
        Args:
            skill_id: Skill ID
            input_params: è¾“å…¥å‚æ•°
            user_profile: ç”¨æˆ·ç”»åƒ
            session_context: ä¼šè¯ä¸Šä¸‹æ–‡
        
        Yields:
            Dict: æµå¼äº‹ä»¶
        """
        # è·å–skill
        skill = self.skill_registry.get_skill(skill_id)
        if not skill:
            yield {
                "type": "error",
                "message": f"Skill not found: {skill_id}"
            }
            return
        
        # åŠ è½½promptå¹¶æ ¼å¼åŒ–
        prompt_content = self._load_prompt(skill)
        context = {
            "user_profile": user_profile,
            "session_context": session_context
        }
        full_prompt = self._format_prompt(prompt_content, input_params, context)
        
        # æµå¼è°ƒç”¨Kimi
        thinking_accumulated = []
        content_accumulated = []
        
        # è·å– thinking_budgetï¼ˆä¼˜å…ˆä½¿ç”¨ skill é…ç½®ï¼‰
        thinking_budget = getattr(skill, 'thinking_budget', 64)
        logger.info(f"ğŸ¯ Executing sub-skill: {skill_id}, thinking_budget={thinking_budget}")
        
        async for chunk in self.gemini_client.generate_stream(
            prompt=full_prompt,
            model=getattr(skill, 'models', {}).get('primary', 'moonshotai/kimi-k2-thinking'),
            thinking_budget=thinking_budget,
            buffer_size=1,
            temperature=getattr(skill, 'temperature', 1.0)
        ):
            # ç´¯ç§¯æ•°æ®
            if chunk["type"] == "thinking":
                thinking_accumulated.append(chunk.get("text", ""))
            elif chunk["type"] == "content":
                content_accumulated.append(chunk.get("text", ""))
            
            # è½¬å‘chunk
            yield chunk
        
        # è§£ææœ€ç»ˆç»“æœ
        full_thinking = "".join(thinking_accumulated)
        full_content = "".join(content_accumulated)
        
        # æå–JSON
        json_str = full_content
        if "```json" in json_str:
            try:
                json_str = json_str.split("```json")[1].split("```")[0].strip()
            except:
                pass
        elif "```" in json_str:
            try:
                json_str = json_str.split("```")[1].split("```")[0].strip()
            except:
                pass
        
        # è§£æJSON
        try:
            parsed_content = json.loads(json_str)
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Failed to parse JSON: {e}")
            yield {
                "type": "error",
                "message": "ç”Ÿæˆå†…å®¹æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•"
            }
            return
        
        # æ£€æµ‹content_type
        content_type = "unknown"
        if "quiz_set_id" in parsed_content or "questions" in parsed_content:
            content_type = "quiz_set"
        elif "concept" in parsed_content:
            content_type = "explanation"
        elif "card_set_id" in parsed_content or "cards" in parsed_content:
            content_type = "flashcard_set"
        elif "structured_notes" in parsed_content:
            content_type = "notes"
        elif "root" in parsed_content:
            content_type = "mindmap"
        
        # æ„å»ºå®Œæ•´ç»“æœ
        result = {
            "skill_id": skill_id,
            "content_type": content_type,
            **parsed_content
        }
        
        # å‘é€doneäº‹ä»¶ï¼ˆæ ¼å¼ç»Ÿä¸€ï¼šä½¿ç”¨contentå­—æ®µï¼‰
        yield {
            "type": "done",
            "thinking": full_thinking,
            "content": parsed_content,
            "content_type": content_type
        }
    
    async def _execute_skill(
        self,
        skill: SkillDefinition,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ‰§è¡ŒæŠ€èƒ½ï¼ˆè°ƒç”¨ Gemini APIï¼‰- ğŸ†• æ”¯æŒæ€è€ƒæ¨¡å‹
        
        Args:
            skill: Skill å®šä¹‰
            params: è¾“å…¥å‚æ•°
            context: ä¸Šä¸‹æ–‡
        
        Returns:
            Dict[str, Any]: åŒ…å«ä»¥ä¸‹é”®ï¼š
                - "content": ç”Ÿæˆçš„å†…å®¹
                - "thinking": æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
                - "usage": Token ä½¿ç”¨ç»Ÿè®¡
        """
        # åŠ è½½ prompt æ¨¡æ¿
        prompt_content = self._load_prompt(skill)
        
        # æ„å»ºå®Œæ•´ prompt
        full_prompt = self._format_prompt(prompt_content, params, context)
        
        # è°ƒç”¨ Gemini
        model = skill.models.get("primary", "gemini-2.5-flash-lite")  # ğŸ†• ä½¿ç”¨ 2.5 Flash Lite
        thinking_budget = skill.thinking_budget or 1024  # ğŸ†• ä» skill é…ç½®è¯»å–
        
        logger.debug(f"ğŸ¤– Calling Gemini model: {model} (thinking_budget={thinking_budget})")
        
        # ğŸ†• ä½¿ç”¨ generate æ–¹æ³•ï¼ˆè¿”å›å­—å…¸ï¼‰
        response = await self.gemini_client.generate(
            prompt=full_prompt,
            model=model,
            response_format="json",
            thinking_budget=thinking_budget,
            return_thinking=True
        )
        
        # response æ˜¯å­—å…¸: {"content": str, "thinking": str, "usage": dict}
        return response
    
    def _load_prompt(self, skill: SkillDefinition) -> str:
        """
        åŠ è½½ Skill çš„ Prompt æ¨¡æ¿
        
        Args:
            skill: Skill å®šä¹‰
        
        Returns:
            Prompt å†…å®¹
        """
        if not skill.prompt_file:
            raise ValueError(f"Skill {skill.id} has no prompt_file configured")
        
        prompt_path = os.path.join(self.prompts_dir, skill.prompt_file)
        
        if not os.path.exists(prompt_path):
            raise FileNotFoundError(f"Prompt file not found: {prompt_path}")
        
        with open(prompt_path, 'r', encoding='utf-8') as f:
            return f.read()
    
    def _format_prompt(
        self,
        prompt_template: str,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> str:
        """
        æ ¼å¼åŒ– Promptï¼ˆå°†å‚æ•°å¡«å…¥æ¨¡æ¿ï¼‰
        
        Args:
            prompt_template: Prompt æ¨¡æ¿
            params: è¾“å…¥å‚æ•°
            context: ä¸Šä¸‹æ–‡
        
        Returns:
            æ ¼å¼åŒ–åçš„ prompt
        """
        import json
        
        # ğŸ”¥ Step 1: æ›¿æ¢ prompt æ¨¡æ¿ä¸­çš„å ä½ç¬¦
        # å‡†å¤‡æ ¼å¼åŒ–å‚æ•°ï¼ˆåŒ…æ‹¬ JSON åºåˆ—åŒ–ï¼‰
        format_params = {}
        for k, v in params.items():
            if v is None:
                format_params[k] = ""  # None æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²
            elif isinstance(v, (dict, list)):
                # å­—å…¸å’Œåˆ—è¡¨åºåˆ—åŒ–ä¸º JSON
                format_params[k] = json.dumps(v, ensure_ascii=False, indent=2)
            else:
                format_params[k] = str(v)
        
        # æ›¿æ¢æ¨¡æ¿ä¸­çš„å ä½ç¬¦
        try:
            formatted = prompt_template.format(**format_params)
        except KeyError as e:
            # å¦‚æœæœ‰ç¼ºå¤±çš„å‚æ•°ï¼Œè®°å½•è­¦å‘Šå¹¶ä½¿ç”¨åŸæ¨¡æ¿
            logger.warning(f"âš ï¸  Prompt æ¨¡æ¿ç¼ºå°‘å‚æ•°: {e}")
            formatted = prompt_template
        
        # ğŸ”¥ Step 2: é™„åŠ å‚æ•° JSONï¼ˆä½œä¸ºå¤‡ç”¨/è°ƒè¯•ä¿¡æ¯ï¼‰
        # è¿‡æ»¤æ‰ None å€¼å’Œä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
        clean_params = {}
        for k, v in params.items():
            if v is not None:
                try:
                    json.dumps(v)
                    clean_params[k] = v
                except (TypeError, ValueError):
                    clean_params[k] = str(v)
        
        params_json = json.dumps(clean_params, ensure_ascii=False, indent=2)
        
        formatted += f"""

## Input Parameters (JSON)

```json
{params_json}
```

Please respond with valid JSON according to the output schema defined above.
"""
        return formatted
    
    def _wrap_output(
        self,
        skill: SkillDefinition,
        result: Dict[str, Any],
        intent_result: IntentResult = None
    ) -> Dict[str, Any]:
        """
        å°è£…è¾“å‡ºç»“æœï¼ˆç»Ÿä¸€å“åº”æ ¼å¼ï¼‰
        
        Args:
            skill: Skill å®šä¹‰
            result: åŸå§‹ç»“æœï¼ˆGemini è¿”å›çš„ JSONï¼‰
            intent_result: æ„å›¾è¯†åˆ«ç»“æœ
        
        Returns:
            å°è£…åçš„ç»“æœï¼ŒåŒ…å« contentã€content_typeã€intentã€skill_id
        """
        # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœ result æ˜¯åˆ—è¡¨ï¼ˆlearning_bundle å¯èƒ½è¿”å›åˆ—è¡¨ï¼‰ï¼ŒåŒ…è£…æˆå­—å…¸
        if isinstance(result, list):
            logger.warning(f"âš ï¸  Skill {skill.id} returned a list instead of dict, wrapping it")
            result = {
                "bundle_id": f"bundle_{datetime.now().strftime('%Y%m%d%H%M%S')}",
                "components": result,
                "subject": intent_result.topic.split("-")[0] if intent_result and intent_result.topic else "é€šç”¨",
                "topic": intent_result.topic if intent_result and intent_result.topic else "å­¦ä¹ èµ„æ–™"
            }
        
        # æ£€æµ‹å†…å®¹ç±»å‹
        content_type = "unknown"
        if "quiz_set_id" in result or "questions" in result:
            content_type = "quiz_set"
        elif "concept" in result or "explanation" in result:
            content_type = "explanation"
        elif "flashcard_set_id" in result or "cards" in result:
            content_type = "flashcard_set"
        elif "notes_id" in result or "structured_notes" in result:
            content_type = "notes"
        elif "bundle_id" in result or "components" in result:
            content_type = "learning_bundle"
        elif "mindmap_id" in result or "root" in result:
            content_type = "mindmap"
        elif "error" in result:
            content_type = "error"
        
        # æå–æ„å›¾
        intent = "unknown"
        if intent_result:
            if isinstance(intent_result.intent, list):
                intent = intent_result.intent[0] if intent_result.intent else "unknown"
            else:
                intent = intent_result.intent
        
        return {
            "content": result,          # å®é™…å†…å®¹ï¼ˆGemini è¿”å›çš„ JSONï¼‰
            "content_type": content_type,  # quiz_set, explanation, error ç­‰
            "intent": intent,           # åŸå§‹æ„å›¾
            "skill_id": skill.id,       # ä½¿ç”¨çš„æŠ€èƒ½ ID
            "skill_name": skill.display_name,
            "success": True
        }
    
    async def _update_memory(
        self,
        user_id: str,
        session_id: str,
        intent_result: IntentResult,
        skill_result: Dict[str, Any]
    ):
        """
        æ›´æ–°ç”¨æˆ·è®°å¿†ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ä¸»æµç¨‹ï¼‰
        
        åŒ…æ‹¬ï¼š
        1. ä¿å­˜ artifact åˆ° S3ï¼ˆæ„å»ºç”¨æˆ·ç”»åƒï¼‰
        2. æ›´æ–° session contextï¼ˆå½“å‰ä¸»é¢˜ã€æ„å›¾å†å²ï¼‰
        3. ç»´æŠ¤ artifact_history å¼•ç”¨é“¾
        
        Args:
            user_id: ç”¨æˆ· ID
            session_id: ä¼šè¯ ID
            intent_result: æ„å›¾ç»“æœ
            skill_result: æŠ€èƒ½ç»“æœ
        """
        try:
            # æ›´æ–°ä¼šè¯ä¸Šä¸‹æ–‡
            session_context = await self.memory_manager.get_session_context(session_id)
            
            # ğŸ†• æ›´æ–°å½“å‰ä¸»é¢˜ï¼ˆåªæœ‰å½“æœ‰æ˜ç¡®ä¸»é¢˜æ—¶ï¼‰
            #     ç®€å•ç­–ç•¥ï¼šå¦‚æœ topic ä¸ä¸º None ä¸”é•¿åº¦>=3ï¼Œå°±è®¤ä¸ºæ˜¯æ˜ç¡®ä¸»é¢˜
            #     æ— éœ€ç¡¬ç¼–ç çš„ invalid_topics åˆ—è¡¨ï¼Œè®©è§„åˆ™å¼•æ“/LLM å†³å®š
            topic = intent_result.topic
            if topic and len(topic) >= 3:
                session_context.current_topic = topic
                logger.info(f"âœ… Updated current_topic to: {topic}")
            elif topic:
                logger.info(f"â­ï¸  Topic too short ({len(topic)} chars), keeping current_topic: {session_context.current_topic}")
                # ä½¿ç”¨ current_topic ä½œä¸º fallback
                topic = session_context.current_topic
            else:
                topic = session_context.current_topic or "æœªçŸ¥ä¸»é¢˜"
            
            # æ·»åŠ æ„å›¾åˆ°å†å²
            intent = intent_result.intent
            if isinstance(intent, list):
                intent = intent[0]
            
            if not session_context.recent_intents:
                session_context.recent_intents = []
            session_context.recent_intents.append(intent)
            
            # ä¿æŒæœ€è¿‘10ä¸ª
            if len(session_context.recent_intents) > 10:
                session_context.recent_intents = session_context.recent_intents[-10:]
            
            # ğŸ”¥ æ ¸å¿ƒï¼šä¿å­˜ artifact åˆ° S3ï¼Œæ„å»ºç”¨æˆ·ç”»åƒ
            try:
                # ç¡®å®š artifact ç±»å‹
                artifact_type_mapping = {
                    "quiz_request": "quiz_set",
                    "flashcard_request": "flashcard_set",
                    "explain_request": "explanation",
                    "notes": "notes",
                    "mindmap": "mindmap",
                    "learning_bundle": "learning_bundle"
                }
                
                artifact_type = artifact_type_mapping.get(intent, intent)
                
                # ç§»é™¤å†…éƒ¨å­—æ®µ
                artifact_content = {k: v for k, v in skill_result.items() if not k.startswith('_')}
                
                # ä¿å­˜åˆ° S3
                artifact_record = await self.memory_manager.save_artifact(
                    session_id=session_id,
                    artifact=artifact_content,
                    artifact_type=artifact_type,
                    topic=topic,
                    user_id=user_id
                )
                
                logger.info(f"âœ… Artifact saved: {artifact_record.artifact_id} (Storage: {artifact_record.storage_type})")
                
                # æ³¨æ„ï¼šartifact_history å·²ç»åœ¨ memory_manager.save_artifact() ä¸­æ›´æ–°äº†
                # è¿™é‡Œä¸éœ€è¦é‡å¤æ·»åŠ ï¼Œåªéœ€è¦è®°å½•æ—¥å¿—
                session_context_updated = await self.memory_manager.get_session_context(session_id)
                logger.info(f"ğŸ“ Artifact history updated: {len(session_context_updated.artifact_history)} artifacts")
                
            except Exception as e:
                logger.error(f"âŒ Failed to save artifact: {e}")
                # ä¸ä¸­æ–­æµç¨‹ï¼Œç»§ç»­æ›´æ–° session context
            
            await self.memory_manager.update_session_context(session_id, session_context)
            
            logger.debug(f"ğŸ“ Memory updated for user {user_id}, session {session_id}")
        
        except Exception as e:
            logger.warning(f"âš ï¸  Failed to update memory: {e}")
    
    async def _extract_recent_topics(self, session_id: str) -> List[str]:
        """
        ä» session context æå–æœ€è¿‘çš„ä¸»é¢˜åˆ—è¡¨
        
        Args:
            session_id: ä¼šè¯ ID
        
        Returns:
            ä¸»é¢˜åˆ—è¡¨ï¼ˆå»é‡ï¼ŒæŒ‰æœ€è¿‘é¡ºåºï¼‰
        """
        try:
            session_context = await self.memory_manager.get_session_context(session_id)
            
            if not session_context or not session_context.artifact_history:
                return []
            
            # ä» artifact_history æå–ä¸»é¢˜
            topics = []
            seen_topics = set()
            
            # å€’åºéå†ï¼ˆæœ€è¿‘çš„ä¼˜å…ˆï¼‰
            for artifact_id in reversed(session_context.artifact_history[-10:]):  # æœ€è¿‘10ä¸ª
                # artifact_id æ ¼å¼: artifact_{type}_{topic}_{timestamp}
                parts = artifact_id.split('_')
                if len(parts) >= 3:
                    # æå– topicï¼ˆå¯èƒ½åŒ…å«å¤šä¸ªéƒ¨åˆ†ï¼‰
                    topic_parts = parts[2:-1]  # æ’é™¤ type å’Œ timestamp
                    if topic_parts:
                        topic = '_'.join(topic_parts)
                        if topic and topic not in seen_topics and topic != "æœªçŸ¥ä¸»é¢˜":
                            topics.append(topic)
                            seen_topics.add(topic)
            
            logger.info(f"ğŸ“š Extracted {len(topics)} recent topics: {topics}")
            return topics
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to extract recent topics: {e}")
            return []
    
    def _create_error_response(self, error_type: str, message: str) -> Dict[str, Any]:
        """
        åˆ›å»ºé”™è¯¯å“åº”
        
        Args:
            error_type: é”™è¯¯ç±»å‹
            message: é”™è¯¯æ¶ˆæ¯
        
        Returns:
            é”™è¯¯å“åº”å­—å…¸
        """
        return {
            "success": False,
            "error": error_type,
            "message": message
        }

