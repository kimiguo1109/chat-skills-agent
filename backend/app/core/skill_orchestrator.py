"""
Skill Orchestrator - æŠ€èƒ½ç¼–æ’å™¨

è´Ÿè´£ï¼š
1. æ„å›¾åˆ°æŠ€èƒ½æ˜ å°„
2. æŠ€èƒ½é€‰æ‹©ç­–ç•¥
3. è¾“å…¥å‚æ•°æ„å»º  
4. æŠ€èƒ½æ‰§è¡Œï¼ˆè°ƒç”¨ Geminiï¼‰
5. è¾“å‡ºå°è£…
6. è®°å¿†æ›´æ–°
"""
import json
import logging
import os
from typing import Dict, Any, Optional, List
from datetime import datetime

from ..models.intent import IntentResult, MemorySummary
from ..models.memory import UserLearningProfile, SessionContext
from ..models.skill import SkillDefinition
try:
    from ..services.gemini import GeminiClient
except ImportError:
    GeminiClient = None
from ..services.kimi import KimiClient  # ğŸ†• å¯¼å…¥ KimiClient
from ..config import settings  # ğŸ†• å¯¼å…¥é…ç½®
from .skill_registry import SkillRegistry, get_skill_registry
from .memory_manager import MemoryManager
from .thinking_mode_selector import ThinkingModeSelector  # ğŸ†• å¯¼å…¥æ™ºèƒ½æ€è€ƒæ¨¡å¼é€‰æ‹©å™¨
from .reference_resolver import get_reference_resolver, ReferenceResolver  # ğŸ†• å¯¼å…¥å¼•ç”¨è§£æå™¨

logger = logging.getLogger(__name__)


class SkillOrchestrator:
    """æŠ€èƒ½ç¼–æ’å™¨ - è°ƒåº¦æ ¸å¿ƒ"""
    
    def __init__(
        self,
        skill_registry: Optional[SkillRegistry] = None,
        gemini_client: Optional[GeminiClient] = None,
        memory_manager: Optional[MemoryManager] = None
    ):
        """
        åˆå§‹åŒ– Skill Orchestrator
        
        Args:
            skill_registry: Skill Registry å®ä¾‹
            gemini_client: Gemini Client å®ä¾‹ï¼ˆå…¼å®¹å‚æ•°ï¼‰
            memory_manager: Memory Manager å®ä¾‹
        """
        self.skill_registry = skill_registry or get_skill_registry()
        
        # ğŸ”§ ä¸´æ—¶é…ç½®ï¼šå…¨éƒ¨ä½¿ç”¨ Geminiï¼ˆå…³é—­ Kimi ä»¥æå‡é€Ÿåº¦ï¼‰
        self.llm_client = gemini_client or GeminiClient()
        logger.info("âœ… Using Gemini Client for ALL LLM operations (Kimi disabled)")
        
        # Gemini Client ä¹ŸæŒ‡å‘åŒä¸€å®ä¾‹
        self.gemini_client = self.llm_client
        logger.info("âœ… All thinking modes use Gemini 2.5 Flash")
        
        # ç¡®ä¿ MemoryManager ä½¿ç”¨ S3ï¼ˆå¦‚æœé…ç½®å¯ç”¨ï¼‰
        self.memory_manager = memory_manager or MemoryManager(use_s3=settings.USE_S3_STORAGE)
        
        # ğŸ†• åˆå§‹åŒ–æ™ºèƒ½æ€è€ƒæ¨¡å¼é€‰æ‹©å™¨
        self.thinking_mode_selector = ThinkingModeSelector()
        
        # Prompt æ–‡ä»¶ç›®å½•
        self.prompts_dir = os.path.join(
            os.path.dirname(os.path.dirname(__file__)),
            "prompts"
        )
        
        logger.info("âœ… SkillOrchestrator initialized with ThinkingModeSelector")
    
    async def execute_stream(
        self,
        intent_result: IntentResult,
        user_id: str,
        session_id: str,
        additional_params: Optional[Dict[str, Any]] = None
    ):
        """
        ğŸ†• æµå¼æ‰§è¡ŒæŠ€èƒ½ï¼ˆå®æ—¶å±•ç¤ºæ€è€ƒè¿‡ç¨‹å’Œç”Ÿæˆå†…å®¹ï¼‰
        
        Args:
            intent_result: æ„å›¾è¯†åˆ«ç»“æœ
            user_id: ç”¨æˆ· ID
            session_id: ä¼šè¯ ID
            additional_params: é¢å¤–å‚æ•°
        
        Yields:
            Dict: æµå¼äº‹ä»¶ {"type": "status|thinking|content|done", ...}
        """
        try:
            logger.info(f"ğŸŒŠ Stream orchestrating: intent={intent_result.intent}, topic={intent_result.topic}")
            
            # ============= Phase -1: å¤„ç† clarification_needed (æµå¼ç‰ˆæœ¬) =============
            
            if intent_result.intent == "clarification_needed":
                reason = intent_result.parameters.get('clarification_reason')
                logger.warning(f"âš ï¸  Clarification needed: {reason}")
                
                # è·å–session context
                session_context = await self.memory_manager.get_session_context(session_id)
                
                if reason == "topic_missing":
                    # Topic ç¼ºå¤±ï¼Œéœ€è¦ç”¨æˆ·æä¾›
                    recent_topics = []
                    if session_context and session_context.artifact_history:
                        recent_topics = [a.topic for a in session_context.artifact_history[-5:] if a.topic]  # æœ€è¿‘5ä¸ªtopics
                    
                    if recent_topics:
                        # æœ‰å†å² topicsï¼Œè®©ç”¨æˆ·é€‰æ‹©
                        yield {
                            "type": "done",
                            "content_type": "clarification_needed",
                            "content": {
                                "question": "æ‚¨æƒ³åŸºäºä»¥ä¸‹å“ªä¸ªä¸»é¢˜ç»§ç»­ï¼Ÿ",
                                "reason": "topic_missing",
                                "options": [
                                    {
                                        "type": "topic",
                                        "label": topic,
                                        "value": topic,
                                        "icon": "ğŸ“š",
                                        "description": f"ç»§ç»­å­¦ä¹ ï¼š{topic}"
                                    }
                                    for topic in recent_topics
                                ],
                                "allow_custom_input": True,
                                "custom_input_placeholder": "æˆ–è¾“å…¥æ–°çš„å­¦ä¹ ä¸»é¢˜..."
                            }
                        }
                    else:
                        # æ²¡æœ‰å†å² topicsï¼Œè¯·æ±‚ç”¨æˆ·è¾“å…¥
                        yield {
                            "type": "done",
                            "content_type": "clarification_needed",
                            "content": {
                                "question": "è¯·é—®æ‚¨æƒ³å­¦ä¹ ä»€ä¹ˆä¸»é¢˜ï¼Ÿ",
                                "reason": "topic_missing",
                                "options": [],
                                "allow_custom_input": True,
                                "custom_input_placeholder": "ä¾‹å¦‚ï¼šå…‰åˆä½œç”¨ã€äºŒæˆ˜å†å²ã€å¾®ç§¯åˆ†..."
                            }
                        }
                    return
                
                elif reason == "multi_topic_insufficient":
                    # ç”¨æˆ·è¯·æ±‚å¤šä¸ª topicsï¼Œä½†å†å²ä¸è¶³
                    yield {
                        "type": "done",
                        "content_type": "clarification_needed",
                        "content": {
                            "question": "æ‚¨æåˆ°äº†å¤šä¸ªä¸»é¢˜ï¼Œä½†æˆ‘æš‚æ—¶åªè®°å½•äº†ä¸€ä¸ªä¸»é¢˜ã€‚å¯ä»¥å‘Šè¯‰æˆ‘å…·ä½“æ˜¯å“ªäº›ä¸»é¢˜å—ï¼Ÿ",
                            "reason": "multi_topic_insufficient",
                            "options": [],
                            "allow_custom_input": True,
                            "custom_input_placeholder": "ä¾‹å¦‚ï¼šå…‰åˆä½œç”¨å’ŒäºŒæˆ˜å†å²"
                        }
                    }
                    return
            
            # ğŸ†• å¤„ç† 'other' intentï¼ˆæ™®é€šå¯¹è¯ï¼‰
            if intent_result.intent == "other":
                logger.info(f"ğŸ’¬ Handling 'other' intent as chat conversation")
                async for chunk in self._handle_chat_stream(intent_result, user_id, session_id):
                    yield chunk
                return
            
            # Step 1: é€‰æ‹©æŠ€èƒ½
            skill = self._select_skill(intent_result)  # ğŸ”§ ä¿®å¤ï¼šä¼ é€’IntentResultå¯¹è±¡
            if not skill:
                yield {
                    "type": "error",
                    "message": f"No skill found for intent: {intent_result.intent}"
                }
                return
            
            # ğŸ”§ æ£€æµ‹Plan Skill - Plan Skillä¸æ”¯æŒæµå¼ï¼ˆæš‚æ—¶å›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼ï¼‰
            logger.debug(f"ğŸ” Checking skill type: skill.id={skill.id}, skill.skill_type={skill.skill_type}")
            
            # ğŸ”§ å¢å¼ºæ£€æµ‹ï¼šæ£€æŸ¥skill_typeæˆ–skill.idï¼ˆé˜²æ­¢skill_typeæœªåŠ è½½ï¼‰
            is_plan_skill = (
                skill.skill_type == "plan" or 
                skill.id == "learning_plan_skill" or
                "plan" in skill.id.lower()
            )
            
            if is_plan_skill:
                # ğŸ†• Plan Skill æµå¼æ‰§è¡Œ
                logger.info(f"ğŸŒŠ Executing Plan Skill in streaming mode")
                
                # åŠ è½½ç”¨æˆ·ç”»åƒå’Œä¼šè¯ä¸Šä¸‹æ–‡
                user_profile = await self.memory_manager.get_user_profile(user_id)
                session_context = await self.memory_manager.get_session_context(session_id)
                
                # æ„å»ºè¾“å…¥å‚æ•°
                context = await self._build_context(skill, user_id, session_id)
                input_params = self._build_input_params(
                    skill, intent_result, context, additional_params
                )
                
                # ä½¿ç”¨PlanSkillExecutoræµå¼æ‰§è¡Œ
                from .plan_skill_executor import PlanSkillExecutor
                plan_executor = PlanSkillExecutor(skill_orchestrator=self)
                
                # æ”¶é›†æœ€ç»ˆç»“æœï¼ˆç”¨äºè¿½åŠ åˆ° MDï¼‰
                final_content = None
                
                async for chunk in plan_executor.execute_plan_stream(
                    plan_config=skill.raw_config,
                    user_input=input_params,
                    user_profile=user_profile,
                    session_context=session_context
                ):
                    # è½¬å‘ç»™å‰ç«¯
                    yield chunk
                    
                    # æ”¶é›†æœ€ç»ˆç»“æœ
                    if chunk.get("type") == "done":
                        final_content = chunk.get("content", {})
                
                # è¿½åŠ åˆ° Conversation Session MD æ–‡ä»¶
                if final_content:
                    try:
                        session_mgr = self.memory_manager.get_conversation_session_manager(user_id)
                        await session_mgr.start_or_continue_session(intent_result.raw_text, session_id=session_id)
                        
                        await session_mgr.append_turn({
                            "user_query": intent_result.raw_text,
                            "agent_response": {
                                "skill": skill.id,
                                "artifact_id": final_content.get("bundle_id", ""),
                                "content": final_content
                            },
                            "response_type": "learning_bundle",
                            "timestamp": datetime.now(),
                            "intent": intent_result.model_dump(),
                            "metadata": {
                                "thinking_tokens": 0,  # Plan Skill æ²¡æœ‰å•ç‹¬çš„ thinking
                                "output_tokens": 0,
                                "model": skill.models.get("primary", "unknown")
                            }
                        })
                        logger.debug(f"ğŸ“ Appended Plan Skill turn to conversation session MD")
                    except Exception as e:
                        logger.error(f"âŒ Failed to append Plan Skill to conversation session: {e}")
                
                return
            
            yield {
                "type": "status",
                "message": f"ä½¿ç”¨ {skill.display_name}"
            }
            
            # Step 2: æ„å»ºä¸Šä¸‹æ–‡
            context = await self._build_context(skill, user_id, session_id)
            
            # Step 3: æ„å»ºè¾“å…¥å‚æ•°
            params = self._build_input_params(
                skill, intent_result, context, additional_params
            )
            
            # ğŸ†• Step 3.1: å¼•ç”¨è§£æï¼ˆå¦‚æœæ¶ˆæ¯åŒ…å«å¯¹å†å² artifacts çš„å¼•ç”¨ï¼‰
            if intent_result.has_reference:
                reference_resolver = get_reference_resolver()
                session_context_for_ref = await self.memory_manager.get_session_context(session_id)
                
                if session_context_for_ref and session_context_for_ref.artifact_history:
                    resolved_refs = reference_resolver.resolve_references(
                        intent_result.raw_text,
                        session_context_for_ref.artifact_history
                    )
                    
                    if resolved_refs:
                        resolved_content = reference_resolver.format_resolved_content(resolved_refs)
                        if resolved_content:
                            params["referenced_content"] = resolved_content
                            logger.info(f"ğŸ”— Resolved {len(resolved_refs)} reference(s): {len(resolved_content)} chars")
                            
                            # ğŸ†• ä½¿ç”¨æ¥æº artifact çš„ topicï¼ˆè€Œé current_topicï¼‰
                            # ä¾‹å¦‚ï¼šç”¨æˆ·è¯´ "æŠŠç¬¬ä¸€å¼ é—ªå¡å‡ºé¢˜"ï¼Œé—ªå¡æ˜¯å…‰åˆä½œç”¨çš„ï¼Œ
                            # å³ä½¿ current_topic æ˜¯ç»†èƒå‘¼å¸ï¼Œä¹Ÿåº”è¯¥ç”¨å…‰åˆä½œç”¨
                            source_topic = resolved_refs[0].source_topic
                            if source_topic:
                                params["topic"] = source_topic
                                intent_result.topic = source_topic  # ğŸ”§ ä¹Ÿæ›´æ–° intent_result
                                logger.info(f"ğŸ”— Using source topic from referenced artifact: {source_topic}")
                            
                            yield {
                                "type": "status",
                                "message": f"ğŸ“ å·²æå–å¼•ç”¨å†…å®¹ (æ¥æº: {source_topic or 'æœªçŸ¥'})"
                            }
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¾„æ¸…
            if not params.get("topic"):
                yield {
                    "type": "clarification_needed",
                    "message": "éœ€è¦æ˜ç¡®å­¦ä¹ ä¸»é¢˜"
                }
                return
            
            # ğŸ†• Step 3.5: å¤šä¸»é¢˜æ¾„æ¸…æ£€æŸ¥ï¼ˆæµå¼ç‰ˆæœ¬ï¼‰
            session_context = await self.memory_manager.get_session_context(session_id)
            
            # ğŸ”§ å¦‚æœå¼•ç”¨å·²ç»è§£ææˆåŠŸï¼Œè·³è¿‡å¤šä¸»é¢˜æ¾„æ¸…
            # å› ä¸ºå¼•ç”¨è§£æå·²ç»ç¡®å®šäº†ç›®æ ‡å†…å®¹çš„ topic
            reference_resolved = params.get("referenced_content") is not None
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªä¸»é¢˜éœ€è¦æ¾„æ¸…
            if not reference_resolved and session_context and session_context.artifact_history:
                recent_topics = await self._extract_recent_topics(session_id)
                
                # å¦‚æœæœ‰ 2+ ä¸ªä¸åŒä¸»é¢˜ï¼Œä¸”ç”¨æˆ·æ²¡æœ‰æ˜ç¡®æŒ‡å®šä¸»é¢˜
                if len(recent_topics) >= 2:
                    # æ£€æŸ¥ç”¨æˆ·æ¶ˆæ¯æ˜¯å¦æ˜ç¡®æåˆ°äº†æŸä¸ªä¸»é¢˜
                    message_lower = intent_result.raw_text.lower()
                    has_explicit_topic = any(topic.lower() in message_lower for topic in recent_topics)
                    
                    if not has_explicit_topic:
                        logger.info(f"â“ Multi-topic clarification needed: {recent_topics}")
                        yield {
                            "type": "done",
                            "content_type": "clarification_needed",
                            "content": {
                                "question": f"æ‚¨æƒ³åŸºäºå“ªä¸ªä¸»é¢˜ç»§ç»­ï¼Ÿ",
                                "reason": "topic_ambiguous",
                                "options": [
                                    {
                                        "type": "topic",
                                        "label": topic,
                                        "value": topic,
                                        "icon": "ğŸ“š"
                                    }
                                    for topic in recent_topics[:5]
                                ],
                                "allow_custom_input": True,
                                "custom_input_placeholder": "æˆ–è€…è¾“å…¥æ–°çš„ä¸»é¢˜...",
                                "original_intent": intent_result.intent,
                                "original_message": intent_result.raw_text
                            }
                        }
                        return
            elif reference_resolved:
                logger.info(f"âœ… Reference resolved, skipping multi-topic clarification")
            
            # ğŸ†• Step 3.6: æ™ºèƒ½é€‰æ‹©æ€è€ƒæ¨¡å¼
            thinking_config = self.thinking_mode_selector.select_mode(
                intent_result=intent_result,
                session_context=session_context
            )
            
            # ğŸ”§ ä¸´æ—¶é…ç½®ï¼šå…¨éƒ¨ä½¿ç”¨ Geminiï¼ˆå…³é—­ Kimiï¼‰
            active_client = GeminiClient()
            logger.info(f"âš¡ Using Gemini: {thinking_config['reasoning']}")
            
            # é€šçŸ¥å‰ç«¯ä½¿ç”¨çš„æ¨¡å¼
            yield {
                "type": "status",
                "message": f"ğŸ¤– {thinking_config['reasoning']}"
            }
            
            # Step 4: åŠ è½½ prompt
            prompt_content = self._load_prompt(skill)
            prompt = self._format_prompt(prompt_content, params, context)
            
            # ğŸ†• Step 4.5: å‘é€ä¸Šä¸‹æ–‡é¢„è§ˆï¼ˆè®©ç”¨æˆ·çŸ¥é“åŸºäºä»€ä¹ˆç”Ÿæˆï¼‰
            context_preview = self._generate_context_preview(
                context=context,
                params=params,
                thinking_mode=thinking_config["mode"]
            )
            if context_preview:
                yield {
                    "type": "context_preview",
                    "message": context_preview["message"],
                    "details": context_preview.get("details", [])
                }
            
            # ğŸ”¥ Step 4.6: flashcard_skill ç‰¹æ®Šå¤„ç† - æ€»æ˜¯è°ƒç”¨å¤–éƒ¨ API
            # ğŸ“Œ å¤–éƒ¨ API æ”¯æŒå¤šç§è¾“å…¥ï¼š
            #    - æœ‰ reference_explanationï¼ˆå‰é¢æœ‰è§£é‡Šå†…å®¹ï¼‰â†’ ä½¿ç”¨è§£é‡Šå†…å®¹
            #    - æœ‰ referenced_contentï¼ˆç”¨æˆ·å¼•ç”¨äº†å†å²å†…å®¹ï¼‰â†’ ä½¿ç”¨å¼•ç”¨å†…å®¹
            #    - æœ‰ input_textï¼ˆç”¨æˆ·æä¾›çš„åŸå§‹æ–‡æœ¬ï¼‰â†’ ä½¿ç”¨åŸå§‹æ–‡æœ¬
            #    - åªæœ‰ topic â†’ ä½¿ç”¨ topic ä½œä¸ºè¾“å…¥
            
            if skill.id == 'flashcard_skill':
                logger.info(f"ğŸŒ Using External API for flashcard_skill")
                yield {
                    "type": "status",
                    "message": "ğŸŒ æ­£åœ¨è°ƒç”¨å¤–éƒ¨æœåŠ¡ç”Ÿæˆé—ªå¡..."
                }
                
                try:
                    # è°ƒç”¨å¤–éƒ¨ API
                    api_result = await self._execute_flashcard_via_external_api(params, context)
                    
                    # è§£æç»“æœ
                    parsed_content = json.loads(api_result["content"])
                    content_type = "flashcard_set"
                    
                    # æ¨¡æ‹Ÿæµå¼è¾“å‡º - å‘é€å†…å®¹
                    yield {
                        "type": "content",
                        "text": api_result["content"],
                        "accumulated": api_result["content"]
                    }
                    
                    # Step 8: æ›´æ–° memoryï¼ˆä¿å­˜ artifactï¼‰
                    logger.info(f"ğŸ’¾ Saving artifact in stream mode (type: {content_type})")
                    try:
                        await self._update_memory(
                            user_id=user_id,
                            session_id=session_id,
                            intent_result=intent_result,
                            skill_result=parsed_content
                        )
                        logger.info(f"âœ… Artifact saved and memory updated in stream mode")
                    except Exception as e:
                        logger.error(f"âŒ Failed to save artifact in stream mode: {e}")
                    
                    # ğŸ†• æå–å®é™… topic
                    actual_topic_stream = self._extract_topic_from_result(parsed_content, intent_result.topic)
                    if actual_topic_stream:
                        intent_result.topic = actual_topic_stream
                    
                    # Step 9: è¿½åŠ åˆ° Conversation Session MD æ–‡ä»¶
                    try:
                        session_mgr = self.memory_manager.get_conversation_session_manager(user_id)
                        await session_mgr.start_or_continue_session(intent_result.raw_text, session_id=session_id)
                        
                        await session_mgr.append_turn({
                            "user_query": intent_result.raw_text,
                            "agent_response": {
                                "skill": skill.id,
                                "artifact_id": parsed_content.get("artifact_id", ""),
                                "content": parsed_content,
                                "topic": actual_topic_stream  # ğŸ†• å®é™… topic
                            },
                            "response_type": content_type,
                            "timestamp": datetime.now(),
                            "intent": intent_result.model_dump(),
                            "metadata": {
                                "external_api": True,
                                "model": "external_flashcard_api"
                            }
                        })
                        logger.debug(f"ğŸ“ Appended turn to conversation session MD")
                    except Exception as e:
                        logger.error(f"âŒ Failed to append to conversation session: {e}")
                    
                    logger.info(f"âœ… External API flashcard generation complete")
                    
                    # å‘é€å®Œæˆäº‹ä»¶
                    yield {
                        "type": "done",
                        "thinking": None,
                        "content": parsed_content,
                        "content_type": content_type,
                        "usage_summary": {"external_api": True}
                    }
                    
                    logger.info(f"âœ… Stream orchestration complete for {skill.id} (external API)")
                    return
                    
                except Exception as e:
                    logger.error(f"âŒ External flashcard API failed: {e}, falling back to LLM")
                    yield {
                        "type": "status",
                        "message": f"âš ï¸ å¤–éƒ¨æœåŠ¡å¼‚å¸¸ï¼Œä½¿ç”¨ AI ç”Ÿæˆ..."
                    }
                    # ç»§ç»­æ‰§è¡Œ LLM æµç¨‹ä½œä¸º fallback
            
            # ğŸ”¥ Step 4.7: quiz_skill ç‰¹æ®Šå¤„ç† - æ€»æ˜¯è°ƒç”¨å¤–éƒ¨ API
            if skill.id == 'quiz_skill':
                logger.info(f"ğŸŒ Using External API for quiz_skill")
                yield {
                    "type": "status",
                    "message": "ğŸŒ æ­£åœ¨è°ƒç”¨å¤–éƒ¨æœåŠ¡ç”Ÿæˆæµ‹éªŒ..."
                }
                
                try:
                    # è°ƒç”¨å¤–éƒ¨ API
                    api_result = await self._execute_quiz_via_external_api(params, context)
                    
                    # è§£æç»“æœ
                    parsed_content = json.loads(api_result["content"])
                    content_type = "quiz_set"
                    
                    # æ¨¡æ‹Ÿæµå¼è¾“å‡º - å‘é€å†…å®¹
                    yield {
                        "type": "content",
                        "text": api_result["content"],
                        "accumulated": api_result["content"]
                    }
                    
                    # Step 8: æ›´æ–° memoryï¼ˆä¿å­˜ artifactï¼‰
                    logger.info(f"ğŸ’¾ Saving artifact in stream mode (type: {content_type})")
                    try:
                        await self._update_memory(
                            user_id=user_id,
                            session_id=session_id,
                            intent_result=intent_result,
                            skill_result=parsed_content
                        )
                        logger.info(f"âœ… Artifact saved and memory updated in stream mode")
                    except Exception as e:
                        logger.error(f"âŒ Failed to save artifact in stream mode: {e}")
                    
                    # ğŸ†• æå–å®é™… topic
                    actual_topic_quiz = self._extract_topic_from_result(parsed_content, intent_result.topic)
                    if actual_topic_quiz:
                        intent_result.topic = actual_topic_quiz
                    
                    # Step 9: è¿½åŠ åˆ° Conversation Session MD æ–‡ä»¶
                    try:
                        session_mgr = self.memory_manager.get_conversation_session_manager(user_id)
                        await session_mgr.start_or_continue_session(intent_result.raw_text, session_id=session_id)
                        
                        await session_mgr.append_turn({
                            "user_query": intent_result.raw_text,
                            "agent_response": {
                                "skill": skill.id,
                                "artifact_id": parsed_content.get("artifact_id", ""),
                                "content": parsed_content,
                                "topic": actual_topic_quiz  # ğŸ†• å®é™… topic
                            },
                            "response_type": content_type,
                            "timestamp": datetime.now(),
                            "intent": intent_result.model_dump(),
                            "metadata": {
                                "external_api": True,
                                "model": "external_quiz_api"
                            }
                        })
                        logger.debug(f"ğŸ“ Appended turn to conversation session MD")
                    except Exception as e:
                        logger.error(f"âŒ Failed to append to conversation session: {e}")
                    
                    logger.info(f"âœ… External API quiz generation complete")
                    
                    # å‘é€å®Œæˆäº‹ä»¶
                    yield {
                        "type": "done",
                        "thinking": None,
                        "content": parsed_content,
                        "content_type": content_type,
                        "usage_summary": {"external_api": True}
                    }
                    
                    logger.info(f"âœ… Stream orchestration complete for {skill.id} (external API)")
                    return
                    
                except Exception as e:
                    logger.error(f"âŒ External quiz API failed: {e}, falling back to LLM")
                    yield {
                        "type": "status",
                        "message": f"âš ï¸ å¤–éƒ¨æœåŠ¡å¼‚å¸¸ï¼Œä½¿ç”¨ AI ç”Ÿæˆ..."
                    }
                    # ç»§ç»­æ‰§è¡Œ LLM æµç¨‹ä½œä¸º fallback
            
            # Step 5: æµå¼è°ƒç”¨ LLM
            yield {
                "type": "status", 
                "message": "æ­£åœ¨ç”Ÿæˆå†…å®¹..."
            }
            
            thinking_accumulated = []
            content_accumulated = []
            usage_stats = {}  # ğŸ†• æ”¶é›† token ä½¿ç”¨ç»Ÿè®¡
            
            # ğŸ”„ é‡è¯•æœºåˆ¶ï¼šå¤„ç† API è¿æ¥ä¸­æ–­
            max_retries = 2
            retry_count = 0
            api_error_occurred = False
            
            while retry_count <= max_retries:
                try:
                    if retry_count > 0:
                        yield {
                            "type": "status",
                            "message": f"è¿æ¥ä¸­æ–­ï¼Œæ­£åœ¨é‡è¯• ({retry_count}/{max_retries})..."
                        }
                        logger.warning(f"ğŸ”„ Retrying API call (attempt {retry_count}/{max_retries})")
                    
                    # ğŸ”¥ ä½¿ç”¨æ™ºèƒ½é€‰æ‹©çš„ LLM å®¢æˆ·ç«¯
                    # ğŸ†• ç›´æ¥ä½¿ç”¨é…ç½®çš„ thinking_budgetï¼Œä¸å†å¼ºåˆ¶æå‡åˆ° 64
                    optimized_budget = thinking_config.get("thinking_budget", 32)
                    
                    async for chunk in active_client.generate_stream(
                        prompt=prompt,
                        model=thinking_config["model"],
                        thinking_budget=optimized_budget,  # ä½¿ç”¨ä¼˜åŒ–åçš„ budget
                        buffer_size=1,
                        temperature=thinking_config.get("temperature", 1.0)
                    ):
                        # ç´¯ç§¯æ•°æ®
                        if chunk["type"] == "thinking":
                            thinking_accumulated.append(chunk.get("text", ""))
                        elif chunk["type"] == "content":
                            content_accumulated.append(chunk.get("text", ""))
                        elif chunk["type"] == "usage":
                            # ğŸ†• æ”¶é›† token ä½¿ç”¨ç»Ÿè®¡
                            usage_stats = chunk.get("usage", {})
                            logger.info(f"ğŸ“Š Collected usage stats: {usage_stats}")
                            continue  # ä¸è½¬å‘ç»™å‰ç«¯ï¼Œä»…å†…éƒ¨ä½¿ç”¨
                        elif chunk["type"] == "done":
                            # ğŸ”§ FIX: ä¸è½¬å‘åº•å±‚çš„ done äº‹ä»¶ï¼Œç”± orchestrator å‘é€è‡ªå·±çš„ done äº‹ä»¶
                            # è¿™æ ·å¯ä»¥ç¡®ä¿ content_type è¢«æ­£ç¡®è®¾ç½®
                            logger.debug(f"ğŸ“¦ Received done from LLM client, will send orchestrator's done event")
                            continue
                        elif chunk["type"] == "error":
                            # API è¿”å›çš„é”™è¯¯
                            api_error_occurred = True
                            yield chunk
                            break
                        
                        # è½¬å‘ç»™å‰ç«¯
                        yield chunk
                    
                    # æˆåŠŸå®Œæˆï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                    if not api_error_occurred:
                        break
                    
                except Exception as e:
                    error_msg = str(e)
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯
                    is_retryable = (
                        "peer closed connection" in error_msg.lower() or
                        "incomplete chunked read" in error_msg.lower() or
                        "connection reset" in error_msg.lower() or
                        "timeout" in error_msg.lower()
                    )
                    
                    if is_retryable and retry_count < max_retries:
                        retry_count += 1
                        logger.warning(f"âš ï¸  Retryable error detected: {error_msg}")
                        # æ¸…ç©ºä¹‹å‰çš„ç´¯ç§¯å†…å®¹
                        thinking_accumulated = []
                        content_accumulated = []
                        continue
                    else:
                        # ä¸å¯é‡è¯•æˆ–å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°
                        logger.error(f"âŒ Non-retryable error or max retries reached: {e}")
                        yield {
                            "type": "error",
                            "message": f"AIæœåŠ¡è¿æ¥å¤±è´¥ï¼Œè¯·ç¨åé‡è¯• ({error_msg[:100]})",
                            "code": 503
                        }
                        return
                
                # å¦‚æœ API è¿”å›äº†é”™è¯¯ï¼Œä¹Ÿéœ€è¦å¢åŠ é‡è¯•æ¬¡æ•°
                if api_error_occurred:
                    retry_count += 1
                    if retry_count > max_retries:
                        return  # é”™è¯¯å·²ç»é€šè¿‡ chunk å‘é€ç»™å‰ç«¯äº†
                    api_error_occurred = False
                    thinking_accumulated = []
                    content_accumulated = []
            
            # Step 6: è§£ææœ€ç»ˆç»“æœ
            full_thinking = "".join(thinking_accumulated)
            full_content = "".join(content_accumulated)
            
            # ğŸ”¥ å¦‚æœcontentæ²¡æœ‰æµå¼å‘é€è¿‡ï¼ˆKimiä¸€æ¬¡æ€§ç”Ÿæˆï¼‰ï¼Œå¼ºåˆ¶æ‹†åˆ†æµå¼æ˜¾ç¤º
            content_chunks_sent = len(content_accumulated)
            logger.info(f"ğŸ“Š Content chunks received: {content_chunks_sent}")
            
            if content_chunks_sent == 0 and full_content:
                # å®Œå…¨æ²¡æœ‰content chunksï¼Œä½†æœ‰å®Œæ•´contentï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰
                logger.warning(f"âš ï¸  No content chunks but have full_content, forcing stream")
                # å¼ºåˆ¶æ‹†åˆ†å‘é€
                chunk_size = 50
                for i in range(0, len(full_content), chunk_size):
                    mini_chunk = full_content[i:i+chunk_size]
                    accumulated_so_far = full_content[:i+len(mini_chunk)]
                    yield {
                        "type": "content",
                        "text": mini_chunk,
                        "accumulated": accumulated_so_far
                    }
            elif content_chunks_sent > 0 and content_chunks_sent < 5:
                # Content chunkså¤ªå°‘ï¼ˆå¯èƒ½Kimiä¸€æ¬¡æ€§ç”Ÿæˆäº†å¤§å—ï¼‰ï¼Œå¼ºåˆ¶æ‹†åˆ†æœ€åä¸€å—
                logger.info(f"ğŸ“¦ Content sent in {content_chunks_sent} large chunks, forcing granular stream")
                # å¦‚æœæœ€åä¸€å—å¾ˆå¤§ï¼Œæ‹†åˆ†å®ƒ
                if len(content_accumulated) > 0:
                    last_chunk = content_accumulated[-1]
                    if len(last_chunk) > 100:  # å¦‚æœæœ€åä¸€å—è¶…è¿‡100å­—ç¬¦
                        logger.info(f"âœ‚ï¸  Splitting large final chunk ({len(last_chunk)} chars)")
                        chunk_size = 50
                        base_accumulated = "".join(content_accumulated[:-1])
                        for i in range(0, len(last_chunk), chunk_size):
                            mini_chunk = last_chunk[i:i+chunk_size]
                            accumulated_so_far = base_accumulated + last_chunk[:i+len(mini_chunk)]
                            yield {
                                "type": "content",
                                "text": mini_chunk,
                                "accumulated": accumulated_so_far
                            }
            
            # ğŸ”§ æå–JSONï¼ˆå»é™¤markdownä»£ç å—ï¼‰
            json_str = full_content
            if "```json" in json_str:
                # JSONè¢«åŒ…è£¹åœ¨```json ...```ä¸­
                try:
                    json_str = json_str.split("```json")[1].split("```")[0].strip()
                    logger.info(f"âœ‚ï¸  Extracted JSON from markdown code block")
                except:
                    logger.warning(f"âš ï¸  Failed to extract JSON from markdown")
            elif "```" in json_str:
                # JSONè¢«åŒ…è£¹åœ¨``` ...```ä¸­
                try:
                    json_str = json_str.split("```")[1].split("```")[0].strip()
                    logger.info(f"âœ‚ï¸  Extracted JSON from code block")
                except:
                    pass
            
            # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©ºï¼ˆå¯èƒ½å› APIé”™è¯¯ä¸­æ–­ï¼‰
            if not json_str or len(json_str.strip()) < 10:
                logger.error(f"âŒ Content is empty or too short, likely due to API interruption")
                yield {
                    "type": "error",
                    "message": "AIæœåŠ¡æš‚æ—¶è¿‡è½½ï¼Œè¯·ç¨åé‡è¯• (503 Service Unavailable)"
                }
                return
            
            # æ£€æŸ¥å†…å®¹æ˜¯å¦çœ‹èµ·æ¥åƒmarkdownï¼ˆè€Œä¸æ˜¯JSONï¼‰
            if json_str.strip().startswith('**') or json_str.strip().startswith('#'):
                logger.error(f"âŒ Content appears to be markdown, not JSON - API stream was interrupted")
                yield {
                    "type": "error",
                    "message": "AIæœåŠ¡ä¸­æ–­äº†ç”Ÿæˆè¿‡ç¨‹ï¼Œè¯·åˆ·æ–°é¡µé¢åé‡è¯•"
                }
                return
            
            # ğŸ”§ Step 1: æ¸…ç†å¸¸è§æ ¼å¼é—®é¢˜ï¼ˆä¸­æ–‡å¼•å·ã€trailing commasç­‰ï¼‰
            json_str = self._clean_json_string(json_str)
            
            # ğŸ”§ Step 2: ä¿®å¤ LaTeX å…¬å¼ä¸­çš„è½¬ä¹‰é—®é¢˜
            json_str = self._fix_latex_escapes(json_str)
            
            # å°è¯•è§£æ JSON
            try:
                parsed_content = json.loads(json_str)
                logger.info(f"âœ… JSON parsed successfully")
            except json.JSONDecodeError as e:
                logger.error(f"âŒ Failed to parse JSON: {e}")
                logger.error(f"Content preview: {json_str[:200]}...")
                logger.error(f"Content tail: ...{json_str[-100:]}")
                
                # ğŸ”§ æ™ºèƒ½ä¿®å¤æˆªæ–­çš„ JSON
                if "Unterminated string" in str(e) or "Expecting" in str(e) or "truncated" in str(e).lower():
                    logger.warning(f"âš ï¸  JSON appears truncated at position {e.pos if hasattr(e, 'pos') else 'unknown'}, attempting smart fix...")
                    
                    # ç­–ç•¥ 1: æ™ºèƒ½æ£€æµ‹å¹¶ä¿®å¤
                    parsed_content = self._smart_fix_truncated_json(json_str, e)
                    
                    if parsed_content:
                        logger.info(f"âœ… JSON smart fixed successfully")
                    else:
                        # ç­–ç•¥ 2: æš´åŠ›å°è¯•å„ç§é—­åˆç»„åˆ
                        fixed_attempts = [
                            json_str + '"}]}}',  # å­—ç¬¦ä¸²+æ•°ç»„+å¯¹è±¡
                            json_str + '"}}',    # å­—ç¬¦ä¸²+å¯¹è±¡
                            json_str + '"]}}',   # æ•°ç»„+å¯¹è±¡
                            json_str + '}]}}',   # å¯¹è±¡+æ•°ç»„+å¯¹è±¡
                            json_str + '}}',     # å¯¹è±¡
                            json_str + ']}}',    # æ•°ç»„+å¯¹è±¡
                            json_str + ']}'      # æ•°ç»„+å¯¹è±¡
                        ]
                        
                        for i, attempt in enumerate(fixed_attempts):
                            try:
                                parsed_content = json.loads(attempt)
                                logger.info(f"âœ… JSON fixed (brute force attempt {i+1})")
                                break
                            except:
                                continue
                        else:
                            # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥ - è¿”å›å‹å¥½é”™è¯¯
                            yield {
                                "type": "error",
                                "message": "ç”Ÿæˆå†…å®¹è¢«æ„å¤–ä¸­æ–­ï¼ˆAPIè¿æ¥é—®é¢˜ï¼‰ï¼Œè¯·ç¨åé‡è¯•",
                                "code": 503
                            }
                            return
                else:
                    yield {
                        "type": "error",
                        "message": "ç”Ÿæˆå†…å®¹æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•"
                    }
                    return
            
            # Step 7: æ£€æµ‹å†…å®¹ç±»å‹ï¼ˆä½¿ç”¨å’Œä¼ ç»ŸAPIç›¸åŒçš„é€»è¾‘ï¼‰
            content_type = "unknown"
            if "quiz_set_id" in parsed_content or "questions" in parsed_content:
                content_type = "quiz_set"
            elif "concept" in parsed_content or "explanation" in parsed_content:
                content_type = "explanation"
            elif "cardList" in parsed_content or "flashcard_set_id" in parsed_content or "cards" in parsed_content:
                content_type = "flashcard_set"
            elif "notes_id" in parsed_content or "structured_notes" in parsed_content:
                content_type = "notes"
            elif "bundle_id" in parsed_content or "components" in parsed_content:
                content_type = "learning_bundle"
            elif "mindmap_id" in parsed_content or "root" in parsed_content:
                content_type = "mindmap"
            elif "error" in parsed_content:
                content_type = "error"
            
            logger.info(f"âœ… Detected content_type: {content_type}")
            
            # Step 8: æ›´æ–° memoryï¼ˆä¿å­˜ artifactï¼Œæ„å»ºç”¨æˆ·ç”»åƒï¼‰
            logger.info(f"ğŸ’¾ Saving artifact in stream mode (type: {content_type})")
            
            # ğŸ”¥ è°ƒç”¨ç»Ÿä¸€çš„ _update_memory æ–¹æ³•
            try:
                await self._update_memory(
                    user_id=user_id,
                    session_id=session_id,
                    intent_result=intent_result,
                    skill_result=parsed_content
                )
                logger.info(f"âœ… Artifact saved and memory updated in stream mode")
            except Exception as e:
                logger.error(f"âŒ Failed to save artifact in stream mode: {e}")
                # ä¸ä¸­æ–­æµç¨‹ï¼Œç»§ç»­è¿”å›ç»“æœ
            
            # ğŸ†• æå–å®é™… topic
            actual_topic_llm = self._extract_topic_from_result(parsed_content, intent_result.topic)
            if actual_topic_llm:
                intent_result.topic = actual_topic_llm
            
            # Step 9: è¿½åŠ åˆ° Conversation Session MD æ–‡ä»¶
            try:
                session_mgr = self.memory_manager.get_conversation_session_manager(user_id)
                await session_mgr.start_or_continue_session(intent_result.raw_text, session_id=session_id)
                
                await session_mgr.append_turn({
                    "user_query": intent_result.raw_text,
                    "agent_response": {
                        "skill": skill.id,
                        "artifact_id": parsed_content.get("artifact_id", ""),
                        "content": parsed_content,
                        "topic": actual_topic_llm  # ğŸ†• å®é™… topic
                    },
                    "response_type": content_type,
                    "timestamp": datetime.now(),
                    "intent": intent_result.model_dump(),
                    "metadata": {
                        "thinking_tokens": len(full_thinking.split()),  # ç²—ç•¥ä¼°ç®—
                        "output_tokens": len(full_content.split()),  # ç²—ç•¥ä¼°ç®—
                        "model": skill.models.get("primary", "unknown")
                    }
                })
                logger.debug(f"ğŸ“ Appended turn to conversation session MD (stream mode)")
            except Exception as e:
                logger.error(f"âŒ Failed to append to conversation session (stream): {e}")
            
            # ğŸ†• è¾“å‡ºè¯¦ç»†çš„ Token ä½¿ç”¨æ±‡æ€»
            logger.info(f"\n{'='*70}")
            logger.info(f"ğŸ“Š REQUEST TOKEN USAGE SUMMARY")
            logger.info(f"{'='*70}")
            logger.info(f"ğŸ¯ Skill: {skill.id} ({skill.display_name})")
            logger.info(f"ğŸ“š Topic: {intent_result.topic}")
            logger.info(f"ğŸ¤– Model: {thinking_config.get('model', 'unknown')}")
            logger.info(f"{'â”€'*70}")
            
            # Intent Router (0 tokens - local matching)
            logger.info(f"1ï¸âƒ£  Intent Router:        0 tokens (local skill registry match)")
            
            # Main LLM Generation
            model_name = usage_stats.get('model', thinking_config.get('model', 'unknown')) if usage_stats else 'unknown'
            is_gemini = 'gemini' in model_name.lower()
            llm_label = "Gemini" if is_gemini else "Kimi"
            
            if usage_stats:
                source = usage_stats.get('source', 'unknown')
                gen_time = usage_stats.get('generation_time', 0)
                
                if source == 'api':
                    # ç²¾ç¡®æ•°æ®ï¼ˆæ¥è‡ª APIï¼‰
                    prompt_tokens = usage_stats.get('prompt_tokens', 0)
                    completion_tokens = usage_stats.get('completion_tokens', 0)
                    total_tokens = usage_stats.get('total_tokens', 0)
                    logger.info(f"2ï¸âƒ£  Main Generation ({llm_label}) [EXACT]:")
                    logger.info(f"    â€¢ Input:    {prompt_tokens:,} tokens")
                    logger.info(f"    â€¢ Output:   {completion_tokens:,} tokens")
                    logger.info(f"    â€¢ Total:    {total_tokens:,} tokens")
                    if gen_time > 0:
                        logger.info(f"    â€¢ Time:     {gen_time:.1f}s")
                    main_total = total_tokens
                elif source == 'estimated':
                    # ä¼°ç®—æ•°æ®ï¼ˆGemini æµå¼ fallbackï¼‰
                    thinking_chars = usage_stats.get('thinking_chars', 0)
                    content_chars = usage_stats.get('content_chars', 0)
                    completion_tokens = usage_stats.get('completion_tokens', 0)
                    # Gemini Flash prompt é€šå¸¸è¾ƒå°ï¼ˆskill prompt ~500 + context ~500ï¼‰
                    estimated_input = 1000
                    total_estimated = estimated_input + completion_tokens
                    logger.info(f"2ï¸âƒ£  Main Generation ({llm_label}) [ESTIMATED]:")
                    logger.info(f"    â€¢ Input:    ~{estimated_input:,} tokens (prompt)")
                    logger.info(f"    â€¢ Output:   ~{completion_tokens:,} tokens (from {content_chars} chars)")
                    logger.info(f"    â€¢ Total:    ~{total_estimated:,} tokens")
                    main_total = total_estimated
                else:
                    # gemini_stream æ ¼å¼ï¼ˆåªæœ‰ charsï¼‰
                    thinking_chars = usage_stats.get('thinking_chars', 0)
                    content_chars = usage_stats.get('content_chars', 0)
                    # ä¼°ç®— tokensï¼ˆä¸­æ–‡çº¦ 0.5 token/charï¼ŒJSON çº¦ 0.3 token/charï¼‰
                    estimated_output = int((thinking_chars + content_chars) * 0.4)
                    # Gemini Flash prompt é€šå¸¸è¾ƒå°ï¼ˆskill prompt ~500 + context ~500ï¼‰
                    estimated_input = 1000
                    total_estimated = estimated_input + estimated_output
                    logger.info(f"2ï¸âƒ£  Main Generation ({llm_label}) [ESTIMATED]:")
                    logger.info(f"    â€¢ Input:    ~{estimated_input:,} tokens (prompt)")
                    logger.info(f"    â€¢ Output:   ~{estimated_output:,} tokens (from {content_chars} chars)")
                    logger.info(f"    â€¢ Total:    ~{total_estimated:,} tokens")
                    if gen_time > 0:
                        logger.info(f"    â€¢ Time:     {gen_time:.1f}s")
                    main_total = total_estimated
            else:
                logger.info(f"2ï¸âƒ£  Main Generation ({llm_label}): No usage stats available")
                main_total = 0
            
            # Background compression (conditional based on artifact size)
            # ğŸ†• åªæœ‰ artifact > 2500 chars æ—¶æ‰è§¦å‘ LLM å‹ç¼©
            content_size = len(json.dumps(parsed_content, ensure_ascii=False)) if parsed_content else 0
            
            # å§‹ç»ˆä½¿ç”¨ Gemini å‹ç¼©ï¼ˆå¼‚æ­¥åå°æ‰§è¡Œï¼‰
            # Gemini 2.0 Flash Exp å‹ç¼©æˆæœ¬ï¼š~500-800 tokens â‰ˆ $0.0001/æ¬¡
            compression_estimate = 600  # Gemini å‹ç¼©è¯·æ±‚çš„å¹³å‡ token æ¶ˆè€—
            estimated_compressed = int(content_size * 0.25)  # çº¦å‹ç¼©åˆ° 25%
            logger.info(f"3ï¸âƒ£  Context Compress:     ~{compression_estimate:,} tokens (Gemini async, {content_size} â†’ ~{estimated_compressed} chars)")
            logger.info(f"{'â”€'*70}")
            
            # Total estimate
            total_estimated = main_total + compression_estimate
            logger.info(f"ğŸ“ˆ TOTAL FOR THIS REQUEST: ~{total_estimated:,} tokens")
            logger.info(f"{'='*70}\n")
            
            # å®Œæˆ
            yield {
                "type": "done",
                "thinking": full_thinking,
                "content": parsed_content,
                "content_type": content_type,
                "usage_summary": usage_stats  # ğŸ†• åŒ…å«ä½¿ç”¨ç»Ÿè®¡
            }
            
            logger.info(f"âœ… Stream orchestration complete for {skill.id}")
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ Stream orchestration error: {e}")
            
            # æ£€æµ‹503é”™è¯¯ï¼ˆAPIè¿‡è½½ï¼‰
            if "503" in error_msg or "overloaded" in error_msg.lower() or "unavailable" in error_msg.lower():
                yield {
                    "type": "error",
                    "message": "ğŸ”„ AIæœåŠ¡æš‚æ—¶è¿‡è½½ï¼Œè¯·ç­‰å¾…10-30ç§’åé‡è¯•",
                    "code": 503
                }
            else:
                yield {
                    "type": "error",
                    "message": f"å‘ç”Ÿé”™è¯¯: {error_msg}",
                    "code": 500
                }
    
    async def execute(
        self,
        intent_result: IntentResult,
        user_id: str,
        session_id: str,
        additional_params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„ç¼–æ’æµç¨‹
        
        Args:
            intent_result: æ„å›¾è¯†åˆ«ç»“æœ
            user_id: ç”¨æˆ· ID
            session_id: ä¼šè¯ ID
            additional_params: é¢å¤–å‚æ•°
        
        Returns:
            æŠ€èƒ½æ‰§è¡Œç»“æœ
        """
        logger.info(f"ğŸ¯ Orchestrating: intent={intent_result.intent}, topic={intent_result.topic}, confidence={intent_result.confidence:.2f}")
        
        # ============= Phase -1: å¤„ç† Skill Registry çš„ clarification_needed =============
        
        if intent_result.intent == "clarification_needed":
            reason = intent_result.parameters.get('clarification_reason')
            logger.warning(f"âš ï¸  Clarification needed: {reason}")
            
            if reason == "topic_missing":
                # Topic ç¼ºå¤±ï¼Œéœ€è¦ç”¨æˆ·æä¾›
                # æ£€æŸ¥å†å² topics
                session_context = await self.memory_manager.get_session_context(session_id)
                recent_topics = []
                if session_context and session_context.artifact_history:
                    recent_topics = [a.topic for a in session_context.artifact_history[-5:] if a.topic]  # æœ€è¿‘5ä¸ªtopics
                
                if recent_topics:
                    # æœ‰å†å² topicsï¼Œè®©ç”¨æˆ·é€‰æ‹©
                    return {
                        "content_type": "clarification_needed",
                        "intent": "clarification",
                        "response_content": {
                            "question": "æ‚¨æƒ³åŸºäºä»¥ä¸‹å“ªä¸ªä¸»é¢˜ç»§ç»­ï¼Ÿ",
                            "reason": "topic_missing",
                            "options": [
                                {
                                    "type": "topic",
                                    "label": topic,
                                    "value": topic,
                                    "icon": "ğŸ“š",
                                    "description": f"ç»§ç»­å­¦ä¹ ï¼š{topic}"
                                }
                                for topic in recent_topics
                            ],
                            "allow_custom_input": True,
                            "custom_input_placeholder": "æˆ–è¾“å…¥æ–°çš„å­¦ä¹ ä¸»é¢˜..."
                        }
                    }
                else:
                    # æ²¡æœ‰å†å² topicsï¼Œè¯·æ±‚ç”¨æˆ·è¾“å…¥
                    return {
                        "content_type": "clarification_needed",
                        "intent": "clarification",
                        "response_content": {
                            "question": "è¯·é—®æ‚¨æƒ³å­¦ä¹ ä»€ä¹ˆä¸»é¢˜ï¼Ÿ",
                            "reason": "topic_missing",
                            "options": [],
                            "allow_custom_input": True,
                            "custom_input_placeholder": "ä¾‹å¦‚ï¼šå…‰åˆä½œç”¨ã€äºŒæˆ˜å†å²ã€å¾®ç§¯åˆ†..."
                        }
                    }
            
            elif reason == "multi_topic_insufficient":
                # ç”¨æˆ·è¯·æ±‚å¤šä¸ª topicsï¼Œä½†å†å²ä¸è¶³
                return {
                    "content_type": "clarification_needed",
                    "intent": "clarification",
                    "response_content": {
                        "question": "æ‚¨æåˆ°äº†å¤šä¸ªä¸»é¢˜ï¼Œä½†æˆ‘æš‚æ—¶åªè®°å½•äº†ä¸€ä¸ªä¸»é¢˜ã€‚å¯ä»¥å‘Šè¯‰æˆ‘å…·ä½“æ˜¯å“ªäº›ä¸»é¢˜å—ï¼Ÿ",
                        "reason": "multi_topic_insufficient",
                        "options": [],
                        "allow_custom_input": True,
                        "custom_input_placeholder": "ä¾‹å¦‚ï¼šå…‰åˆä½œç”¨å’ŒäºŒæˆ˜å†å²"
                    }
                }
        
        # ============= Phase 0: æ™ºèƒ½æ¾„æ¸…æœºåˆ¶ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰=============
        
        # ğŸ†• ç½®ä¿¡åº¦è¿‡ä½ï¼šæä¾›æ¾„æ¸…é€‰é¡¹
        if intent_result.confidence < 0.60:  # ç½®ä¿¡åº¦ < 60%
            logger.info(f"âš ï¸ Low confidence ({intent_result.confidence:.2f}), requesting clarification")
            
            session_context = await self.memory_manager.get_session_context(session_id)
            recent_intents = session_context.recent_intents[-5:] if session_context and session_context.recent_intents else []
            
            # æ„å»ºæ„å›¾é€‰é¡¹
            intent_options = []
            intent_labels = {
                "explain_request": {"label": "è§£é‡Šæ¦‚å¿µ", "icon": "ğŸ“–", "description": "è¯¦ç»†è®²è§£ä¸€ä¸ªçŸ¥è¯†ç‚¹"},
                "quiz_request": {"label": "ç»ƒä¹ é¢˜ç›®", "icon": "âœï¸", "description": "ç”Ÿæˆæµ‹è¯•é¢˜"},
                "flashcard_request": {"label": "è®°å¿†é—ªå¡", "icon": "ğŸ—‚ï¸", "description": "ç”Ÿæˆè®°å¿†å¡ç‰‡"},
                "notes": {"label": "å­¦ä¹ ç¬”è®°", "icon": "ğŸ“", "description": "ç”Ÿæˆç»“æ„åŒ–ç¬”è®°"},
                "mindmap": {"label": "æ€ç»´å¯¼å›¾", "icon": "ğŸ§ ", "description": "ç”ŸæˆçŸ¥è¯†å¯¼å›¾"},
            }
            
            # ä¼˜å…ˆæ˜¾ç¤ºæœ€è¿‘ä½¿ç”¨çš„æ„å›¾
            for intent in recent_intents:
                if intent in intent_labels and intent not in [opt["value"] for opt in intent_options]:
                    info = intent_labels[intent]
                    intent_options.append({
                        "type": "intent",
                        "label": info["label"],
                        "value": intent,
                        "icon": info["icon"],
                        "description": info["description"]
                    })
            
            # è¡¥å……å…¶ä»–å¸¸ç”¨æ„å›¾
            for intent, info in intent_labels.items():
                if intent not in [opt["value"] for opt in intent_options]:
                    intent_options.append({
                        "type": "intent",
                        "label": info["label"],
                        "value": intent,
                        "icon": info["icon"],
                        "description": info["description"]
                    })
            
            return {
                "content_type": "clarification_needed",
                "intent": "clarification",
                "response_content": {
                    "question": "æŠ±æ­‰ï¼Œæˆ‘ä¸å¤ªç¡®å®šæ‚¨æƒ³è¦ä»€ä¹ˆã€‚è¯·é€‰æ‹©ä¸€ä¸ªé€‰é¡¹ï¼š",
                    "reason": "low_confidence",
                    "confidence": intent_result.confidence,
                    "options": intent_options[:5],  # æœ€å¤š5ä¸ªé€‰é¡¹
                    "allow_custom_input": True,
                    "custom_input_placeholder": "æˆ–è€…ç”¨å…¶ä»–æ–¹å¼æè¿°æ‚¨çš„éœ€æ±‚...",
                    "original_intent": intent_result.intent,
                    "original_message": intent_result.raw_text
                }
            }
        
        # ============= Phase 0 ç»§ç»­: ä¸»é¢˜ç›¸å…³æ¾„æ¸… =============
        
        # ğŸ¯ æ¾„æ¸…æœºåˆ¶ï¼šå¯¹æ‰€æœ‰éœ€è¦æ˜ç¡®ä¸»é¢˜çš„skillsï¼Œæä¾›å¼•å¯¼æˆ–æ¾„æ¸…
        needs_clarification_intents = [
            "notes", "flashcard_request", "quiz_request", 
            "explain_request", "mindmap", "learning_bundle"
        ]
        
        if intent_result.intent in needs_clarification_intents:
            # è·å– session context
            session_context = await self.memory_manager.get_session_context(session_id)
            artifact_history = []
            
            if session_context:
                artifact_history = session_context.artifact_history or []
            
            # ğŸ¯ å…³é”®ï¼šåªæœ‰å½“topicæ— æ•ˆæ—¶æ‰éœ€è¦æ¾„æ¸…/å¼•å¯¼
            #    å¦‚æœç”¨æˆ·æ˜ç¡®è¯´äº†topicï¼ˆå¦‚"å¾®ç§¯åˆ†"ï¼‰ï¼Œç›´æ¥æ‰§è¡Œï¼Œä¸éœ€è¦å¼•å¯¼
            topic_is_valid = intent_result.topic and len(intent_result.topic) >= 3
            
            # ğŸ†• æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶é™„ä»¶ï¼ˆæœ‰æ–‡ä»¶æ—¶è·³è¿‡onboardingï¼‰
            has_file_uri = bool(intent_result.parameters.get('file_uri'))
            
            # ğŸ†• å¯¹äº learning_bundleï¼Œæ£€æŸ¥åŸå§‹æ¶ˆæ¯æ˜¯å¦æœ‰å…·ä½“ä¸»é¢˜
            # ä¾‹å¦‚ "å¸®æˆ‘åˆ¶å®šå­¦ä¹ è®¡åˆ’ï¼Œä¸»é¢˜æ˜¯å…‰åˆä½œç”¨" åº”è¯¥ç›´æ¥æ‰§è¡Œ
            raw_text = intent_result.raw_text or ""
            has_explicit_topic_in_message = any(kw in raw_text for kw in ['ä¸»é¢˜æ˜¯', 'å…³äº', 'å­¦ä¹ ', 'è®¡åˆ’'])
            
            # ğŸ†• é¦–æ¬¡è®¿é—® + æ— æ˜ç¡®topic + æ— æ–‡ä»¶ï¼šæä¾›onboardingå¼•å¯¼ï¼ˆ0 tokenæ¶ˆè€—ï¼‰
            # è·³è¿‡æ¡ä»¶ï¼šæœ‰æ–‡ä»¶ã€æœ‰æ˜ç¡®ä¸»é¢˜æŒ‡å®šã€æˆ–æ˜¯ learning_bundle ä¸”æ¶ˆæ¯ä¸­æœ‰æ˜ç¡®ä¸»é¢˜
            skip_onboarding = has_file_uri or (intent_result.intent == "learning_bundle" and has_explicit_topic_in_message)
            
            if len(artifact_history) == 0 and not topic_is_valid and not skip_onboarding:
                logger.info(f"ğŸ‘‹ First-time user detected, showing onboarding (0 tokens)")
                
                # ğŸ†• è·å–è¯­è¨€è®¾ç½®
                language = additional_params.get("language", "en") if additional_params else "en"
                
                if language == "en":
                    return {
                        "content_type": "onboarding",
                        "intent": intent_result.intent,
                        "response_content": {
                            "welcome": "ğŸ‘‹ Welcome to StudyX Agent!",
                            "message": "I noticed you haven't started learning any topic yet.",
                            "suggestions": [
                                {
                                    "category": "Physics",
                                    "topics": ["Newton's Laws", "Optics", "Electromagnetism", "Quantum Mechanics"],
                                    "icon": "âš›ï¸"
                                },
                                {
                                    "category": "Math",
                                    "topics": ["Calculus", "Linear Algebra", "Probability", "Statistics"],
                                    "icon": "ğŸ“"
                                },
                                {
                                    "category": "History",
                                    "topics": ["World War II", "Renaissance", "Industrial Revolution", "Ancient Civilizations"],
                                    "icon": "ğŸ“œ"
                                },
                                {
                                    "category": "Biology",
                                    "topics": ["Photosynthesis", "Cell Structure", "Genetics", "Evolution"],
                                    "icon": "ğŸ§¬"
                                },
                                {
                                    "category": "Computer Science",
                                    "topics": ["Data Structures", "Algorithms", "Machine Learning", "Networking"],
                                    "icon": "ğŸ’»"
                                }
                            ],
                            "call_to_action": "Please tell me what topic you'd like to learn, for example: 'Explain Newton's second law' or 'What is photosynthesis?'"
                        }
                    }
                else:
                    return {
                        "content_type": "onboarding",
                        "intent": intent_result.intent,
                        "response_content": {
                            "welcome": "ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ StudyX Agentï¼",
                            "message": "æˆ‘æ³¨æ„åˆ°æ‚¨è¿˜æ²¡æœ‰å¼€å§‹å­¦ä¹ ä»»ä½•ä¸»é¢˜ã€‚",
                            "suggestions": [
                                {
                                    "category": "ç‰©ç†",
                                    "topics": ["ç‰›é¡¿å®šå¾‹", "å…‰å­¦", "ç”µç£å­¦", "é‡å­åŠ›å­¦"],
                                    "icon": "âš›ï¸"
                                },
                                {
                                    "category": "æ•°å­¦",
                                    "topics": ["å¾®ç§¯åˆ†", "çº¿æ€§ä»£æ•°", "æ¦‚ç‡è®º", "ç»Ÿè®¡å­¦"],
                                    "icon": "ğŸ“"
                                },
                                {
                                    "category": "å†å²",
                                    "topics": ["äºŒæˆ˜å†å²", "æ–‡è‰ºå¤å…´", "å·¥ä¸šé©å‘½", "å¤ä»£æ–‡æ˜"],
                                    "icon": "ğŸ“œ"
                                },
                                {
                                    "category": "ç”Ÿç‰©",
                                    "topics": ["å…‰åˆä½œç”¨", "ç»†èƒç»“æ„", "é—ä¼ å­¦", "è¿›åŒ–è®º"],
                                    "icon": "ğŸ§¬"
                                },
                                {
                                    "category": "è®¡ç®—æœº",
                                    "topics": ["æ•°æ®ç»“æ„", "ç®—æ³•", "æœºå™¨å­¦ä¹ ", "ç½‘ç»œ"],
                                    "icon": "ğŸ’»"
                                }
                            ],
                            "call_to_action": "è¯·å…ˆå‘Šè¯‰æˆ‘æ‚¨æƒ³å­¦ä¹ ä»€ä¹ˆä¸»é¢˜ï¼Œä¾‹å¦‚ï¼šã€Œè®²è®²ç‰›é¡¿ç¬¬äºŒå®šå¾‹ã€æˆ–ã€Œä»€ä¹ˆæ˜¯å…‰åˆä½œç”¨ã€"
                        }
                    }
            
            # ğŸ†• å¤šä¸»é¢˜æ¾„æ¸…ï¼šä»…åœ¨ç”¨æˆ·è¯·æ±‚éå¸¸æ¨¡ç³Šæ—¶è§¦å‘
            # æ¡ä»¶ï¼š1) æ²¡æœ‰æ–‡ä»¶é™„ä»¶  2) æ¶ˆæ¯ä¸­æ²¡æœ‰æ˜ç¡®æŒ‡å®šä¸»é¢˜
            if len(artifact_history) > 0 and not has_file_uri:
                # æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«ä»»ä½•æ˜ç¡®çš„ä¸»é¢˜è¯æ±‡
                message_lower = intent_result.raw_text.lower()
                
                # æ¨¡ç³Šè¯·æ±‚æ¨¡å¼ï¼ˆå¦‚ "å†æ¥ä¸‰é“é¢˜"ã€"ç»§ç»­"ï¼‰
                vague_patterns = ['å†æ¥', 'ç»§ç»­', 'æ›´å¤š', 'è¿˜è¦', 'å†ç»™', 'å¤šæ¥', 'å†å‡º']
                is_vague_request = any(p in message_lower for p in vague_patterns) and len(message_lower) < 15
                
                # æå–æœ€è¿‘çš„ä¸»é¢˜åˆ—è¡¨ï¼ˆå»é‡ï¼‰
                recent_topics = await self._extract_recent_topics(session_id)
                unique_topics = list(dict.fromkeys(recent_topics))  # å»é‡ä½†ä¿æŒé¡ºåº
                
                # æ£€æŸ¥ç”¨æˆ·æ¶ˆæ¯æ˜¯å¦æ˜ç¡®æåˆ°äº†æŸä¸ªä¸»é¢˜
                has_explicit_topic = any(topic.lower() in message_lower for topic in unique_topics if topic)
                
                # ğŸ”¥ å…³é”®ï¼šå½“è¯·æ±‚æ¨¡ç³Š + æœ‰å¤šä¸ªä¸åŒä¸»é¢˜ + æ²¡æœ‰æ˜ç¡®æŒ‡å®šä¸»é¢˜æ—¶ï¼Œè§¦å‘æ¾„æ¸…
                # å³ä½¿ topic_is_valid ä¸º Trueï¼ˆä» current_topic ç»§æ‰¿ï¼‰ï¼Œä¹Ÿè¦æ¾„æ¸…
                if is_vague_request and len(unique_topics) >= 2 and not has_explicit_topic:
                    logger.info(f"â“ Vague request with {len(unique_topics)} unique topics: {unique_topics}")
                    logger.info(f"ğŸ¤” Multi-topic clarification needed (even though current_topic is set)")
                    
                    return {
                        "content_type": "clarification_needed",
                        "intent": intent_result.intent,
                        "topic": intent_result.topic,  # ä¿ç•™å½“å‰ topic ä¾›å‚è€ƒ
                        "response_content": {
                            "question": "æˆ‘æ³¨æ„åˆ°æ‚¨ä¹‹å‰å­¦ä¹ äº†å¤šä¸ªä¸»é¢˜ï¼Œè¯·é—®æ‚¨æƒ³åŸºäºå“ªä¸ªä¸»é¢˜ç»§ç»­ï¼Ÿ",
                            "reason": "topic_ambiguous",
                            "options": [
                                {
                                    "type": "topic",
                                    "label": topic,
                                    "value": topic,
                                    "icon": "ğŸ“š"
                                }
                                for topic in unique_topics[:5]  # æœ€å¤š5ä¸ªé€‰é¡¹
                            ],
                            "allow_custom_input": True,
                            "custom_input_placeholder": "æˆ–è€…è¾“å…¥æ–°çš„ä¸»é¢˜...",
                            "original_intent": intent_result.intent,
                            "original_message": intent_result.raw_text
                        }
                    }
            
            # ğŸ†• å½“æœ‰æœ‰æ•ˆ topic æ—¶ï¼Œä¸å†è§¦å‘æ¾„æ¸… - ç›´æ¥ä½¿ç”¨è¯¥ topic
            # ç”¨æˆ·æ˜ç¡®æŒ‡å®šçš„ topic æˆ– file_uri ä¼šç»•è¿‡æ¾„æ¸…é€»è¾‘
            # åˆ é™¤äº†æ—§çš„ "Ambiguous request with N topics" é€»è¾‘ï¼Œå› ä¸ºå®ƒè¿‡äºæ¿€è¿›
            
            # å¤šä¸»é¢˜æ¾„æ¸…ï¼šåªæœ‰å½“ topic å®Œå…¨æ— æ•ˆã€æ²¡æœ‰æ–‡ä»¶é™„ä»¶ã€ä¸”è¯·æ±‚æ¨¡ç³Šæ—¶æ‰è§¦å‘
            # ğŸ†• å¢åŠ æ›´ä¸¥æ ¼çš„æ¡ä»¶ï¼šåªæœ‰æç«¯æ¨¡ç³Šçš„è¯·æ±‚æ‰éœ€è¦æ¾„æ¸…
            if not topic_is_valid and len(artifact_history) > 1 and not has_file_uri:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æç«¯æ¨¡ç³Šçš„è¯·æ±‚ï¼ˆåªæœ‰åŠ¨ä½œæ²¡æœ‰ä»»ä½•å†…å®¹ï¼‰
                message_lower = intent_result.raw_text.lower()
                extreme_vague_patterns = ['å†æ¥', 'ç»§ç»­', 'æ›´å¤š', 'è¿˜è¦', 'å†ç»™', 'å¤šæ¥', 'å‡ºé¢˜', 'ç»™æˆ‘']
                is_extreme_vague = len(message_lower) < 10 and any(p in message_lower for p in extreme_vague_patterns)
                
                if is_extreme_vague:
                    # æå–æ‰€æœ‰å·²å­¦ä¹ çš„ä¸»é¢˜
                    learned_topics = []
                    seen_topics = set()
                    for artifact in reversed(artifact_history):  # æœ€æ–°çš„åœ¨å‰
                        topic_val = artifact.topic if hasattr(artifact, 'topic') else artifact.get("topic")
                        artifact_type = artifact.artifact_type if hasattr(artifact, 'artifact_type') else artifact.get("artifact_type", "unknown")
                        
                        if topic_val and topic_val not in seen_topics:
                            seen_topics.add(topic_val)
                            learned_topics.append({
                                "topic": topic_val,
                                "type": artifact_type
                            })
                    
                    if len(learned_topics) >= 2:  # ğŸ†• è‡³å°‘2ä¸ªä¸åŒä¸»é¢˜æ‰æ¾„æ¸…
                        logger.info(f"ğŸ’¬ Extreme vague request with {len(learned_topics)} topic(s), asking user (0 tokens)")
                        
                        # æ ¹æ®ä¸åŒintentç”Ÿæˆä¸åŒçš„é—®é¢˜
                        intent_questions = {
                            "notes": ("åšç¬”è®°", "åš{topic}çš„ç¬”è®°"),
                            "quiz_request": ("ç”Ÿæˆé¢˜ç›®", "ç”Ÿæˆ{topic}çš„é¢˜ç›®"),
                            "flashcard_request": ("ç”Ÿæˆé—ªå¡", "ç”Ÿæˆ{topic}çš„é—ªå¡"),
                            "explain_request": ("è®²è§£", "è®²è§£{topic}"),
                            "mindmap": ("ç”Ÿæˆæ€ç»´å¯¼å›¾", "ç”Ÿæˆ{topic}çš„æ€ç»´å¯¼å›¾"),
                            "learning_bundle": ("è·å–å­¦ä¹ åŒ…", "è·å–{topic}çš„å­¦ä¹ èµ„æ–™")
                        }
                        
                        action_text, example_text = intent_questions.get(
                            intent_result.intent, 
                            ("å­¦ä¹ ", "å­¦ä¹ {topic}")
                        )
                        
                        # è¿”å›æ¾„æ¸…å“åº”ï¼ˆ0 tokenæ¶ˆè€—ï¼‰
                        return {
                            "content_type": "clarification",
                            "intent": intent_result.intent,
                            "response_content": {
                                "question": f"æ‚¨æƒ³å¯¹å“ªä¸ªä¸»é¢˜{action_text}å‘¢ï¼Ÿ",
                                "learned_topics": learned_topics[:5],  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                                "suggestion": f"è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³é€‰æ‹©çš„ä¸»é¢˜ï¼Œä¾‹å¦‚ï¼šã€Œ{example_text.format(topic=learned_topics[0]['topic'])}ã€"
                            }
                        }
        
        # ============= Phase 3: å¤„ç† ambiguous/contextual æ„å›¾ =============
        
        # Step 0.1: å¤„ç†æ¨¡ç³Šæ„å›¾ (éœ€è¦åå¥½æ¨æ–­)
        if intent_result.intent == "ambiguous":
            logger.info("ğŸ”„ Processing ambiguous intent - applying user preference...")
            
            # è·å–ç”¨æˆ·åå¥½ï¼ˆä¸è°ƒç”¨ LLMï¼Œç›´æ¥æŸ¥è¯¢æ•°æ®åº“/å†…å­˜ï¼‰
            user_profile = await self.memory_manager.get_user_profile(user_id)
            
            # ä»ç”¨æˆ·åå¥½ä¸­æå– top preference
            top_preference = "explain"  # é»˜è®¤
            if user_profile and user_profile.preferences:
                # preferences æ˜¯ dict: {"preferred_artifact": "quiz", ...}
                preferred_artifact = user_profile.preferences.get("preferred_artifact")
                if preferred_artifact:
                    top_preference = preferred_artifact
            
            # æ›´æ–° intent ä¸ºç”¨æˆ·åå¥½çš„æŠ€èƒ½
            intent_result.intent = top_preference
            logger.info(f"âœ… Ambiguous intent resolved to: {top_preference} (based on user preference)")
            
            # ğŸ†• æå–å½“å‰å­¦ä¹ ä¸»é¢˜ï¼ˆå¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®štopicï¼Œä½¿ç”¨å½“å‰ä¸»é¢˜ï¼‰
            if not intent_result.topic:
                session_context = await self.memory_manager.get_session_context(session_id)
                if session_context and session_context.current_topic:
                    intent_result.topic = session_context.current_topic
                    logger.info(f"âœ… Ambiguous intent: using current topic: {session_context.current_topic}")
        
        # Step 0.2: å¤„ç†ä¸Šä¸‹æ–‡å¼•ç”¨ (éœ€è¦ä» last_artifact æå–ä¿¡æ¯)
        if intent_result.intent == "contextual":
            logger.info("ğŸ”„ Processing contextual intent - extracting from last artifact...")
            
            # è·å– session contextï¼ˆä¸è°ƒç”¨ LLMï¼Œç›´æ¥è¯»å–å†…å­˜ï¼‰
            session_context = await self.memory_manager.get_session_context(session_id)
            
            # ğŸ†• é¦–å…ˆæ£€æŸ¥ç”¨æˆ·æ¶ˆæ¯çš„æ„å›¾ç±»å‹
            # è¯¢é—®ç±»æ¶ˆæ¯åº”è¯¥è½¬æ¢ä¸º explain/otherï¼Œè€Œä¸æ˜¯ç”Ÿæˆæ–°å†…å®¹
            user_message = intent_result.raw_text.lower()
            
            # è¯¢é—®/è§£é‡Šè¯·æ±‚æ¨¡å¼ï¼ˆæ‰©å±•è¦†ç›–æ›´å¤šåœºæ™¯ï¼‰
            inquiry_patterns = [
                # ç†è§£/æ¾„æ¸…ç±»
                "ä¸å¤ªç†è§£", "ä¸ç†è§£", "ä¸å¤ªæ‡‚", "ä¸æ‡‚", "ä¸æ˜ç™½", "ä¸æ¸…æ¥š",
                "èƒ½è§£é‡Š", "å¸®æˆ‘è§£é‡Š", "è¯¦ç»†è§£é‡Š", "æ›´ç®€å•", "ç®€å•ä¸€ç‚¹",
                "ä»€ä¹ˆæ„æ€", "æ€ä¹ˆç†è§£", "ä¸¾ä¸ªä¾‹å­", "èƒ½ä¸¾ä¾‹",
                # æè¿°/ä»‹ç»ç±»
                "è®²äº†ä»€ä¹ˆ", "è¯´äº†ä»€ä¹ˆ", "æ˜¯ä»€ä¹ˆ", "ä»€ä¹ˆå†…å®¹", "æè¿°ä¸€ä¸‹", "ä»‹ç»ä¸€ä¸‹",
                "è®²çš„æ˜¯ä»€ä¹ˆ", "è¯´çš„æ˜¯ä»€ä¹ˆ", "å†…å®¹æ˜¯ä»€ä¹ˆ",
                # æ¯”è¾ƒ/åˆ†æç±»
                "æ¯”è¾ƒ", "å¯¹æ¯”", "ä¸åŒ", "åŒºåˆ«", "è”ç³»", "å…³ç³»", "ç›¸åŒ", "ç›¸ä¼¼",
                # æé—®/è¯·æ±‚å¸®åŠ©ç±»
                "æ€ä¹ˆåš", "å¦‚ä½•åš", "å¸®æˆ‘è§£ç­”", "å¸®æˆ‘è§£å†³", "æœ‰ä»€ä¹ˆ",
                "ç»™æˆ‘ä¸€äº›", "ç»™ç‚¹", "æç¤º", "æ€è·¯", "æ–¹å‘",
                # æ€»ç»“/æ¦‚è¿°ç±»ï¼ˆä¸æ˜¯è¦æ±‚ç”Ÿæˆç¬”è®°ï¼‰
                "æ€»ä½“æ¥è¯´", "æ€»çš„æ¥è¯´", "æ¦‚æ‹¬ä¸€ä¸‹", "ç®€å•è¯´è¯´"
            ]
            
            # ç”Ÿæˆè¯·æ±‚æ¨¡å¼ï¼ˆæ˜ç¡®è¦æ±‚ç”Ÿæˆæ–°å†…å®¹ï¼‰
            generate_patterns = [
                "å†æ¥", "å†å‡º", "å†ç»™", "å¤šå‡º", "ç»§ç»­å‡º", "è¿˜è¦",
                "æ›´å¤šé¢˜", "æ›´å¤šé—ªå¡", "æ›´å¤šå¡ç‰‡",
                "å¸®æˆ‘å‡º", "ç»™æˆ‘å‡º", "å‡ºå‡ é“", "ç”Ÿæˆ", "åˆ›å»º"
            ]
            
            is_inquiry_request = any(p in user_message for p in inquiry_patterns)
            is_generate_request = any(p in user_message for p in generate_patterns)
            
            if is_inquiry_request and not is_generate_request:
                # ç”¨æˆ·åœ¨è¯·æ±‚è¯¢é—®/è§£é‡Šï¼Œä¸æ˜¯ç”Ÿæˆæ–°å†…å®¹
                # è¿”å›ä¸€ä¸ªç‰¹æ®Šæ ‡è®°ï¼Œè®© external.py ä½¿ç”¨ Gemini å¤„ç†
                logger.info(f"ğŸ” Detected inquiry request in contextual message, redirecting to 'other' intent")
                return {
                    "content_type": "redirect_to_other",
                    "intent": "other",
                    "topic": session_context.current_topic if session_context else "",
                    "content": {},
                    "redirect": True,
                    "original_message": intent_result.raw_text
                }
            
            # ä» last_artifact æå– topic
            if session_context and session_context.last_artifact:
                # last_artifact æ ¼å¼: "Type: explanation | Topic: ç‰›é¡¿ç¬¬äºŒå®šå¾‹"
                last_artifact = session_context.last_artifact
                
                # ğŸ†• ä¼˜å…ˆä» last_artifact å­—ç¬¦ä¸²æå–ï¼Œå¦‚æœå¤±è´¥åˆ™ä» current_topic æå–
                if " | Topic: " in last_artifact:
                    topic = last_artifact.split(" | Topic: ")[1].strip()
                    intent_result.topic = topic
                    logger.info(f"âœ… Extracted topic from last artifact: {topic}")
                elif session_context.current_topic:
                    # Fallback: å¦‚æœ last_artifact æ²¡æœ‰ topic ä¿¡æ¯ï¼Œä½¿ç”¨ current_topic
                    intent_result.topic = session_context.current_topic
                    logger.info(f"âœ… Using current_topic as fallback: {session_context.current_topic}")
                else:
                    logger.warning("âš ï¸ No topic found in last artifact or current_topic")
                
                # æ ¹æ® last artifact ç±»å‹æ¨æ–­æ„å›¾
                # å¦‚æœä¸Šä¸€è½®æ˜¯ explainï¼Œè¿™ä¸€è½®å¯èƒ½æ˜¯ quiz æˆ– flashcard
                user_profile = await self.memory_manager.get_user_profile(user_id)
                top_preference = "quiz"  # é»˜è®¤
                if user_profile and user_profile.preferences:
                    preferred_artifact = user_profile.preferences.get("preferred_artifact")
                    if preferred_artifact:
                        top_preference = preferred_artifact
                
                intent_result.intent = top_preference
                logger.info(f"âœ… Contextual intent resolved to: {top_preference}")
                
                # æ ‡è®°éœ€è¦ä½¿ç”¨ last_artifact å†…å®¹
                if not intent_result.parameters:
                    intent_result.parameters = {}
                intent_result.parameters['use_last_artifact'] = True
            else:
                logger.warning("âš ï¸ No last artifact found for contextual intent, falling back to 'other'")
                intent_result.intent = "other"
        
        # ============= End Phase 3 Processing =============
        
        # Step 1: é€‰æ‹©æŠ€èƒ½
        skill = self._select_skill(intent_result)
        if not skill:
            return self._create_error_response(
                "no_skill_found",
                f"æœªæ‰¾åˆ°åŒ¹é…æ„å›¾ '{intent_result.intent}' çš„æŠ€èƒ½"
            )
        
        logger.info(f"ğŸ“¦ Selected skill: {skill.id} ({skill.display_name})")
        
        # ğŸ†• Step 1.5: æ£€æŸ¥æ˜¯å¦ä¸º Plan Skill
        if skill.skill_type == "plan":
            logger.info(f"ğŸ¯ Detected Plan Skill: {skill.id}")
            return await self._execute_plan_skill(
                skill=skill,
                intent_result=intent_result,
                user_id=user_id,
                session_id=session_id,
                additional_params=additional_params
            )
        
        # Step 2: è·å–ä¸Šä¸‹æ–‡
        context = await self._build_context(skill, user_id, session_id)
        
        # Step 3: æ„å»ºè¾“å…¥å‚æ•°
        params = self._build_input_params(skill, intent_result, context, additional_params)
        
        # ğŸ†• Step 3.1: å¼•ç”¨è§£æï¼ˆå¦‚æœæ¶ˆæ¯åŒ…å«å¯¹å†å² artifacts çš„å¼•ç”¨ï¼‰
        if intent_result.has_reference:
            reference_resolver = get_reference_resolver()
            session_context_for_ref = await self.memory_manager.get_session_context(session_id)
            
            if session_context_for_ref and session_context_for_ref.artifact_history:
                resolved_refs = reference_resolver.resolve_references(
                    intent_result.raw_text,
                    session_context_for_ref.artifact_history
                )
                
                if resolved_refs:
                    resolved_content = reference_resolver.format_resolved_content(resolved_refs)
                    if resolved_content:
                        params["referenced_content"] = resolved_content
                        logger.info(f"ğŸ”— Resolved {len(resolved_refs)} reference(s): {len(resolved_content)} chars")
                        
                        # ä½¿ç”¨æ¥æº artifact çš„ topic
                        for ref in resolved_refs:
                            if ref.source_topic:
                                intent_result.topic = ref.source_topic
                                logger.info(f"ğŸ”— Using source topic from reference: {ref.source_topic}")
                                break
                    else:
                        logger.warning(f"âš ï¸  References detected but no content resolved")
                else:
                    logger.warning(f"âš ï¸  has_reference=True but resolve_references returned empty")
            else:
                logger.warning(f"âš ï¸  has_reference=True but no artifact_history available")
        
        # ğŸ†• Step 3.5: æ™ºèƒ½é€‰æ‹©æ€è€ƒæ¨¡å¼
        session_context = await self.memory_manager.get_session_context(session_id)
        thinking_config = self.thinking_mode_selector.select_mode(
            intent_result=intent_result,
            session_context=session_context
        )
        
        # ğŸ”§ ä¸´æ—¶é…ç½®ï¼šå…¨éƒ¨ä½¿ç”¨ Geminiï¼ˆå…³é—­ Kimiï¼‰
        active_client = GeminiClient()
        logger.info(f"âš¡ Using Gemini: {thinking_config['reasoning']}")
        
        # Step 4: æ‰§è¡ŒæŠ€èƒ½
        try:
            response = await self._execute_skill(skill, params, context, 
                                                 client=active_client, 
                                                 thinking_config=thinking_config)
            # ğŸ†• response æ˜¯å­—å…¸: {"content": str, "thinking": str, "usage": dict}
            
            # æå–å†…å®¹
            result_json = response.get("content", response) if isinstance(response, dict) else response
            thinking = response.get("thinking") if isinstance(response, dict) else None
            usage = response.get("usage", {}) if isinstance(response, dict) else {}
            
            # è§£æ JSON
            result = json.loads(result_json) if isinstance(result_json, str) else result_json
            
            # ğŸ†• å°†æ€è€ƒè¿‡ç¨‹æ·»åŠ åˆ°ç»“æœä¸­
            if thinking:
                result["_thinking"] = thinking
                result["_usage"] = usage
                logger.info(f"ğŸ§  Thinking process included: {len(thinking)} chars")
            
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"âŒ Failed to parse skill result JSON: {e}")
            return self._create_error_response("json_parse_error", f"Invalid JSON response: {str(e)}")
        except Exception as e:
            logger.error(f"âŒ Skill execution failed: {e}")
            return self._create_error_response("execution_error", str(e))
        
        # ğŸ†• Step 5: æå–å®é™… topic å¹¶æ›´æ–° intent_result
        # è¿™æ · API å“åº”å’Œ MD æ–‡ä»¶ä¸­å­˜å‚¨çš„ topic æ˜¯å®é™…çš„ï¼Œè€Œä¸æ˜¯ä»ç”¨æˆ·æ¶ˆæ¯æå–çš„
        actual_topic = self._extract_topic_from_result(result, intent_result.topic)
        if actual_topic and actual_topic != intent_result.topic:
            logger.info(f"ğŸ“¤ Updating intent_result.topic: '{intent_result.topic}' â†’ '{actual_topic}'")
            intent_result.topic = actual_topic
        
        # Step 5.5: å°è£…è¾“å‡ºï¼ˆä¼ å…¥æ›´æ–°åçš„ intent_resultï¼‰
        output = self._wrap_output(skill, result, intent_result)
        
        # ğŸ†• æ·»åŠ  topic åˆ°è¾“å‡º
        output["topic"] = actual_topic or intent_result.topic or ""
        
        # Step 6: æ›´æ–°è®°å¿†ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ï¼‰
        await self._update_memory(user_id, session_id, intent_result, result)
        
        # Step 7: è¿½åŠ åˆ° Conversation Session MD æ–‡ä»¶
        try:
            session_mgr = self.memory_manager.get_conversation_session_manager(user_id)
            await session_mgr.start_or_continue_session(intent_result.raw_text, session_id=session_id)
            
            await session_mgr.append_turn({
                "user_query": intent_result.raw_text,
                "agent_response": {
                    "skill": skill.id,
                    "artifact_id": result.get("artifact_id", ""),
                    "content": result,
                    "topic": actual_topic  # ğŸ†• ç›´æ¥ä¼ é€’å®é™… topic
                },
                "response_type": output.get("content_type", "unknown"),
                "timestamp": datetime.now(),
                "intent": intent_result.model_dump(),
                "metadata": {
                    "thinking_tokens": result.get("_usage", {}).get("thinking_tokens", 0),
                    "output_tokens": result.get("_usage", {}).get("output_tokens", 0),
                    "model": skill.models.get("primary", "unknown")
                }
            })
            logger.debug(f"ğŸ“ Appended turn to conversation session MD")
        except Exception as e:
            logger.error(f"âŒ Failed to append to conversation session: {e}")
        
        # ğŸ†• æ·»åŠ  usage_summary åˆ°è¾“å‡ºï¼ˆä¾›å¤–éƒ¨ API ç»Ÿè®¡ï¼‰
        # ç¡®ä¿åŒ…å«æ¨¡å‹ä¿¡æ¯
        usage_summary = usage.copy() if usage else {}
        if not usage_summary.get("model"):
            usage_summary["model"] = thinking_config.get("model", "unknown")
        if "thinking_mode" not in usage_summary:
            usage_summary["thinking_mode"] = thinking_config.get("mode") == "real_thinking"
        output["usage_summary"] = usage_summary
        
        logger.info(f"âœ… Orchestration complete for {skill.id}")
        return output
    
    async def _handle_chat_stream(
        self,
        intent_result: IntentResult,
        user_id: str,
        session_id: str
    ):
        """
        ğŸ†• å¤„ç†æ™®é€šå¯¹è¯çš„æµå¼å“åº”ï¼ˆintent=otherï¼‰
        
        Args:
            intent_result: æ„å›¾è¯†åˆ«ç»“æœ
            user_id: ç”¨æˆ· ID
            session_id: ä¼šè¯ ID
            
        Yields:
            æµå¼å“åº”äº‹ä»¶
        """
        logger.info(f"ğŸ’¬ Starting chat stream for user {user_id}")
        
        # åŠ è½½å¯¹è¯å†å²ï¼ˆç®€åŒ–ç‰ˆï¼Œç›´æ¥è·å–æœ€è¿‘çš„ turns æ–‡æœ¬ï¼‰
        session_mgr = self.memory_manager.get_conversation_session_manager(user_id)
        conversation_context = ""
        
        try:
            await session_mgr.start_or_continue_session(intent_result.raw_text, session_id=session_id)
            # è·å–æœ€è¿‘ 3 è½®å¯¹è¯çš„ Markdown æ–‡æœ¬
            conversation_context = await session_mgr.get_recent_turns(num_turns=3)
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to load conversation history: {e}")
        
        # æ„å»º promptï¼ˆå°† system instruction å’Œå¯¹è¯å†å²åˆå¹¶åˆ° promptï¼‰
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„å­¦ä¹ åŠ©æ‰‹ã€‚è¯·ç”¨ç®€æ´æ¸…æ™°çš„è¯­è¨€å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å¦‚æœç”¨æˆ·é—®çš„æ˜¯å­¦ä¹ ç›¸å…³çš„é—®é¢˜ï¼Œæä¾›æœ‰å¸®åŠ©çš„ä¿¡æ¯ã€‚
å¦‚æœç”¨æˆ·åªæ˜¯æ‰“æ‹›å‘¼æˆ–é—²èŠï¼Œå‹å¥½åœ°å›åº”å¹¶å¼•å¯¼ä»–ä»¬å¼€å§‹å­¦ä¹ ã€‚
å›å¤ä½¿ç”¨ä¸­æ–‡ã€‚"""
        
        # æ„å»ºå®Œæ•´çš„ promptï¼ˆåŒ…å«å†å²ï¼‰
        full_prompt = f"{system_prompt}\n\n"
        if conversation_context:
            full_prompt += f"å¯¹è¯å†å²ï¼š\n{conversation_context}\n\n"
        full_prompt += f"ç”¨æˆ·: {intent_result.raw_text}\nåŠ©æ‰‹:"
        
        # ä½¿ç”¨ Gemini ç”Ÿæˆå“åº”
        full_response = ""
        
        try:
            yield {"type": "status", "message": "æ­£åœ¨æ€è€ƒ..."}
            
            async for chunk in self.gemini_client.generate_stream(
                prompt=full_prompt,
                model="gemini-2.5-flash",
                thinking_budget=0,  # ğŸ”§ ç¦ç”¨æ€è€ƒä»¥ç¡®ä¿å®Œæ•´è¾“å‡º
                buffer_size=5,
                temperature=0.7
            ):
                if chunk.get("type") == "content":
                    content = chunk.get("content", "")
                    full_response += content
                    yield {
                        "type": "content",
                        "content": content,
                        "accumulated": full_response
                    }
                elif chunk.get("type") == "error":
                    # æµå¼ç”Ÿæˆå‡ºé”™
                    error_msg = chunk.get("message", "ç”Ÿæˆå¤±è´¥")
                    logger.error(f"âŒ Stream generation error: {error_msg}")
                    full_response = f"æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›å¤ã€‚è¯·ç¨åå†è¯•ã€‚"
                    yield {
                        "type": "content",
                        "content": full_response,
                        "accumulated": full_response
                    }
            
            # å¦‚æœå“åº”ä¸ºç©ºï¼Œæä¾›ä¸€ä¸ªé»˜è®¤å›å¤
            if not full_response:
                full_response = "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
            
            # å‘é€å®Œæˆäº‹ä»¶
            yield {
                "type": "done",
                "content_type": "text",
                "content": {"text": full_response},
                "intent": "other"
            }
            
            # ä¿å­˜åˆ°ä¼šè¯å†å²
            try:
                from datetime import datetime
                await session_mgr.append_turn({
                    "user_query": intent_result.raw_text,
                    "agent_response": {
                        "skill": "chat",
                        "artifact_id": "",
                        "content": {"text": full_response}
                    },
                    "response_type": "text",  # ğŸ†• æ·»åŠ å¿…éœ€çš„ response_type å­—æ®µ
                    "metadata": {
                        "model": "gemini-2.5-flash",
                        "source": "chat_stream"
                    },
                    "timestamp": datetime.now(),  # ğŸ†• æ”¹ä¸º datetime å¯¹è±¡
                    "intent": {
                        "intent": "other",
                        "topic": intent_result.topic
                    }
                })
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to save chat turn: {e}")
                
        except Exception as e:
            logger.error(f"âŒ Chat stream error: {e}")
            yield {
                "type": "error",
                "message": f"å¯¹è¯ç”Ÿæˆå¤±è´¥: {str(e)}"
            }
    
    def _select_skill(self, intent_result: IntentResult) -> Optional[SkillDefinition]:
        """
        æ ¹æ®æ„å›¾é€‰æ‹©åˆé€‚çš„æŠ€èƒ½
        
        Args:
            intent_result: æ„å›¾è¯†åˆ«ç»“æœ
        
        Returns:
            é€‰ä¸­çš„ Skill å®šä¹‰ï¼Œæˆ– None
        """
        # è·å–åŒ¹é…çš„ skills
        intent = intent_result.intent
        if isinstance(intent, list):
            intent = intent[0]  # å–ç¬¬ä¸€ä¸ªæ„å›¾
        
        matching_skills = self.skill_registry.get_skills_by_intent(intent)
        
        if not matching_skills:
            logger.warning(f"âš ï¸  No skill found for intent: {intent}")
            return None
        
        # ç®€å•ç­–ç•¥ï¼šå–ç¬¬ä¸€ä¸ª
        # TODO: å¯ä»¥å®ç°æ›´å¤æ‚çš„é€‰æ‹©ç­–ç•¥ï¼ˆåŸºäºä¸Šä¸‹æ–‡ã€ç”¨æˆ·åå¥½ç­‰ï¼‰
        return matching_skills[0]
    
    def _clean_json_string(self, json_str: str) -> str:
        """
        å…¨é¢æ¸…ç† JSON å­—ç¬¦ä¸²ï¼Œä¿®å¤å¸¸è§æ ¼å¼é—®é¢˜
        
        ä¿®å¤ï¼š
        1. ä¸­æ–‡å¼•å· â†’ è‹±æ–‡å¼•å·
        2. å¤šä½™çš„é€—å·ï¼ˆtrailing commasï¼‰
        3. ç¼ºå°‘çš„é€—å·
        4. å…¶ä»–æ ¼å¼é—®é¢˜
        
        Args:
            json_str: JSON å­—ç¬¦ä¸²
        
        Returns:
            æ¸…ç†åçš„ JSON å­—ç¬¦ä¸²
        """
        # 1. ä¿®å¤ä¸­æ–‡å¼•å·
        json_str = json_str.replace('"', '"').replace('"', '"')
        json_str = json_str.replace(''', "'").replace(''', "'")
        
        # 2. ä¿®å¤ trailing commas (å¯¹è±¡ç»“å°¾)
        import re
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*\]', ']', json_str)
        
        # 3. ä¿®å¤å¤šä¸ªè¿ç»­é€—å·
        json_str = re.sub(r',\s*,', ',', json_str)
        
        return json_str
    
    def _fix_latex_escapes(self, json_str: str) -> str:
        """
        ä¿®å¤ JSON å­—ç¬¦ä¸²ä¸­ LaTeX å…¬å¼çš„è½¬ä¹‰é—®é¢˜
        
        LaTeX å…¬å¼ä¸­çš„åæ–œæ ï¼ˆå¦‚ \vec, \fracï¼‰åœ¨ JSON å­—ç¬¦ä¸²ä¸­éœ€è¦è½¬ä¹‰ä¸º \\
        é—®é¢˜ï¼šLLM ç”Ÿæˆçš„ JSON ä¸­ï¼ŒLaTeX å‘½ä»¤å¦‚ \vec æ²¡æœ‰è½¬ä¹‰ï¼Œå¯¼è‡´ JSON è§£æå¤±è´¥
        
        ç­–ç•¥ï¼šé€å­—ç¬¦æ‰«æï¼Œæ‰¾åˆ°å­—ç¬¦ä¸²å€¼ä¸­çš„ LaTeX å‘½ä»¤å¹¶è½¬ä¹‰
        
        Args:
            json_str: JSON å­—ç¬¦ä¸²
        
        Returns:
            ä¿®å¤åçš„ JSON å­—ç¬¦ä¸²
        """
        import re
        
        # åŒ¹é… JSON å­—ç¬¦ä¸²å€¼ï¼ˆ"..."ï¼‰ï¼ŒåŒ…æ‹¬è½¬ä¹‰çš„å¼•å·å’Œåæ–œæ 
        def fix_string_with_latex(match):
            """ä¿®å¤å­—ç¬¦ä¸²å€¼ä¸­çš„ LaTeX è½¬ä¹‰"""
            full_match = match.group(0)
            content = match.group(1)  # å­—ç¬¦ä¸²å†…å®¹ï¼ˆä¸åŒ…æ‹¬å¼•å·ï¼‰
            
            # å¦‚æœå†…å®¹ä¸­ä¸åŒ…å« $ï¼Œè¯´æ˜å¯èƒ½æ²¡æœ‰ LaTeXï¼Œç›´æ¥è¿”å›
            if '$' not in content:
                return full_match
            
            # é€å­—ç¬¦å¤„ç†ï¼Œä¿®å¤ LaTeX å‘½ä»¤
            result = []
            i = 0
            while i < len(content):
                char = content[i]
                
                # å¦‚æœé‡åˆ°åæ–œæ 
                if char == '\\':
                    # æ£€æŸ¥ä¸‹ä¸€ä¸ªå­—ç¬¦
                    if i + 1 < len(content):
                        next_char = content[i + 1]
                        
                        # å¦‚æœä¸‹ä¸€ä¸ªå­—ç¬¦æ˜¯å­—æ¯ï¼ˆLaTeX å‘½ä»¤ï¼‰ï¼Œéœ€è¦è½¬ä¹‰
                        if next_char.isalpha():
                            # æ£€æŸ¥å‰é¢æ˜¯å¦å·²ç»æ˜¯è½¬ä¹‰çš„åæ–œæ 
                            # åœ¨åŸå§‹å­—ç¬¦ä¸²ä¸­ï¼Œå¦‚æœå‰ä¸€ä¸ªå­—ç¬¦ä¹Ÿæ˜¯ \ï¼Œè¯´æ˜å·²ç»æ˜¯è½¬ä¹‰çš„
                            if i > 0 and content[i - 1] == '\\':
                                # å·²ç»æ˜¯è½¬ä¹‰çš„ï¼ˆåœ¨åŸå§‹å­—ç¬¦ä¸²ä¸­æ˜¯ \\ï¼‰ï¼Œä¿æŒä¸å˜
                                result.append(char)
                                result.append(next_char)
                            else:
                                # éœ€è¦è½¬ä¹‰ï¼šæ·»åŠ é¢å¤–çš„åæ–œæ 
                                # åœ¨ JSON å­—ç¬¦ä¸²ä¸­ï¼Œ\\ è¡¨ç¤ºå•ä¸ªåæ–œæ 
                                result.append('\\\\')
                                result.append(next_char)
                            i += 2
                            continue
                        else:
                            # ä¸æ˜¯ LaTeX å‘½ä»¤ï¼ˆå¯èƒ½æ˜¯è½¬ä¹‰åºåˆ—å¦‚ \n, \tï¼‰ï¼Œä¿æŒåŸæ ·
                            result.append(char)
                            result.append(next_char)
                            i += 2
                            continue
                    else:
                        # åæ–œæ åœ¨æœ«å°¾ï¼Œä¿æŒåŸæ ·
                        result.append(char)
                else:
                    result.append(char)
                
                i += 1
            
            fixed_content = ''.join(result)
            return f'"{fixed_content}"'
        
        # åŒ¹é… JSON å­—ç¬¦ä¸²å€¼ï¼ˆåŒ…æ‹¬è½¬ä¹‰çš„å¼•å·ï¼‰
        # æ¨¡å¼ï¼šåŒ¹é… "..." ä¸­çš„å†…å®¹ï¼Œå¤„ç†è½¬ä¹‰çš„å­—ç¬¦
        pattern = r'"((?:[^"\\]|\\.)*)"'
        
        fixed_json = re.sub(pattern, fix_string_with_latex, json_str)
        
        return fixed_json
    
    def _smart_fix_truncated_json(
        self,
        json_str: str,
        error: json.JSONDecodeError
    ) -> Optional[Dict[str, Any]]:
        """
        æ™ºèƒ½ä¿®å¤æˆªæ–­çš„ JSON
        
        ç­–ç•¥ï¼š
        1. æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„å­—æ®µ
        2. æ£€æµ‹å½“å‰åœ¨ä»€ä¹ˆç»“æ„ä¸­ï¼ˆå¯¹è±¡ã€æ•°ç»„ã€å­—ç¬¦ä¸²ï¼‰
        3. æ™ºèƒ½æ·»åŠ é—­åˆç¬¦å·
        
        Args:
            json_str: æˆªæ–­çš„ JSON å­—ç¬¦ä¸²
            error: JSON è§£æé”™è¯¯
        
        Returns:
            ä¿®å¤åçš„ dict æˆ– None
        """
        try:
            # è®¡ç®—éœ€è¦çš„é—­åˆç¬¦å·
            open_braces = json_str.count('{')
            close_braces = json_str.count('}')
            open_brackets = json_str.count('[')
            close_brackets = json_str.count(']')
            
            # è®¡ç®—æœªé—­åˆçš„å¼•å·ï¼ˆå­—ç¬¦ä¸²ï¼‰
            in_string = False
            escape_next = False
            for char in json_str:
                if escape_next:
                    escape_next = False
                    continue
                if char == '\\':
                    escape_next = True
                    continue
                if char == '"':
                    in_string = not in_string
            
            # æ„å»ºä¿®å¤å­—ç¬¦ä¸²
            fix = ""
            
            # å¦‚æœåœ¨å­—ç¬¦ä¸²å†…è¢«æˆªæ–­
            if in_string:
                fix += '"'
            
            # å…³é—­æœªé—­åˆçš„æ•°ç»„
            for _ in range(open_brackets - close_brackets):
                fix += ']'
            
            # å…³é—­æœªé—­åˆçš„å¯¹è±¡
            for _ in range(open_braces - close_braces):
                fix += '}'
            
            # å°è¯•ä¿®å¤
            fixed_json = json_str + fix
            parsed = json.loads(fixed_json)
            
            logger.info(f"ğŸ”§ Smart fix applied: added {repr(fix)}")
            return parsed
        
        except Exception as e:
            logger.debug(f"Smart fix failed: {e}")
            return None
    
    async def _build_context(
        self,
        skill: SkillDefinition,
        user_id: str,
        session_id: str
    ) -> Dict[str, Any]:
        """
        ğŸ†• æ„å»ºæŠ€èƒ½æ‰§è¡Œæ‰€éœ€çš„ä¸Šä¸‹æ–‡ï¼ˆæ™ºèƒ½åŠ è½½ï¼‰
        
        åŒ…æ‹¬ï¼š
        1. ç”¨æˆ·ç”»åƒå’Œä¼šè¯ä¸Šä¸‹æ–‡
        2. æœ€è¿‘çš„ artifactsï¼ˆç”¨äºä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼‰
        3. Memory summaryï¼ˆè¡Œä¸ºæ€»ç»“ï¼‰
        4. ğŸ†• Conversation Session Contextï¼ˆé•¿æœŸè®°å¿†ï¼Œæ™ºèƒ½å‹ç¼©ï¼‰
        
        Args:
            skill: Skill å®šä¹‰
            user_id: ç”¨æˆ· ID
            session_id: ä¼šè¯ ID
        
        Returns:
            ä¸Šä¸‹æ–‡å­—å…¸
        """
        context = {}
        
        # æ ¹æ® skill çš„ context é…ç½®è·å–å¿…è¦çš„ä¸Šä¸‹æ–‡
        if skill.context.get("need_user_memory", False):
            user_profile = await self.memory_manager.get_user_profile(user_id)
            session_context = await self.memory_manager.get_session_context(session_id)
            memory_summary = await self.memory_manager.generate_memory_summary(user_id, session_id)
            
            context["user_profile"] = user_profile.model_dump()
            context["session_context"] = session_context.model_dump()
            context["memory_summary"] = memory_summary.recent_behavior
            
            # ğŸ”¥ åŠ è½½æœ€è¿‘çš„ artifactsï¼ˆæ„å»ºä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼‰
            try:
                recent_artifacts = []
                if session_context.artifact_history:
                    # ğŸ” è°ƒè¯•ï¼šæŸ¥çœ‹ artifact_history å†…å®¹
                    logger.info(f"ğŸ” Total artifacts in history: {len(session_context.artifact_history)}")
                    for idx, record in enumerate(session_context.artifact_history):
                        logger.debug(f"  [{idx}] {record.artifact_id[:50]}... | {record.topic} | {len(str(record.content)) if record.content else 0} chars")
                    
                    # è·å–æœ€è¿‘çš„ 2 ä¸ª artifact records (é™åˆ¶ä¸º2é¿å…promptè¿‡å¤§)
                    recent_artifact_records = session_context.artifact_history[-2:]
                    
                    for artifact_record in recent_artifact_records:
                        # ğŸ†• ä½¿ç”¨ summaryï¼ˆå‹ç¼©æ‘˜è¦ï¼‰ä½œä¸º LLM ä¸Šä¸‹æ–‡
                        # content ä¿ç•™åŸå§‹å®Œæ•´æ•°æ®ï¼Œä¾› reference_resolver ä½¿ç”¨
                        summary_str = artifact_record.summary if artifact_record.summary else ""
                        summary_size = len(summary_str)
                        
                        if summary_str:
                            recent_artifacts.append({
                                "artifact_id": artifact_record.artifact_id,
                                "topic": artifact_record.topic,
                                "type": artifact_record.artifact_type,
                                "summary": artifact_record.summary,  # ç”¨äº LLM ä¸Šä¸‹æ–‡
                                # ğŸ†• ä¸å†ä¼  content ç»™ LLMï¼ˆå¤ªå¤§ï¼‰ï¼Œåªä¼  summary
                            })
                            logger.info(f"ğŸ“„ Loaded artifact: {artifact_record.topic} ({artifact_record.artifact_type}, {summary_size} chars)")
                        else:
                            logger.warning(f"âš ï¸  Artifact {artifact_record.artifact_id} has no summary")
                
                context["recent_artifacts"] = recent_artifacts
                logger.info(f"ğŸ“š Loaded {len(recent_artifacts)} recent artifacts for context")
                
            except Exception as e:
                logger.warning(f"âš ï¸  Failed to load recent artifacts: {e}")
                context["recent_artifacts"] = []
        
        # ğŸ†• åŠ è½½ Conversation Session Contextï¼ˆé•¿æœŸè®°å¿† + æ™ºèƒ½å‹ç¼©ï¼‰
        try:
            session_mgr = self.memory_manager.get_conversation_session_manager(user_id)
            
            # è·å–æ™ºèƒ½æ„å»ºçš„ session contextï¼ˆåŒ…å«ç»§æ‰¿ + æœ€è¿‘å¯¹è¯ï¼‰
            conversation_context = await session_mgr.get_session_context_for_llm(
                include_recent_turns=5,  # æœ€è¿‘ 5 è½®
                include_inherited=True   # åŒ…å«ç»§æ‰¿çš„ summary
            )
            
            if conversation_context:
                context["conversation_history"] = conversation_context
                logger.debug(f"ğŸ—‚ï¸  Loaded conversation session context ({len(conversation_context)} chars)")
            else:
                context["conversation_history"] = ""
                logger.debug("ğŸ—‚ï¸  No conversation history available")
        
        except Exception as e:
            logger.warning(f"âš ï¸  Failed to load conversation session context: {e}")
            context["conversation_history"] = ""
        
        # TODO: å¦‚æœéœ€è¦ content_storeï¼Œä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³å†…å®¹
        if skill.context.get("need_content_store", False):
            context["content_context"] = []  # å ä½ç¬¦
        
        return context
    
    def _build_input_params(
        self,
        skill: SkillDefinition,
        intent_result: IntentResult,
        context: Dict[str, Any],
        additional_params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ„å»ºæŠ€èƒ½çš„è¾“å…¥å‚æ•°
        
        Args:
            skill: Skill å®šä¹‰
            intent_result: æ„å›¾ç»“æœ
            context: ä¸Šä¸‹æ–‡
            additional_params: é¢å¤–å‚æ•°
        
        Returns:
            è¾“å…¥å‚æ•°å­—å…¸
        """
        params = {}
        
        # ä» intent_result æå–åŸºæœ¬å‚æ•°ï¼Œå¹¶éªŒè¯ topic æœ‰æ•ˆæ€§
        topic = intent_result.topic
        topic_is_valid = False
        
        if topic:
            # éªŒè¯ topic æ˜¯å¦æœ‰æ•ˆï¼ˆé•¿åº¦ >= 2ï¼Œä¸”ä¸æ˜¯çº¯æ•°å­—/åºæ•°è¯ï¼‰
            invalid_topics = ["ç¬¬ä¸€", "ç¬¬äºŒ", "ç¬¬ä¸‰", "è¿™", "é‚£", "å®ƒ", "è¿™ä¸ª", "é‚£ä¸ª"]
            if len(topic) >= 2 and topic not in invalid_topics and not topic.isdigit():
                params["topic"] = topic
                topic_is_valid = True
            else:
                logger.info(f"âš ï¸  Invalid topic detected: '{topic}', will use fallback")
        
        # ğŸ†• Topic Fallback ç­–ç•¥
        if not topic_is_valid:
            if "session_context" in context:
                session_ctx = context["session_context"]
                current_topic = None
                artifact_history = []
                
                if isinstance(session_ctx, dict):
                    current_topic = session_ctx.get('current_topic')
                    artifact_history = session_ctx.get('artifact_history', [])
                else:
                    current_topic = getattr(session_ctx, 'current_topic', None)
                    artifact_history = getattr(session_ctx, 'artifact_history', [])
                
                # ğŸ¯ æ³¨æ„ï¼šæ¾„æ¸…æœºåˆ¶å·²ç»åœ¨ execute() æ–¹æ³•å¼€å§‹æ—¶å¤„ç†
                #    å¦‚æœæ‰§è¡Œåˆ°è¿™é‡Œï¼Œè¯´æ˜ä¸éœ€è¦æ¾„æ¸…ï¼Œç›´æ¥ä½¿ç”¨ current_topic fallback
                
                # æ ‡å‡† fallback: ä½¿ç”¨ current_topic
                if current_topic:
                    params["topic"] = current_topic
                    logger.info(f"ğŸ“ Topic fallback: using session current_topic = {current_topic}")
                else:
                    logger.warning(f"âš ï¸  No valid topic found in intent_result or session_context for {skill.id}")
        
        # æ·»åŠ  memory_summary
        if "memory_summary" in context:
            params["memory_summary"] = context["memory_summary"]
        
        # V1.5: æ£€æŸ¥æ˜¯å¦éœ€è¦å¼•ç”¨ä¸Šä¸€è½® artifact
        if hasattr(intent_result, 'parameters') and intent_result.parameters:
            use_last_artifact = intent_result.parameters.get('use_last_artifact', False)
            if use_last_artifact and "session_context" in context:
                session_ctx = context["session_context"]
                # session_ctx å¯èƒ½æ˜¯å­—å…¸ï¼ˆmodel_dumpåï¼‰æˆ–å¯¹è±¡
                if isinstance(session_ctx, dict):
                    last_artifact_content = session_ctx.get('last_artifact_content')
                else:
                    last_artifact_content = getattr(session_ctx, 'last_artifact_content', None)
                
                if last_artifact_content:
                    # ğŸ†• æ™ºèƒ½æå–ï¼šåŸºäºIntent Routerè¯†åˆ«çš„å¼•ç”¨ç±»å‹æå–å†…å®¹
                    import json
                    
                    # ğŸ†• ä¼˜å…ˆä» artifact_history ä¸­æœç´¢ï¼ˆæ”¯æŒå¤šè½®å¼•ç”¨ï¼‰
                    artifact_history = getattr(session_ctx, 'artifact_history', []) if not isinstance(session_ctx, dict) else session_ctx.get('artifact_history', [])
                    
                    source_content = last_artifact_content
                    reference_type = intent_result.parameters.get("reference_type")
                    reference_index = intent_result.parameters.get("reference_index")
                    reference_description = intent_result.parameters.get("reference_description")
                    
                    # ğŸ” å¦‚æœæœ‰reference_descriptionï¼Œå°è¯•ä»å†å²ä¸­æœç´¢åŒ¹é…çš„artifact
                    if reference_description and artifact_history:
                        matched_artifact = self._search_artifact_history(artifact_history, reference_description)
                        if matched_artifact:
                            source_content = matched_artifact.content
                            logger.info(f"ğŸ” Found matching artifact in history: #{matched_artifact.turn_number} ({matched_artifact.artifact_type})")
                        else:
                            logger.info(f"â„¹ï¸  No match found in history for '{reference_description}', using last_artifact")
                    
                    # 1ï¸âƒ£ å¼•ç”¨ç‰¹å®šé¢˜ç›®ï¼ˆæ˜ç¡®åºå·ï¼‰
                    if reference_type == "question" and isinstance(reference_index, int):
                        if isinstance(last_artifact_content, dict) and "questions" in last_artifact_content:
                            questions = last_artifact_content["questions"]
                            if 1 <= reference_index <= len(questions):
                                specific_question = questions[reference_index - 1]
                                source_content = {
                                    "quiz_set_id": last_artifact_content.get("quiz_set_id"),
                                    "subject": last_artifact_content.get("subject"),
                                    "specific_question": specific_question,
                                    "question_number": reference_index
                                }
                                logger.info(f"âœ¨ LLM detected: Extract question #{reference_index} from quiz_set")
                    
                    # 2ï¸âƒ£ å¼•ç”¨ç‰¹å®šä¾‹å­ï¼ˆæ˜ç¡®åºå·ï¼‰
                    elif reference_type == "example" and isinstance(reference_index, int):
                        if isinstance(last_artifact_content, dict) and "examples" in last_artifact_content:
                            examples = last_artifact_content["examples"]
                            if 1 <= reference_index <= len(examples):
                                specific_example = examples[reference_index - 1]
                                source_content = {
                                    "concept": last_artifact_content.get("concept"),
                                    "subject": last_artifact_content.get("subject"),
                                    "specific_example": specific_example,
                                    "example_number": reference_index,
                                    "all_examples": examples  # ä¿ç•™ä¸Šä¸‹æ–‡
                                }
                                logger.info(f"âœ¨ LLM detected: Extract example #{reference_index} from explanation")
                    
                    # 3ï¸âƒ£ å¼•ç”¨æ‰€æœ‰ä¾‹å­
                    elif reference_type == "examples" and reference_index == "all":
                        if isinstance(last_artifact_content, dict) and "examples" in last_artifact_content:
                            source_content = {
                                "concept": last_artifact_content.get("concept"),
                                "subject": last_artifact_content.get("subject"),
                                "all_examples": last_artifact_content["examples"]
                            }
                            logger.info(f"âœ¨ LLM detected: Use all {len(last_artifact_content['examples'])} examples")
                    
                    # 4ï¸âƒ£ å¼•ç”¨ç‰¹å®šå†…å®¹ï¼ˆè¯­ä¹‰æœç´¢ï¼‰
                    elif reference_type == "content" and reference_description:
                        # ğŸ” åœ¨last_artifact_contentä¸­æœç´¢åŒ…å«reference_descriptionçš„å†…å®¹
                        extracted_content = self._semantic_search_content(
                            last_artifact_content, 
                            reference_description
                        )
                        if extracted_content:
                            source_content = extracted_content
                            logger.info(f"âœ¨ LLM detected: Extract content matching '{reference_description}'")
                        else:
                            logger.warning(f"âš ï¸  Could not find content matching '{reference_description}', using full content")
                    
                    # 5ï¸âƒ£ å¼•ç”¨æ•´ä¸ªartifactï¼ˆé»˜è®¤ï¼‰
                    elif reference_type == "last_artifact" or not reference_type:
                        logger.info(f"âœ¨ Using full last_artifact_content as source")
                    
                    # å°†å†…å®¹ä½œä¸º source_content ä¼ é€’ç»™ skill
                    if isinstance(source_content, dict):
                        params["source_content"] = json.dumps(source_content, ensure_ascii=False, indent=2)
                    else:
                        params["source_content"] = str(source_content)
                    logger.info(f"ğŸ“ Prepared source_content for {skill.id}")
        
        # ğŸ†• V1.7: æå– quantity å‚æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨å…·ä½“å‚æ•°åï¼‰
        if hasattr(intent_result, 'parameters') and intent_result.parameters:
            quantity = None
            
            # æ ¹æ®ä¸åŒçš„ skill ä¼˜å…ˆæŸ¥æ‰¾å¯¹åº”çš„å‚æ•°
            if skill.id == 'quiz_skill':
                # ä¼˜å…ˆæŸ¥æ‰¾ num_questionsï¼Œç„¶åæ˜¯ quantity
                quantity = intent_result.parameters.get('num_questions') or intent_result.parameters.get('quantity')
                if quantity is None:
                    quantity = 5  # é»˜è®¤ 5 é“é¢˜
                params['num_questions'] = quantity
                logger.info(f"ğŸ“Š Quiz quantity: {quantity}")
                
            elif skill.id == 'flashcard_skill':
                # ä¼˜å…ˆæŸ¥æ‰¾ num_cardsï¼Œç„¶åæ˜¯ quantity
                quantity = intent_result.parameters.get('num_cards') or intent_result.parameters.get('quantity')
                if quantity is None:
                    quantity = 5  # é»˜è®¤ 5 å¼ å¡
                params['num_cards'] = quantity
                logger.info(f"ğŸ“Š Flashcard quantity: {quantity}")
        
        # ğŸ”¥ åˆå¹¶æ‰€æœ‰ intent parameters (é™¤äº†å·²ç»è¢«å¤„ç†çš„)
        # è¿™ç¡®ä¿ Plan Skill å¯ä»¥æ¥æ”¶ flashcard_quantity, quiz_quantity ç­‰è‡ªå®šä¹‰å‚æ•°
        # âš ï¸  åªåˆå¹¶éç©ºå€¼ï¼Œé¿å…ä¼ é€’ None æˆ–ç©ºå­—ç¬¦ä¸²å¯¼è‡´åç»­å¤„ç†é”™è¯¯
        if hasattr(intent_result, 'parameters') and intent_result.parameters:
            for key, value in intent_result.parameters.items():
                # è¿‡æ»¤æ‰ Noneã€ç©ºå­—ç¬¦ä¸²ã€ç©ºåˆ—è¡¨ç­‰æ— æ•ˆå€¼
                if value is not None and value != "" and value != [] and key not in params:
                    params[key] = value
        
        # æ·»åŠ ç”¨æˆ·æä¾›çš„é¢å¤–å‚æ•°
        if additional_params:
            params.update(additional_params)
        
        return params
    
    def _search_artifact_history(
        self,
        artifact_history: List[Any],
        keyword: str
    ) -> Optional[Any]:
        """
        åœ¨artifact_historyä¸­æœç´¢åŒ…å«keywordçš„artifact
        
        Args:
            artifact_history: artifactå†å²è®°å½•åˆ—è¡¨
            keyword: æœç´¢å…³é”®è¯
        
        Returns:
            åŒ¹é…çš„ArtifactRecordï¼Œå¦‚æœæ²¡æ‰¾åˆ°è¿”å›None
        """
        import json
        
        keyword_lower = keyword.lower()
        
        # ä»æœ€æ–°åˆ°æœ€æ—§æœç´¢
        for artifact in reversed(artifact_history):
            # 1. æœç´¢summary
            if hasattr(artifact, 'summary') and artifact.summary:
                if keyword_lower in artifact.summary.lower():
                    logger.info(f"ğŸ¯ Keyword '{keyword}' found in artifact #{artifact.turn_number} summary")
                    return artifact
            
            # 2. æœç´¢topic
            if hasattr(artifact, 'topic') and artifact.topic:
                if keyword_lower in artifact.topic.lower():
                    logger.info(f"ğŸ¯ Keyword '{keyword}' found in artifact #{artifact.turn_number} topic")
                    return artifact
            
            # 3. æœç´¢content
            if hasattr(artifact, 'content'):
                content_str = json.dumps(artifact.content, ensure_ascii=False).lower()
                if keyword_lower in content_str:
                    logger.info(f"ğŸ¯ Keyword '{keyword}' found in artifact #{artifact.turn_number} content")
                    return artifact
        
        return None
    
    def _semantic_search_content(
        self,
        content: Dict[str, Any],
        keyword: str
    ) -> Optional[Dict[str, Any]]:
        """
        åœ¨contentä¸­æœç´¢åŒ…å«keywordçš„éƒ¨åˆ†ï¼ˆç®€å•çš„å…³é”®è¯åŒ¹é…ï¼‰
        
        Args:
            content: è¦æœç´¢çš„å†…å®¹ï¼ˆlast_artifact_contentï¼‰
            keyword: æœç´¢å…³é”®è¯ï¼ˆå¦‚ "åŒ—æå†°å·"ã€"æ¸©å®¤æ•ˆåº”"ï¼‰
        
        Returns:
            åŒ¹é…çš„å†…å®¹ï¼Œå¦‚æœæ²¡æ‰¾åˆ°è¿”å›None
        """
        import json
        
        # å°†contentè½¬ä¸ºå­—ç¬¦ä¸²ä¾¿äºæœç´¢
        content_str = json.dumps(content, ensure_ascii=False).lower()
        keyword_lower = keyword.lower()
        
        # 1. åœ¨examplesä¸­æœç´¢
        if "examples" in content and isinstance(content["examples"], list):
            for idx, example in enumerate(content["examples"]):
                example_str = json.dumps(example, ensure_ascii=False).lower()
                if keyword_lower in example_str:
                    logger.info(f"ğŸ” Found keyword '{keyword}' in example #{idx+1}")
                    return {
                        "concept": content.get("concept"),
                        "subject": content.get("subject"),
                        "specific_example": example,
                        "example_number": idx + 1,
                        "matched_keyword": keyword,
                        "all_examples": content["examples"]
                    }
        
        # 2. åœ¨questionsä¸­æœç´¢
        if "questions" in content and isinstance(content["questions"], list):
            for idx, question in enumerate(content["questions"]):
                question_str = json.dumps(question, ensure_ascii=False).lower()
                if keyword_lower in question_str:
                    logger.info(f"ğŸ” Found keyword '{keyword}' in question #{idx+1}")
                    return {
                        "quiz_set_id": content.get("quiz_set_id"),
                        "subject": content.get("subject"),
                        "specific_question": question,
                        "question_number": idx + 1,
                        "matched_keyword": keyword
                    }
        
        # 3. åœ¨flashcardsä¸­æœç´¢
        if "flashcards" in content and isinstance(content["flashcards"], list):
            matched_cards = []
            for idx, card in enumerate(content["flashcards"]):
                card_str = json.dumps(card, ensure_ascii=False).lower()
                if keyword_lower in card_str:
                    matched_cards.append(card)
            
            if matched_cards:
                logger.info(f"ğŸ” Found keyword '{keyword}' in {len(matched_cards)} flashcard(s)")
                return {
                    "flashcard_set_id": content.get("flashcard_set_id"),
                    "subject": content.get("subject"),
                    "matched_flashcards": matched_cards,
                    "matched_keyword": keyword
                }
        
        # 4. æ²¡æ‰¾åˆ°ï¼Œè¿”å›None
        logger.warning(f"âš ï¸  Keyword '{keyword}' not found in content")
        return None
    
    async def _execute_plan_skill(
        self,
        skill: SkillDefinition,
        intent_result: IntentResult,
        user_id: str,
        session_id: str,
        additional_params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œ Plan Skillï¼ˆä¸²è”è°ƒç”¨å¤šä¸ª skillsï¼‰
        
        Args:
            skill: Plan Skill å®šä¹‰
            intent_result: æ„å›¾ç»“æœ
            user_id: ç”¨æˆ· ID
            session_id: ä¼šè¯ ID
            additional_params: é¢å¤–å‚æ•°
        
        Returns:
            å­¦ä¹ åŒ…ç»“æœ
        """
        from .plan_skill_executor import PlanSkillExecutor
        
        logger.info(f"\n{'='*70}")
        logger.info(f"ğŸ¯ å¼€å§‹æ‰§è¡Œ Plan Skill: {skill.id}")
        logger.info(f"{'='*70}\n")
        
        # è·å–ç”¨æˆ·ç”»åƒå’Œä¼šè¯ä¸Šä¸‹æ–‡
        user_profile = await self.memory_manager.get_user_profile(user_id)
        session_context = await self.memory_manager.get_session_context(session_id)
        
        # ç”Ÿæˆ memory summary
        memory_summary = await self.memory_manager.generate_memory_summary(user_id, session_id)
        
        # æ„å»ºç”¨æˆ·è¾“å…¥
        user_input = {
            "subject": intent_result.parameters.get("subject") if intent_result.parameters else None,
            "topic": intent_result.topic,
            "difficulty": intent_result.parameters.get("difficulty", "medium") if intent_result.parameters else "medium",
            "memory_summary": memory_summary.recent_behavior,  # ğŸ”§ ä½¿ç”¨ generate_memory_summary ç»“æœ
            "language": additional_params.get("language", "auto") if additional_params else "auto"  # ğŸ†• ä¼ é€’è¯­è¨€åå¥½
        }
        
        # ğŸ”¥ å°†æ‰€æœ‰ intent parameters åˆå¹¶åˆ° user_inputï¼Œç¡®ä¿ Plan Skill å¯ä»¥è®¿é—®æ‰€æœ‰æå–çš„å‚æ•°
        # (ä¾‹å¦‚ flashcard_quantity, quiz_quantity ç­‰)
        # âš ï¸  åªåˆå¹¶éç©ºå€¼ï¼Œé¿å…ä¼ é€’ None æˆ–ç©ºå­—ç¬¦ä¸²å¯¼è‡´åç»­å¤„ç†é”™è¯¯
        if intent_result.parameters:
            for key, value in intent_result.parameters.items():
                # è¿‡æ»¤æ‰ Noneã€ç©ºå­—ç¬¦ä¸²ã€ç©ºåˆ—è¡¨ç­‰æ— æ•ˆå€¼
                if value is not None and value != "" and value != [] and key not in user_input:
                    user_input[key] = value
                    logger.debug(f"ğŸ“ Merged parameter from intent: {key}={value}")
        
        # å¦‚æœ subject ä¸ºç©ºï¼Œå°è¯•ä» topic ä¸­æå–
        if not user_input.get("subject") and intent_result.topic:
            # ç®€å•æå–ï¼šå‡è®¾ topic å¯èƒ½åŒ…å«å­¦ç§‘ä¿¡æ¯
            user_input["subject"] = "é€šç”¨"
        
        # ğŸ› DEBUG: Log final user_input before executing plan
        logger.debug(f"ğŸ“¥ Final user_input for Plan Skill: {user_input}")
        
        # åˆ›å»º Plan Skill æ‰§è¡Œå™¨
        executor = PlanSkillExecutor(skill_orchestrator=self)
        
        # æ‰§è¡Œè®¡åˆ’
        try:
            bundle = await executor.execute_plan(
                plan_config=skill.raw_config,  # ğŸ†• ä½¿ç”¨åŸå§‹é…ç½®
                user_input=user_input,
                user_profile=user_profile,
                session_context=session_context
            )
            
            # å°è£…è¾“å‡º
            output = {
                "skill_id": skill.id,
                "content_type": "learning_bundle",
                "response_content": bundle,
                "intent": intent_result.intent
            }
            
            # æ›´æ–°è®°å¿†ï¼ˆä¿å­˜å­¦ä¹ åŒ…åˆ° artifact_historyï¼‰
            await self._update_memory(user_id, session_id, intent_result, bundle)
            
            logger.info(f"âœ… Plan Skill æ‰§è¡Œå®Œæˆ: {skill.id}")
            
            return output
            
        except Exception as e:
            logger.error(f"âŒ Plan Skill æ‰§è¡Œå¤±è´¥: {e}")
            logger.exception(e)
            return self._create_error_response(
                "plan_execution_error",
                f"å­¦ä¹ åŒ…ç”Ÿæˆå¤±è´¥: {str(e)}"
            )
    
    async def _execute_single_skill(
        self,
        skill_id: str,
        input_params: Dict[str, Any],
        user_profile: Any,
        session_context: Any
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ª skillï¼ˆä¾› PlanSkillExecutor è°ƒç”¨ï¼‰
        
        Args:
            skill_id: Skill ID
            input_params: è¾“å…¥å‚æ•°
            user_profile: ç”¨æˆ·ç”»åƒ
            session_context: ä¼šè¯ä¸Šä¸‹æ–‡
        
        Returns:
            Skill æ‰§è¡Œç»“æœ
        """
        # ä» registry è·å– skillï¼ˆä½¿ç”¨å…¬å…±æ–¹æ³•ï¼‰
        skill = self.skill_registry.get_skill(skill_id)
        
        if not skill:
            raise ValueError(f"Skill not found: {skill_id}")
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context = {
            "user_profile": user_profile,
            "session_context": session_context
        }
        
        # æ‰§è¡Œ skill
        response = await self._execute_skill(skill, input_params, context)
        
        # ğŸ†• response æ˜¯å­—å…¸: {"content": str, "thinking": str, "usage": dict}
        # æå–å†…å®¹
        result_json = response.get("content", response) if isinstance(response, dict) else response
        thinking = response.get("thinking") if isinstance(response, dict) else None
        usage = response.get("usage", {}) if isinstance(response, dict) else {}
        
        # è§£æç»“æœ
        result = json.loads(result_json) if isinstance(result_json, str) else result_json
        
        # ğŸ†• å°†æ€è€ƒè¿‡ç¨‹æ·»åŠ åˆ°ç»“æœä¸­
        if thinking:
            result["_thinking"] = thinking
            result["_usage"] = usage
        
        return result
    
    async def _execute_single_skill_stream(
        self,
        skill_id: str,
        input_params: Dict[str, Any],
        user_profile: Any,
        session_context: Any,
        step_index: int = 1  # ğŸ†• æ­¥éª¤ç´¢å¼•ï¼Œç”¨äºæ™ºèƒ½é€‰æ‹© thinking æ¨¡å¼
    ):
        """
        ğŸ†• æµå¼æ‰§è¡Œå•ä¸ªskillï¼ˆç”¨äºPlan Skillçš„æ¯ä¸ªæ­¥éª¤ï¼‰
        
        Args:
            skill_id: Skill ID
            input_params: è¾“å…¥å‚æ•°
            user_profile: ç”¨æˆ·ç”»åƒ
            session_context: ä¼šè¯ä¸Šä¸‹æ–‡
            step_index: æ­¥éª¤ç´¢å¼•ï¼ˆ1=ç¬¬ä¸€æ­¥ï¼Œ2+=åç»­æ­¥éª¤ï¼‰
        
        Thinking æ¨¡å¼é€‰æ‹©é€»è¾‘ï¼š
            - ç¬¬ä¸€æ­¥ (explain_skill) â†’ çœŸæ€è€ƒ (Kimi)ï¼Œæ·±åº¦ç†è§£æ ¸å¿ƒæ¦‚å¿µ
            - åç»­æ­¥éª¤ (flashcard/quiz/notes/mindmap) â†’ ä¼ªæ€è€ƒ (Gemini)ï¼Œå¿«é€Ÿç”Ÿæˆ
        
        Yields:
            Dict: æµå¼äº‹ä»¶
        """
        # è·å–skill
        skill = self.skill_registry.get_skill(skill_id)
        if not skill:
            yield {
                "type": "error",
                "message": f"Skill not found: {skill_id}"
            }
            return
        
        # åŠ è½½promptå¹¶æ ¼å¼åŒ–
        prompt_content = self._load_prompt(skill)
        context = {
            "user_profile": user_profile,
            "session_context": session_context
        }
        full_prompt = self._format_prompt(prompt_content, input_params, context)
        
        # ğŸ”¥ æ™ºèƒ½é€‰æ‹© Thinking æ¨¡å¼
        # 
        # åˆ¤æ–­æ¡ä»¶ï¼š
        # 1. ç¬¬ä¸€æ­¥ (step_index == 1) ä¸” session ä¸­æ²¡æœ‰è¯¥ topic çš„ artifact â†’ çœŸæ€è€ƒ
        # 2. åç»­æ­¥éª¤æˆ–å·²æœ‰ä¸Šä¸‹æ–‡ â†’ ä¼ªæ€è€ƒ
        #
        # è¿™æ ·æ— è®º Plan Skill çš„æ­¥éª¤é¡ºåºå¦‚ä½•ï¼ˆå¯èƒ½æ˜¯ flashcard + quizï¼Œæ²¡æœ‰ explainï¼‰ï¼Œ
        # ç¬¬ä¸€æ­¥éƒ½ä¼šç”¨çœŸæ€è€ƒæ¥ç†è§£ topicï¼Œåç»­æ­¥éª¤ç”¨ä¼ªæ€è€ƒåŸºäºå·²æœ‰å†…å®¹å¿«é€Ÿç”Ÿæˆ
        
        # æ£€æŸ¥ session ä¸­æ˜¯å¦å·²æœ‰è¯¥ topic çš„ artifact
        topic = input_params.get("topic", "")
        has_existing_context = False
        if session_context and hasattr(session_context, 'artifact_history'):
            for artifact in session_context.artifact_history:
                if artifact.topic == topic:
                    has_existing_context = True
                    break
        
        # ğŸ”§ ä¸´æ—¶é…ç½®ï¼šå…¨éƒ¨ä½¿ç”¨ Geminiï¼ˆå…³é—­ Kimiï¼‰
        
        thinking_accumulated = []
        content_accumulated = []
        
        # âš¡ å…¨éƒ¨ä½¿ç”¨ Geminiï¼ˆå¿«é€Ÿç¨³å®šï¼‰
        logger.info(f"âš¡ Executing sub-skill: {skill_id} (Step {step_index}, topic='{topic}' â†’ Gemini)")
        
        async for chunk in self.gemini_client.generate_stream(
            prompt=full_prompt,
            model="gemini-2.5-flash",
            thinking_budget=0,  # ğŸ”§ ç¦ç”¨æ€è€ƒä»¥ç¡®ä¿å®Œæ•´è¾“å‡º
            buffer_size=1,
            temperature=getattr(skill, 'temperature', 0.7)
        ):
            # ç´¯ç§¯æ•°æ®
            if chunk["type"] == "thinking":
                thinking_accumulated.append(chunk.get("text", ""))
            elif chunk["type"] == "content":
                content_accumulated.append(chunk.get("text", ""))
            
            # ğŸ”¥ è½¬å‘ chunkï¼ˆè·³è¿‡ LLM å®¢æˆ·ç«¯çš„ done äº‹ä»¶ï¼Œæˆ‘ä»¬è‡ªå·±æ„å»ºï¼‰
            if chunk["type"] != "done":
                yield chunk
        
        # è§£ææœ€ç»ˆç»“æœ
        full_thinking = "".join(thinking_accumulated)
        full_content = "".join(content_accumulated)
        
        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æœ‰å®é™…å†…å®¹ï¼ˆLLM å¯èƒ½æŠŠæ‰€æœ‰ token èŠ±åœ¨ thinking ä¸Šï¼‰
        if not full_content or len(full_content.strip()) < 10:
            logger.error(f"âŒ No content generated (content: {len(full_content)} chars, thinking: {len(full_thinking)} chars)")
            yield {
                "type": "error",
                "message": "LLM ç”Ÿæˆå†…å®¹ä¸ºç©ºï¼ˆå¯èƒ½ thinking æ¶ˆè€—äº†æ‰€æœ‰ tokenï¼‰ï¼Œè¯·é‡è¯•"
            }
            return
        
        # æå–JSON
        json_str = full_content
        if "```json" in json_str:
            try:
                json_str = json_str.split("```json")[1].split("```")[0].strip()
            except:
                pass
        elif "```" in json_str:
            try:
                json_str = json_str.split("```")[1].split("```")[0].strip()
            except:
                pass
        
        # ğŸ”§ Step 1: æ¸…ç†å¸¸è§æ ¼å¼é—®é¢˜
        json_str = self._clean_json_string(json_str)
        
        # ğŸ”§ Step 2: ä¿®å¤ LaTeX å…¬å¼ä¸­çš„è½¬ä¹‰é—®é¢˜
        json_str = self._fix_latex_escapes(json_str)
        
        # è§£æJSON
        parsed_content = None
        try:
            parsed_content = json.loads(json_str)
            logger.info(f"âœ… JSON parsed successfully (sub-skill)")
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Failed to parse JSON: {e}")
            logger.error(f"Content preview: {json_str[:200]}...")
            
            # ğŸ”§ æ™ºèƒ½ä¿®å¤æˆªæ–­çš„ JSON
            if "Unterminated string" in str(e) or "Expecting" in str(e):
                logger.warning(f"âš ï¸  JSON appears malformed, attempting smart fix...")
                
                # ç­–ç•¥ 1: æ™ºèƒ½æ£€æµ‹å¹¶ä¿®å¤
                parsed_content = self._smart_fix_truncated_json(json_str, e)
                
                # ç­–ç•¥ 2: æš´åŠ›ä¿®å¤ï¼ˆå¦‚æœæ™ºèƒ½ä¿®å¤å¤±è´¥ï¼‰
                if parsed_content is None:
                    logger.warning(f"âš ï¸  Smart fix failed, trying brute force...")
                    fixed_attempts = [
                        json_str + '"}',       # ç¼ºå°‘å¼•å·å’ŒèŠ±æ‹¬å·
                        json_str + '"]}}',     # æ•°ç»„+å¯¹è±¡
                        json_str + '"}}',      # å­—ç¬¦ä¸²+å¯¹è±¡
                        json_str + '}}',       # å¯¹è±¡
                        json_str + ']}}',      # æ•°ç»„+å¯¹è±¡
                    ]
                    
                    for i, attempt in enumerate(fixed_attempts):
                        try:
                            parsed_content = json.loads(attempt)
                            logger.info(f"âœ… JSON fixed (brute force attempt {i+1})")
                            break
                        except:
                            continue
            
            if parsed_content is None:
                yield {
                    "type": "error",
                    "message": "ç”Ÿæˆå†…å®¹æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•"
                }
                return
        
        # æ£€æµ‹content_type
        content_type = "unknown"
        if "quiz_set_id" in parsed_content or "questions" in parsed_content:
            content_type = "quiz_set"
        elif "concept" in parsed_content:
            content_type = "explanation"
        elif "cardList" in parsed_content or "card_set_id" in parsed_content or "cards" in parsed_content:
            content_type = "flashcard_set"
        elif "structured_notes" in parsed_content:
            content_type = "notes"
        elif "root" in parsed_content:
            content_type = "mindmap"
        
        # æ„å»ºå®Œæ•´ç»“æœ
        result = {
            "skill_id": skill_id,
            "content_type": content_type,
            **parsed_content
        }
        
        # å‘é€doneäº‹ä»¶ï¼ˆæ ¼å¼ç»Ÿä¸€ï¼šä½¿ç”¨contentå­—æ®µï¼‰
        yield {
            "type": "done",
            "thinking": full_thinking,
            "content": parsed_content,
            "content_type": content_type
        }
    
    async def _execute_skill(
        self,
        skill: SkillDefinition,
        params: Dict[str, Any],
        context: Dict[str, Any],
        client: Optional[Any] = None,
        thinking_config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡ŒæŠ€èƒ½ - ğŸ†• æ”¯æŒæ™ºèƒ½æ€è€ƒæ¨¡å¼é€‰æ‹©
        
        Args:
            skill: Skill å®šä¹‰
            params: è¾“å…¥å‚æ•°
            context: ä¸Šä¸‹æ–‡
            client: LLM å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨é»˜è®¤ï¼‰
            thinking_config: æ€è€ƒæ¨¡å¼é…ç½®ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            Dict[str, Any]: åŒ…å«ä»¥ä¸‹é”®ï¼š
                - "content": ç”Ÿæˆçš„å†…å®¹
                - "thinking": æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
                - "usage": Token ä½¿ç”¨ç»Ÿè®¡
        """
        # ğŸ”¥ flashcard_skill ç‰¹æ®Šå¤„ç†ï¼šè°ƒç”¨å¤–éƒ¨ APIï¼ˆå¸¦ fallbackï¼‰
        if skill.id == 'flashcard_skill':
            try:
                result = await self._execute_flashcard_via_external_api(params, context)
                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                content = json.loads(result.get("content", "{}"))
                if not content.get("error"):
                    return result
                logger.warning(f"âš ï¸ External flashcard API returned error, falling back to LLM")
            except Exception as e:
                logger.warning(f"âš ï¸ External flashcard API failed: {e}, falling back to LLM")
            # Fallback: ç»§ç»­æ‰§è¡Œ LLM æµç¨‹
        
        # ğŸ”¥ quiz_skill ç‰¹æ®Šå¤„ç†ï¼šè°ƒç”¨å¤–éƒ¨ APIï¼ˆå¸¦ fallbackï¼‰
        if skill.id == 'quiz_skill':
            try:
                result = await self._execute_quiz_via_external_api(params, context)
                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                content = json.loads(result.get("content", "{}"))
                if not content.get("error"):
                    return result
                logger.warning(f"âš ï¸ External quiz API returned error, falling back to LLM")
            except Exception as e:
                logger.warning(f"âš ï¸ External quiz API failed: {e}, falling back to LLM")
            # Fallback: ç»§ç»­æ‰§è¡Œ LLM æµç¨‹
        
        # åŠ è½½ prompt æ¨¡æ¿
        prompt_content = self._load_prompt(skill)
        
        # æ„å»ºå®Œæ•´ prompt
        full_prompt = self._format_prompt(prompt_content, params, context)
        
        # ğŸ†• ä½¿ç”¨æä¾›çš„å®¢æˆ·ç«¯æˆ–é»˜è®¤å®¢æˆ·ç«¯
        active_client = client or self.llm_client
        
        # ğŸ†• ä½¿ç”¨æ€è€ƒé…ç½®æˆ–é»˜è®¤é…ç½®
        if thinking_config:
            model = thinking_config["model"]
            thinking_budget = thinking_config.get("thinking_budget")
            temperature = thinking_config.get("temperature", 1.0)
        else:
            model = skill.models.get("primary", self.llm_client.model)
            thinking_budget = skill.thinking_budget or 32
            temperature = getattr(skill, 'temperature', 1.0)
        
        # ğŸ†• ä» params è·å– max_tokensï¼Œé»˜è®¤ 4000ï¼ˆé¿å…å¤æ‚å›ç­”è¢«æˆªæ–­ï¼‰
        max_tokens = params.get('max_tokens', 4000)
        
        logger.debug(f"ğŸ¤– Calling LLM: {model} (thinking_budget={thinking_budget}, temp={temperature}, max_tokens={max_tokens})")
        
        # ğŸ†• ä½¿ç”¨ generate æ–¹æ³•ï¼ˆè¿”å›å­—å…¸ï¼‰
        response = await active_client.generate(
            prompt=full_prompt,
            model=model,
            response_format="json",
            thinking_budget=thinking_budget,
            return_thinking=True,
            temperature=temperature,
            max_tokens=max_tokens  # ğŸ†• å¢åŠ  token é™åˆ¶ï¼Œé¿å…æˆªæ–­
        )
        
        # response æ˜¯å­—å…¸: {"content": str, "thinking": str, "usage": dict}
        return response
    
    async def _execute_flashcard_via_external_api(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ğŸ”¥ é€šè¿‡å¤–éƒ¨ API ç”Ÿæˆé—ªå¡ï¼ˆæ›¿ä»£ LLM è°ƒç”¨ï¼‰
        
        ä»…å½“æœ‰ä¸°å¯Œå†…å®¹æ—¶è°ƒç”¨ï¼š
        - reference_explanation: å‰é¢çš„è§£é‡Šå†…å®¹
        - referenced_content: ç”¨æˆ·å¼•ç”¨çš„å†å²å†…å®¹
        - input_text: ç”¨æˆ·æä¾›çš„åŸå§‹æ–‡æœ¬
        
        Args:
            params: è¾“å…¥å‚æ•°ï¼ˆåŒ…å« topic, num_cards ç­‰ï¼‰
            context: ä¸Šä¸‹æ–‡
        
        Returns:
            Dict: {"content": str (JSON), "thinking": None, "usage": {}}
        """
        import json
        from ..services.external_flashcard_service import get_external_flashcard_service
        
        # è·å–å¤–éƒ¨æœåŠ¡
        external_service = get_external_flashcard_service()
        
        # æå–å‚æ•°
        topic = params.get('topic', '')
        # num_cards: ç”¨æˆ·æŒ‡å®šçš„æ•°é‡ï¼ŒNone è¡¨ç¤ºè®© API è‡ªåŠ¨å†³å®š
        num_cards = params.get('num_cards')  # ä¸è®¾é»˜è®¤å€¼ï¼Œè®© API è‡ªåŠ¨å†³å®š
        
        # æ„å»ºè¾“å…¥æ–‡æœ¬ - æŒ‰ä¼˜å…ˆçº§é€‰æ‹©å†…å®¹æº
        input_text = ""
        content_source = ""
        
        # 1. ä¼˜å…ˆä½¿ç”¨ reference_explanationï¼ˆå‰é¢çš„è§£é‡Šå†…å®¹ï¼‰
        if params.get('reference_explanation'):
            ref = params['reference_explanation']
            if isinstance(ref, dict):
                # ä»è§£é‡Šå†…å®¹ä¸­æå–æ–‡æœ¬
                parts = []
                if ref.get('intuition'):
                    parts.append(ref['intuition'])
                if ref.get('deep_dive'):
                    parts.append(ref['deep_dive'])
                if ref.get('examples'):
                    for ex in ref['examples'][:2]:  # å–å‰2ä¸ªä¾‹å­
                        if isinstance(ex, dict):
                            parts.append(ex.get('description', ''))
                        else:
                            parts.append(str(ex))
                input_text = " ".join(parts)
            else:
                input_text = str(ref)
            content_source = "reference_explanation"
        
        # 2. å…¶æ¬¡ä½¿ç”¨ referenced_contentï¼ˆç”¨æˆ·å¼•ç”¨çš„å†å²å†…å®¹ï¼‰
        elif params.get('referenced_content'):
            input_text = params['referenced_content']
            content_source = "referenced_content"
        
        # 3. ä½¿ç”¨ input_textï¼ˆç”¨æˆ·æä¾›çš„åŸå§‹æ–‡æœ¬ï¼‰
        elif params.get('input_text'):
            input_text = params['input_text']
            content_source = "input_text"
        
        # ğŸ†• è·å– file_urisï¼ˆå¤šæ–‡ä»¶é™„ä»¶ï¼‰
        file_uris = params.get('file_uris', [])
        file_uri = params.get('file_uri')  # å…¼å®¹æ—§é€»è¾‘
        from_file = params.get('from_file', False)
        
        # 4. Fallback: ä½¿ç”¨ topicï¼ˆä½†è¿™ç§æƒ…å†µä¸åº”è¯¥èµ°å¤–éƒ¨ APIï¼‰
        has_files = (file_uris and len(file_uris) > 0) or file_uri
        if not input_text.strip():
            if has_files:
                # ğŸ†• æœ‰æ–‡ä»¶æ—¶ï¼Œä½¿ç”¨ç®€å•æŒ‡ä»¤è®©å¤–éƒ¨ API å¤„ç†
                file_count = len(file_uris) if file_uris else 1
                input_text = f"æ ¹æ®{file_count}ä¸ªæ–‡ä»¶çš„å†…å®¹ç”Ÿæˆé—ªå¡"
                content_source = "file_based"
            else:
                input_text = topic
                content_source = "topic_only"
        
        # ğŸ†• è·å–è¯­è¨€è®¾ç½®
        language = params.get('language', 'auto')
        # è¯­è¨€æ˜ å°„ï¼šå°†å†…éƒ¨è¯­è¨€ä»£ç æ˜ å°„åˆ°å¤–éƒ¨ API æ”¯æŒçš„æ ¼å¼ï¼ˆæ”¯æŒ 30+ è¯­è¨€ï¼‰
        lang_map = {
            'auto': None,  # None è¡¨ç¤ºè®© API è‡ªåŠ¨æ£€æµ‹
            'en': 'English',
            'zh': 'Chinese',
            'zh-CN': 'Chinese',
            'zh-TW': 'Traditional Chinese',
            'ja': 'Japanese',
            'ko': 'Korean',
            'fr': 'French',
            'es': 'Spanish',
            'pt': 'Portuguese',
            'de': 'German',
            'it': 'Italian',
            'ru': 'Russian',
            'vi': 'Vietnamese',
            'th': 'Thai',
            'hi': 'Hindi',
            'id': 'Indonesian',
            'ms': 'Malay',
            'tr': 'Turkish',
            'pl': 'Polish',
            'nl': 'Dutch',
            'ro': 'Romanian',
            'cs': 'Czech',
            'sk': 'Slovak',
            'hu': 'Hungarian',
            'tl': 'Filipino',
            'no': 'Norwegian',
            'da': 'Danish',
            'fi': 'Finnish',
        }
        output_language = lang_map.get(language, None)
        
        logger.info(f"ğŸŒ Executing flashcard via external API: topic='{topic}', num_cards={num_cards}, source={content_source}, input_len={len(input_text)}, file_uris={file_uris if file_uris else 'N/A'}, language={language}â†’{output_language}")
        
        try:
            # è°ƒç”¨å¤–éƒ¨ APIï¼ˆä¼ é€’å¤šæ–‡ä»¶ï¼‰
            result = await external_service.create_flashcards(
                text=input_text,
                card_size=num_cards,
                output_language=output_language,  # ğŸ†• ä½¿ç”¨ç”¨æˆ·è¯­è¨€åå¥½
                file_uri=file_uri,  # å…¼å®¹æ—§é€»è¾‘
                file_uris=file_uris  # ğŸ†• ä¼ é€’å¤šæ–‡ä»¶ URI åˆ—è¡¨
            )
            
            # ğŸ†• å¤–éƒ¨ API å¯èƒ½å¿½ç•¥ cardSizeï¼Œæ‰‹åŠ¨æˆªå–åˆ°ç”¨æˆ·æŒ‡å®šæ•°é‡
            if num_cards and 'cardList' in result:
                actual_count = len(result['cardList'])
                if actual_count > num_cards:
                    logger.info(f"âœ‚ï¸ Trimming flashcards: API returned {actual_count}, user requested {num_cards}")
                    result['cardList'] = result['cardList'][:num_cards]
            
            # è¿”å›æ ¼å¼ä¸ LLM è°ƒç”¨ä¸€è‡´
            return {
                "content": json.dumps(result, ensure_ascii=False),
                "thinking": None,
                "usage": {"external_api": True}
            }
            
        except Exception as e:
            logger.error(f"âŒ External flashcard API failed: {e}")
            # è¿”å›é”™è¯¯æ ¼å¼
            error_result = {
                "title": f"ç”Ÿæˆå¤±è´¥: {topic}",
                "cardList": [],
                "error": str(e)
            }
            return {
                "content": json.dumps(error_result, ensure_ascii=False),
                "thinking": None,
                "usage": {"external_api": True, "error": str(e)}
            }
    
    async def _execute_quiz_via_external_api(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ğŸ”¥ é€šè¿‡å¤–éƒ¨ API ç”Ÿæˆæµ‹éªŒé¢˜ç›®ï¼ˆæ›¿ä»£ LLM è°ƒç”¨ï¼‰
        
        Args:
            params: è¾“å…¥å‚æ•°ï¼ˆåŒ…å« topic, num_questions ç­‰ï¼‰
            context: ä¸Šä¸‹æ–‡
        
        Returns:
            Dict: {"content": str (JSON), "thinking": None, "usage": {}}
        """
        from ..services.external_quiz_service import get_external_quiz_service
        
        # è·å–å¤–éƒ¨æœåŠ¡
        external_service = get_external_quiz_service()
        
        # æå–å‚æ•°
        topic = params.get('topic', '')
        # num_questions: ç”¨æˆ·æŒ‡å®šçš„æ•°é‡ï¼ŒNone è¡¨ç¤ºè®© API è‡ªåŠ¨å†³å®š
        num_questions = params.get('num_questions')
        
        # æ„å»ºè¾“å…¥æ–‡æœ¬ - æŒ‰ä¼˜å…ˆçº§é€‰æ‹©å†…å®¹æº
        input_text = ""
        content_source = ""
        
        # 1. ä¼˜å…ˆä½¿ç”¨ reference_explanationï¼ˆå‰é¢çš„è§£é‡Šå†…å®¹ï¼‰
        if params.get('reference_explanation'):
            ref = params['reference_explanation']
            if isinstance(ref, dict):
                parts = []
                if ref.get('intuition'):
                    parts.append(ref['intuition'])
                if ref.get('deep_dive'):
                    parts.append(ref['deep_dive'])
                if ref.get('examples'):
                    for ex in ref['examples'][:2]:
                        if isinstance(ex, dict):
                            parts.append(ex.get('description', ''))
                        else:
                            parts.append(str(ex))
                input_text = " ".join(parts)
            else:
                input_text = str(ref)
            content_source = "reference_explanation"
        
        # 2. å…¶æ¬¡ä½¿ç”¨ referenced_contentï¼ˆç”¨æˆ·å¼•ç”¨çš„å†å²å†…å®¹ï¼‰
        elif params.get('referenced_content'):
            input_text = params['referenced_content']
            content_source = "referenced_content"
        
        # 3. ä½¿ç”¨ input_textï¼ˆç”¨æˆ·æä¾›çš„åŸå§‹æ–‡æœ¬ï¼‰
        elif params.get('input_text'):
            input_text = params['input_text']
            content_source = "input_text"
        
        # ğŸ†• è·å– file_urisï¼ˆå¤šæ–‡ä»¶é™„ä»¶ï¼‰
        file_uris = params.get('file_uris', [])
        file_uri = params.get('file_uri')  # å…¼å®¹æ—§é€»è¾‘
        from_file = params.get('from_file', False)
        
        # 4. Fallback: ä½¿ç”¨ topic
        has_files = (file_uris and len(file_uris) > 0) or file_uri
        if not input_text.strip():
            if has_files:
                # ğŸ†• æœ‰æ–‡ä»¶æ—¶ï¼Œä½¿ç”¨ç®€å•æŒ‡ä»¤è®©å¤–éƒ¨ API å¤„ç†
                file_count = len(file_uris) if file_uris else 1
                input_text = f"æ ¹æ®{file_count}ä¸ªæ–‡ä»¶çš„å†…å®¹å‡ºé¢˜"
                content_source = "file_based"
            else:
                input_text = topic
                content_source = "topic_only"
        
        # ğŸ†• è·å–è¯­è¨€è®¾ç½®
        language = params.get('language', 'auto')
        # è¯­è¨€æ˜ å°„ï¼šå°†å†…éƒ¨è¯­è¨€ä»£ç æ˜ å°„åˆ°å¤–éƒ¨ API æ”¯æŒçš„æ ¼å¼ï¼ˆæ”¯æŒ 30+ è¯­è¨€ï¼‰
        lang_map = {
            'auto': None,  # None è¡¨ç¤ºè®© API è‡ªåŠ¨æ£€æµ‹
            'en': 'English',
            'zh': 'Chinese',
            'zh-CN': 'Chinese',
            'zh-TW': 'Traditional Chinese',
            'ja': 'Japanese',
            'ko': 'Korean',
            'fr': 'French',
            'es': 'Spanish',
            'pt': 'Portuguese',
            'de': 'German',
            'it': 'Italian',
            'ru': 'Russian',
            'vi': 'Vietnamese',
            'th': 'Thai',
            'hi': 'Hindi',
            'id': 'Indonesian',
            'ms': 'Malay',
            'tr': 'Turkish',
            'pl': 'Polish',
            'nl': 'Dutch',
            'ro': 'Romanian',
            'cs': 'Czech',
            'sk': 'Slovak',
            'hu': 'Hungarian',
            'tl': 'Filipino',
            'no': 'Norwegian',
            'da': 'Danish',
            'fi': 'Finnish',
        }
        output_language = lang_map.get(language, None)
        
        logger.info(f"ğŸŒ Executing quiz via external API: topic='{topic}', num_questions={num_questions}, source={content_source}, input_len={len(input_text)}, file_uris={file_uris if file_uris else 'N/A'}, language={language}â†’{output_language}")
        
        try:
            # è°ƒç”¨å¤–éƒ¨ APIï¼ˆä¼ é€’å¤šæ–‡ä»¶ï¼‰
            result = await external_service.create_quiz(
                text=input_text,
                question_count=num_questions,
                output_language=output_language,  # ğŸ†• ä½¿ç”¨ç”¨æˆ·è¯­è¨€åå¥½
                file_uri=file_uri,  # å…¼å®¹æ—§é€»è¾‘
                file_uris=file_uris  # ğŸ†• ä¼ é€’å¤šæ–‡ä»¶ URI åˆ—è¡¨
            )
            
            # ğŸ†• å¤–éƒ¨ API å¯èƒ½å¿½ç•¥ questionCountï¼Œæ‰‹åŠ¨æˆªå–åˆ°ç”¨æˆ·æŒ‡å®šæ•°é‡
            if num_questions and 'questions' in result:
                actual_count = len(result['questions'])
                if actual_count > num_questions:
                    logger.info(f"âœ‚ï¸ Trimming quiz: API returned {actual_count}, user requested {num_questions}")
                    result['questions'] = result['questions'][:num_questions]
            
            # è¿”å›æ ¼å¼ä¸ LLM è°ƒç”¨ä¸€è‡´
            return {
                "content": json.dumps(result, ensure_ascii=False),
                "thinking": None,
                "usage": {"external_api": True}
            }
            
        except Exception as e:
            logger.error(f"âŒ External quiz API failed: {e}")
            # è¿”å›é”™è¯¯æ ¼å¼
            error_result = {
                "title": f"ç”Ÿæˆå¤±è´¥: {topic}",
                "questions": [],
                "error": str(e)
            }
            return {
                "content": json.dumps(error_result, ensure_ascii=False),
                "thinking": None,
                "usage": {"external_api": True, "error": str(e)}
            }
    
    def _generate_context_preview(
        self,
        context: Dict[str, Any],
        params: Dict[str, Any],
        thinking_mode: str
    ) -> Optional[Dict[str, Any]]:
        """
        ğŸ†• ç”Ÿæˆä¸Šä¸‹æ–‡é¢„è§ˆä¿¡æ¯ï¼ˆè®©ç”¨æˆ·çŸ¥é“åŸºäºä»€ä¹ˆæ¥ç”Ÿæˆï¼‰
        
        Args:
            context: ä¸Šä¸‹æ–‡å­—å…¸
            params: å‚æ•°å­—å…¸
            thinking_mode: æ€è€ƒæ¨¡å¼ ("real_thinking" / "fake_thinking")
        
        Returns:
            é¢„è§ˆä¿¡æ¯å­—å…¸ï¼ŒåŒ…å« message å’Œ details
        """
        details = []
        
        # 1. æå–ä¸»é¢˜
        topic = params.get("topic", "")
        if topic:
            details.append(f"ğŸ“š ä¸»é¢˜ï¼š{topic}")
        
        # 2. æå–å¼•ç”¨å†…å®¹æ‘˜è¦ï¼ˆæ¸…ç† LaTeXï¼‰
        if params.get("referenced_content"):
            ref_content = params["referenced_content"]
            # æ¸…ç† LaTeX å’Œç‰¹æ®Šç¬¦å·
            ref_preview = self._clean_for_display(ref_content[:150])
            details.append(f"ğŸ“ å¼•ç”¨å†…å®¹ï¼š{ref_preview}...")
        
        # 3. æå–å†å²ä¸Šä¸‹æ–‡æ‘˜è¦
        recent_artifacts = context.get("recent_artifacts", [])
        if recent_artifacts:
            # åªæ˜¾ç¤ºæœ€è¿‘ 2 ä¸ª
            for artifact in recent_artifacts[:2]:
                artifact_topic = artifact.get("topic", "")
                artifact_type = artifact.get("type", "")
                # ç±»å‹ä¸­æ–‡æ˜ å°„
                type_map = {
                    "explanation": "æ¦‚å¿µè®²è§£",
                    "quiz_set": "ç»ƒä¹ é¢˜",
                    "flashcard_set": "é—ªå¡",
                    "mindmap": "æ€ç»´å¯¼å›¾",
                    "notes": "ç¬”è®°"
                }
                type_cn = type_map.get(artifact_type, artifact_type)
                
                # è·å–æ‘˜è¦å¹¶æ¸…ç†
                summary = artifact.get("summary", "")
                if summary:
                    summary_preview = self._clean_for_display(summary[:80])
                    details.append(f"ğŸ“„ {artifact_topic}({type_cn})ï¼š{summary_preview}...")
        
        # 4. ç”Ÿæˆä¸»æ¶ˆæ¯
        if not details:
            return None  # æ²¡æœ‰ä¸Šä¸‹æ–‡ï¼Œä¸æ˜¾ç¤ºé¢„è§ˆ
        
        # æ ¹æ®æ€è€ƒæ¨¡å¼é€‰æ‹©æç¤ºè¯­
        if thinking_mode == "real_thinking":
            message = "ğŸ§  æ·±åº¦åˆ†æä¸­ï¼ŒåŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡..."
        else:
            message = "âš¡ å¿«é€Ÿç”Ÿæˆä¸­ï¼ŒåŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡..."
        
        return {
            "message": message,
            "details": details
        }
    
    def _clean_for_display(self, text: str) -> str:
        """
        æ¸…ç†æ–‡æœ¬ç”¨äºæ˜¾ç¤ºï¼ˆç§»é™¤ LaTeXã€ç‰¹æ®Šç¬¦å·ç­‰ï¼‰
        
        Args:
            text: åŸå§‹æ–‡æœ¬
        
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        import re
        
        if not text:
            return ""
        
        # ç§»é™¤ LaTeX å…¬å¼ $...$ å’Œ $$...$$
        text = re.sub(r'\$\$[^$]+\$\$', '[å…¬å¼]', text)
        text = re.sub(r'\$[^$]+\$', '[å…¬å¼]', text)
        
        # ç§»é™¤ LaTeX å‘½ä»¤ \xxx{...}
        text = re.sub(r'\\[a-zA-Z]+\{[^}]*\}', '', text)
        text = re.sub(r'\\[a-zA-Z]+', '', text)
        
        # ç§»é™¤ JSON ç‰¹æ®Šå­—ç¬¦
        text = text.replace('{', '').replace('}', '')
        text = text.replace('[', '').replace(']', '')
        text = text.replace('"', '').replace("'", '')
        
        # ç§»é™¤å¤šä½™ç©ºç™½
        text = ' '.join(text.split())
        
        return text.strip()
    
    def _load_prompt(self, skill: SkillDefinition) -> str:
        """
        åŠ è½½ Skill çš„ Prompt æ¨¡æ¿
        
        Args:
            skill: Skill å®šä¹‰
        
        Returns:
            Prompt å†…å®¹
        """
        if not skill.prompt_file:
            raise ValueError(f"Skill {skill.id} has no prompt_file configured")
        
        prompt_path = os.path.join(self.prompts_dir, skill.prompt_file)
        
        if not os.path.exists(prompt_path):
            raise FileNotFoundError(f"Prompt file not found: {prompt_path}")
        
        with open(prompt_path, 'r', encoding='utf-8') as f:
            return f.read()
    
    def _format_prompt(
        self,
        prompt_template: str,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> str:
        """
        æ ¼å¼åŒ– Promptï¼ˆç›´æ¥æ‹¼æ¥æ¨¡æ¿å’Œå‚æ•° JSONï¼‰
        
        æ–°ç‰ˆ Prompt ä¸å†ä½¿ç”¨å ä½ç¬¦ï¼Œè€Œæ˜¯ç›´æ¥é€šè¿‡ JSON ä¼ é€’å‚æ•°
        
        Args:
            prompt_template: Prompt æ¨¡æ¿
            params: è¾“å…¥å‚æ•°
            context: ä¸Šä¸‹æ–‡
        
        Returns:
            æ ¼å¼åŒ–åçš„ prompt
        """
        import json
        
        # æ–°ç‰ˆ Prompt ä¸ä½¿ç”¨å ä½ç¬¦ï¼Œç›´æ¥ä½¿ç”¨åŸæ¨¡æ¿
        formatted = prompt_template
        
        # ğŸ”¥ Step 2: é™„åŠ å‚æ•° JSONï¼ˆä½œä¸ºå¤‡ç”¨/è°ƒè¯•ä¿¡æ¯ï¼‰
        # è¿‡æ»¤æ‰ None å€¼å’Œä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
        clean_params = {}
        for k, v in params.items():
            if v is not None:
                try:
                    json.dumps(v)
                    clean_params[k] = v
                except (TypeError, ValueError):
                    clean_params[k] = str(v)
        
        params_json = json.dumps(clean_params, ensure_ascii=False, indent=2)
        
        formatted += f"""

## Input Parameters (JSON)

```json
{params_json}
```
"""
        
        # ğŸ†• æ·»åŠ è¯­è¨€æŒ‡ä»¤ï¼ˆå¦‚æœæœ‰ language å‚æ•°ï¼‰
        language = params.get('language', 'auto')
        if language and language != 'auto':
            # è¯­è¨€ä»£ç åˆ°è¯­è¨€åç§°çš„æ˜ å°„
            LANGUAGE_NAMES = {
                "en": "English",
                "zh": "Simplified Chinese (ç®€ä½“ä¸­æ–‡)",
                "zh-CN": "Simplified Chinese (ç®€ä½“ä¸­æ–‡)",
                "zh-TW": "Traditional Chinese (ç¹é«”ä¸­æ–‡)",
                "ja": "Japanese (æ—¥æœ¬èª)",
                "ko": "Korean (í•œêµ­ì–´)",
                "fr": "French (FranÃ§ais)",
                "es": "Spanish (EspaÃ±ol)",
                "pt": "Portuguese (PortuguÃªs)",
                "de": "German (Deutsch)",
                "it": "Italian (Italiano)",
                "ru": "Russian (Ğ ÑƒÑÑĞºĞ¸Ğ¹)",
                "vi": "Vietnamese (Tiáº¿ng Viá»‡t)",
                "th": "Thai (à¸ à¸²à¸©à¸²à¹„à¸—à¸¢)",
                "hi": "Hindi (à¤¹à¤¿à¤‚à¤¦à¥€)",
                "id": "Indonesian (Bahasa Indonesia)",
                "ms": "Malay (Melayu)",
                "tr": "Turkish (TÃ¼rkÃ§e)",
                "pl": "Polish (Polski)",
                "nl": "Dutch (Nederlands)",
                "ro": "Romanian (RomÃ¢nÄƒ)",
                "cs": "Czech (ÄŒeÅ¡tina)",
                "sk": "Slovak (SlovenÄina)",
                "hu": "Hungarian (Magyar)",
                "tl": "Filipino/Tagalog",
                "no": "Norwegian (Norsk)",
                "da": "Danish (Dansk)",
                "fi": "Finnish (Suomi)",
            }
            target_language = LANGUAGE_NAMES.get(language, language)
            formatted += f"""

## âš ï¸ LANGUAGE REQUIREMENT

**CRITICAL**: You MUST respond in **{target_language}** only. All text content in your response must be in {target_language}. This is a strict requirement.
"""
            logger.info(f"ğŸŒ Added language instruction: {target_language}")
        
        # ğŸ†• Step 2.5: é™„åŠ å¼•ç”¨å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
        if "referenced_content" in params and params["referenced_content"]:
            formatted += f"""

## Referenced Content (ç”¨æˆ·å¼•ç”¨çš„å†å²å†…å®¹)

ç”¨æˆ·æ¶ˆæ¯ä¸­å¼•ç”¨äº†ä»¥ä¸‹å†å²å†…å®¹ï¼Œè¯·åœ¨ç”Ÿæˆå“åº”æ—¶åŸºäºè¿™äº›å†…å®¹ï¼š

{params["referenced_content"]}
"""
            logger.info(f"ğŸ“ Added referenced content to prompt (~{len(params['referenced_content'])} chars)")
        
        # ğŸ”¥ Step 3: é™„åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆä¸Šä¸‹æ–‡å¸è½½çš„å…³é”®ï¼ï¼‰
        if context:
            # æ·»åŠ  recent artifactsï¼ˆå‹ç¼©çš„å†å²ä¸Šä¸‹æ–‡ï¼‰
            if "recent_artifacts" in context and context["recent_artifacts"]:
                artifacts_summary = []
                for artifact in context["recent_artifacts"]:
                    # ğŸ†• åªä½¿ç”¨ summaryï¼ˆå‹ç¼©æ‘˜è¦ï¼‰ï¼Œä¸ä¼  contentï¼ˆå®Œæ•´æ•°æ®å¤ªå¤§ï¼‰
                    artifacts_summary.append({
                        "topic": artifact.get("topic"),
                        "type": artifact.get("type"),
                        "summary": artifact.get("summary")  # å‹ç¼©çš„ä¸Šä¸‹æ–‡æ‘˜è¦
                    })
                
                artifacts_json = json.dumps(artifacts_summary, ensure_ascii=False, indent=2)
                formatted += f"""

## Previous Learning Context (Compressed)

The user has previously learned the following topics. Use this context to maintain continuity and avoid repetition:

```json
{artifacts_json}
```
"""
                logger.info(f"ğŸ“¦ Added {len(artifacts_summary)} artifact summaries to prompt (~{len(artifacts_json)} chars)")
            
            # æ·»åŠ  conversation historyï¼ˆå¦‚æœæœ‰ï¼‰
            if "conversation_history" in context and context["conversation_history"]:
                formatted += f"""

## Recent Conversation

{context["conversation_history"][:1000]}  
"""
                logger.debug(f"ğŸ’¬ Added conversation history to prompt")
        
        formatted += """

Please respond with valid JSON according to the output schema defined above.
"""
        return formatted
    
    def _wrap_output(
        self,
        skill: SkillDefinition,
        result: Dict[str, Any],
        intent_result: IntentResult = None
    ) -> Dict[str, Any]:
        """
        å°è£…è¾“å‡ºç»“æœï¼ˆç»Ÿä¸€å“åº”æ ¼å¼ï¼‰
        
        Args:
            skill: Skill å®šä¹‰
            result: åŸå§‹ç»“æœï¼ˆGemini è¿”å›çš„ JSONï¼‰
            intent_result: æ„å›¾è¯†åˆ«ç»“æœ
        
        Returns:
            å°è£…åçš„ç»“æœï¼ŒåŒ…å« contentã€content_typeã€intentã€skill_id
        """
        # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœ result æ˜¯åˆ—è¡¨ï¼ˆlearning_bundle å¯èƒ½è¿”å›åˆ—è¡¨ï¼‰ï¼ŒåŒ…è£…æˆå­—å…¸
        if isinstance(result, list):
            logger.warning(f"âš ï¸  Skill {skill.id} returned a list instead of dict, wrapping it")
            result = {
                "bundle_id": f"bundle_{datetime.now().strftime('%Y%m%d%H%M%S')}",
                "components": result,
                "subject": intent_result.topic.split("-")[0] if intent_result and intent_result.topic else "é€šç”¨",
                "topic": intent_result.topic if intent_result and intent_result.topic else "å­¦ä¹ èµ„æ–™"
            }
        
        # æ£€æµ‹å†…å®¹ç±»å‹
        content_type = "unknown"
        if "quiz_set_id" in result or "questions" in result:
            content_type = "quiz_set"
        elif "concept" in result or "explanation" in result:
            content_type = "explanation"
        elif "cardList" in result or "flashcard_set_id" in result or "cards" in result:
            content_type = "flashcard_set"
        elif "notes_id" in result or "structured_notes" in result:
            content_type = "notes"
        elif "bundle_id" in result or "components" in result:
            content_type = "learning_bundle"
        elif "mindmap_id" in result or "root" in result:
            content_type = "mindmap"
        elif "error" in result:
            content_type = "error"
        
        # æå–æ„å›¾
        intent = "unknown"
        if intent_result:
            if isinstance(intent_result.intent, list):
                intent = intent_result.intent[0] if intent_result.intent else "unknown"
            else:
                intent = intent_result.intent
        
        return {
            "content": result,          # å®é™…å†…å®¹ï¼ˆGemini è¿”å›çš„ JSONï¼‰
            "content_type": content_type,  # quiz_set, explanation, error ç­‰
            "intent": intent,           # åŸå§‹æ„å›¾
            "skill_id": skill.id,       # ä½¿ç”¨çš„æŠ€èƒ½ ID
            "skill_name": skill.display_name,
            "success": True
        }
    
    async def _update_memory(
        self,
        user_id: str,
        session_id: str,
        intent_result: IntentResult,
        skill_result: Dict[str, Any]
    ):
        """
        æ›´æ–°ç”¨æˆ·è®°å¿†ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ä¸»æµç¨‹ï¼‰
        
        åŒ…æ‹¬ï¼š
        1. ä¿å­˜ artifact åˆ° S3ï¼ˆæ„å»ºç”¨æˆ·ç”»åƒï¼‰
        2. æ›´æ–° session contextï¼ˆå½“å‰ä¸»é¢˜ã€æ„å›¾å†å²ï¼‰
        3. ç»´æŠ¤ artifact_history å¼•ç”¨é“¾
        
        Args:
            user_id: ç”¨æˆ· ID
            session_id: ä¼šè¯ ID
            intent_result: æ„å›¾ç»“æœ
            skill_result: æŠ€èƒ½ç»“æœ
        """
        try:
            # æ›´æ–°ä¼šè¯ä¸Šä¸‹æ–‡
            session_context = await self.memory_manager.get_session_context(session_id)
            
            # ğŸ†• ä¼˜å…ˆä» skill_result ä¸­æå–å®é™… topicï¼ˆAPI è¿”å›çš„ï¼‰
            # å¦‚æœ skill_result æ²¡æœ‰ï¼Œå†ä½¿ç”¨ intent_result.topic
            topic = None
            
            # 1. å°è¯•ä» skill_result ä¸­æå– topic
            if skill_result:
                # Quiz/Flashcard: title å­—æ®µ
                if skill_result.get('title'):
                    topic = skill_result.get('title')
                    logger.info(f"ğŸ“¤ Extracted topic from skill_result.title: '{topic}'")
                # Explanation: concept æˆ– subject å­—æ®µ
                elif skill_result.get('concept'):
                    topic = skill_result.get('concept')
                    logger.info(f"ğŸ“¤ Extracted topic from skill_result.concept: '{topic}'")
                elif skill_result.get('subject'):
                    topic = skill_result.get('subject')
                    logger.info(f"ğŸ“¤ Extracted topic from skill_result.subject: '{topic}'")
                # Learning Bundle: topic å­—æ®µ
                elif skill_result.get('topic'):
                    topic = skill_result.get('topic')
                    logger.info(f"ğŸ“¤ Extracted topic from skill_result.topic: '{topic}'")
            
            # 2. Fallback: ä½¿ç”¨ intent_result.topicï¼ˆä½†æ’é™¤æ— æ•ˆçš„ topicï¼‰
            invalid_topics = {"æ–‡ä»¶å†…å®¹", "è¿™æ–‡ä»¶ å†…å®¹", "é™„ä»¶å†…å®¹", "æ–‡ä»¶", "é™„ä»¶", "None", ""}
            if not topic or topic in invalid_topics:
                intent_topic = intent_result.topic
                if intent_topic and intent_topic not in invalid_topics and len(intent_topic) >= 3:
                    topic = intent_topic
                    logger.info(f"ğŸ“¤ Using intent_result.topic: '{topic}'")
                else:
                    # 3. Fallback: ä½¿ç”¨ session current_topic
                    topic = session_context.current_topic or "æœªçŸ¥ä¸»é¢˜"
                    logger.info(f"ğŸ“¤ Fallback to session current_topic: '{topic}'")
            
            # æ›´æ–° session çš„ current_topic
            if topic and topic not in invalid_topics and len(topic) >= 3:
                session_context.current_topic = topic
                logger.info(f"âœ… Updated current_topic to: {topic}")
            
            # æ·»åŠ æ„å›¾åˆ°å†å²
            intent = intent_result.intent
            if isinstance(intent, list):
                intent = intent[0]
            
            if not session_context.recent_intents:
                session_context.recent_intents = []
            session_context.recent_intents.append(intent)
            
            # ä¿æŒæœ€è¿‘10ä¸ª
            if len(session_context.recent_intents) > 10:
                session_context.recent_intents = session_context.recent_intents[-10:]
            
            # ğŸ”¥ æ ¸å¿ƒï¼šä¿å­˜ artifact åˆ° S3ï¼Œæ„å»ºç”¨æˆ·ç”»åƒ
            try:
                # ç¡®å®š artifact ç±»å‹
                artifact_type_mapping = {
                    "quiz_request": "quiz_set",
                    "flashcard_request": "flashcard_set",
                    "explain_request": "explanation",
                    "notes": "notes",
                    "mindmap": "mindmap",
                    "learning_bundle": "learning_bundle"
                }
                
                artifact_type = artifact_type_mapping.get(intent, intent)
                
                # ç§»é™¤å†…éƒ¨å­—æ®µ
                artifact_content = {k: v for k, v in skill_result.items() if not k.startswith('_')}
                
                # ä¿å­˜åˆ° S3
                artifact_record = await self.memory_manager.save_artifact(
                    session_id=session_id,
                    artifact=artifact_content,
                    artifact_type=artifact_type,
                    topic=topic,
                    user_id=user_id
                )
                
                logger.info(f"âœ… Artifact saved: {artifact_record.artifact_id} (Storage: {artifact_record.storage_type})")
                
                # æ³¨æ„ï¼šartifact_history å·²ç»åœ¨ memory_manager.save_artifact() ä¸­æ›´æ–°äº†
                # è¿™é‡Œä¸éœ€è¦é‡å¤æ·»åŠ ï¼Œåªéœ€è¦è®°å½•æ—¥å¿—
                session_context_updated = await self.memory_manager.get_session_context(session_id)
                logger.info(f"ğŸ“ Artifact history updated: {len(session_context_updated.artifact_history)} artifacts")
                
            except Exception as e:
                logger.error(f"âŒ Failed to save artifact: {e}")
                # ä¸ä¸­æ–­æµç¨‹ï¼Œç»§ç»­æ›´æ–° session context
            
            await self.memory_manager.update_session_context(session_id, session_context)
            
            logger.debug(f"ğŸ“ Memory updated for user {user_id}, session {session_id}")
        
        except Exception as e:
            logger.warning(f"âš ï¸  Failed to update memory: {e}")
    
    async def _extract_recent_topics(self, session_id: str) -> List[str]:
        """
        ä» session context æå–æœ€è¿‘çš„ä¸»é¢˜åˆ—è¡¨
        
        Args:
            session_id: ä¼šè¯ ID
        
        Returns:
            ä¸»é¢˜åˆ—è¡¨ï¼ˆå»é‡ï¼ŒæŒ‰æœ€è¿‘é¡ºåºï¼‰
        """
        try:
            session_context = await self.memory_manager.get_session_context(session_id)
            
            if not session_context or not session_context.artifact_history:
                return []
            
            # ä» artifact_history æå–ä¸»é¢˜
            topics = []
            seen_topics = set()
            
            # å€’åºéå†ï¼ˆæœ€è¿‘çš„ä¼˜å…ˆï¼‰
            for artifact_record in reversed(session_context.artifact_history[-10:]):  # æœ€è¿‘10ä¸ª
                # ğŸ”¥ ç›´æ¥ä½¿ç”¨ artifact_record.topic
                topic = artifact_record.topic
                if topic and topic not in seen_topics and topic != "æœªçŸ¥ä¸»é¢˜":
                    topics.append(topic)
                    seen_topics.add(topic)
            
            logger.info(f"ğŸ“š Extracted {len(topics)} recent topics: {topics}")
            return topics
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to extract recent topics: {e}")
            return []
    
    def _extract_topic_from_result(self, skill_result: Dict[str, Any], fallback_topic: str = None) -> str:
        """
        ä» skill_result ä¸­æå–å®é™… topic
        
        ä¼˜å…ˆçº§ï¼š
        1. skill_result.title (quiz/flashcard)
        2. skill_result.concept (explanation)
        3. skill_result.subject (explanation)
        4. skill_result.topic (learning_bundle)
        5. fallback_topic
        
        Args:
            skill_result: æŠ€èƒ½æ‰§è¡Œç»“æœ
            fallback_topic: åå¤‡ topic
        
        Returns:
            æå–çš„ topic
        """
        if not skill_result:
            return fallback_topic or ""
        
        # ğŸ†• ç±»å‹æ£€æŸ¥ï¼šå¦‚æœ skill_result æ˜¯åˆ—è¡¨ï¼Œå°è¯•ä»ç¬¬ä¸€ä¸ªå…ƒç´ æå–
        if isinstance(skill_result, list):
            if len(skill_result) > 0 and isinstance(skill_result[0], dict):
                skill_result = skill_result[0]
            else:
                return fallback_topic or ""
        
        # ç¡®ä¿ skill_result æ˜¯å­—å…¸
        if not isinstance(skill_result, dict):
            return fallback_topic or ""
        
        # æ— æ•ˆ topic åˆ—è¡¨
        invalid_topics = {"æ–‡ä»¶å†…å®¹", "è¿™æ–‡ä»¶ å†…å®¹", "é™„ä»¶å†…å®¹", "æ–‡ä»¶", "é™„ä»¶", "None", "", "N/A", "æœªçŸ¥ä¸»é¢˜"}
        
        # æŒ‰ä¼˜å…ˆçº§å°è¯•æå–
        candidates = [
            skill_result.get('title'),       # Quiz/Flashcard
            skill_result.get('concept'),     # Explanation
            skill_result.get('subject'),     # Explanation fallback
            skill_result.get('topic'),       # Learning Bundle
        ]
        
        for candidate in candidates:
            if candidate and candidate not in invalid_topics and len(str(candidate)) >= 2:
                return str(candidate)
        
        # ä½¿ç”¨ fallbackï¼Œä½†éœ€è¦éªŒè¯
        if fallback_topic and fallback_topic not in invalid_topics and len(fallback_topic) >= 2:
            return fallback_topic
        
        return ""
    
    def _create_error_response(self, error_type: str, message: str) -> Dict[str, Any]:
        """
        åˆ›å»ºé”™è¯¯å“åº”
        
        Args:
            error_type: é”™è¯¯ç±»å‹
            message: é”™è¯¯æ¶ˆæ¯
        
        Returns:
            é”™è¯¯å“åº”å­—å…¸
        """
        return {
            "success": False,
            "error": error_type,
            "message": message
        }

