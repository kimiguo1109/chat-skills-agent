"""
Memory Manager - è®°å¿†ç®¡ç†å™¨

è´Ÿè´£ç®¡ç†ç”¨æˆ·çš„é•¿æœŸå­¦ä¹ ç”»åƒï¼ˆUserLearningProfileï¼‰å’ŒçŸ­æœŸä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆSessionContextï¼‰ã€‚
æ”¯æŒå†…å­˜å’Œ S3 ä¸¤ç§å­˜å‚¨æ–¹å¼ã€‚
ğŸ†• Phase 2.5: æ”¯æŒ Artifact è‡ªåŠ¨å¸è½½åˆ° S3/æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿã€‚
"""
import os
import logging
import json
import asyncio
from typing import Optional, Dict, Union, Any
from datetime import datetime
from pathlib import Path

from ..models.memory import UserLearningProfile, SessionContext, ArtifactRecord
from ..models.intent import MemorySummary
from ..config import settings
from .s3_storage import S3StorageManager
from .artifact_storage import ArtifactStorage
from .conversation_session_manager import ConversationSessionManager

logger = logging.getLogger(__name__)


class MemoryManager:
    """è®°å¿†ç®¡ç†å™¨ - ç®¡ç†ç”¨æˆ·å­¦ä¹ ç”»åƒå’Œä¼šè¯ä¸Šä¸‹æ–‡"""
    
    # ğŸ†• æœåŠ¡å¯åŠ¨ IDï¼ˆç±»å˜é‡ï¼Œæ•´ä¸ªè¿›ç¨‹å…±äº«ï¼‰
    _server_start_id: str = None
    
    # ğŸ†• å¹¶å‘å®‰å…¨ï¼šç”¨äºä¿æŠ¤ _conversation_sessions å­—å…¸çš„é”
    _session_lock: asyncio.Lock = None
    
    @classmethod
    def _get_session_lock(cls) -> asyncio.Lock:
        """è·å–æˆ–åˆ›å»º session é”ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ä»¥å…¼å®¹äº‹ä»¶å¾ªç¯ï¼‰"""
        if cls._session_lock is None:
            cls._session_lock = asyncio.Lock()
        return cls._session_lock
    
    @classmethod
    def get_server_start_id(cls) -> str:
        """è·å–æˆ–ç”ŸæˆæœåŠ¡å¯åŠ¨ IDï¼ˆæ¯æ¬¡æœåŠ¡é‡å¯æ—¶ç”Ÿæˆæ–°çš„ï¼‰"""
        if cls._server_start_id is None:
            import uuid
            cls._server_start_id = str(uuid.uuid4())
            logger.info(f"ğŸ†• Generated server_start_id: {cls._server_start_id[:8]}...")
        return cls._server_start_id
    
    def __init__(self, use_s3: Optional[bool] = None, local_storage_dir: Optional[str] = None):
        """
        åˆå§‹åŒ– Memory Manager
        
        Args:
            use_s3: æ˜¯å¦ä½¿ç”¨ S3 å­˜å‚¨ï¼ˆNone æ—¶ä½¿ç”¨ settings é…ç½®ï¼ŒFalse å¼ºåˆ¶å†…å­˜ï¼ŒTrue å¼ºåˆ¶ S3ï¼‰
            local_storage_dir: æœ¬åœ°å­˜å‚¨ç›®å½•ï¼ˆç”¨äºè°ƒè¯•å’ŒæŸ¥çœ‹memoryå†…å®¹ï¼‰
        """
        # ç¡®å®šæ˜¯å¦ä½¿ç”¨ S3
        # å¦‚æœ use_s3=Noneï¼Œä½¿ç”¨ settings é…ç½®ï¼›å¦åˆ™ä½¿ç”¨ä¼ å…¥çš„å€¼
        use_s3_setting = use_s3 if use_s3 is not None else settings.USE_S3_STORAGE
        
        # ğŸ†• é›†æˆ S3StorageManager å’Œ ArtifactStorage
        # å¦‚æœé…ç½®å¯ç”¨ S3ï¼Œå§‹ç»ˆåˆ›å»º S3StorageManagerï¼ˆè®©å®ƒè‡ªå·±åˆ¤æ–­æ˜¯å¦å¯ç”¨ï¼‰
        # è¿™æ · ConversationSessionManager å¯ä»¥è·å¾— s3_managerï¼Œå³ä½¿ S3 æš‚æ—¶ä¸å¯ç”¨
        if use_s3_setting:
            self.s3_manager = S3StorageManager()
            # æ ¹æ®å®é™…å¯ç”¨æ€§æ›´æ–° use_s3
            self.use_s3 = self.s3_manager.is_available()
            if not self.use_s3:
                logger.warning("âš ï¸  S3 configured but not available, falling back to local storage")
        else:
            self.s3_manager = None
            self.use_s3 = False
        
        # å†…å­˜å­˜å‚¨
        self._user_profiles: Dict[str, UserLearningProfile] = {}
        self._session_contexts: Dict[str, SessionContext] = {}
        
        # æœ¬åœ°å­˜å‚¨é…ç½®ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        self.local_storage_dir = Path(local_storage_dir or os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
            "memory_storage"
        ))
        self.local_storage_dir.mkdir(parents=True, exist_ok=True)
        self.artifact_storage = ArtifactStorage(
            base_dir="artifacts",
            s3_manager=self.s3_manager
        )
        
        # ğŸ†• Conversation Session Managers (æ¯ä¸ªç”¨æˆ·ä¸€ä¸ª)
        self._conversation_sessions: Dict[str, ConversationSessionManager] = {}
        
        logger.info(
            f"âœ… MemoryManager initialized "
            f"(S3: {self.use_s3}, Local: {self.local_storage_dir}, "
            f"Artifact Storage: S3={self.artifact_storage.use_s3})"
        )
        
        # ğŸ†• ä»æœ¬åœ°æ–‡ä»¶åŠ è½½ç°æœ‰æ•°æ®ï¼ˆç”¨äºå¼€å‘è°ƒè¯•ï¼‰
        if not self.use_s3:
            self._load_from_local_files()
    
    # ============= User Learning Profile =============
    
    async def get_user_profile(self, user_id: str) -> UserLearningProfile:
        """
        è·å–ç”¨æˆ·å­¦ä¹ ç”»åƒ
        
        Args:
            user_id: ç”¨æˆ· ID
        
        Returns:
            UserLearningProfile: ç”¨æˆ·å­¦ä¹ ç”»åƒ
        """
        if self.use_s3:
            return await self._get_user_profile_from_s3(user_id)
        
        # ä»å†…å­˜è·å–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºé»˜è®¤ç”»åƒ
        if user_id not in self._user_profiles:
            logger.info(f"ğŸ“ Creating new user profile for {user_id}")
            self._user_profiles[user_id] = UserLearningProfile(
                user_id=user_id,
                mastery={},
                preferences={},
                history={
                    "quiz_sessions": 0,
                    "homework_help_count": 0,
                    "topics_visited": []
                }
            )
        
        return self._user_profiles[user_id]
    
    async def update_user_profile(
        self,
        user_id: str,
        profile: UserLearningProfile
    ) -> UserLearningProfile:
        """
        æ›´æ–°ç”¨æˆ·å­¦ä¹ ç”»åƒ
        
        Args:
            user_id: ç”¨æˆ· ID
            profile: æ›´æ–°åçš„ç”»åƒ
        
        Returns:
            UserLearningProfile: æ›´æ–°åçš„ç”»åƒ
        """
        profile.updated_at = datetime.now()
        
        if self.use_s3:
            return await self._update_user_profile_to_s3(user_id, profile)
        
        self._user_profiles[user_id] = profile
        logger.info(f"âœ… Updated user profile for {user_id}")
        
        # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        await self._save_to_local_file(user_id, profile, "profile")
        
        return profile
    
    # ============= Session Context =============
    
    async def get_session_context(self, session_id: str, user_id: Optional[str] = None) -> SessionContext:
        """
        è·å–ä¼šè¯ä¸Šä¸‹æ–‡
        
        Args:
            session_id: ä¼šè¯ ID
            user_id: ç”¨æˆ· IDï¼ˆå¯é€‰ï¼Œç”¨äºä» ConversationSessionManager è·å– inherited_topicï¼‰
        
        Returns:
            SessionContext: ä¼šè¯ä¸Šä¸‹æ–‡
        """
        if self.use_s3:
            return await self._get_session_context_from_s3(session_id, user_id)
        
        # ä»å†…å­˜è·å–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºé»˜è®¤ä¸Šä¸‹æ–‡
        if session_id not in self._session_contexts:
            logger.info(f"ğŸ“ Creating new session context for {session_id}")
            
            # ğŸ†• å°è¯•ä» ConversationSessionManager è·å– inherited_topic
            inherited_topic = None
            if user_id and user_id in self._conversation_sessions:
                conversation_mgr = self._conversation_sessions[user_id]
                inherited_topic = conversation_mgr.session_metadata.get("inherited_topic")
                if inherited_topic:
                    logger.info(f"ğŸ“š Using inherited_topic from conversation session: {inherited_topic}")
            
            self._session_contexts[session_id] = SessionContext(
                session_id=session_id,
                current_topic=inherited_topic,  # ğŸ†• ä½¿ç”¨ç»§æ‰¿çš„ä¸»é¢˜
                recent_intents=[],
                last_artifact=None,
                last_user_message=""
            )
        
        return self._session_contexts[session_id]
    
    async def update_session_context(
        self,
        session_id: str,
        context: SessionContext
    ) -> SessionContext:
        """
        æ›´æ–°ä¼šè¯ä¸Šä¸‹æ–‡
        
        Args:
            session_id: ä¼šè¯ ID
            context: æ›´æ–°åçš„ä¸Šä¸‹æ–‡
        
        Returns:
            SessionContext: æ›´æ–°åçš„ä¸Šä¸‹æ–‡
        """
        context.updated_at = datetime.now()
        
        if self.use_s3:
            return await self._update_session_context_to_s3(session_id, context)
        
        self._session_contexts[session_id] = context
        logger.info(f"âœ… Updated session context for {session_id}")
        
        # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        await self._save_to_local_file(session_id, context, "session")
        
        return context
    
    # ============= Memory Summary =============
    
    async def generate_memory_summary(
        self,
        user_id: str,
        session_id: str
    ) -> MemorySummary:
        """
        ç”Ÿæˆè®°å¿†æ‘˜è¦ï¼Œç”¨äº Intent Router
        åŒ…å«å­¦ä¹ åå¥½åˆ†æï¼
        
        Args:
            user_id: ç”¨æˆ· ID
            session_id: ä¼šè¯ ID
        
        Returns:
            MemorySummary: è®°å¿†æ‘˜è¦
        """
        # è·å–ç”¨æˆ·ç”»åƒå’Œä¼šè¯ä¸Šä¸‹æ–‡
        user_profile = await self.get_user_profile(user_id)
        session_context = await self.get_session_context(session_id)
        
        # åˆ†æç”¨æˆ·çš„Skillä½¿ç”¨åå¥½
        skill_preference_hint = self._analyze_skill_preference(session_context.recent_intents)
        
        # ç”Ÿæˆ topic_hint
        topic_hint = session_context.current_topic
        
        # ç”Ÿæˆ user_mastery_hintï¼ˆå¦‚æœæœ‰å½“å‰ä¸»é¢˜ï¼‰
        user_mastery_hint = None
        if topic_hint and topic_hint in user_profile.mastery:
            user_mastery_hint = user_profile.mastery[topic_hint]
        
        # ç”Ÿæˆ recent_behavior æè¿°ï¼ˆåŒ…å«åå¥½æç¤ºï¼‰
        recent_behavior = self._generate_behavior_description(
            user_profile,
            session_context,
            skill_preference_hint
        )
        
        summary = MemorySummary(
            topic_hint=topic_hint,
            user_mastery_hint=user_mastery_hint,
            recent_behavior=recent_behavior
        )
        
        # ä½¿ç”¨ INFO çº§åˆ«æ—¥å¿—ï¼Œä¾¿äºæŸ¥çœ‹åå¥½æ˜¯å¦ç”Ÿæ•ˆ
        logger.info(f"ğŸ“Š Generated memory summary: recent_behavior='{recent_behavior}'")
        if skill_preference_hint:
            logger.info(f"âœ¨ User preference detected: {skill_preference_hint}")
        
        return summary
    
    def _generate_behavior_description(
        self,
        profile: UserLearningProfile,
        context: SessionContext,
        skill_preference_hint: str = ""
    ) -> str:
        """
        ç”Ÿæˆç”¨æˆ·è¡Œä¸ºæè¿°
        
        Args:
            profile: ç”¨æˆ·ç”»åƒ
            context: ä¼šè¯ä¸Šä¸‹æ–‡
            skill_preference_hint: å­¦ä¹ åå¥½æç¤º
        
        Returns:
            str: è¡Œä¸ºæè¿°
        """
        behaviors = []
        
        # æ·»åŠ å­¦ä¹ åå¥½æç¤ºï¼ˆå¦‚æœæœ‰ï¼‰
        if skill_preference_hint:
            behaviors.append(skill_preference_hint)
        
        # æœ€è¿‘çš„æ„å›¾
        if context.recent_intents:
            last_intent = context.recent_intents[-1] if context.recent_intents else None
            if last_intent == "quiz_request":
                behaviors.append("åˆšåšè¿‡ç»ƒä¹ é¢˜")
            elif last_intent == "explain_request":
                behaviors.append("åˆšçœ‹è¿‡æ¦‚å¿µè®²è§£")
            elif last_intent == "flashcard_request":
                behaviors.append("åˆšå­¦è¿‡é—ªå¡")
        
        # åå¥½
        if profile.preferences.get("preferred_artifact"):
            pref = profile.preferences["preferred_artifact"]
            if pref == "quiz":
                behaviors.append("åå¥½åšç»ƒä¹ ")
            elif pref == "explanation":
                behaviors.append("åå¥½çœ‹è®²è§£")
        
        # å†å²ç»Ÿè®¡
        quiz_count = profile.history.get("quiz_sessions", 0)
        if quiz_count > 0:
            behaviors.append(f"å·²åšè¿‡{quiz_count}æ¬¡ç»ƒä¹ ")
        
        return "ï¼›".join(behaviors) if behaviors else "æ–°ç”¨æˆ·"
    
    def _analyze_skill_preference(self, recent_intents: list) -> str:
        """
        åˆ†æç”¨æˆ·çš„Skillä½¿ç”¨åå¥½
        
        Args:
            recent_intents: æœ€è¿‘çš„æ„å›¾åˆ—è¡¨
        
        Returns:
            str: åå¥½æç¤ºï¼ˆå¦‚æœæœ‰æ˜æ˜¾åå¥½ï¼‰
        """
        if not recent_intents or len(recent_intents) < 2:  # é™ä½é˜ˆå€¼ï¼šä»3æ”¹ä¸º2
            return ""
        
        # ç»Ÿè®¡å„ä¸ªæ„å›¾çš„å‡ºç°æ¬¡æ•°
        intent_counts = {}
        for intent in recent_intents[-10:]:  # åªçœ‹æœ€è¿‘10æ¬¡
            intent_counts[intent] = intent_counts.get(intent, 0) + 1
        
        total = len(recent_intents[-10:])
        
        # é™ä½åå¥½è§¦å‘é˜ˆå€¼ï¼šä» >=60% æ”¹ä¸º >=50%
        for intent, count in intent_counts.items():
            preference_ratio = count / total
            if preference_ratio >= 0.5:
                intent_name_map = {
                    "flashcard_request": "flashcards",
                    "quiz_request": "quiz practice",
                    "explain_request": "concept explanations",
                    "learning_bundle": "complete learning packages"
                }
                intent_display = intent_name_map.get(intent, intent)
                
                # å¢å¼ºåå¥½å¼ºåº¦è¡¨è¾¾
                if preference_ratio >= 0.75:
                    strength = "Very strongly"
                elif preference_ratio >= 0.60:
                    strength = "Strongly"
                else:
                    strength = "Prefers"
                
                return f"[User Preference: {strength} prefers {intent_display} for learning ({int(preference_ratio*100)}% of recent activities)]"
        
        return ""
    
    # ============= S3 æ“ä½œï¼ˆå ä½ç¬¦ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦ boto3ï¼‰=============
    
    async def _get_user_profile_from_s3(self, user_id: str) -> UserLearningProfile:
        """ä» S3 è·å–ç”¨æˆ·ç”»åƒï¼ˆå ä½ç¬¦ï¼‰"""
        # å ä½ç¬¦ï¼šä½¿ç”¨å†…å­˜å­˜å‚¨
        if user_id not in self._user_profiles:
            self._user_profiles[user_id] = UserLearningProfile(
                user_id=user_id,
                mastery={},
                preferences={},
                history={
                    "quiz_sessions": 0,
                    "homework_help_count": 0,
                    "topics_visited": []
                }
            )
        return self._user_profiles[user_id]
    
    async def _update_user_profile_to_s3(
        self,
        user_id: str,
        profile: UserLearningProfile
    ) -> UserLearningProfile:
        """æ›´æ–°ç”¨æˆ·ç”»åƒåˆ° S3ï¼ˆå ä½ç¬¦ï¼‰"""
        # å ä½ç¬¦ï¼šä½¿ç”¨å†…å­˜å­˜å‚¨
        self._user_profiles[user_id] = profile
        return profile
    
    async def _get_session_context_from_s3(self, session_id: str, user_id: Optional[str] = None) -> SessionContext:
        """ä» S3 è·å–ä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆå ä½ç¬¦ï¼‰"""
        # å ä½ç¬¦ï¼šä½¿ç”¨å†…å­˜å­˜å‚¨
        if session_id not in self._session_contexts:
            # ğŸ†• å°è¯•ä» ConversationSessionManager è·å– inherited_topic
            inherited_topic = None
            if user_id and user_id in self._conversation_sessions:
                conversation_mgr = self._conversation_sessions[user_id]
                inherited_topic = conversation_mgr.session_metadata.get("inherited_topic")
                if inherited_topic:
                    logger.info(f"ğŸ“š Using inherited_topic from conversation session: {inherited_topic}")
            
            self._session_contexts[session_id] = SessionContext(
                session_id=session_id,
                current_topic=inherited_topic,  # ğŸ†• ä½¿ç”¨ç»§æ‰¿çš„ä¸»é¢˜
                recent_intents=[],
                last_artifact=None,
                last_user_message=""
            )
        return self._session_contexts[session_id]
    
    async def _update_session_context_to_s3(
        self,
        session_id: str,
        context: SessionContext
    ) -> SessionContext:
        """æ›´æ–°ä¼šè¯ä¸Šä¸‹æ–‡åˆ° S3ï¼ˆå ä½ç¬¦ï¼‰"""
        # å ä½ç¬¦ï¼šä½¿ç”¨å†…å­˜å­˜å‚¨
        self._session_contexts[session_id] = context
        return context
    
    # ============= æœ¬åœ°æ–‡ä»¶å­˜å‚¨ï¼ˆç”¨äºè°ƒè¯•ï¼‰ =============
    
    async def _save_to_local_file(
        self,
        id_str: str,
        data: Union[UserLearningProfile, SessionContext],
        data_type: str
    ):
        """
        ä¿å­˜æ•°æ®åˆ°æœ¬åœ°æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•å’ŒæŸ¥çœ‹memoryå†…å®¹ï¼‰
        
        Args:
            id_str: ç”¨æˆ·IDæˆ–ä¼šè¯ID
            data: UserLearningProfile æˆ– SessionContext
            data_type: "profile" æˆ– "session"
        """
        try:
            import json
            from datetime import datetime
            
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            filename = f"{data_type}_{id_str}.json"
            filepath = os.path.join(self.local_storage_dir, filename)
            
            # è½¬æ¢ä¸ºå­—å…¸å¹¶æ·»åŠ æ—¶é—´æˆ³
            if isinstance(data, (UserLearningProfile, SessionContext)):
                data_dict = data.model_dump()
            else:
                data_dict = dict(data)
            
            # ğŸ†• è½¬æ¢æ‰€æœ‰datetimeå¯¹è±¡ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²
            def convert_datetime(obj):
                """é€’å½’è½¬æ¢datetimeå¯¹è±¡"""
                if isinstance(obj, datetime):
                    return obj.isoformat()
                elif isinstance(obj, dict):
                    return {k: convert_datetime(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_datetime(item) for item in obj]
                else:
                    return obj
            
            data_dict = convert_datetime(data_dict)
            data_dict["_last_updated"] = datetime.now().isoformat()
            
            # å†™å…¥æ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data_dict, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"ğŸ’¾ Saved {data_type} to {filepath}")
            
        except Exception as e:
            logger.warning(f"âš ï¸  Failed to save {data_type} to local file: {e}")
    
    # ============= Artifact Search =============
    
    async def find_artifact_by_id(self, artifact_id: str):
        """
        ä»æ‰€æœ‰ sessions ä¸­æŸ¥æ‰¾æŒ‡å®š ID çš„ artifact
        
        Args:
            artifact_id: Artifact ID
        
        Returns:
            ArtifactRecord æˆ– None
        """
        # éå†æ‰€æœ‰ session contexts
        for session_id, session_context in self._session_contexts.items():
            if session_context.artifact_history:
                for artifact in session_context.artifact_history:
                    if artifact.artifact_id == artifact_id:
                        logger.info(f"âœ… Found artifact {artifact_id} in session {session_id}")
                        return artifact
        
        logger.warning(f"âš ï¸  Artifact {artifact_id} not found in any session")
        return None
    
    # ============= Local File Loading =============
    
    def _load_from_local_files(self):
        """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½å·²å­˜å‚¨çš„ session contextsï¼ˆç”¨äºå¼€å‘è°ƒè¯•ï¼‰"""
        try:
            # æ‰«æ memory_storage ç›®å½•ä¸­çš„ session æ–‡ä»¶
            import glob
            session_files = glob.glob(os.path.join(self.local_storage_dir, "*-session.json"))
            
            loaded_count = 0
            for filepath in session_files:
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # æå– session_id
                    session_id = data.get("session_id")
                    if not session_id:
                        continue
                    
                    # è½¬æ¢ artifact_history ä¸­çš„ datetime å­—ç¬¦ä¸²
                    if "artifact_history" in data and data["artifact_history"]:
                        for artifact in data["artifact_history"]:
                            if "timestamp" in artifact and isinstance(artifact["timestamp"], str):
                                artifact["timestamp"] = datetime.fromisoformat(artifact["timestamp"])
                    
                    # è½¬æ¢ updated_at
                    if "updated_at" in data and isinstance(data["updated_at"], str):
                        data["updated_at"] = datetime.fromisoformat(data["updated_at"])
                    
                    # åˆ›å»º SessionContext å¯¹è±¡
                    session_context = SessionContext(**data)
                    self._session_contexts[session_id] = session_context
                    loaded_count += 1
                    
                    logger.info(f"ğŸ“‚ Loaded session {session_id} with {len(session_context.artifact_history)} artifacts")
                    
                except Exception as e:
                    logger.warning(f"âš ï¸  Failed to load {filepath}: {e}")
            
            if loaded_count > 0:
                logger.info(f"âœ… Loaded {loaded_count} session(s) from local files")
            
        except Exception as e:
            logger.warning(f"âš ï¸  Failed to load from local files: {e}")
    
    # ============= Artifact Management (Phase 2.5) =============
    
    async def save_artifact(
        self,
        session_id: str,
        artifact: Dict[str, Any],
        artifact_type: str,
        topic: str,
        user_id: str
    ) -> ArtifactRecord:
        """
        ä¿å­˜ artifactï¼ˆè‡ªåŠ¨å¸è½½åˆ° S3/æœ¬åœ°ï¼‰
        
        å†³ç­–é€»è¾‘ï¼š
        - å°å†…å®¹ (< 500 bytes): inline å­˜å‚¨ï¼ˆç›´æ¥å­˜å‚¨åœ¨ ArtifactRecord.contentï¼‰
        - å¤§å†…å®¹ (>= 500 bytes): å¸è½½åˆ° S3/æ–‡ä»¶ç³»ç»Ÿï¼ˆå­˜å‚¨å¼•ç”¨ï¼‰
        
        Args:
            session_id: ä¼šè¯ID
            artifact: Artifact å†…å®¹
            artifact_type: ç±»å‹ï¼ˆexplanation, quiz_set, flashcard_setç­‰ï¼‰
            topic: ä¸»é¢˜
            user_id: ç”¨æˆ·ID
        
        Returns:
            ArtifactRecord å®ä¾‹
        
        Raises:
            ValueError: å†…å®¹éªŒè¯å¤±è´¥
            IOError: å­˜å‚¨å¤±è´¥
        """
        artifact_id = self._generate_artifact_id(artifact_type, topic)
        
        # ğŸ”§ æ•°æ®éªŒè¯
        if not self._validate_artifact_content(artifact):
            logger.error(f"âŒ Invalid artifact content for {artifact_id}")
            # å­˜åˆ°éš”ç¦»åŒº
            self._quarantine_invalid_artifact(artifact_id, artifact, "validation_failed")
            raise ValueError(f"Invalid artifact content: {artifact_id}")
        
        # ä¼°ç®—å¤§å°
        try:
            content_json = json.dumps(artifact, ensure_ascii=False)
            content_size = len(content_json)
        except Exception as e:
            logger.error(f"âŒ Failed to serialize artifact {artifact_id}: {e}")
            self._quarantine_invalid_artifact(artifact_id, artifact, "serialization_failed")
            raise ValueError(f"Cannot serialize artifact: {e}") from e
        
        # ğŸšï¸ å­˜å‚¨ç­–ç•¥ï¼šä¿å­˜å‹ç¼©çš„summaryä½œä¸ºcontentï¼Œæ”¯æŒä¸Šä¸‹æ–‡å¸è½½
        # å®Œæ•´å†…å®¹åœ¨MDæ–‡ä»¶ä¸­ï¼Œè¿™é‡Œåªä¿å­˜æ‘˜è¦ç”¨äºLLMå¿«é€Ÿä¸Šä¸‹æ–‡åŠ è½½
        summary_text = self._generate_summary(artifact, artifact_type)
        
        # ğŸ”¥ å…ˆä½¿ç”¨ fallback å‹ç¼©ä½œä¸º summaryï¼ˆç”¨äº LLM ä¸Šä¸‹æ–‡ï¼‰
        context_summary_placeholder = self._fallback_compression(artifact, artifact_type, topic)
        
        # ğŸ†• content ä¿å­˜åŸå§‹å®Œæ•´æ•°æ®ï¼ˆç”¨äºå¼•ç”¨è§£æï¼‰ï¼Œsummary ä¿å­˜å‹ç¼©æ‘˜è¦ï¼ˆç”¨äº LLM ä¸Šä¸‹æ–‡ï¼‰
        record = ArtifactRecord(
            artifact_id=artifact_id,
            turn_number=self._get_turn_number(session_id),
            artifact_type=artifact_type,
            topic=topic,
            summary=context_summary_placeholder,  # ğŸ†• æ‘˜è¦æ”¾è¿™é‡Œï¼Œç”¨äº LLM ä¸Šä¸‹æ–‡
            content=artifact,  # ğŸ†• åŸå§‹å®Œæ•´æ•°æ®æ”¾è¿™é‡Œï¼Œç”¨äºå¼•ç”¨è§£æ
            content_reference=None  # ä¸éœ€è¦å¤–éƒ¨å¼•ç”¨ï¼ˆå®Œæ•´å†…å®¹åœ¨MDï¼‰
        )
        logger.info(f"ğŸ“ Artifact {artifact_id} recorded (full content: {content_size} chars, summary: {len(str(context_summary_placeholder))} chars)")
        
        # æ·»åŠ åˆ° session context
        session_context = await self.get_session_context(session_id)
        session_context.artifact_history.append(record)
        session_context.last_artifact_id = artifact_id
        await self.update_session_context(session_id, session_context)
        
        # ğŸ†• æŒ‰éœ€å‹ç¼©ç­–ç•¥ï¼ˆä¼˜åŒ– token æ¶ˆè€—ï¼‰
        # - å° artifact (<1000 chars)ï¼šä¸å‹ç¼©ï¼Œç›´æ¥ä½¿ç”¨ fallback summary
        # - ä¸­ç­‰ artifact (1000-5000 chars)ï¼šä½¿ç”¨ Gemini å‹ç¼©
        # - å¤§ artifact (>5000 chars)ï¼šå¿…é¡»å‹ç¼©
        #
        # Token æˆæœ¬åˆ†æ (Gemini 2.0 Flash Lite):
        # - Input: $0.075/M tokens â†’ ~1900 tokens â‰ˆ $0.00014
        # - Output: $0.30/M tokens â†’ ~700 tokens â‰ˆ $0.00021
        # - Total: ~$0.00035/æ¬¡
        artifact_size = len(json.dumps(artifact, ensure_ascii=False))
        
        # å‹ç¼©é˜ˆå€¼é…ç½®
        COMPRESSION_THRESHOLD = 1000  # åªå¯¹ >1000 chars çš„ artifact è¿›è¡Œ LLM å‹ç¼©
        
        if artifact_size >= COMPRESSION_THRESHOLD:
            # å¯åŠ¨åå° Gemini å‹ç¼©
            logger.info(f"ğŸ“Š Artifact size: {artifact_size} chars (>= {COMPRESSION_THRESHOLD}), triggering Gemini compression")
            task = asyncio.create_task(
                self._compress_artifact_async(artifact_id, artifact, artifact_type, topic, session_id, user_id)
            )
            task.add_done_callback(lambda t: t.exception() if not t.cancelled() else None)
            logger.debug(f"ğŸ”„ Started background Gemini compression for {artifact_id}")
        else:
            # å° artifactï¼šè·³è¿‡ LLM å‹ç¼©ï¼ŒèŠ‚çœ token
            logger.info(f"ğŸ“Š Artifact size: {artifact_size} chars (< {COMPRESSION_THRESHOLD}), skipping LLM compression (using rule-based summary)")
        
        return record
    
    async def get_artifact(
        self,
        artifact_id: str
    ) -> Optional[Dict[str, Any]]:
        """
        è·å– artifact å†…å®¹ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰
        
        - å¦‚æœæ˜¯ inline å­˜å‚¨ï¼šç›´æ¥è¿”å› content
        - å¦‚æœæ˜¯å¤–éƒ¨å­˜å‚¨ï¼šä» S3/æ–‡ä»¶åŠ è½½
        
        Args:
            artifact_id: Artifact ID
        
        Returns:
            Artifact å†…å®¹æˆ– None
        """
        # æŸ¥æ‰¾ artifact record
        record = self._find_artifact_record(artifact_id)
        if not record:
            logger.warning(f"âš ï¸  Artifact {artifact_id} not found")
            return None
        
        # inline å­˜å‚¨
        if record.content is not None:
            logger.debug(f"ğŸ“„ Loading inline artifact {artifact_id}")
            return record.content
        
        # å¤–éƒ¨å­˜å‚¨ï¼ˆS3/æœ¬åœ°ï¼‰
        if record.content_reference:
            try:
                content = self.artifact_storage.load_artifact_by_reference(record.content_reference)
                logger.debug(f"ğŸ’¾ Loaded artifact {artifact_id} from {record.storage_type}")
                return content
            except Exception as e:
                logger.error(f"âŒ Failed to load artifact {artifact_id}: {e}")
                return None
        
        logger.warning(f"âš ï¸  Artifact {artifact_id} has no content or reference")
        return None
    
    def _find_artifact_record(self, artifact_id: str) -> Optional[ArtifactRecord]:
        """åœ¨æ‰€æœ‰ session contexts ä¸­æŸ¥æ‰¾ artifact record"""
        for session_context in self._session_contexts.values():
            for artifact in session_context.artifact_history:
                if artifact.artifact_id == artifact_id:
                    return artifact
        return None
    
    def _validate_artifact_content(self, content: Dict[str, Any]) -> bool:
        """
        éªŒè¯ artifact å†…å®¹
        
        è§„åˆ™ï¼š
        1. å¿…é¡»æ˜¯å­—å…¸
        2. å¿…é¡»å¯ JSON åºåˆ—åŒ–
        3. å¤§å° < 10MB
        """
        if not isinstance(content, dict):
            return False
        
        try:
            content_json = json.dumps(content, ensure_ascii=False)
            MAX_SIZE = 10 * 1024 * 1024  # 10MB
            return len(content_json) <= MAX_SIZE
        except:
            return False
    
    def _quarantine_invalid_artifact(
        self,
        artifact_id: str,
        content: Any,
        reason: str
    ):
        """
        å°†æ— æ•ˆ artifact å­˜åˆ°éš”ç¦»åŒºï¼ˆç”¨äºåç»­åˆ†æï¼‰
        """
        quarantine_dir = Path("quarantine")
        quarantine_dir.mkdir(exist_ok=True)
        
        quarantine_file = quarantine_dir / f"{artifact_id}_{reason}.json"
        try:
            with open(quarantine_file, "w", encoding="utf-8") as f:
                json.dump({
                    "artifact_id": artifact_id,
                    "reason": reason,
                    "timestamp": datetime.now().isoformat(),
                    "content": str(content)  # å¼ºåˆ¶è½¬å­—ç¬¦ä¸²
                }, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ”’ Quarantined invalid artifact: {quarantine_file}")
        except Exception as e:
            logger.error(f"âŒ Failed to quarantine artifact: {e}")
    
    def _generate_artifact_id(self, artifact_type: str, topic: str) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„ artifact ID"""
        import uuid
        short_id = uuid.uuid4().hex[:8]
        timestamp = int(datetime.now().timestamp())
        # artifact_explanation_physics_12345678_1699999999
        safe_topic = topic.replace(" ", "_").replace("/", "_")[:20]
        return f"artifact_{artifact_type}_{safe_topic}_{short_id}_{timestamp}"
    
    def _get_turn_number(self, session_id: str) -> int:
        """è·å–å½“å‰ä¼šè¯çš„ turn number"""
        session_context = self._session_contexts.get(session_id)
        if session_context:
            return len(session_context.artifact_history) + 1
        return 1
    
    def _generate_summary(self, artifact: Dict[str, Any], artifact_type: str) -> str:
        """ç”Ÿæˆ artifact æ‘˜è¦ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰"""
        # æ ¹æ®ä¸åŒç±»å‹ç”Ÿæˆæ‘˜è¦
        if artifact_type == "explanation":
            concept = artifact.get("concept", "Unknown")
            return f"Explanation: {concept}"
        elif artifact_type == "quiz_set":
            num_questions = len(artifact.get("questions", []))
            return f"Quiz: {num_questions} questions"
        elif artifact_type == "flashcard_set":
            # å…¼å®¹æ–°æ—§æ ¼å¼ï¼šcardList (æ–°) æˆ– cards (æ—§)
            cards = artifact.get("cardList") or artifact.get("cards", [])
            num_cards = len(cards)
            return f"Flashcards: {num_cards} cards"
        elif artifact_type == "notes":
            title = artifact.get("structured_notes", {}).get("title", "Unknown")
            return f"Notes: {title}"
        else:
            return f"{artifact_type}"
    
    async def _compress_artifact_async(
        self,
        artifact_id: str,
        artifact: Dict[str, Any],
        artifact_type: str,
        topic: str,
        session_id: str,
        user_id: str = "unknown"  # ğŸ†• æ·»åŠ  user_id å‚æ•°
    ):
        """
        åå°å¼‚æ­¥ä»»åŠ¡ï¼šä½¿ç”¨ LLM æ™ºèƒ½å‹ç¼© artifact
        
        æ‰§è¡Œæµç¨‹ï¼š
        1. è°ƒç”¨ LLM è¿›è¡Œæ™ºèƒ½å‹ç¼©
        2. æ›´æ–° session_context ä¸­çš„ artifact record
        3. ä¸é˜»å¡ç”¨æˆ·å“åº”
        4. ğŸ†• è®°å½• token ä½¿ç”¨åˆ° MemoryTokenTracker
        
        âš ï¸ æ³¨æ„ï¼šæ­¤æ–¹æ³•ä¼šé•¿æ—¶é—´è¿è¡Œ (~260s)ï¼Œä½†ä¸ä¼šé˜»å¡ç”¨æˆ·
        """
        try:
            logger.info(f"ğŸ”„ Background compression started for {artifact_id}")
            logger.debug(f"   This will take ~260s but won't block user response")
            
            # è°ƒç”¨ LLM è¿›è¡Œæ™ºèƒ½å‹ç¼© (é•¿æ—¶é—´è¿è¡Œ)
            compressed_summary, token_usage = await self._create_context_summary(artifact, artifact_type, topic)
            
            # ğŸ†• è®°å½• token ä½¿ç”¨
            if token_usage and token_usage.get("total_tokens", 0) > 0:
                from app.services.memory_token_tracker import get_memory_token_tracker
                tracker = get_memory_token_tracker()
                tracker.record_compression(
                    user_id=user_id,
                    session_id=session_id,
                    artifact_id=artifact_id,
                    prompt_tokens=token_usage.get("prompt_tokens", 0),
                    completion_tokens=token_usage.get("completion_tokens", 0),
                    total_tokens=token_usage.get("total_tokens", 0),
                    model=token_usage.get("model", "gemini-2.5-flash")
                )
            
            # æ›´æ–° session context ä¸­çš„ artifact record
            session_context = await self.get_session_context(session_id)
            
            for record in session_context.artifact_history:
                if record.artifact_id == artifact_id:
                    # ğŸ†• compressed_summary ç°åœ¨å§‹ç»ˆæ˜¯ stringï¼ˆåœ¨ _compress_artifact ä¸­å·²è½¬æ¢ï¼‰
                    record.summary = str(compressed_summary)
                    # ğŸ”¥ ä¸è¦†ç›– record.contentï¼Œä¿ç•™åŸå§‹å®Œæ•´æ•°æ®ç”¨äºå¼•ç”¨è§£æ
                    logger.info(f"âœ… Background compression complete for {artifact_id}, summary: {len(record.summary)} chars")
                    break
            
            # ä¿å­˜æ›´æ–°åçš„ session context
            await self.update_session_context(session_id, session_context)
            logger.info(f"ğŸ’¾ Session context updated with compressed artifact")
            
        except Exception as e:
            logger.error(f"âŒ Background compression failed for {artifact_id}: {e}")
            logger.exception(e)
            logger.debug(f"   Fallback summary will be used instead")
    
    async def _create_context_summary(self, artifact: Dict[str, Any], artifact_type: str, topic: str) -> Dict[str, Any]:
        """
        ğŸ†• åˆ›å»ºä¸Šä¸‹æ–‡å‹å¥½çš„æ‘˜è¦ï¼ˆä½¿ç”¨ LLM æ™ºèƒ½å‹ç¼©ï¼‰
        
        ç­–ç•¥ï¼š
        - ä½¿ç”¨ summary_skill LLM è¿›è¡Œè¯­ä¹‰å‹ç¼©
        - ç›®æ ‡å‹ç¼©æ¯” > 90% (e.g., 2000 tokens â†’ < 200 tokens)
        - ä¿ç•™é€»è¾‘å…³ç³»ï¼Œä¸¢å¼ƒå†—ä½™æè¿°
        
        Args:
            artifact: åŸå§‹ artifact å†…å®¹
            artifact_type: Artifact ç±»å‹
            topic: ä¸»é¢˜
        
        Returns:
            å‹ç¼©çš„ context summaryï¼ˆDictï¼‰
        """
        try:
            import json
            from pathlib import Path
            
            # åŠ è½½ summary_skill prompt
            # __file__ = backend/app/core/memory_manager.py
            # parent = backend/app/core
            # parent.parent = backend/app
            # parent.parent.parent = backend
            summary_prompt_path = Path(__file__).parent.parent / "prompts" / "summary_skill.txt"
            
            if not summary_prompt_path.exists():
                logger.warning(f"âš ï¸ summary_skill.txt not found at {summary_prompt_path}, using fallback compression")
                return self._fallback_compression(artifact, artifact_type, topic)
            
            with open(summary_prompt_path, 'r', encoding='utf-8') as f:
                summary_prompt = f.read()
            
            # æ„é€ å‹ç¼©è¯·æ±‚
            compression_input = {
                "interaction_type": self._map_artifact_type_to_interaction(artifact_type),
                "topic": topic,
                "ai_response": json.dumps(artifact, ensure_ascii=False),
                "artifact_type": artifact_type
            }
            
            # æ·»åŠ å‚æ•° JSON
            params_json = json.dumps(compression_input, ensure_ascii=False, indent=2)
            full_prompt = f"{summary_prompt}\n\n## Input Parameters (JSON)\n\n```json\n{params_json}\n```"
            
            # ğŸ”„ ä½¿ç”¨ Gemini 2.0 Flash Exp è¿›è¡Œå¿«é€Ÿå‹ç¼©ï¼ˆä¸ç”¨ thinking æ¨¡å‹ï¼‰
            from app.services.gemini import GeminiClient
            gemini = GeminiClient()
            
            response = await gemini.generate(
                prompt=full_prompt,
                response_format="json",
                temperature=0.3,  # ä½æ¸©åº¦ï¼Œä¿è¯ç¡®å®šæ€§è¾“å‡º
                thinking_budget=0,  # ğŸ”§ ç¦ç”¨æ€è€ƒæ¨¡å¼ä»¥ç¡®ä¿å®Œæ•´è¾“å‡º
                return_thinking=False
            )
            
            # ğŸ†• æå– token ä½¿ç”¨ä¿¡æ¯
            # æ³¨æ„ï¼šGemini è¿”å› input_tokens/output_tokensï¼Œéœ€è¦æ˜ å°„åˆ° prompt_tokens/completion_tokens
            token_usage = {}
            if isinstance(response, dict) and "usage" in response:
                usage = response["usage"]
                # Gemini ä½¿ç”¨ input_tokens/output_tokensï¼Œä½†å…¶ä»–åœ°æ–¹ä½¿ç”¨ prompt_tokens/completion_tokens
                input_t = usage.get("input_tokens", 0) or usage.get("prompt_tokens", 0)
                output_t = usage.get("output_tokens", 0) or usage.get("completion_tokens", 0)
                token_usage = {
                    "prompt_tokens": input_t,
                    "completion_tokens": output_t,
                    "total_tokens": usage.get("total_tokens", 0) or (input_t + output_t),
                    "model": "gemini-2.5-flash"
                }
                logger.info(f"ğŸ“Š Compression token usage: input={input_t:,}, output={output_t:,}, total={token_usage['total_tokens']:,}")
            
            # è§£æå‹ç¼©ç»“æœ
            if isinstance(response, dict) and "content" in response:
                content = response["content"]
                
                # content å¯èƒ½æ˜¯ str (JSON string) æˆ– dict (å·²è§£æçš„ JSON)
                if isinstance(content, str):
                    compressed = json.loads(content)
                elif isinstance(content, dict):
                    compressed = content
                else:
                    logger.warning(f"âš ï¸ Unexpected content type: {type(content)}, using fallback")
                    return self._fallback_compression(artifact, artifact_type, topic), {}
                
                original_size = len(json.dumps(artifact, ensure_ascii=False))
                
                # ğŸ†• å°† Gemini è¿”å›çš„ dict è½¬æ¢ä¸º string summary
                # ArtifactRecord.summary å¿…é¡»æ˜¯ string
                if isinstance(compressed, dict):
                    # ä¼˜å…ˆæå– context_summary å­—æ®µ
                    if 'context_summary' in compressed:
                        summary_str = str(compressed['context_summary'])
                    # å¦åˆ™å°è¯•æå–å…³é”®æ‘˜è¦å­—æ®µ
                    elif 'summary' in compressed:
                        summary_str = str(compressed['summary'])
                    elif 'mental_model' in compressed:
                        mental = compressed.get('mental_model', '')
                        key_concepts = compressed.get('key_concepts', [])
                        summary_str = f"[{artifact_type}] {topic}: {mental}. å…³é”®æ¦‚å¿µ: {', '.join(key_concepts[:3])}"
                    else:
                        # å°†æ•´ä¸ª dict è½¬ä¸ºç®€æ´çš„ JSON string
                        summary_str = json.dumps(compressed, ensure_ascii=False)[:300]
                else:
                    summary_str = str(compressed)
                
                compressed_size = len(summary_str)
                compression_ratio = (1 - compressed_size / original_size) * 100 if original_size > 0 else 0
                
                logger.info(f"âœ… LLM compressed {artifact_type}: {original_size} â†’ {compressed_size} chars (-{compression_ratio:.1f}%)")
                return summary_str, token_usage  # ğŸ†• è¿”å› tuple
            else:
                logger.warning("âš ï¸ LLM compression failed, using fallback")
                return self._fallback_compression(artifact, artifact_type, topic), {}
        
        except Exception as e:
            logger.error(f"âŒ Error during LLM compression: {e}")
            return self._fallback_compression(artifact, artifact_type, topic), {}
    
    def _map_artifact_type_to_interaction(self, artifact_type: str) -> str:
        """å°† artifact_type æ˜ å°„åˆ° interaction_type"""
        mapping = {
            "explanation": "explain",
            "quiz_set": "quiz",
            "flashcard_set": "flashcard"
        }
        return mapping.get(artifact_type, "chat")
    
    def _fallback_compression(self, artifact: Dict[str, Any], artifact_type: str, topic: str) -> str:
        """
        Fallback: ç®€å•çš„åŸºäºè§„åˆ™çš„å‹ç¼©ï¼ˆå½“ LLM ä¸å¯ç”¨æ—¶ï¼‰
        
        ğŸ”§ é‡è¦ï¼šè¿”å› string è€Œä¸æ˜¯ dictï¼Œå› ä¸º ArtifactRecord.summary æœŸæœ› string
        """
        if artifact_type == "explanation":
            concept = artifact.get("concept", topic)
            intuition = artifact.get("intuition", "")[:100]
            examples = [ex.get("example", "")[:50] for ex in artifact.get("examples", [])[:2]]
            return f"[æ¦‚å¿µè®²è§£] {concept}: {intuition}... ä¾‹å­: {', '.join(examples)}"
        
        elif artifact_type == "quiz_set":
            questions = artifact.get("questions", [])
            q_summaries = [q.get("question_text", "")[:40] for q in questions[:3]]
            return f"[ç»ƒä¹ é¢˜] {topic}: {len(questions)}é“é¢˜ - {'; '.join(q_summaries)}..."
        
        elif artifact_type == "flashcard_set":
            # å…¼å®¹æ–°æ—§æ ¼å¼ï¼šcardList (æ–°) æˆ– cards (æ—§)
            cards = artifact.get("cardList") or artifact.get("cards", [])
            card_fronts = [c.get("front", "")[:30] for c in cards[:3]]
            return f"[é—ªå¡] {topic}: {len(cards)}å¼  - {'; '.join(card_fronts)}..."
        
        elif artifact_type == "mindmap":
            return f"[æ€ç»´å¯¼å›¾] {topic}: ç»“æ„åŒ–çŸ¥è¯†æ¢³ç†"
        
        elif artifact_type == "notes":
            return f"[ç¬”è®°] {topic}: å­¦ä¹ è¦ç‚¹æ•´ç†"
        
        else:
            return f"[{artifact_type}] {topic}: å­¦ä¹ å†…å®¹"
    
    def get_conversation_session_manager(
        self,
        user_id: str
    ) -> ConversationSessionManager:
        """
        è·å–æˆ–åˆ›å»ºç”¨æˆ·çš„ ConversationSessionManager
        
        ğŸ”’ å¹¶å‘å®‰å…¨ï¼šä½¿ç”¨åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼
        
        Args:
            user_id: ç”¨æˆ·ID
        
        Returns:
            ConversationSessionManager å®ä¾‹
        """
        # ğŸ”’ ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼ˆæ— é”ï¼Œå¿«é€Ÿè·¯å¾„ï¼‰
        if user_id in self._conversation_sessions:
            return self._conversation_sessions[user_id]
        
        # ğŸ”’ éœ€è¦åˆ›å»ºæ–°çš„ session managerï¼Œä½¿ç”¨åŒæ­¥é”ä¿æŠ¤
        import threading
        if not hasattr(self, '_sync_lock'):
            self._sync_lock = threading.Lock()
        
        with self._sync_lock:
            # ğŸ”’ ç¬¬äºŒæ¬¡æ£€æŸ¥ï¼ˆæœ‰é”ï¼Œé˜²æ­¢é‡å¤åˆ›å»ºï¼‰
            if user_id not in self._conversation_sessions:
                # åˆ›å»ºæ–°çš„ session manager
                storage_path = self.artifact_storage.base_dir / user_id
                storage_path.mkdir(parents=True, exist_ok=True)
                
                self._conversation_sessions[user_id] = ConversationSessionManager(
                    user_id=user_id,
                    storage_path=str(storage_path),
                    s3_manager=self.s3_manager,
                    server_start_id=self.get_server_start_id()  # ğŸ†• ä¼ é€’æœåŠ¡å¯åŠ¨ ID
                )
                
                logger.info(f"âœ… Created ConversationSessionManager for {user_id}")
        
        return self._conversation_sessions[user_id]

