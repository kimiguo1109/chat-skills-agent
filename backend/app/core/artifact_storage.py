"""
Artifact Storage - Context Offloading æ ¸å¿ƒæ¨¡å—

è´Ÿè´£å°† Plan Skill çš„ step ç»“æœæŒä¹…åŒ–åˆ°æ–‡ä»¶ç³»ç»Ÿï¼Œ
å®ç°çœŸæ­£çš„ä¸Šä¸‹æ–‡å¸è½½ï¼ˆè€Œä¸æ˜¯å†…å­˜ç´¯ç§¯ï¼‰ã€‚

è®¾è®¡åŸåˆ™ï¼š
- ç‹¬ç«‹æ¨¡å—ï¼Œé›¶ä¾µå…¥
- å®Œå…¨å¯é€‰ï¼Œé»˜è®¤ä¸ä½¿ç”¨
- é™çº§å‹å¥½ï¼Œæ–‡ä»¶æ“ä½œå¤±è´¥æ—¶ä¸å½±å“ä¸»æµç¨‹
"""

import json
import logging
import time
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)


class ArtifactStorage:
    """
    Artifact å­˜å‚¨ç®¡ç†å™¨
    
    èŒè´£ï¼š
    1. ä¿å­˜ step ç»“æœåˆ°æ–‡ä»¶ç³»ç»Ÿ
    2. æŒ‰éœ€åŠ è½½ artifact
    3. åˆ›å»ºè½»é‡çº§å¼•ç”¨ï¼ˆartifact_referenceï¼‰
    4. ç®¡ç† artifact ç”Ÿå‘½å‘¨æœŸ
    
    ä½¿ç”¨åœºæ™¯ï¼š
    - Plan Skill ä¸­çš„ step ç»“æœæŒä¹…åŒ–
    - è·¨ step çš„ä¸Šä¸‹æ–‡ä¼ é€’ï¼ˆé€šè¿‡å¼•ç”¨è€Œä¸æ˜¯å®Œæ•´å†…å®¹ï¼‰
    
    ä¸å½±å“ï¼š
    - Single Skill æ‰§è¡Œï¼ˆå®Œå…¨ç‹¬ç«‹ï¼‰
    - Intent Routerï¼ˆä¸æ¶‰åŠï¼‰
    - Memory Systemï¼ˆä¸åŒå­˜å‚¨ç›®å½•ï¼‰
    """
    
    def __init__(
        self, 
        base_dir: str = "artifacts",
        s3_manager: Optional[Any] = None
    ):
        """
        åˆå§‹åŒ– Artifact Storage
        
        Args:
            base_dir: artifact å­˜å‚¨æ ¹ç›®å½•ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
            s3_manager: S3StorageManager å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        """
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
        # ğŸ†• S3 æ”¯æŒ
        self.s3_manager = s3_manager
        self.use_s3 = s3_manager is not None and s3_manager.is_available()
        
        logger.info(f"âœ… ArtifactStorage initialized: local={self.base_dir.absolute()}, S3={self.use_s3}")
    
    def save_step_result(
        self,
        session_id: str,
        step_id: str,
        result: Dict[str, Any],
        metadata: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ä¿å­˜ step ç»“æœï¼ˆåªä¸Šä¼ åˆ° S3ï¼Œä¸ä¿å­˜æœ¬åœ°ï¼‰
        
        æ³¨æ„ï¼šæ ¹æ®éœ€æ±‚ï¼Œstep_artifact JSON æ–‡ä»¶ä¸éœ€è¦æœ¬åœ°ä¿å­˜ï¼Œ
        å› ä¸ºè¯¦ç»†å†…å®¹å·²ç»åœ¨ MD æ–‡ä»¶ä¸­äº†ã€‚åªä¸Šä¼ åˆ° S3 ç”¨äºäº‘ç«¯å¤‡ä»½ã€‚
        
        Args:
            session_id: Plan æ‰§è¡Œçš„å”¯ä¸€ session ID æˆ– user session ID
            step_id: Step æ ‡è¯†ç¬¦ï¼ˆå¦‚ "explain", "notes", "quiz"ï¼‰
            result: Step æ‰§è¡Œç»“æœï¼ˆå®Œæ•´å†…å®¹ï¼‰
            metadata: å¯é€‰çš„å…ƒæ•°æ®ï¼ˆå¦‚ skill_id, tokens_usedï¼‰
        
        Returns:
            å¼•ç”¨å­—ç¬¦ä¸²ï¼š
            - S3: "s3://bucket/user_xxx/step_001.json"
            - å¦‚æœS3ä¸å¯ç”¨: è¿”å›ç©ºå­—ç¬¦ä¸²ï¼ˆä¸ä¿å­˜æœ¬åœ°ï¼‰
            
        Raises:
            IOError: S3 ä¸Šä¼ å¤±è´¥ä¸”æ— æ³•é™çº§æ—¶
        """
        # ğŸ¯ åªä¸Šä¼ åˆ° S3ï¼Œä¸ä¿å­˜æœ¬åœ°
        if self.use_s3:
            try:
                # æå– user_id
                user_id = self._extract_user_id(session_id)
                
                # ä¸Šä¼ åˆ° S3
                s3_uri = self.s3_manager.save_artifact(
                    user_id=user_id,
                    artifact_id=f"step_{step_id}",
                    content=result,
                    metadata=metadata
                )
                
                if s3_uri:
                    logger.debug(f"ğŸ’¾ Saved to S3: {s3_uri}")
                    return s3_uri
                else:
                    logger.warning("âš ï¸  S3 upload returned None, skipping local storage (as per requirement)")
                    # è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºæœªä¿å­˜ï¼ˆå› ä¸ºä¸éœ€è¦æœ¬åœ°ä¿å­˜ï¼‰
                    return ""
            except Exception as e:
                logger.error(f"âŒ S3 save error: {e}, skipping local storage (as per requirement)")
                # è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºæœªä¿å­˜
                return ""
        
        # S3 ä¸å¯ç”¨æ—¶ï¼Œä¹Ÿä¸ä¿å­˜æœ¬åœ°ï¼ˆæ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼‰
        logger.warning("âš ï¸  S3 not available, skipping step_artifact storage (content already in MD file)")
        return ""
    
    def _extract_user_id(self, session_id: str) -> str:
        """
        ä» session_id æå– user_id
        
        æ”¯æŒçš„æ ¼å¼ï¼š
        - user_{user_id}_{timestamp}: æå– user_id
        - plan_{timestamp}_{uuid}: è¿”å› "anonymous"
        """
        if session_id.startswith("user_"):
            parts = session_id.split("_")
            # user_alice_123456 -> alice
            if len(parts) >= 2:
                return "_".join(parts[1:-1]) if len(parts) > 2 else parts[1]
        return "anonymous"
    
    def load_step_result(
        self,
        session_id: str,
        step_id: str
    ) -> Dict[str, Any]:
        """
        æŒ‰éœ€åŠ è½½ step ç»“æœï¼ˆå®Œæ•´å†…å®¹ï¼‰
        
        Args:
            session_id: Plan æ‰§è¡Œçš„ session ID
            step_id: Step æ ‡è¯†ç¬¦
        
        Returns:
            Step æ‰§è¡Œç»“æœï¼ˆresult å­—æ®µï¼‰
            
        Raises:
            FileNotFoundError: artifact ä¸å­˜åœ¨
            json.JSONDecodeError: JSON è§£æå¤±è´¥
        """
        file_path = self.base_dir / session_id / f"step_{step_id}.json"
        
        if not file_path.exists():
            raise FileNotFoundError(
                f"Artifact not found: {file_path.relative_to(self.base_dir)}"
            )
        
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                artifact = json.load(f)
            
            logger.debug(
                f"ğŸ” Loaded artifact: {session_id}/step_{step_id}.json "
                f"({len(json.dumps(artifact['result'], ensure_ascii=False))} bytes)"
            )
            
            return artifact["result"]
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Failed to parse artifact JSON: {e}")
            raise
    
    def load_artifact_by_reference(
        self,
        reference: str
    ) -> Dict[str, Any]:
        """
        æŒ‰éœ€åŠ è½½ artifactï¼ˆæ”¯æŒ S3 URI æˆ–æœ¬åœ°è·¯å¾„ï¼‰
        
        Args:
            reference: "s3://..." æˆ– "user_xxx/step_001.json"
        
        Returns:
            Artifact å†…å®¹
            
        Raises:
            FileNotFoundError: artifact ä¸å­˜åœ¨
            RuntimeError: S3 ä¸å¯ç”¨ä½†å¼•ç”¨æ˜¯ S3 URI
        """
        # S3 å¼•ç”¨
        if reference.startswith("s3://"):
            if not self.use_s3:
                raise RuntimeError(f"S3 not available, cannot load: {reference}")
            
            content = self.s3_manager.load_artifact(reference)
            if content is None:
                raise FileNotFoundError(f"Artifact not found in S3: {reference}")
            return content
        
        # æœ¬åœ°æ–‡ä»¶å¼•ç”¨
        file_path = self.base_dir / reference
        if not file_path.exists():
            raise FileNotFoundError(f"Artifact not found locally: {file_path}")
        
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                artifact = json.load(f)
            
            logger.debug(f"ğŸ” Loaded artifact from local: {reference}")
            return artifact.get("result", {})
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Failed to parse artifact JSON from {file_path}: {e}")
            raise
        except Exception as e:
            logger.error(f"âŒ Failed to load from {file_path}: {e}")
            raise
    
    def create_reference(
        self,
        session_id: str,
        step_id: str,
        fields: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        åˆ›å»ºè½»é‡çº§ artifact å¼•ç”¨ï¼ˆè€Œä¸æ˜¯ä¼ é€’å®Œæ•´å†…å®¹ï¼‰
        
        è¿™æ˜¯ Context Offloading çš„æ ¸å¿ƒï¼š
        - ä¸ä¼ é€’ 2000+ tokens çš„å®Œæ•´å†…å®¹
        - åªä¼ é€’ ~100 bytes çš„å¼•ç”¨
        - æŒ‰éœ€åŠ è½½ï¼ˆ_format_prompt æ—¶ï¼‰
        
        Args:
            session_id: Plan æ‰§è¡Œçš„ session ID
            step_id: Step æ ‡è¯†ç¬¦
            fields: å¯é€‰çš„å­—æ®µåˆ—è¡¨ï¼ˆåªåŠ è½½è¿™äº›å­—æ®µï¼Œè¿›ä¸€æ­¥èŠ‚çœï¼‰
        
        Returns:
            Artifact å¼•ç”¨å¯¹è±¡ï¼ˆtype="artifact_reference"ï¼‰
        """
        reference = {
            "type": "artifact_reference",
            "session_id": session_id,
            "step_id": step_id,
            "fields": fields,
            "file_path": f"{session_id}/step_{step_id}.json"
        }
        
        reference_size = len(json.dumps(reference, ensure_ascii=False))
        logger.debug(
            f"ğŸ“ Created reference: {step_id} "
            f"({reference_size} bytes, fields: {fields or 'all'})"
        )
        
        return reference
    
    def save_plan_metadata(
        self,
        session_id: str,
        plan_config: Dict[str, Any],
        user_input: Dict[str, Any]
    ) -> str:
        """
        ä¿å­˜ Plan æ•´ä½“å…ƒæ•°æ®
        
        ç”¨äºè¿½æº¯å’Œæ¢å¤ï¼š
        - Plan é…ç½®
        - ç”¨æˆ·è¾“å…¥
        - æ‰§è¡Œæ—¶é—´
        
        Args:
            session_id: Plan æ‰§è¡Œçš„ session ID
            plan_config: Plan é…ç½®ï¼ˆæ¥è‡ª YAMLï¼‰
            user_input: ç”¨æˆ·è¾“å…¥å‚æ•°
        
        Returns:
            metadata æ–‡ä»¶ç›¸å¯¹è·¯å¾„
        """
        try:
            session_dir = self.base_dir / session_id
            session_dir.mkdir(parents=True, exist_ok=True)
            
            file_path = session_dir / "plan_metadata.json"
            
            metadata = {
                "session_id": session_id,
                "timestamp": datetime.now().isoformat(),
                "plan_config": {
                    "skill_id": plan_config.get("id"),
                    "display_name": plan_config.get("display_name"),
                    "steps": [
                        {
                            "step_id": step.get("step_id"),
                            "skill_id": step.get("skill_id"),
                            "name": step.get("name")
                        }
                        for step in plan_config.get("execution_plan", [])
                    ]
                },
                "user_input": user_input
            }
            
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            relative_path = file_path.relative_to(self.base_dir)
            logger.info(f"ğŸ“‹ Saved plan metadata: {relative_path}")
            
            return str(relative_path)
            
        except Exception as e:
            logger.error(f"âŒ Failed to save plan metadata: {e}")
            raise
    
    def load_plan_metadata(self, session_id: str) -> Dict[str, Any]:
        """
        åŠ è½½ Plan å…ƒæ•°æ®
        
        Args:
            session_id: Plan æ‰§è¡Œçš„ session ID
        
        Returns:
            Plan å…ƒæ•°æ®
            
        Raises:
            FileNotFoundError: metadata ä¸å­˜åœ¨
        """
        file_path = self.base_dir / session_id / "plan_metadata.json"
        
        if not file_path.exists():
            raise FileNotFoundError(f"Plan metadata not found: {session_id}")
        
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    
    def cleanup_session(self, session_id: str) -> None:
        """
        æ¸…ç† session çš„æ‰€æœ‰ artifactsï¼ˆå¯é€‰ï¼‰
        
        Args:
            session_id: Plan æ‰§è¡Œçš„ session ID
        """
        session_dir = self.base_dir / session_id
        
        if not session_dir.exists():
            logger.warning(f"âš ï¸  Session dir not found: {session_id}")
            return
        
        try:
            import shutil
            shutil.rmtree(session_dir)
            logger.info(f"ğŸ—‘ï¸  Cleaned up session: {session_id}")
        except Exception as e:
            logger.error(f"âŒ Failed to cleanup session {session_id}: {e}")
    
    def list_sessions(self) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºæ‰€æœ‰ sessionï¼ˆç”¨äºè°ƒè¯•å’Œç®¡ç†ï¼‰
        
        Returns:
            Session åˆ—è¡¨ï¼ˆåŒ…å« session_id, timestamp, step_countï¼‰
        """
        sessions = []
        
        for session_dir in self.base_dir.iterdir():
            if not session_dir.is_dir():
                continue
            
            session_id = session_dir.name
            
            try:
                # è¯»å– metadata
                metadata = self.load_plan_metadata(session_id)
                
                # ç»Ÿè®¡ step æ•°é‡
                step_files = list(session_dir.glob("step_*.json"))
                
                sessions.append({
                    "session_id": session_id,
                    "timestamp": metadata.get("timestamp"),
                    "step_count": len(step_files),
                    "plan_name": metadata.get("plan_config", {}).get("display_name")
                })
            except Exception as e:
                logger.warning(f"âš ï¸  Failed to load session {session_id}: {e}")
        
        return sessions


def generate_session_id() -> str:
    """
    ç”Ÿæˆå”¯ä¸€çš„ session ID
    
    æ ¼å¼: plan_{timestamp}_{uuid}
    
    Returns:
        Session ID å­—ç¬¦ä¸²
    """
    timestamp = int(time.time())
    unique_id = uuid.uuid4().hex[:8]
    return f"plan_{timestamp}_{unique_id}"

