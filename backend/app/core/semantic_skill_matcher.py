"""
Semantic Skill Matcher - åŸºäº Embedding çš„è¯­ä¹‰æŠ€èƒ½åŒ¹é…å™¨

ä½¿ç”¨ Sentence Transformers è¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ï¼Œè§£å†³å…³é”®è¯åŒ¹é…çš„å±€é™æ€§ï¼š
1. ç†è§£è¯­ä¹‰è€Œéè¡¨é¢è¯æ±‡
2. æ”¯æŒå¤šè¯­è¨€ï¼ˆä¸­è‹±æ—¥éŸ©ç­‰ï¼‰
3. å¯¹ç”¨æˆ·è¡¨è¾¾æ–¹å¼çš„å˜åŒ–æ›´é²æ£’
4. 0-token åŒ¹é…ï¼ˆæœ¬åœ°è®¡ç®—ï¼‰

æ ¸å¿ƒæ€è·¯ï¼š
- é¢„å®šä¹‰æ¯ä¸ªæŠ€èƒ½çš„è¯­ä¹‰æè¿°ï¼ˆæ­£ä¾‹ + åä¾‹ï¼‰
- å°†ç”¨æˆ·æ¶ˆæ¯ç¼–ç ä¸ºå‘é‡
- è®¡ç®—ä¸å„æŠ€èƒ½æè¿°çš„ç›¸ä¼¼åº¦
- è¿”å›æœ€ä½³åŒ¹é…

Author: AI Agent
Date: 2025-12-19
"""

import logging
import os
import json
import hashlib
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
import numpy as np

logger = logging.getLogger(__name__)

# å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹
_model = None
_model_name = "paraphrase-multilingual-MiniLM-L12-v2"


def get_embedding_model():
    """å»¶è¿ŸåŠ è½½ Embedding æ¨¡å‹"""
    global _model
    if _model is None:
        try:
            from sentence_transformers import SentenceTransformer
            logger.info(f"ğŸ”„ Loading embedding model: {_model_name}")
            _model = SentenceTransformer(_model_name)
            logger.info(f"âœ… Embedding model loaded successfully")
        except ImportError:
            logger.warning("âš ï¸ sentence-transformers not installed, semantic matching disabled")
            return None
        except Exception as e:
            logger.error(f"âŒ Failed to load embedding model: {e}")
            return None
    return _model


@dataclass
class SemanticMatch:
    """è¯­ä¹‰åŒ¹é…ç»“æœ"""
    skill_id: str
    confidence: float
    matched_description: str
    is_negative_match: bool = False  # æ˜¯å¦åŒ¹é…åˆ°åä¾‹


class SemanticSkillMatcher:
    """
    åŸºäºè¯­ä¹‰å‘é‡çš„æŠ€èƒ½åŒ¹é…å™¨
    
    ç‰¹ç‚¹ï¼š
    1. ä½¿ç”¨å¤šè¯­è¨€ Sentence Transformer æ¨¡å‹
    2. é¢„è®¡ç®—æŠ€èƒ½æè¿°çš„å‘é‡ï¼ˆç¼“å­˜ï¼‰
    3. æ”¯æŒæ­£ä¾‹å’Œåä¾‹åŒ¹é…
    4. ç½®ä¿¡åº¦é˜ˆå€¼æ§åˆ¶
    """
    
    # ğŸ”¥ æ ¸å¿ƒï¼šæŠ€èƒ½çš„è¯­ä¹‰æè¿°
    # æ¯ä¸ªæŠ€èƒ½æœ‰æ­£ä¾‹ï¼ˆåº”è¯¥åŒ¹é…ï¼‰å’Œåä¾‹ï¼ˆä¸åº”è¯¥åŒ¹é…ï¼‰
    SKILL_DESCRIPTIONS = {
        "quiz": {
            "positive": [
                # ä¸­æ–‡æ­£ä¾‹
                "ç»™æˆ‘å‡ºå‡ é“ç»ƒä¹ é¢˜",
                "å¸®æˆ‘å‡º3é“å…³äºå…‰åˆä½œç”¨çš„é€‰æ‹©é¢˜",
                "å‡ºä¸¤é“ç‰›é¡¿å®šå¾‹çš„æµ‹éªŒé¢˜",
                "åšä¸€äº›ç»ƒä¹ é¢˜æ¥æµ‹è¯•æˆ‘",
                "ç”Ÿæˆ5é“è€ƒè¯•é¢˜",
                "å¸®æˆ‘åšå‡ é“é¢˜ç›®",
                "å‡ºé¢˜æµ‹è¯•ä¸€ä¸‹",
                "æ¥å‡ é“ç»ƒä¹ ",
                "ç»™æˆ‘ä¸€äº›æµ‹éªŒé¢˜",
                "å¸®æˆ‘å‡ºå‡ é“é€‰æ‹©é¢˜",
                # è‹±æ–‡æ­£ä¾‹
                "Generate practice questions about photosynthesis",
                "Give me 3 quiz questions on Newton's laws",
                "Create some test questions for me",
                "Make a quiz about DNA",
                "I want some practice problems",
                "Generate exercises for this topic",
            ],
            "negative": [
                # ä¸åº”è¯¥åŒ¹é…ä¸º quiz çš„æ¶ˆæ¯
                "å­¦ç”Ÿé€šå¸¸åœ¨è¿™ç±»é—®é¢˜ä¸­çŠ¯ä»€ä¹ˆé”™è¯¯",
                "è¿™ä¸ªé—®é¢˜æ€ä¹ˆè§£",
                "è¿™é“é¢˜çš„ç­”æ¡ˆæ˜¯ä»€ä¹ˆ",
                "è¿™ç±»é—®é¢˜æœ‰ä»€ä¹ˆæŠ€å·§",
                "å…³äºè¿™ä¸ªé—®é¢˜æˆ‘æœ‰ç–‘é—®",
                "What mistakes do students make on this problem",
                "How to solve this question",
                "What is the answer to this problem",
            ],
            "weight": 1.0,  # æƒé‡ï¼ˆå¯è°ƒæ•´ä¼˜å…ˆçº§ï¼‰
        },
        
        "flashcard": {
            "positive": [
                # ä¸­æ–‡æ­£ä¾‹
                "å¸®æˆ‘åšå‡ å¼ é—ªå¡",
                "ç”Ÿæˆ3å¼ å…³äºåŒ–å­¦é”®çš„è®°å¿†å¡",
                "åš5å¼ å•è¯å¡ç‰‡",
                "å¸®æˆ‘åˆ¶ä½œé—ªå¡æ¥å¤ä¹ ",
                "ç”Ÿæˆä¸€äº›èƒŒè¯µå¡",
                "åšå‡ å¼ å¤ä¹ å¡ç‰‡",
                "å¸®æˆ‘åšæŠ½è®¤å¡",
                "ç”Ÿæˆå…³äºDNAçš„è®°å¿†å¡",  # ğŸ†•
                "ç»™æˆ‘åšå‡ å¼ å¡ç‰‡",  # ğŸ†•
                "æ¥å‡ å¼ é—ªå¡",  # ğŸ†•
                "åˆ¶ä½œè®°å¿†å¡",  # ğŸ†•
                # è‹±æ–‡æ­£ä¾‹
                "Create flashcards for vocabulary",
                "Make 5 flash cards about chemistry",
                "Generate memory cards for studying",
                "I need some flashcards to review",
                "Create study cards for me",
                "Generate memory cards about DNA",  # ğŸ†•
            ],
            "negative": [
                "è¿™å¼ å¡ç‰‡ä¸Šå†™çš„æ˜¯ä»€ä¹ˆ",
                "å¡ç‰‡çš„å†…å®¹æ˜¯ä»€ä¹ˆæ„æ€",
                "What does this card say",
                "è§£é‡Šè¿™ä¸ªæ¦‚å¿µ",  # ğŸ†• é˜²æ­¢ä¸ explain æ··æ·†
                "è®²è§£ä¸€ä¸‹",  # ğŸ†•
            ],
            "weight": 1.1,  # ğŸ†• ç•¥å¾®æé«˜æƒé‡
        },
        
        "explain": {
            "positive": [
                # ä¸­æ–‡æ­£ä¾‹
                "è¯¦ç»†è®²è§£ä¸€ä¸‹å…‰åˆä½œç”¨",
                "è§£é‡Šä»€ä¹ˆæ˜¯ç‰›é¡¿ç¬¬äºŒå®šå¾‹",
                "å¸®æˆ‘ç†è§£ç»†èƒå‘¼å¸",
                "è®²ä¸€è®²è¿™ä¸ªæ¦‚å¿µ",
                "æ•™æˆ‘DNAçš„ç»“æ„",
                "ç§‘æ™®ä¸€ä¸‹é‡å­åŠ›å­¦",
                "ç»™æˆ‘ä»‹ç»ä¸€ä¸‹è¿™ä¸ªçŸ¥è¯†ç‚¹",
                "è§£è¯»ä¸€ä¸‹è¿™ä¸ªå®šç†",
                # è‹±æ–‡æ­£ä¾‹
                "Explain photosynthesis in detail",
                "What is Newton's second law",
                "Help me understand cell respiration",
                "Teach me about DNA structure",
                "Explain this concept to me",
            ],
            "negative": [
                "å‡ºå‡ é“é¢˜æ¥æµ‹è¯•è¿™ä¸ªæ¦‚å¿µ",
                "åšå‡ å¼ é—ªå¡",
                "Generate questions about this",
            ],
            "weight": 1.0,
        },
        
        "notes": {
            "positive": [
                # ä¸­æ–‡æ­£ä¾‹
                "å¸®æˆ‘åšç¬”è®°",
                "æ•´ç†è¿™ä¸ªç« èŠ‚çš„è¦ç‚¹",
                "æ€»ç»“ä¸€ä¸‹è¿™äº›å†…å®¹",
                "å½’çº³è¿™ä¸ªä¸»é¢˜",
                "å¸®æˆ‘æ¢³ç†çŸ¥è¯†ç‚¹",
                "æç‚¼é‡ç‚¹",
                # è‹±æ–‡æ­£ä¾‹
                "Take notes on this topic",
                "Summarize the key points",
                "Outline this chapter",
                "Create a summary for me",
            ],
            "negative": [],
            "weight": 0.9,
        },
        
        "mindmap": {
            "positive": [
                # ä¸­æ–‡æ­£ä¾‹
                "ç”»ä¸€å¼ æ€ç»´å¯¼å›¾",
                "ç”ŸæˆçŸ¥è¯†å›¾è°±",
                "åšä¸€ä¸ªæ¦‚å¿µå›¾",
                "å¸®æˆ‘åšè„‘å›¾",
                "ç”»ç»“æ„å›¾",
                # è‹±æ–‡æ­£ä¾‹
                "Create a mind map",
                "Generate a concept map",
                "Make a knowledge graph",
                "Draw a structure diagram",
            ],
            "negative": [],
            "weight": 0.9,
        },
        
        "learning_bundle": {
            "positive": [
                # ä¸­æ–‡æ­£ä¾‹
                "å¸®æˆ‘åˆ¶å®šå­¦ä¹ è®¡åˆ’",
                "ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å­¦ä¹ åŒ…",
                "åšä¸€å¥—å­¦ä¹ èµ„æ–™",
                "å¸®æˆ‘è§„åˆ’å­¦ä¹ è·¯çº¿",
                "å…ˆè®²è§£å†å‡ºé¢˜",
                "è®²è§£+é—ªå¡+æµ‹éªŒ",
                "ç»™æˆ‘ä¸€å¥—å®Œæ•´çš„å­¦ä¹ ææ–™",  # ğŸ†•
                "åŒ…å«é—ªå¡å’Œæµ‹éªŒçš„å­¦ä¹ åŒ…",  # ğŸ†•
                # è‹±æ–‡æ­£ä¾‹
                "Create a study plan",
                "Generate a learning bundle",
                "Make a complete study package",
                "Plan my learning path",
                "Give me a complete study set",  # ğŸ†•
            ],
            "negative": [
                # ğŸ†• ç®€å•çš„ç»§ç»­/å¯¹è¯ä¸åº”è¯¥åŒ¹é…
                "ç»§ç»­è®²",
                "ç»§ç»­",
                "ç„¶åå‘¢",
                "æ¥ç€è®²",
                "Go on",
                "Continue",
            ],
            "weight": 0.9,
        },
        
        "other": {
            "positive": [
                # ä¸­æ–‡æ­£ä¾‹ - å¯¹è¯/è®¨è®ºç±»
                "å­¦ç”Ÿé€šå¸¸åœ¨è¿™ç±»é—®é¢˜ä¸­çŠ¯ä»€ä¹ˆé”™è¯¯",
                "è¿™ä¸ªé—®é¢˜æœ‰å“ªäº›å¸¸è§è¯¯åŒº",
                "è¿™é“é¢˜æ€ä¹ˆè§£",
                "ç­”æ¡ˆæ˜¯ä»€ä¹ˆ",
                "èƒ½ä¸¾ä¸ªä¾‹å­å—",
                "ç»§ç»­è®²",
                "ç»§ç»­",  # ğŸ†•
                "ç„¶åå‘¢",  # ğŸ†•
                "æ¥ç€è®²",  # ğŸ†•
                "å†è¯´è¯´",  # ğŸ†•
                "ä½ å¥½",
                "è°¢è°¢",
                "æˆ‘æƒ³å­¦ä¹ ç‰©ç†",
                "å¸®æˆ‘è§£ç­”è¿™é“é¢˜",
                "è¿™ä¸ªå…¬å¼æ€ä¹ˆç”¨",
                "æœ‰ä»€ä¹ˆæŠ€å·§",
                "ä¸ºä»€ä¹ˆæ˜¯è¿™æ ·",
                "å¥½çš„",  # ğŸ†•
                "æ˜ç™½äº†",  # ğŸ†•
                "æ‡‚äº†",  # ğŸ†•
                # è‹±æ–‡æ­£ä¾‹
                "What mistakes do students make",
                "How to solve this problem",
                "What is the answer",
                "Can you give an example",
                "Continue please",
                "Go on",  # ğŸ†•
                "Then what",  # ğŸ†•
                "Hello",
                "Thanks",
                "I want to learn physics",
                "Help me solve this",
                "How to use this formula",
                "I see",  # ğŸ†•
                "Got it",  # ğŸ†•
            ],
            "negative": [
                # æ˜ç¡®çš„æŠ€èƒ½è¯·æ±‚ä¸åº”è¯¥åŒ¹é…ä¸º other
                "å‡ºå‡ é“é¢˜",
                "åšå‡ å¼ é—ªå¡",
                "è¯¦ç»†è®²è§£å…‰åˆä½œç”¨",  # ğŸ†• æ³¨æ„ï¼šéœ€è¦æœ‰å…·ä½“ä¸»é¢˜æ‰æ˜¯æ˜ç¡®çš„è®²è§£è¯·æ±‚
                "Generate questions",
                "Create flashcards",
                "å¸®æˆ‘åˆ¶å®šå­¦ä¹ è®¡åˆ’",  # ğŸ†•
                "åšä¸€ä¸ªå­¦ä¹ åŒ…",  # ğŸ†•
            ],
            "weight": 0.85,  # ğŸ†• ç•¥å¾®æé«˜æƒé‡
        },
    }
    
    def __init__(self, cache_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–è¯­ä¹‰åŒ¹é…å™¨
        
        Args:
            cache_dir: å‘é‡ç¼“å­˜ç›®å½•
        """
        self.model = None
        self._embeddings_cache: Dict[str, np.ndarray] = {}
        self._initialized = False
        
        # ç¼“å­˜ç›®å½•
        if cache_dir is None:
            base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
            cache_dir = os.path.join(base_dir, ".embedding_cache")
        self.cache_dir = cache_dir
        
        # é¢„è®¡ç®—çš„æŠ€èƒ½å‘é‡
        self._skill_embeddings: Dict[str, Dict[str, np.ndarray]] = {}
        
    def initialize(self) -> bool:
        """
        åˆå§‹åŒ–æ¨¡å‹å’Œé¢„è®¡ç®—å‘é‡
        
        Returns:
            æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
        """
        if self._initialized:
            return True
            
        self.model = get_embedding_model()
        if self.model is None:
            logger.warning("âš ï¸ Semantic matcher disabled: model not available")
            return False
        
        # é¢„è®¡ç®—æŠ€èƒ½æè¿°çš„å‘é‡
        logger.info("ğŸ”„ Pre-computing skill description embeddings...")
        
        for skill_id, descriptions in self.SKILL_DESCRIPTIONS.items():
            self._skill_embeddings[skill_id] = {
                "positive": self._encode_texts(descriptions["positive"]),
                "negative": self._encode_texts(descriptions.get("negative", [])),
                "weight": descriptions.get("weight", 1.0),
            }
        
        logger.info(f"âœ… Semantic matcher initialized with {len(self._skill_embeddings)} skills")
        self._initialized = True
        return True
    
    def _encode_texts(self, texts: List[str]) -> Optional[np.ndarray]:
        """ç¼–ç æ–‡æœ¬åˆ—è¡¨ä¸ºå‘é‡"""
        if not texts or self.model is None:
            return None
        return self.model.encode(texts, convert_to_numpy=True)
    
    def _compute_similarity(self, query_embedding: np.ndarray, target_embeddings: np.ndarray) -> float:
        """è®¡ç®—æŸ¥è¯¢å‘é‡ä¸ç›®æ ‡å‘é‡ç»„çš„æœ€å¤§ç›¸ä¼¼åº¦"""
        if target_embeddings is None or len(target_embeddings) == 0:
            return 0.0
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = np.dot(target_embeddings, query_embedding) / (
            np.linalg.norm(target_embeddings, axis=1) * np.linalg.norm(query_embedding) + 1e-8
        )
        return float(np.max(similarities))
    
    def match(
        self, 
        message: str, 
        threshold: float = 0.65,  # ğŸ†• æé«˜é˜ˆå€¼ï¼Œæ›´ä¸¥æ ¼
        negative_threshold: float = 0.6,  # ğŸ†• é™ä½åå‘é˜ˆå€¼ï¼Œæ›´å®¹æ˜“æ’é™¤
        confidence_gap: float = 0.15  # ğŸ†• æœ€é«˜åˆ†å’Œæ¬¡é«˜åˆ†çš„å·®è·è¦æ±‚
    ) -> Optional[SemanticMatch]:
        """
        è¯­ä¹‰åŒ¹é…ç”¨æˆ·æ¶ˆæ¯åˆ°æŠ€èƒ½
        
        ğŸ†• ä¸¥æ ¼åŒ¹é…ç­–ç•¥ï¼š
        1. æé«˜æ­£å‘é˜ˆå€¼åˆ° 0.65ï¼ˆä¹‹å‰ 0.5ï¼‰
        2. é™ä½åå‘é˜ˆå€¼åˆ° 0.6ï¼ˆæ›´å®¹æ˜“æ’é™¤ï¼‰
        3. è¦æ±‚æœ€é«˜åˆ†å’Œæ¬¡é«˜åˆ†æœ‰æ˜æ˜¾å·®è·ï¼ˆ0.15ï¼‰
        4. å¯¹äºä¸ç¡®å®šçš„æƒ…å†µï¼Œè¿”å› None è®© LLM å¤„ç†
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            threshold: æ­£å‘åŒ¹é…é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œæ›´é«˜ = æ›´ä¸¥æ ¼
            negative_threshold: åå‘åŒ¹é…é˜ˆå€¼ï¼ˆé«˜äºæ­¤å€¼æ—¶æ’é™¤ï¼‰
            confidence_gap: æœ€é«˜åˆ†å’Œæ¬¡é«˜åˆ†çš„æœ€å°å·®è·
            
        Returns:
            SemanticMatch æˆ– Noneï¼ˆä¸ç¡®å®šæ—¶è¿”å› Noneï¼‰
        """
        if not self._initialized:
            if not self.initialize():
                return None
        
        # ç¼–ç ç”¨æˆ·æ¶ˆæ¯
        query_embedding = self.model.encode([message], convert_to_numpy=True)[0]
        
        # è®¡ç®—ä¸å„æŠ€èƒ½çš„ç›¸ä¼¼åº¦
        results: List[Tuple[str, float, float, str]] = []  # (skill_id, positive_score, negative_score, best_desc)
        
        for skill_id, embeddings in self._skill_embeddings.items():
            positive_emb = embeddings["positive"]
            negative_emb = embeddings["negative"]
            weight = embeddings["weight"]
            
            # è®¡ç®—æ­£å‘ç›¸ä¼¼åº¦
            positive_score = self._compute_similarity(query_embedding, positive_emb) * weight
            
            # è®¡ç®—åå‘ç›¸ä¼¼åº¦ï¼ˆå¦‚æœæœ‰åä¾‹ï¼‰
            negative_score = 0.0
            if negative_emb is not None and len(negative_emb) > 0:
                negative_score = self._compute_similarity(query_embedding, negative_emb)
            
            results.append((skill_id, positive_score, negative_score, ""))
        
        # æ’åºï¼šä¼˜å…ˆæ­£å‘åˆ†æ•°é«˜ï¼ŒåŒæ—¶æ’é™¤åå‘åˆ†æ•°é«˜çš„
        results.sort(key=lambda x: x[1], reverse=True)
        
        best_skill, best_positive, best_negative, _ = results[0]
        second_skill, second_positive, second_negative, _ = results[1] if len(results) > 1 else (None, 0, 0, "")
        
        # æ—¥å¿—
        logger.info(f"ğŸ” Semantic matching: '{message[:50]}...'")
        for skill_id, pos, neg, _ in results[:3]:
            logger.info(f"   â€¢ {skill_id}: positive={pos:.3f}, negative={neg:.3f}")
        
        # ğŸ†• ä¸¥æ ¼æ£€æŸ¥ 1: æœ€é«˜åˆ†å¿…é¡»è¶…è¿‡é˜ˆå€¼
        if best_positive < threshold:
            logger.info(f"âš ï¸ No confident match: best={best_skill}({best_positive:.3f}) < threshold({threshold})")
            return None
        
        # ğŸ†• ä¸¥æ ¼æ£€æŸ¥ 2: æœ€é«˜åˆ†å’Œæ¬¡é«˜åˆ†è¦æœ‰æ˜æ˜¾å·®è·
        score_gap = best_positive - second_positive
        if score_gap < confidence_gap and best_skill != "other":
            logger.info(f"âš ï¸ Ambiguous match: gap={score_gap:.3f} < {confidence_gap} between {best_skill} and {second_skill}")
            # ğŸ†• å¦‚æœå·®è·ä¸å¤Ÿï¼Œä¸”æœ€ä½³ä¸æ˜¯ otherï¼Œè¿”å› None è®© LLM å†³å®š
            return None
        
        # ğŸ†• ä¸¥æ ¼æ£€æŸ¥ 3: æ£€æŸ¥åå‘åŒ¹é…
        if best_negative > negative_threshold:
            logger.info(f"âš ï¸ Rejected {best_skill}: negative score {best_negative:.3f} > {negative_threshold}")
            return None
        
        # ğŸ†• ä¸¥æ ¼æ£€æŸ¥ 4: æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æŠ€èƒ½çš„å¼ºåå‘åŒ¹é…
        for skill_id, pos, neg, _ in results:
            if skill_id == best_skill:
                continue
            if neg > negative_threshold:
                logger.info(f"âš ï¸ Strong negative match for {skill_id}: {neg:.3f}")
        
        # ğŸ†• ä¸¥æ ¼æ£€æŸ¥ 5: å¦‚æœæœ€ä½³åŒ¹é…æ˜¯é other çš„ç”ŸæˆæŠ€èƒ½ï¼Œä½†åˆ†æ•°ä¸å¤Ÿé«˜ï¼ˆ<0.75ï¼‰ï¼Œä¹Ÿè¿”å› None
        generation_skills = {"quiz", "flashcard", "explain", "notes", "mindmap", "learning_bundle"}
        if best_skill in generation_skills and best_positive < 0.75:
            logger.info(f"âš ï¸ Generation skill {best_skill} needs higher confidence: {best_positive:.3f} < 0.75")
            return None
        
        logger.info(f"âœ… Confident match: {best_skill} (score={best_positive:.3f}, gap={score_gap:.3f})")
        return SemanticMatch(
            skill_id=best_skill,
            confidence=best_positive,
            matched_description="",
        )
    
    def get_all_scores(self, message: str) -> Dict[str, float]:
        """è·å–æ¶ˆæ¯ä¸æ‰€æœ‰æŠ€èƒ½çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        if not self._initialized:
            if not self.initialize():
                return {}
        
        query_embedding = self.model.encode([message], convert_to_numpy=True)[0]
        
        scores = {}
        for skill_id, embeddings in self._skill_embeddings.items():
            positive_emb = embeddings["positive"]
            weight = embeddings["weight"]
            scores[skill_id] = self._compute_similarity(query_embedding, positive_emb) * weight
        
        return scores


# å…¨å±€å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰
_semantic_matcher: Optional[SemanticSkillMatcher] = None


def get_semantic_matcher() -> Optional[SemanticSkillMatcher]:
    """è·å–å…¨å±€è¯­ä¹‰åŒ¹é…å™¨å®ä¾‹"""
    global _semantic_matcher
    if _semantic_matcher is None:
        _semantic_matcher = SemanticSkillMatcher()
    return _semantic_matcher


