"""
Skill Registry - æŠ€èƒ½æ³¨å†Œè¡¨

è´Ÿè´£åŠ è½½ã€ç®¡ç†å’ŒæŸ¥è¯¢æ‰€æœ‰å¯ç”¨çš„ Skillsã€‚
ä» YAML é…ç½®æ–‡ä»¶å’Œ skill.md å…ƒæ•°æ®ä¸­åŠ è½½ Skill å®šä¹‰ã€‚

Phase 4: å®ç° 0-token æ„å›¾åŒ¹é…åŠŸèƒ½
"""
import logging
import os
import re
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
import yaml

from ..models.skill import SkillDefinition
from ..config import settings

logger = logging.getLogger(__name__)


@dataclass
class SkillMatch:
    """æŠ€èƒ½åŒ¹é…ç»“æœ"""
    skill_id: str
    confidence: float
    parameters: Dict[str, Any]
    matched_keywords: List[str]


class SkillRegistry:
    """æŠ€èƒ½æ³¨å†Œè¡¨ - ç®¡ç†æ‰€æœ‰å¯ç”¨çš„ Skills"""
    
    def __init__(self, config_dir: Optional[str] = None):
        """
        åˆå§‹åŒ– Skill Registry
        
        Args:
            config_dir: Skills é…ç½®æ–‡ä»¶ç›®å½•ï¼ˆé»˜è®¤ä¸º skills_config/ï¼‰
        """
        if config_dir is None:
            # é»˜è®¤é…ç½®ç›®å½•åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ skills_config/
            base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
            config_dir = os.path.join(base_dir, "skills_config")
            self.skills_metadata_dir = os.path.join(base_dir, "skills")
        else:
            self.skills_metadata_dir = os.path.join(os.path.dirname(config_dir), "skills")
        
        self.config_dir = config_dir
        self._skills: Dict[str, SkillDefinition] = {}
        self._intent_map: Dict[str, List[str]] = {}  # intent -> [skill_ids]
        
        # ğŸ†• Phase 4: åŠ è½½ skill.md å…ƒæ•°æ®
        self._skill_metadata: Dict[str, Dict[str, Any]] = {}  # skill_id -> metadata
        
        # åŠ è½½æ‰€æœ‰ skills
        self._load_skills()
        
        # ğŸ†• åŠ è½½ skill.md å…ƒæ•°æ®ï¼ˆç”¨äº 0-token åŒ¹é…ï¼‰
        self._load_skill_metadata()
        
        logger.info(f"âœ… SkillRegistry initialized with {len(self._skills)} skills ({len(self._skill_metadata)} with metadata)")
    
    def _load_skills(self):
        """ä»é…ç½®ç›®å½•åŠ è½½æ‰€æœ‰ Skill å®šä¹‰"""
        if not os.path.exists(self.config_dir):
            logger.warning(f"Skills config directory not found: {self.config_dir}")
            return
        
        yaml_files = [f for f in os.listdir(self.config_dir) if f.endswith('.yaml') or f.endswith('.yml')]
        
        for filename in yaml_files:
            filepath = os.path.join(self.config_dir, filename)
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                
                # ä½¿ç”¨ Pydantic æ¨¡å‹éªŒè¯
                skill_def = SkillDefinition(**config)
                
                # ğŸ†• ä¿å­˜åŸå§‹é…ç½®
                skill_def.raw_config = config
                
                # æ³¨å†Œ skill
                self._skills[skill_def.id] = skill_def
                
                # å»ºç«‹ intent æ˜ å°„
                for intent_tag in skill_def.intent_tags:
                    if intent_tag not in self._intent_map:
                        self._intent_map[intent_tag] = []
                    self._intent_map[intent_tag].append(skill_def.id)
                
                logger.info(f"âœ… Loaded skill: {skill_def.id} ({skill_def.display_name})")
            
            except Exception as e:
                logger.error(f"âŒ Failed to load skill from {filename}: {e}")
    
    def get_skill(self, skill_id: str) -> Optional[SkillDefinition]:
        """
        æ ¹æ® ID è·å– Skill å®šä¹‰
        
        Args:
            skill_id: Skill ID
        
        Returns:
            SkillDefinition æˆ– Noneï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        """
        return self._skills.get(skill_id)
    
    def get_skills_by_intent(self, intent: str) -> List[SkillDefinition]:
        """
        æ ¹æ®æ„å›¾è·å–åŒ¹é…çš„ Skills
        
        Args:
            intent: ç”¨æˆ·æ„å›¾æ ‡ç­¾
        
        Returns:
            åŒ¹é…çš„ Skill å®šä¹‰åˆ—è¡¨
        """
        skill_ids = self._intent_map.get(intent, [])
        return [self._skills[sid] for sid in skill_ids if sid in self._skills]
    
    def list_all_skills(self) -> List[SkillDefinition]:
        """
        åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„ Skills
        
        Returns:
            æ‰€æœ‰ Skill å®šä¹‰çš„åˆ—è¡¨
        """
        return list(self._skills.values())
    
    def get_skill_ids(self) -> List[str]:
        """
        è·å–æ‰€æœ‰ Skill ID
        
        Returns:
            Skill ID åˆ—è¡¨
        """
        return list(self._skills.keys())
    
    def get_all_intents(self) -> List[str]:
        """
        è·å–æ‰€æœ‰æ”¯æŒçš„æ„å›¾æ ‡ç­¾
        
        Returns:
            æ„å›¾æ ‡ç­¾åˆ—è¡¨
        """
        return list(self._intent_map.keys())
    
    def validate_skill_dependencies(self, skill_id: str) -> bool:
        """
        éªŒè¯ Skill çš„ä¾èµ–æ˜¯å¦éƒ½å·²æ³¨å†Œ
        
        Args:
            skill_id: Skill ID
        
        Returns:
            True å¦‚æœæ‰€æœ‰ä¾èµ–éƒ½æ»¡è¶³ï¼Œå¦åˆ™ False
        """
        skill = self.get_skill(skill_id)
        if not skill:
            return False
        
        for dep_id in skill.dependencies:
            if dep_id not in self._skills:
                logger.warning(f"âš ï¸  Skill {skill_id} depends on {dep_id}, but it's not registered")
                return False
        
        return True
    
    def get_composable_skills(self) -> List[SkillDefinition]:
        """
        è·å–æ‰€æœ‰å¯ç»„åˆçš„ Skills
        
        Returns:
            å¯ç»„åˆçš„ Skill åˆ—è¡¨
        """
        return [skill for skill in self._skills.values() if skill.composable]
    
    # ==================== Phase 4: 0-Token Matching ====================
    
    def _load_skill_metadata(self):
        """
        åŠ è½½æ‰€æœ‰ skill.md å…ƒæ•°æ®æ–‡ä»¶
        ç”¨äº 0-token æ„å›¾åŒ¹é…
        """
        if not os.path.exists(self.skills_metadata_dir):
            logger.warning(f"Skills metadata directory not found: {self.skills_metadata_dir}")
            return
        
        for skill_dir in os.listdir(self.skills_metadata_dir):
            skill_path = os.path.join(self.skills_metadata_dir, skill_dir)
            if not os.path.isdir(skill_path):
                continue
            
            skill_md_path = os.path.join(skill_path, "skill.md")
            if not os.path.exists(skill_md_path):
                logger.debug(f"No skill.md found for {skill_dir}")
                continue
            
            try:
                metadata = self._parse_skill_md(skill_md_path)
                skill_id = metadata.get("id", skill_dir)
                self._skill_metadata[skill_id] = metadata
                logger.info(f"âœ… Loaded metadata for: {skill_id}")
            except Exception as e:
                logger.error(f"âŒ Failed to load metadata from {skill_md_path}: {e}")
    
    def _parse_skill_md(self, filepath: str) -> Dict[str, Any]:
        """
        è§£æ skill.md æ–‡ä»¶ï¼Œæå–æ„å›¾è§¦å‘è§„åˆ™
        
        Returns:
            metadata dict with:
                - id: skill_id
                - primary_keywords: List[str]
                - quantity_patterns: List[str]
                - topic_patterns: List[str]
                - context_patterns: List[str]
        """
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        metadata = {}
        
        # æå– Skill ID
        id_match = re.search(r'\*\*æŠ€èƒ½ID\*\*:\s*`(.+?)`', content)
        if id_match:
            metadata['id'] = id_match.group(1)
        
        # æå– Primary Keywords
        keywords_section = re.search(
            r'### Primary Keywords.*?```\n(.*?)\n```',
            content,
            re.DOTALL
        )
        if keywords_section:
            keywords_text = keywords_section.group(1).strip()
            # åˆ†å‰²å¹¶æ¸…ç†å…³é”®è¯ï¼ˆæ”¯æŒé€—å·åˆ†éš”ï¼‰
            keywords = [kw.strip() for kw in re.split(r'[,ï¼Œ\s]+', keywords_text) if kw.strip()]
            metadata['primary_keywords'] = keywords
        else:
            metadata['primary_keywords'] = []
        
        # æå– Quantity Patterns
        quantity_section = re.search(
            r'### Quantity Patterns.*?```(?:regex)?\n(.*?)\n```',
            content,
            re.DOTALL
        )
        if quantity_section:
            patterns_text = quantity_section.group(1).strip()
            patterns = [p.strip() for p in patterns_text.split('\n') if p.strip() and not p.strip().startswith('_N/A')]
            metadata['quantity_patterns'] = patterns
        else:
            metadata['quantity_patterns'] = []
        
        # æå– Topic Patterns
        topic_section = re.search(
            r'### Topic Patterns.*?```(?:regex)?\n(.*?)\n```',
            content,
            re.DOTALL
        )
        if topic_section:
            patterns_text = topic_section.group(1).strip()
            patterns = [p.strip() for p in patterns_text.split('\n') if p.strip()]
            metadata['topic_patterns'] = patterns
        else:
            metadata['topic_patterns'] = []
        
        # æå– Context Patterns
        context_section = re.search(
            r'### Context Patterns.*?```\n(.*?)\n```',
            content,
            re.DOTALL
        )
        if context_section:
            patterns_text = context_section.group(1).strip()
            patterns = [p.strip() for p in patterns_text.split('\n') if p.strip()]
            metadata['context_patterns'] = patterns
        else:
            metadata['context_patterns'] = []
        
        return metadata
    
    def match_message(
        self, 
        message: str, 
        current_topic: Optional[str] = None
    ) -> Optional[SkillMatch]:
        """
        åŒ¹é…ç”¨æˆ·æ¶ˆæ¯åˆ°æŠ€èƒ½ï¼ˆ0 tokensï¼‰
        
        æ ¸å¿ƒæ–¹æ³•ï¼šå®ç° Phase 4 çš„ 0-token æ„å›¾è¯†åˆ«
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            current_topic: å½“å‰å¯¹è¯ä¸»é¢˜ï¼ˆä» session_context è·å–ï¼‰
        
        Returns:
            SkillMatch æˆ– Noneï¼ˆæœªåŒ¹é…ï¼‰
        """
        if not self._skill_metadata:
            logger.warning("âš ï¸ No skill metadata loaded, falling back to LLM")
            return None
        
        # ğŸ†• Phase 4.1: å…ˆæ£€æµ‹æ··åˆæ„å›¾
        mixed_match = self._detect_mixed_intent(message, current_topic)
        if mixed_match:
            logger.info(f"ğŸ”€ Detected mixed intent, matched to: {mixed_match.skill_id}")
            return mixed_match
        
        best_match: Optional[SkillMatch] = None
        best_confidence = 0.0
        
        # éå†æ‰€æœ‰æŠ€èƒ½ï¼Œè®¡ç®—åŒ¹é…åº¦
        for skill_id, metadata in self._skill_metadata.items():
            # æ£€æŸ¥ä¸»è¦å…³é”®è¯
            matched_keywords = self._check_keywords(message, metadata.get('primary_keywords', []))
            if not matched_keywords:
                continue  # æ²¡æœ‰åŒ¹é…å…³é”®è¯ï¼Œè·³è¿‡
            
            # æå–å‚æ•°ï¼ˆä¼ é€’ current_topicï¼‰
            parameters = self._extract_parameters(message, metadata, skill_id, current_topic)
            
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence = self._calculate_confidence(
                message,
                metadata,
                matched_keywords,
                parameters
            )
            
            # æ›´æ–°æœ€ä½³åŒ¹é…
            if confidence > best_confidence:
                best_confidence = confidence
                best_match = SkillMatch(
                    skill_id=skill_id,
                    confidence=confidence,
                    parameters=parameters,
                    matched_keywords=matched_keywords
                )
        
        # åªè¿”å›ç½®ä¿¡åº¦ >= 0.7 çš„åŒ¹é…
        if best_match and best_match.confidence >= 0.7:
            logger.info(f"âœ… Matched skill: {best_match.skill_id} (confidence: {best_match.confidence:.2f})")
            return best_match
        
        logger.debug(f"âš ï¸ No confident match found (best: {best_confidence:.2f})")
        return None
    
    def _check_keywords(self, message: str, keywords: List[str]) -> List[str]:
        """æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«å…³é”®è¯"""
        message_lower = message.lower()
        matched = []
        for keyword in keywords:
            if keyword.lower() in message_lower:
                matched.append(keyword)
        return matched
    
    def _extract_parameters(
        self,
        message: str,
        metadata: Dict[str, Any],
        skill_id: str,
        current_topic: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ä»æ¶ˆæ¯ä¸­æå–å‚æ•°
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            metadata: æŠ€èƒ½å…ƒæ•°æ®
            skill_id: æŠ€èƒ½ ID
            current_topic: å½“å‰å¯¹è¯ä¸»é¢˜ï¼ˆä» session_contextï¼‰
        
        Returns:
            parameters dict (topic, quantity, use_last_artifact, etc.)
        """
        params = {}
        
        # 1. æå–æ•°é‡å‚æ•° - æ”¯æŒé˜¿æ‹‰ä¼¯æ•°å­—å’Œä¸­æ–‡æ•°å­—
        # ä¸­æ–‡æ•°å­—æ˜ å°„
        chinese_numbers = {
            'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5,
            'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10,
            'ä¸¤': 2
        }
        
        quantity_value = None
        
        # ä¼˜å…ˆåŒ¹é…é˜¿æ‹‰ä¼¯æ•°å­—
        arabic_match = re.search(r'(\d+)\s*[é“ä¸ªå¼ ä»½é¢˜å¡]', message)
        if arabic_match:
            quantity_value = int(arabic_match.group(1))
        else:
            # åŒ¹é…ä¸­æ–‡æ•°å­—
            chinese_match = re.search(r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åä¸¤])\s*[é“ä¸ªå¼ ä»½é¢˜å¡]', message)
            if chinese_match:
                chinese_char = chinese_match.group(1)
                quantity_value = chinese_numbers.get(chinese_char)
        
        if quantity_value:
            # æ ¹æ® skill_id è®¾ç½®æ­£ç¡®çš„å‚æ•°å
            if skill_id == 'quiz_skill':
                params['num_questions'] = quantity_value
            elif skill_id == 'flashcard_skill':
                params['num_cards'] = quantity_value
            elif skill_id == 'learning_plan_skill':
                # å­¦ä¹ åŒ…å¯èƒ½åŒ…å«å¤šä¸ªæ•°é‡å‚æ•°
                if 'é—ªå¡' in message or 'å¡ç‰‡' in message:
                    params['flashcard_quantity'] = quantity_value
                elif 'é¢˜' in message:
                    params['quiz_quantity'] = quantity_value
            
            logger.debug(f"ğŸ“Š Extracted quantity: {quantity_value}")
        
        # 2. æå–ä¸»é¢˜
        topic = self._extract_topic(message, metadata)
        
        # ğŸ”¥ å¦‚æœæ¶ˆæ¯ä¸­æ²¡æœ‰æ˜ç¡®ä¸»é¢˜ï¼Œä½†æœ‰ current_topicï¼Œä½¿ç”¨å®ƒ
        if not topic and current_topic:
            topic = current_topic
            logger.info(f"ğŸ“š Using current_topic from context: {topic}")
        
        if topic:
            params['topic'] = topic
            # å¯¹äº explain_skillï¼Œtopic åº”è¯¥è®¾ç½®ä¸º concept_name
            if skill_id == 'explain_skill':
                params['concept_name'] = topic
        
        # 3. æ£€æµ‹ä¸Šä¸‹æ–‡å¼•ç”¨ - ä½¿ç”¨ç®€å•çš„å…³é”®è¯æ£€æµ‹
        context_keywords = ['æ ¹æ®', 'åŸºäº', 'åˆšæ‰', 'è¿™äº›', 'è¿™é“', 'ä¸Šé¢', 'ç¬¬ä¸€', 'ç¬¬äºŒ', 'ç¬¬ä¸‰', 'ç¬¬', 'å†æ¥', 'å†ç»™']
        if any(kw in message for kw in context_keywords):
            params['use_last_artifact'] = True
            logger.debug(f"ğŸ”— Detected context reference")
        
        return params
    
    def _extract_topic(self, message: str, metadata: Dict[str, Any]) -> Optional[str]:
        """ä»æ¶ˆæ¯ä¸­æå–ä¸»é¢˜ - ä½¿ç”¨ç®€å•ç›´æ¥çš„æ–¹æ³•"""
        
        # ä¼˜åŒ–çš„ä¸»é¢˜æå–æ¨¡å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        topic_patterns = [
            # ğŸ†• æœ€é«˜ä¼˜å…ˆçº§ï¼šæ˜ç¡®çš„"XXXçš„è§£é‡Š/è¯´æ˜"ç»“æ„
            r'(.+?)çš„(?:è§£é‡Š|è®²è§£|è¯´æ˜|ä»‹ç»|å®šä¹‰)',          # "äºŒæˆ˜èµ·å› çš„è§£é‡Š"
            
            # é«˜ä¼˜å…ˆçº§ï¼šæ˜ç¡®çš„ä¸»é¢˜è¯
            r'ä»€ä¹ˆæ˜¯(.+?)(?:[ï¼Œã€‚ï¼ï¼Ÿ]|$)',              # "ä»€ä¹ˆæ˜¯å…‰åˆä½œç”¨"
            r'è§£é‡Š(?:ä¸€?ä¸‹?)?(.+?)(?:[ï¼Œã€‚ï¼ï¼Ÿ]|$)',     # "è§£é‡Šå…‰åˆä½œç”¨"
            r'è®²è§£(?:ä¸€?ä¸‹?)?(.+?)(?:[ï¼Œã€‚ï¼ï¼Ÿ]|$)',     # "è®²è§£å…‰åˆä½œç”¨"
            r'ç†è§£(?:ä¸€?ä¸‹?)?(.+?)(?:[ï¼Œã€‚ï¼ï¼Ÿ]|$)',     # "ç†è§£å…‰åˆä½œç”¨"
            r'äº†è§£(?:ä¸€?ä¸‹?)?(.+?)(?:[ï¼Œã€‚ï¼ï¼Ÿ]|$)',     # "äº†è§£å…‰åˆä½œç”¨"
            r'å­¦ä¹ (?:ä¸€?ä¸‹?)?(.+?)(?:[ï¼Œã€‚ï¼ï¼Ÿ]|$)',     # "å­¦ä¹ å…‰åˆä½œç”¨"
            r'å…³äº(.+?)çš„',                             # "å…³äºå…‰åˆä½œç”¨çš„"
            
            # ä¸­ä¼˜å…ˆçº§ï¼šå¸¦æ•°é‡è¯çš„æ¨¡å¼
            r'(?:\d+|[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åä¸¤])[é“ä¸ªå¼ ä»½é¢˜å¡](.+?)(?:çš„)?[é¢˜ç¬”é—ªå¯¼å¡å›¾è®°]',  # "3é“å…‰åˆä½œç”¨çš„é¢˜"
            
            # ä½ä¼˜å…ˆçº§ï¼šå®½æ¾åŒ¹é…
            r'(.+?)[çš„]?[é¢˜ç¬”é—ªå¯¼å¡å›¾è®°]',             # "å…‰åˆä½œç”¨çš„é¢˜"
        ]
        
        for pattern in topic_patterns:
            match = re.search(pattern, message)
            if match:
                # æå–ç¬¬ä¸€ä¸ªæ•è·ç»„
                topic = match.group(1).strip()
                # æ¸…ç†ä¸»é¢˜
                topic = self._clean_topic(topic)
                
                # éªŒè¯æå–çš„ä¸»é¢˜æœ‰æ•ˆæ€§
                # æ’é™¤ä¸€äº›æ˜æ˜¾æ— æ•ˆçš„ç»“æœ
                invalid_topics = [
                    'æˆ‘éœ€è¦', 'å¸®æˆ‘', 'ç»™æˆ‘', 'æˆ‘è¦', 'å†æ¥', 'å†ç»™', 'å†å‡º', 'å‡º',
                    'é€‰æ‹©', 'åˆ¤æ–­', 'å¡«ç©º', 'ç®€ç­”',  # é¢˜ç›®ç±»å‹ï¼Œä¸æ˜¯ä¸»é¢˜
                    'å­¦ä¹ ', 'å¤ä¹ ', 'ç»ƒä¹ ', 'æµ‹è¯•',  # åŠ¨ä½œè¯ï¼Œä¸æ˜¯ä¸»é¢˜
                ]
                if topic and len(topic) >= 2 and topic not in invalid_topics:
                    logger.debug(f"ğŸ“ Extracted topic: {topic} (pattern: {pattern})")
                    return topic
        
        return None
    
    def _clean_topic(self, topic: str) -> str:
        """æ¸…ç†ä¸»é¢˜æ–‡æœ¬ï¼Œç§»é™¤å¡«å……è¯"""
        # ç§»é™¤å¸¸è§å¡«å……è¯å’Œä¸Šä¸‹æ–‡å¼•ç”¨è¯
        filler_words = [
            "çš„", "äº†", "å—", "å‘¢", "å•Š", "å§",
            "ç»™æˆ‘", "å¸®æˆ‘", "æˆ‘è¦", "æˆ‘éœ€è¦", "ç”Ÿæˆ", "åˆ›å»º",
            "å‡º", "åš", "å†™",
            "å…³äº", "æœ‰å…³",
            "æ ¹æ®", "åˆšåˆš", "åˆšæ‰", "ä¸Šé¢", "è¿™ä¸ª", "é‚£ä¸ª",
            " æ€ç»´", " å¯¼å›¾", " ç¬”è®°", " é¢˜ç›®", " é—ªå¡", " å¡ç‰‡"  # æŠ€èƒ½ç›¸å…³çš„è¯
        ]
        for filler in filler_words:
            topic = topic.replace(filler, " ")
        
        # ç§»é™¤æ•°é‡è¯ï¼ˆé˜¿æ‹‰ä¼¯æ•°å­— + ä¸­æ–‡æ•°å­—ï¼‰
        topic = re.sub(r'\d+\s*[ä¸ªé“å¼ ä»½é¢˜å¡]', '', topic)
        topic = re.sub(r'[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åä¸¤]\s*[ä¸ªé“å¼ ä»½é¢˜å¡]', '', topic)
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        topic = ' '.join(topic.split())
        
        return topic.strip()
    
    def _calculate_confidence(
        self,
        message: str,
        metadata: Dict[str, Any],
        matched_keywords: List[str],
        parameters: Dict[str, Any]
    ) -> float:
        """
        è®¡ç®—åŒ¹é…ç½®ä¿¡åº¦
        
        Returns:
            confidence score (0.0 - 1.0)
        """
        confidence = 0.5  # åŸºç¡€åˆ†
        
        # 1. å…³é”®è¯åŒ¹é…ï¼ˆ+0.3ï¼‰
        if matched_keywords:
            confidence += 0.3
        
        # 2. æœ‰æ˜ç¡®ä¸»é¢˜ï¼ˆ+0.15ï¼‰
        if parameters.get('topic') or parameters.get('concept_name'):
            confidence += 0.15
        
        # 3. æœ‰æ•°é‡å‚æ•°ï¼ˆ+0.05ï¼‰
        if any(k in parameters for k in ['num_questions', 'num_cards', 'flashcard_quantity', 'quiz_quantity']):
            confidence += 0.05
        
        # 4. ç®€çŸ­æ˜ç¡®çš„è¯·æ±‚ï¼ˆ+0.1ï¼‰
        if len(message) < 20 and matched_keywords:
            confidence += 0.05
        
        return min(confidence, 1.0)  # æœ€å¤§ 1.0
    
    def _detect_mixed_intent(
        self, 
        message: str, 
        current_topic: Optional[str] = None
    ) -> Optional[SkillMatch]:
        """
        æ£€æµ‹æ··åˆæ„å›¾ï¼ˆå¤šä¸ªæŠ€èƒ½å…³é”®è¯ï¼‰
        
        å¦‚æœæ£€æµ‹åˆ°å¤šä¸ªæŠ€èƒ½çš„å…³é”®è¯ï¼Œè¿”å› learning_plan_skill
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            current_topic: å½“å‰å¯¹è¯ä¸»é¢˜ï¼ˆä» session_contextï¼‰
        
        Returns:
            SkillMatch for learning_plan_skill or None
        """
        # å®šä¹‰å„æŠ€èƒ½çš„å…³é”®è¯é›†åˆ
        skill_keywords = {
            'explain': ['è§£é‡Š', 'è®²è§£', 'è¯´æ˜', 'ç†è§£', 'äº†è§£', 'å­¦ä¹ ', 'ä»€ä¹ˆæ˜¯', 'explain', 'what is', 'understand'],
            'quiz': ['é¢˜', 'é¢˜ç›®', 'ç»ƒä¹ ', 'æµ‹è¯•', 'quiz', 'test', 'question'],
            'flashcard': ['é—ªå¡', 'å¡ç‰‡', 'è®°å¿†å¡', 'flashcard', 'card'],
            'notes': ['ç¬”è®°', 'æ€»ç»“', 'å½’çº³', 'notes', 'summary'],
            'mindmap': ['æ€ç»´å¯¼å›¾', 'å¯¼å›¾', 'çŸ¥è¯†å›¾', 'mindmap', 'mind map', 'concept map'],
            'learning_bundle': ['å­¦ä¹ åŒ…', 'å­¦ä¹ èµ„æ–™', 'å­¦ä¹ ææ–™', 'å®Œæ•´', 'å­¦ä¹ å¥—è£…', 'å­¦ä¹ è®¡åˆ’', 'learning bundle', 'study package']
        }
        
        # æ£€æµ‹æ¶ˆæ¯ä¸­åŒ…å«å“ªäº›æŠ€èƒ½çš„å…³é”®è¯
        matched_skills = []
        for skill_name, keywords in skill_keywords.items():
            if any(kw in message for kw in keywords):
                matched_skills.append(skill_name)
        
        # ğŸ”¥ ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœæ˜ç¡®æåˆ° learning_bundle å…³é”®è¯ï¼Œç›´æ¥è¿”å› learning_plan_skill
        if 'learning_bundle' in matched_skills:
            logger.info(f"ğŸ“¦ Detected explicit learning_bundle keywords")
            
            # æå–å‚æ•°
            params = {}
            topic = self._extract_topic(message, {})
            if not topic and current_topic:
                topic = current_topic
            if topic:
                params['topic'] = topic
            
            # è¿”å› learning_plan_skill åŒ¹é…
            return SkillMatch(
                skill_id='learning_plan_skill',
                confidence=0.95,  # é«˜ç½®ä¿¡åº¦
                parameters=params,
                matched_keywords=['learning_bundle']
            )
        
        # å¦‚æœæ£€æµ‹åˆ° 2 ä¸ªæˆ–ä»¥ä¸Šçš„æŠ€èƒ½å…³é”®è¯ï¼ˆä¸åŒ…æ‹¬ learning_bundleï¼‰ï¼Œåˆ¤å®šä¸ºæ··åˆæ„å›¾
        # è¿‡æ»¤æ‰ learning_bundleï¼Œå› ä¸ºå®ƒå·²ç»åœ¨ä¸Šé¢å¤„ç†äº†
        matched_skills_filtered = [s for s in matched_skills if s != 'learning_bundle']
        if len(matched_skills_filtered) >= 2:
            logger.info(f"ğŸ”€ Mixed intent detected: {matched_skills_filtered}")
            
            # æå–å‚æ•°
            params = {}
            
            # ğŸ†• Phase 4.2: æ·»åŠ  required_stepsï¼Œè®© Plan Skill çŸ¥é“è¦æ‰§è¡Œå“ªäº›æ­¥éª¤
            step_mapping = {
                'explain': 'explain',
                'quiz': 'quiz',
                'flashcard': 'flashcard',
                'notes': 'notes',
                'mindmap': 'mindmap'
            }
            params['required_steps'] = [step_mapping[skill] for skill in matched_skills_filtered if skill in step_mapping]
            logger.info(f"ğŸ“‹ Required steps: {params['required_steps']}")
            
            # æå–ä¸»é¢˜ - ä½¿ç”¨æ›´æ™ºèƒ½çš„æ–¹æ³•
            # å°è¯•ä»å¸¸è§æ¨¡å¼ä¸­æå–ä¸»é¢˜
            topic = None
            topic_patterns = [
                r'è§£é‡Š(?:ä¸€?ä¸‹?)?(.+?)(?:ï¼Œ|å¹¶|ç„¶å|å†)',       # "è§£é‡Šç‰›é¡¿ç¬¬äºŒå®šå¾‹ï¼Œå¹¶..."
                r'è®²è§£(?:ä¸€?ä¸‹?)?(.+?)(?:ï¼Œ|å¹¶|ç„¶å|å†)',       # "è®²è§£ç‰›é¡¿ç¬¬äºŒå®šå¾‹ï¼Œå¹¶..."
                r'ç†è§£(?:ä¸€?ä¸‹?)?(.+?)(?:ï¼Œ|å¹¶|ç„¶å|å†)',       # "ç†è§£ç‰›é¡¿ç¬¬äºŒå®šå¾‹ï¼Œå¹¶..."
                r'äº†è§£(?:ä¸€?ä¸‹?)?(.+?)(?:ï¼Œ|å¹¶|ç„¶å|å†)',       # "äº†è§£ç‰›é¡¿ç¬¬äºŒå®šå¾‹ï¼Œå¹¶..."
                r'å­¦ä¹ (?:ä¸€?ä¸‹?)?(.+?)(?:ï¼Œ|å¹¶|ç„¶å|å†)',       # "å­¦ä¹ ç‰›é¡¿ç¬¬äºŒå®šå¾‹ï¼Œå¹¶..."
                r'å…³äº(.+?)(?:çš„|ï¼Œ)',                         # "å…³äºç‰›é¡¿ç¬¬äºŒå®šå¾‹çš„..."
                r'(.+?)(?:çš„|ï¼Œ)(?:è®²è§£|è§£é‡Š|ç†è§£|é¢˜ç›®|é—ªå¡)',  # "ç‰›é¡¿ç¬¬äºŒå®šå¾‹çš„è®²è§£..."
            ]
            
            for pattern in topic_patterns:
                match = re.search(pattern, message)
                if match:
                    topic = match.group(1).strip()
                    topic = self._clean_topic(topic)
                    if len(topic) >= 2:
                        params['topic'] = topic
                        break
            
            # ğŸ”¥ å¦‚æœæ²¡æœ‰æå–åˆ°ä¸»é¢˜ï¼Œä½¿ç”¨ current_topic
            if not topic and current_topic:
                topic = current_topic
                params['topic'] = topic
                logger.info(f"ğŸ“š Using current_topic for mixed intent: {topic}")
            
            # æå–æ•°é‡å‚æ•°
            quantity_match = re.search(r'(\d+)\s*[é“ä¸ªå¼ ä»½]', message)
            if quantity_match:
                quantity_value = int(quantity_match.group(1))
                # æ ¹æ®æ¶ˆæ¯ä¸­çš„å…³é”®è¯åˆ¤æ–­æ•°é‡å±äºå“ªä¸ªæŠ€èƒ½
                if 'quiz' in matched_skills_filtered:
                    params['quiz_quantity'] = quantity_value
                if 'flashcard' in matched_skills_filtered:
                    params['flashcard_quantity'] = quantity_value
            
            # è¿”å› learning_plan_skill åŒ¹é…
            return SkillMatch(
                skill_id='learning_plan_skill',
                confidence=0.90,  # é«˜ç½®ä¿¡åº¦
                parameters=params,
                matched_keywords=matched_skills_filtered
            )
        
        return None
    
    def reload(self):
        """é‡æ–°åŠ è½½æ‰€æœ‰ Skillsï¼ˆç”¨äºçƒ­æ›´æ–°ï¼‰"""
        logger.info("ğŸ”„ Reloading skills...")
        self._skills.clear()
        self._intent_map.clear()
        self._skill_metadata.clear()
        self._load_skills()
        self._load_skill_metadata()
        logger.info(f"âœ… Reloaded {len(self._skills)} skills ({len(self._skill_metadata)} with metadata)")


# å…¨å±€å•ä¾‹
_registry_instance: Optional[SkillRegistry] = None


def get_skill_registry() -> SkillRegistry:
    """
    è·å–å…¨å±€ SkillRegistry å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    
    Returns:
        SkillRegistry å®ä¾‹
    """
    global _registry_instance
    if _registry_instance is None:
        _registry_instance = SkillRegistry()
    return _registry_instance

