"""
Conversation Session Manager - å¯¹è¯ Session ç®¡ç†å™¨

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ£€æµ‹ 5 åˆ†é’Ÿ cooldownï¼Œè‡ªåŠ¨åˆ›å»º/ç»§ç»­ session
2. ç”Ÿæˆ Markdown æ ¼å¼çš„å¯¹è¯è®°å½•
3. åµŒå…¥ JSON ç»“æ„åŒ–æ•°æ®
4. Session äº’è”ï¼ˆè·¨ session å¼•ç”¨ï¼‰
5. S3 åŒæ­¥
"""

import os
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from pathlib import Path

logger = logging.getLogger(__name__)


class ConversationSessionManager:
    """
    ç®¡ç†è¿ç»­å¯¹è¯ session
    
    æ ¸å¿ƒé€»è¾‘ï¼š
    - ä¸æ˜¯å®æ—¶è®¡æ—¶ 5 åˆ†é’Ÿï¼ˆæµªè´¹èµ„æºï¼‰
    - ä¸‹æ¬¡å¯¹è¯å¼€å§‹æ—¶æ£€æŸ¥è·ç¦»ä¸Šæ¬¡çš„æ—¶é—´å·®
    - å¦‚æœ > 5 åˆ†é’Ÿ â†’ æ–° MD
    - å¦‚æœ â‰¤ 5 åˆ†é’Ÿ â†’ è¿½åŠ åˆ°å½“å‰ MD
    - MD ä¹‹é—´å¯ä»¥äº’è”ï¼ˆè·¨ session å¼•ç”¨ï¼‰
    """
    
    SESSION_TIMEOUT = 300  # 5 åˆ†é’Ÿï¼ˆç§’ï¼‰
    
    def __init__(
        self,
        user_id: str,
        storage_path: str,
        s3_manager: Optional[Any] = None
    ):
        """
        åˆå§‹åŒ– Session ç®¡ç†å™¨
        
        Args:
            user_id: ç”¨æˆ· ID
            storage_path: æœ¬åœ°å­˜å‚¨è·¯å¾„ï¼ˆå¦‚ï¼šbackend/artifacts/user_kimi/ï¼‰
            s3_manager: S3 å­˜å‚¨ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
        """
        self.user_id = user_id
        self.storage_path = Path(storage_path)
        self.s3_manager = s3_manager
        
        # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
        self.storage_path.mkdir(parents=True, exist_ok=True)
        
        # å½“å‰ session çŠ¶æ€
        self.current_session_id: Optional[str] = None
        self.last_activity_time: Optional[datetime] = None
        self.current_session_file: Optional[Path] = None
        self.turn_counter: int = 0
        
        # Session å…ƒæ•°æ®
        self.session_metadata: Dict[str, Any] = {}
        
        logger.info(f"âœ… ConversationSessionManager initialized for user: {user_id}")
    
    async def start_or_continue_session(
        self,
        user_message: str,
        timestamp: Optional[datetime] = None
    ) -> str:
        """
        å¼€å§‹æˆ–ç»§ç»­ sessionï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰
        
        é€»è¾‘ï¼š
        1. æ£€æŸ¥è·ç¦»ä¸Šæ¬¡å¯¹è¯çš„æ—¶é—´å·®
        2. å¦‚æœ > 5 åˆ†é’Ÿ â†’ åˆ›å»ºæ–° session
        3. å¦‚æœ â‰¤ 5 åˆ†é’Ÿ â†’ ç»§ç»­å½“å‰ session
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯ï¼ˆç”¨äºæ£€æµ‹å…³è”ï¼‰
            timestamp: å½“å‰æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º nowï¼‰
        
        Returns:
            session_id
        """
        now = timestamp or datetime.now()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ–° session
        if self._should_start_new_session(now):
            # åˆ›å»ºæ–° session
            await self._start_new_session(now, user_message)
            logger.info(f"ğŸ†• Started new session: {self.current_session_id}")
        else:
            # ç»§ç»­å½“å‰ session
            logger.info(f"â™»ï¸  Continuing session: {self.current_session_id}")
        
        # æ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´
        self.last_activity_time = now
        
        return self.current_session_id
    
    def _should_start_new_session(self, now: datetime) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦æ–° session
        
        æ¡ä»¶ï¼š
        1. å½“å‰æ²¡æœ‰ session
        2. è·ç¦»ä¸Šæ¬¡æ´»åŠ¨ > 5 åˆ†é’Ÿ
        """
        if not self.current_session_id:
            return True
        
        if not self.last_activity_time:
            return True
        
        time_diff = (now - self.last_activity_time).total_seconds()
        
        if time_diff > self.SESSION_TIMEOUT:
            logger.info(f"â° Session timeout: {time_diff:.1f}s > {self.SESSION_TIMEOUT}s")
            return True
        
        return False
    
    async def _start_new_session(self, timestamp: datetime, user_message: str):
        """
        åˆ›å»ºæ–° session
        
        Args:
            timestamp: åˆ›å»ºæ—¶é—´
            user_message: é¦–æ¡æ¶ˆæ¯ï¼ˆç”¨äºæ£€æµ‹å…³è”ï¼‰
        """
        # ç”Ÿæˆ session ID
        self.current_session_id = self._generate_session_id(timestamp)
        
        # åˆ›å»º MD æ–‡ä»¶è·¯å¾„
        self.current_session_file = self.storage_path / f"{self.current_session_id}.md"
        
        # é‡ç½® turn è®¡æ•°å™¨
        self.turn_counter = 0
        
        # åˆå§‹åŒ– session å…ƒæ•°æ®
        self.session_metadata = {
            "session_id": self.current_session_id,
            "user_id": self.user_id,
            "start_time": timestamp.isoformat(),
            "last_updated": timestamp.isoformat(),
            "status": "active",
            "total_turns": 0,
            "topics": [],
            "skills_used": {},
            "artifacts_generated": []
        }
        
        # ğŸ”— æ£€æŸ¥æ˜¯å¦ä¸æ—§ session ç›¸å…³
        related_sessions = await self._find_related_sessions(user_message)
        if related_sessions:
            self.session_metadata["related_sessions"] = related_sessions
            logger.info(f"ğŸ”— Found {len(related_sessions)} related sessions")
        
        # åˆ›å»º MD æ–‡ä»¶å¤´éƒ¨
        await self._write_session_header()
    
    def _generate_session_id(self, timestamp: datetime) -> str:
        """ç”Ÿæˆ session ID"""
        return f"session_{timestamp.strftime('%Y%m%d_%H%M%S')}"
    
    async def _find_related_sessions(
        self,
        user_message: str,
        max_results: int = 3
    ) -> List[Dict[str, Any]]:
        """
        æŸ¥æ‰¾ç›¸å…³çš„æ—§ sessionsï¼ˆè¯­ä¹‰æœç´¢ï¼‰
        
        ç­–ç•¥ï¼š
        1. æå–ç”¨æˆ·æ¶ˆæ¯ä¸­çš„å…³é”®è¯/ä¸»é¢˜
        2. åœ¨æ—§ sessions ä¸­æœç´¢ç›¸å…³ä¸»é¢˜
        3. è®¡ç®—ç›¸å…³åº¦è¯„åˆ†
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            max_results: æœ€å¤šè¿”å›å‡ ä¸ªç›¸å…³ session
        
        Returns:
            ç›¸å…³ sessions åˆ—è¡¨
        """
        # ğŸ” ç®€å•å®ç°ï¼šåŸºäºä¸»é¢˜åŒ¹é…
        # é«˜çº§å®ç°å¯ä»¥ä½¿ç”¨ embedding è¯­ä¹‰æœç´¢
        
        related = []
        
        try:
            # åˆ—å‡ºæ‰€æœ‰ session MD æ–‡ä»¶
            session_files = list(self.storage_path.glob("session_*.md"))
            
            # æå–ç”¨æˆ·æ¶ˆæ¯ä¸­çš„å…³é”®è¯ï¼ˆç®€å•åˆ†è¯ï¼‰
            keywords = self._extract_keywords(user_message)
            
            for session_file in session_files:
                # è·³è¿‡å½“å‰ session
                if self.current_session_id and session_file.stem == self.current_session_id:
                    continue
                
                # è¯»å– session metadataï¼ˆä»æ–‡ä»¶å¤´éƒ¨æˆ–å•ç‹¬çš„ JSONï¼‰
                metadata = await self._load_session_metadata(session_file)
                
                if not metadata:
                    continue
                
                # è®¡ç®—ç›¸å…³åº¦
                relevance = self._calculate_relevance(keywords, metadata)
                
                if relevance > 0.5:  # é˜ˆå€¼ï¼š50%
                    related.append({
                        "session_id": session_file.stem,
                        "relevance_score": relevance,
                        "topics": metadata.get("topics", []),
                        "start_time": metadata.get("start_time", "")
                    })
            
            # æŒ‰ç›¸å…³åº¦æ’åº
            related.sort(key=lambda x: x["relevance_score"], reverse=True)
            
            return related[:max_results]
        
        except Exception as e:
            logger.error(f"âŒ Failed to find related sessions: {e}")
            return []
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯ï¼ˆç®€å•å®ç°ï¼‰"""
        # ç§»é™¤å¸¸è§åœç”¨è¯
        stopwords = {'çš„', 'äº†', 'å—', 'å‘¢', 'å•Š', 'å§', 'ç»™æˆ‘', 'å¸®æˆ‘', 'æˆ‘è¦', 'ä»€ä¹ˆæ˜¯', 'æ˜¯ä»€ä¹ˆ'}
        
        # ç®€å•åˆ†è¯ï¼ˆåŸºäºç©ºæ ¼å’Œæ ‡ç‚¹ï¼‰
        import re
        words = re.findall(r'[\w]+', text)
        
        # è¿‡æ»¤åœç”¨è¯ï¼Œä¿ç•™é•¿åº¦ >= 2 çš„è¯
        keywords = [w for w in words if w not in stopwords and len(w) >= 2]
        
        return keywords[:10]  # æœ€å¤š 10 ä¸ªå…³é”®è¯
    
    async def _load_session_metadata(self, session_file: Path) -> Optional[Dict[str, Any]]:
        """
        åŠ è½½ session å…ƒæ•°æ®
        
        ç­–ç•¥ï¼š
        1. ä¼˜å…ˆä»å•ç‹¬çš„ JSON æ–‡ä»¶åŠ è½½ï¼ˆsession_xxx_metadata.jsonï¼‰
        2. å¦åˆ™ä» MD æ–‡ä»¶æœ«å°¾çš„ JSON ä»£ç å—è§£æ
        """
        # æ–¹æ¡ˆ 1ï¼šå•ç‹¬çš„ metadata JSON æ–‡ä»¶
        metadata_file = session_file.parent / f"{session_file.stem}_metadata.json"
        if metadata_file.exists():
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"âŒ Failed to load metadata from {metadata_file}: {e}")
        
        # æ–¹æ¡ˆ 2ï¼šä» MD æ–‡ä»¶è§£æï¼ˆæš‚ä¸å®ç°ï¼Œé¿å…è¯»å–å¤§æ–‡ä»¶ï¼‰
        # TODO: å®ç°ä» MD æœ«å°¾æå– JSON
        
        return None
    
    def _calculate_relevance(
        self,
        keywords: List[str],
        metadata: Dict[str, Any]
    ) -> float:
        """
        è®¡ç®—ç›¸å…³åº¦
        
        ç­–ç•¥ï¼š
        - keywords ä¸ metadata.topics çš„é‡å åº¦
        
        Returns:
            ç›¸å…³åº¦ (0.0 - 1.0)
        """
        if not keywords or not metadata.get("topics"):
            return 0.0
        
        topics = metadata.get("topics", [])
        
        # è®¡ç®—å…³é”®è¯åœ¨ topics ä¸­å‡ºç°çš„æ¯”ä¾‹
        matches = 0
        for keyword in keywords:
            for topic in topics:
                if keyword in topic or topic in keyword:
                    matches += 1
                    break
        
        relevance = matches / len(keywords) if keywords else 0.0
        
        return min(relevance, 1.0)
    
    async def _write_session_header(self):
        """å†™å…¥ MD æ–‡ä»¶å¤´éƒ¨"""
        header = self._format_session_header()
        
        with open(self.current_session_file, 'w', encoding='utf-8') as f:
            f.write(header)
        
        logger.info(f"ğŸ“ Created session file: {self.current_session_file}")
    
    def _format_session_header(self) -> str:
        """æ ¼å¼åŒ– session å¤´éƒ¨"""
        metadata = self.session_metadata
        timestamp = datetime.fromisoformat(metadata["start_time"])
        
        header = f"""# Learning Session - {timestamp.strftime('%Y-%m-%d %H:%M:%S')}

**User**: {self.user_id}  
**Session ID**: {metadata['session_id']}  
**Started**: {metadata['start_time']}  
**Last Updated**: {metadata['last_updated']}  
**Status**: {metadata['status']}

"""
        
        # æ·»åŠ ç›¸å…³ sessions å¼•ç”¨
        if metadata.get("related_sessions"):
            header += "**Related Sessions**:\n"
            for related in metadata["related_sessions"]:
                header += f"- ğŸ“ [{related['session_id']}]({related['session_id']}.md) - {', '.join(related['topics'])} (ç›¸å…³åº¦: {related['relevance_score']:.0%})\n"
            header += "\n"
        
        header += "---\n\n"
        
        return header
    
    async def append_turn(
        self,
        turn_data: Dict[str, Any]
    ) -> bool:
        """
        è¿½åŠ ä¸€ä¸ªå¯¹è¯è½®æ¬¡åˆ° MD æ–‡ä»¶
        
        Args:
            turn_data: {
                "user_query": str,
                "agent_response": Dict[str, Any],
                "response_type": str,  # explanation, quiz_set, flashcard_set, etc.
                "timestamp": datetime,
                "intent": Dict[str, Any],
                "metadata": Dict[str, Any]  # thinking_tokens, output_tokens, duration, model
            }
        
        Returns:
            æˆåŠŸè¿”å› True
        """
        try:
            # å¢åŠ  turn è®¡æ•°
            self.turn_counter += 1
            turn_data["turn_number"] = self.turn_counter
            
            # æ ¼å¼åŒ– Turn
            from .markdown_formatter import MarkdownFormatter
            formatter = MarkdownFormatter()
            
            turn_md = formatter.format_turn(turn_data)
            
            # è¿½åŠ åˆ°æ–‡ä»¶
            with open(self.current_session_file, 'a', encoding='utf-8') as f:
                f.write(turn_md)
                f.write("\n---\n\n")
            
            # æ›´æ–° session å…ƒæ•°æ®
            await self._update_session_metadata(turn_data)
            
            # ä¸Šä¼ åˆ° S3
            if self.s3_manager and self.s3_manager.s3_client:
                await self._upload_to_s3()
            
            logger.info(f"âœ… Appended Turn {self.turn_counter} to {self.current_session_file.name}")
            
            return True
        
        except Exception as e:
            logger.error(f"âŒ Failed to append turn: {e}")
            return False
    
    async def _update_session_metadata(self, turn_data: Dict[str, Any]):
        """æ›´æ–° session å…ƒæ•°æ®"""
        metadata = self.session_metadata
        
        # æ›´æ–° last_updated
        if isinstance(turn_data["timestamp"], datetime):
            metadata["last_updated"] = turn_data["timestamp"].isoformat()
        else:
            metadata["last_updated"] = turn_data["timestamp"]
        
        # æ›´æ–° total_turns
        metadata["total_turns"] = self.turn_counter
        
        # æ›´æ–° topics
        if "topic" in turn_data.get("intent", {}):
            topic = turn_data["intent"]["topic"]
            if topic and topic not in metadata["topics"]:
                metadata["topics"].append(topic)
        
        # æ›´æ–° skills_used
        response_type = turn_data.get("response_type", "unknown")
        metadata["skills_used"][response_type] = metadata["skills_used"].get(response_type, 0) + 1
        
        # è®°å½• artifacts
        if "artifact_id" in turn_data.get("agent_response", {}):
            metadata["artifacts_generated"].append({
                "turn": self.turn_counter,
                "type": response_type,
                "artifact_id": turn_data["agent_response"]["artifact_id"],
                "topic": turn_data.get("intent", {}).get("topic", "")
            })
        
        # ä¿å­˜å…ƒæ•°æ®åˆ°å•ç‹¬çš„ JSON æ–‡ä»¶
        await self._save_session_metadata()
    
    async def _save_session_metadata(self):
        """ä¿å­˜ session å…ƒæ•°æ®åˆ°å•ç‹¬çš„ JSON æ–‡ä»¶"""
        metadata_file = self.storage_path / f"{self.current_session_id}_metadata.json"
        
        try:
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.session_metadata, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"ğŸ’¾ Saved session metadata: {metadata_file.name}")
        
        except Exception as e:
            logger.error(f"âŒ Failed to save session metadata: {e}")
    
    async def _upload_to_s3(self):
        """ä¸Šä¼  MD æ–‡ä»¶åˆ° S3"""
        if not self.s3_manager or not self.s3_manager.s3_client:
            return
        
        try:
            # S3 è·¯å¾„ï¼šuser_kimi/session_xxx.md
            s3_key = f"{self.user_id}/{self.current_session_file.name}"
            
            await self.s3_manager.save(
                s3_key,
                self.current_session_file.read_text(encoding='utf-8')
            )
            
            logger.debug(f"â˜ï¸  Uploaded to S3: {s3_key}")
        
        except Exception as e:
            logger.error(f"âŒ Failed to upload to S3: {e}")
    
    async def finalize_session(self):
        """
        ç»“æŸ sessionï¼Œæ·»åŠ æ‘˜è¦
        """
        if not self.current_session_id or not self.current_session_file:
            return
        
        try:
            # ç”Ÿæˆ session æ‘˜è¦
            summary = self._generate_session_summary()
            
            # è¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾
            with open(self.current_session_file, 'a', encoding='utf-8') as f:
                f.write(summary)
            
            # æ›´æ–°çŠ¶æ€
            self.session_metadata["status"] = "completed"
            await self._save_session_metadata()
            
            # æœ€åä¸€æ¬¡ä¸Šä¼ åˆ° S3
            if self.s3_manager and self.s3_manager.s3_client:
                await self._upload_to_s3()
            
            logger.info(f"âœ… Finalized session: {self.current_session_id}")
        
        except Exception as e:
            logger.error(f"âŒ Failed to finalize session: {e}")
    
    def _generate_session_summary(self) -> str:
        """ç”Ÿæˆ session æ‘˜è¦"""
        metadata = self.session_metadata
        
        start_time = datetime.fromisoformat(metadata["start_time"])
        end_time = datetime.fromisoformat(metadata["last_updated"])
        duration = (end_time - start_time).total_seconds() / 60  # åˆ†é’Ÿ
        
        summary = f"""## ğŸ“Š Session Summary

**Duration**: {duration:.1f} minutes ({start_time.strftime('%H:%M:%S')} - {end_time.strftime('%H:%M:%S')})  
**Total Turns**: {metadata['total_turns']}  
**Topics Discussed**: {', '.join(metadata['topics']) if metadata['topics'] else 'N/A'}  
**Skills Used**: 
"""
        
        for skill, count in metadata.get("skills_used", {}).items():
            summary += f"- {skill} ({count} time{'s' if count > 1 else ''})\n"
        
        summary += f"""
**Learning Progress**:
- âœ… Generated {len(metadata.get('artifacts_generated', []))} artifacts

**Next Session Suggestions**:
- å¯ä»¥ç»§ç»­å­¦ä¹ ç›¸å…³ä¸»é¢˜
- æˆ–è€…åˆ‡æ¢æ–°ä¸»é¢˜

<details>
<summary>ğŸ“¦ <b>Session å…ƒæ•°æ®ï¼ˆJSONï¼‰</b> - ç‚¹å‡»å±•å¼€</summary>

```json
{json.dumps(metadata, ensure_ascii=False, indent=2)}
```

</details>

---

*Last saved: {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  
*Storage: {self.current_session_file}*  
"""
        
        if self.s3_manager and self.s3_manager.s3_client:
            summary += f"*S3: s3://skill-agent-demo/{self.user_id}/{self.current_session_file.name}*  \n"
        
        return summary
    
    async def load_recent_context(
        self,
        max_sessions: int = 1,
        max_turns_per_session: int = 10
    ) -> str:
        """
        åŠ è½½æœ€è¿‘çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆç”¨äº LLMï¼‰
        
        Args:
            max_sessions: åŠ è½½æœ€è¿‘å‡ ä¸ª session
            max_turns_per_session: æ¯ä¸ª session æœ€å¤šåŠ è½½å‡ ä¸ª turn
        
        Returns:
            å®Œæ•´çš„ Markdown æ–‡æœ¬
        """
        try:
            # åˆ—å‡ºæ‰€æœ‰ session MD æ–‡ä»¶
            session_files = sorted(
                self.storage_path.glob("session_*.md"),
                key=lambda f: f.stat().st_mtime,
                reverse=True
            )
            
            # å–æœ€è¿‘çš„ N ä¸ª
            recent_sessions = session_files[:max_sessions]
            
            context = ""
            for session_file in recent_sessions:
                content = session_file.read_text(encoding='utf-8')
                
                # TODO: å¦‚æœéœ€è¦ï¼Œå¯ä»¥æˆªæ–­æ¯ä¸ª session åªå–æœ€å N ä¸ª turns
                # å½“å‰ç›´æ¥è¿”å›å®Œæ•´å†…å®¹
                
                context += content + "\n\n---\n\n"
            
            logger.info(f"ğŸ“š Loaded context from {len(recent_sessions)} sessions")
            
            return context
        
        except Exception as e:
            logger.error(f"âŒ Failed to load recent context: {e}")
            return ""

