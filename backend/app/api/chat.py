"""
çº¯ Chat API - ç¬¬ä¸€æœŸç®€åŒ–ç‰ˆ
ä¸“æ³¨äº: Chat + ä¸Šä¸‹æ–‡ç®¡ç†ï¼ˆå¸è½½/å‹ç¼©/å…³è”/å­˜å‚¨ï¼‰

åŠŸèƒ½:
1. å¤šæ¨¡æ€è¾“å…¥: æ–‡æœ¬ã€å›¾ç‰‡ã€æ–‡æ¡£ã€è¯­éŸ³(è½¬æ–‡æœ¬)
2. çº¯æ–‡æœ¬è¾“å‡º: ä¸èµ° skill æ¡†æ¶ï¼Œç›´æ¥ LLM å›å¤
3. ä¸Šä¸‹æ–‡ç®¡ç†: å¤ç”¨ç°æœ‰ MD session å­˜å‚¨é€»è¾‘
4. Token ç»Ÿè®¡: è¯¦ç»†è®°å½•æ¯ä¸ªç¯èŠ‚çš„æ¶ˆè€—

åæœŸæ‰©å±•: å¯é€šè¿‡ skill_hint å‚æ•°åˆ‡æ¢åˆ° skill æ¡†æ¶
"""
import logging
import os
import time
from datetime import datetime
from typing import Optional, List, Dict, Any
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

from app.services.gemini import GeminiClient
from app.core.memory_manager import MemoryManager
from app.core.conversation_session_manager import ConversationSessionManager
from app.services.token_stats_service import TokenStatsService

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/chat", tags=["Pure Chat"])


# ============= è¯·æ±‚/å“åº”æ¨¡å‹ =============

class ChatRequest(BaseModel):
    """Chat è¯·æ±‚"""
    message: str  # ç”¨æˆ·æ¶ˆæ¯ï¼ˆæ–‡æœ¬ï¼‰
    user_id: str  # ç”¨æˆ· ID
    session_id: Optional[str] = None  # ä¼šè¯ IDï¼ˆä¸æä¾›åˆ™åˆ›å»ºæ–°ä¼šè¯ï¼‰
    file_uris: Optional[List[str]] = None  # æ–‡ä»¶ URI åˆ—è¡¨ï¼ˆå›¾ç‰‡ã€æ–‡æ¡£ç­‰ï¼‰
    voice_text: Optional[str] = None  # è¯­éŸ³è½¬æ–‡æœ¬å†…å®¹ï¼ˆç”±å‰ç«¯å®Œæˆ ASRï¼‰


class TokenUsageDetail(BaseModel):
    """Token ä½¿ç”¨è¯¦æƒ…"""
    input_tokens: int = 0
    output_tokens: int = 0
    total_tokens: int = 0
    source: str = ""  # gemini, compression, etc.
    model: str = ""


class ContextStats(BaseModel):
    """ä¸Šä¸‹æ–‡ç®¡ç†ç»Ÿè®¡"""
    session_turns: int = 0  # å½“å‰ä¼šè¯è½®æ•°
    total_context_chars: int = 0  # æ€»ä¸Šä¸‹æ–‡å­—ç¬¦æ•°
    compressed_turns: int = 0  # å·²å‹ç¼©çš„è½®æ•°
    compression_ratio: float = 0.0  # å‹ç¼©æ¯”
    artifacts_count: int = 0  # artifact æ•°é‡


class ChatResponse(BaseModel):
    """Chat å“åº”"""
    code: int = 0
    msg: str = "success"
    data: Dict[str, Any] = {}


# ============= æ ¸å¿ƒæœåŠ¡ =============

class PureChatService:
    """
    çº¯ Chat æœåŠ¡
    
    èŒè´£:
    1. å¤„ç†å¤šæ¨¡æ€è¾“å…¥
    2. ç®¡ç†å¯¹è¯ä¸Šä¸‹æ–‡
    3. è°ƒç”¨ LLM ç”Ÿæˆå›å¤
    4. ç»Ÿè®¡ Token æ¶ˆè€—
    """
    
    def __init__(self):
        self.gemini = GeminiClient()
        self.memory_manager = MemoryManager()
        self.token_stats = TokenStatsService()
    
    async def chat(
        self,
        message: str,
        user_id: str,
        session_id: Optional[str] = None,
        file_uris: Optional[List[str]] = None,
        voice_text: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        å¤„ç† Chat è¯·æ±‚
        
        Args:
            message: ç”¨æˆ·æ–‡æœ¬æ¶ˆæ¯
            user_id: ç”¨æˆ· ID
            session_id: ä¼šè¯ ID
            file_uris: æ–‡ä»¶ URI åˆ—è¡¨
            voice_text: è¯­éŸ³è½¬æ–‡æœ¬
        
        Returns:
            åŒ…å«å›å¤å’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        start_time = time.time()
        
        # Token ç»Ÿè®¡
        token_usage = {
            "context_loading": {"input": 0, "output": 0, "total": 0},
            "llm_generation": {"input": 0, "output": 0, "total": 0},
            "context_compression": {"input": 0, "output": 0, "total": 0},
            "total": {"input": 0, "output": 0, "total": 0}
        }
        
        # 1. åˆå¹¶è¾“å…¥ï¼ˆæ–‡æœ¬ + è¯­éŸ³ï¼‰
        full_message = message
        if voice_text:
            full_message = f"{message}\n[è¯­éŸ³è¾“å…¥]: {voice_text}" if message else voice_text
        
        logger.info(f"ğŸ“¥ Chat request: user={user_id}, session={session_id}, files={len(file_uris) if file_uris else 0}")
        
        # 2. åŠ è½½/åˆ›å»ºä¼šè¯ä¸Šä¸‹æ–‡
        session_mgr = await self._get_or_create_session(user_id, session_id, full_message)
        session_id = session_mgr.current_session_id
        
        # 3. åŠ è½½å†å²ä¸Šä¸‹æ–‡ï¼ˆæ”¯æŒæ™ºèƒ½æ£€ç´¢æ—©æœŸå†…å®¹ï¼‰
        context_result = await self._load_context(
            session_mgr, session_id, token_usage, 
            user_message=full_message  # ğŸ†• ä¼ å…¥ç”¨æˆ·æ¶ˆæ¯ç”¨äºæ™ºèƒ½æ£€ç´¢
        )
        history_context = context_result["context"]
        context_stats = context_result["stats"]
        
        # 4. æ„å»º prompt
        prompt = self._build_prompt(full_message, history_context, file_uris)
        
        # 5. è°ƒç”¨ LLM ç”Ÿæˆå›å¤
        llm_result = await self._generate_response(prompt, file_uris, token_usage)
        response_text = llm_result["text"]
        
        # 6. ä¿å­˜åˆ°ä¼šè¯ï¼ˆå¤ç”¨ç°æœ‰ MD session é€»è¾‘ï¼‰
        await self._save_turn(
            session_mgr=session_mgr,
            user_message=full_message,
            assistant_response=response_text,
            file_uris=file_uris,
            token_usage=token_usage
        )
        
        # 7. æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©ï¼ˆå¼‚æ­¥ï¼‰
        compression_triggered = await self._check_and_compress(session_mgr, token_usage)
        
        # 8. è®¡ç®—æ€» token
        token_usage["total"]["input"] = (
            token_usage["context_loading"]["input"] +
            token_usage["llm_generation"]["input"] +
            token_usage["context_compression"]["input"]
        )
        token_usage["total"]["output"] = (
            token_usage["context_loading"]["output"] +
            token_usage["llm_generation"]["output"] +
            token_usage["context_compression"]["output"]
        )
        token_usage["total"]["total"] = token_usage["total"]["input"] + token_usage["total"]["output"]
        
        elapsed = time.time() - start_time
        
        # 9. è®°å½•ç»Ÿè®¡ï¼ˆå¤ç”¨ç°æœ‰ TokenStatsServiceï¼‰
        await self._record_stats(
            user_id=user_id,
            session_id=session_id,
            message=full_message,
            token_usage=token_usage,
            file_uris=file_uris
        )
        
        logger.info(f"âœ… Chat completed in {elapsed:.2f}s | Tokens: {token_usage['total']['total']}")
        
        return {
            "response": response_text,
            "session_id": session_id,
            "token_usage": token_usage,
            "context_stats": {
                "session_turns": context_stats["turns"] + 1,
                "loaded_turns": context_stats["loaded_turns"],
                "retrieved_turns": context_stats.get("retrieved_turns", 0),  # ğŸ†• æ™ºèƒ½æ£€ç´¢åˆ°çš„æ—©æœŸè½®æ•°
                "total_context_chars": context_stats["chars"],
                "compressed_turns": context_stats["compressed"],
                "compression_triggered": compression_triggered
            },
            "generation_time": round(elapsed, 2)
        }
    
    async def _get_or_create_session(
        self,
        user_id: str,
        session_id: Optional[str],
        user_message: str = ""
    ) -> ConversationSessionManager:
        """è·å–æˆ–åˆ›å»ºä¼šè¯ç®¡ç†å™¨"""
        session_mgr = self.memory_manager.get_conversation_session_manager(user_id)
        
        # å¼€å§‹æˆ–ç»§ç»­ä¼šè¯
        await session_mgr.start_or_continue_session(
            user_message=user_message or "chat",
            session_id=session_id
        )
        
        return session_mgr
    
    def _detect_history_reference(self, message: str) -> Dict[str, Any]:
        """
        æ™ºèƒ½æ£€æµ‹ç”¨æˆ·æ˜¯å¦åœ¨å¼•ç”¨æ—©æœŸå†…å®¹
        
        Returns:
            {
                "has_reference": bool,
                "reference_type": "time" | "index" | "keyword" | None,
                "keywords": List[str],  # æ£€æµ‹åˆ°çš„å…³é”®è¯
                "index": int | None     # ç´¢å¼•å¼•ç”¨æ—¶çš„å…·ä½“ç´¢å¼•
            }
        """
        import re
        
        result = {
            "has_reference": False,
            "reference_type": None,
            "keywords": [],
            "index": None
        }
        
        # 1. æ—¶é—´å¼•ç”¨æ£€æµ‹
        time_patterns = [
            r'æœ€å¼€å§‹|ä¸€å¼€å§‹|å¼€å¤´|æœ€åˆ|ä¹‹å‰|æ—©äº›æ—¶å€™|åˆšå¼€å§‹',
            r'å›åˆ°.*(å¼€å§‹|æœ€åˆ|ä¹‹å‰)',
            r'å‰é¢.*(è¯´|è®²|æåˆ°)',
        ]
        for pattern in time_patterns:
            if re.search(pattern, message):
                result["has_reference"] = True
                result["reference_type"] = "time"
                logger.info(f"ğŸ” æ£€æµ‹åˆ°æ—¶é—´å¼•ç”¨: {message[:30]}...")
                break
        
        # 2. ç´¢å¼•å¼•ç”¨æ£€æµ‹
        index_patterns = [
            (r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+)[é“ä¸ªå¼ è½®]', 'cn'),
            (r'ç¬¬(\d+)', 'num'),
        ]
        for pattern, ptype in index_patterns:
            match = re.search(pattern, message)
            if match:
                result["has_reference"] = True
                result["reference_type"] = "index"
                # è½¬æ¢ä¸­æ–‡æ•°å­—
                cn_map = {'ä¸€':1,'äºŒ':2,'ä¸‰':3,'å››':4,'äº”':5,'å…­':6,'ä¸ƒ':7,'å…«':8,'ä¹':9,'å':10}
                idx_str = match.group(1)
                if ptype == 'cn' and idx_str in cn_map:
                    result["index"] = cn_map[idx_str]
                elif idx_str.isdigit():
                    result["index"] = int(idx_str)
                logger.info(f"ğŸ” æ£€æµ‹åˆ°ç´¢å¼•å¼•ç”¨: ç¬¬{result['index']}ä¸ª")
                break
        
        # 3. å…³é”®è¯å¼•ç”¨æ£€æµ‹ (å­¦ç§‘/ä¸»é¢˜)
        keyword_patterns = [
            r'(ç‰›é¡¿|ç‰©ç†|å®šå¾‹|æƒ¯æ€§|ä½œç”¨åŠ›|F=ma)',
            r'(åŒ–å­¦|åŒ–å­¦é”®|å…±ä»·é”®|ç¦»å­é”®)',
            r'(å†å²|äºŒæˆ˜|å‡¡å°”èµ›|æ¡çº¦)',
            r'(æ•°å­¦|å‡ ä½•|å‡½æ•°|æ–¹ç¨‹)',
            r'(ç”Ÿç‰©|ç»†èƒ|å…‰åˆä½œç”¨)',
        ]
        for pattern in keyword_patterns:
            matches = re.findall(pattern, message)
            if matches:
                result["keywords"].extend(matches)
        
        if result["keywords"] and not result["has_reference"]:
            # åªæœ‰å…³é”®è¯ä½†æ²¡æœ‰æ˜ç¡®å¼•ç”¨ï¼Œæ ‡è®°ä¸ºå¯èƒ½çš„å…³é”®è¯å¼•ç”¨
            result["has_reference"] = True
            result["reference_type"] = "keyword"
            logger.info(f"ğŸ” æ£€æµ‹åˆ°å…³é”®è¯å¼•ç”¨: {result['keywords']}")
        
        return result
    
    def _retrieve_from_history(
        self, 
        md_content: str, 
        reference: Dict[str, Any],
        all_turns: List[Dict],
        recent_turn_count: int = 5,
        session_mgr: Optional[Any] = None
    ) -> List[Dict]:
        """
        ä»å†å²ä¸­æ£€ç´¢ç›¸å…³å¯¹è¯ï¼ˆæ”¯æŒå½’æ¡£æ–‡ä»¶ï¼‰
        
        Args:
            md_content: MD æ–‡ä»¶å†…å®¹
            reference: _detect_history_reference çš„è¿”å›å€¼
            all_turns: æ‰€æœ‰è§£æå‡ºçš„å¯¹è¯è½®æ¬¡
            recent_turn_count: æœ€è¿‘å·²åŠ è½½çš„è½®æ¬¡æ•°
            session_mgr: ConversationSessionManager å®ä¾‹ï¼ˆç”¨äºè®¿é—®å½’æ¡£æ–‡ä»¶ï¼‰
            
        Returns:
            éœ€è¦é¢å¤–åŠ è½½çš„å†å²å¯¹è¯åˆ—è¡¨
        """
        import re
        
        retrieved = []
        
        if not reference["has_reference"] or not all_turns:
            return retrieved
        
        # æ—©æœŸå¯¹è¯ (ä¸åœ¨æœ€è¿‘5è½®ä¸­çš„)
        early_turns = all_turns[:-recent_turn_count] if len(all_turns) > recent_turn_count else []
        
        ref_type = reference["reference_type"]
        
        # 1. æ—¶é—´å¼•ç”¨ - è¿”å›æœ€æ—©çš„å‡ è½®
        if ref_type == "time":
            if early_turns:
                retrieved = early_turns[:3]  # è¿”å›æœ€æ—©3è½®
            else:
                # ğŸ†• å¦‚æœå½“å‰æ–‡ä»¶æ²¡æœ‰æ—©æœŸå¯¹è¯ï¼Œå°è¯•ä»å½’æ¡£æ–‡ä»¶è·å–
                archived_turns = self._load_from_archive(session_mgr, target_range="earliest")
                if archived_turns:
                    retrieved = archived_turns[:3]
                    logger.info(f"ğŸ”ğŸ“¦ ä»å½’æ¡£æ–‡ä»¶æ£€ç´¢: è¿”å›æœ€æ—© {len(retrieved)} è½®")
                    return retrieved
            logger.info(f"ğŸ” æ—¶é—´å¼•ç”¨æ£€ç´¢: è¿”å›æœ€æ—© {len(retrieved)} è½®")
        
        # 2. ç´¢å¼•å¼•ç”¨ - è¿”å›ç‰¹å®šè½®æ¬¡
        elif ref_type == "index" and reference["index"]:
            idx = reference["index"] - 1  # è½¬ä¸º0-based
            if 0 <= idx < len(all_turns):
                retrieved = [all_turns[idx]]
            else:
                # ğŸ†• ç´¢å¼•è¶…å‡ºå½“å‰èŒƒå›´ï¼Œå°è¯•ä»å½’æ¡£æ–‡ä»¶è·å–
                archived_turns = self._load_from_archive(
                    session_mgr, 
                    target_turn=reference["index"]
                )
                if archived_turns:
                    retrieved = archived_turns
                    logger.info(f"ğŸ”ğŸ“¦ ä»å½’æ¡£æ–‡ä»¶æ£€ç´¢: è¿”å›ç¬¬ {reference['index']} è½®")
                    return retrieved
            logger.info(f"ğŸ” ç´¢å¼•å¼•ç”¨æ£€ç´¢: è¿”å›ç¬¬ {reference['index']} è½®")
        
        # 3. å…³é”®è¯å¼•ç”¨ - æœç´¢åŒ…å«å…³é”®è¯çš„å¯¹è¯
        elif ref_type == "keyword" and reference["keywords"]:
            keywords = reference["keywords"]
            
            # å…ˆæœç´¢å½“å‰æ–‡ä»¶çš„æ—©æœŸå¯¹è¯
            for turn in early_turns:
                user_query = turn.get("user_query", "")
                assistant_text = turn.get("assistant_text", "")
                combined = user_query + assistant_text
                
                for kw in keywords:
                    if kw in combined:
                        if turn not in retrieved:
                            retrieved.append(turn)
                        break
            
            # ğŸ†• å¦‚æœå½“å‰æ–‡ä»¶æ‰¾åˆ°çš„ä¸å¤Ÿï¼Œå°è¯•ä»å½’æ¡£æ–‡ä»¶æœç´¢
            if len(retrieved) < 3:
                archived_turns = self._load_from_archive(
                    session_mgr,
                    keywords=keywords,
                    max_results=3 - len(retrieved)
                )
                if archived_turns:
                    retrieved.extend(archived_turns)
                    logger.info(f"ğŸ”ğŸ“¦ ä»å½’æ¡£æ–‡ä»¶é¢å¤–æ£€ç´¢: æ‰¾åˆ° {len(archived_turns)} è½®")
            
            # æœ€å¤šè¿”å›3è½®
            retrieved = retrieved[:3]
            logger.info(f"ğŸ” å…³é”®è¯å¼•ç”¨æ£€ç´¢: å…±æ‰¾åˆ° {len(retrieved)} è½®ç›¸å…³å¯¹è¯")
        
        return retrieved
    
    def _load_from_archive(
        self,
        session_mgr: Optional[Any],
        target_range: str = None,  # "earliest", "latest"
        target_turn: int = None,   # ç‰¹å®šè½®æ¬¡å·
        keywords: List[str] = None,  # å…³é”®è¯æœç´¢
        max_results: int = 3
    ) -> List[Dict]:
        """
        ğŸ†• ä»å½’æ¡£æ–‡ä»¶åŠ è½½å¯¹è¯è¯¦æƒ…
        
        Args:
            session_mgr: ConversationSessionManager å®ä¾‹
            target_range: "earliest" æˆ– "latest"
            target_turn: ç‰¹å®šè½®æ¬¡å·
            keywords: å…³é”®è¯åˆ—è¡¨ï¼ˆç”¨äºæœç´¢ï¼‰
            max_results: æœ€å¤§è¿”å›æ•°é‡
            
        Returns:
            ä»å½’æ¡£æ–‡ä»¶è§£æå‡ºçš„å¯¹è¯åˆ—è¡¨
        """
        import re
        import json as json_lib
        
        if not session_mgr:
            return []
        
        # è·å–å½’æ¡£æ–‡ä»¶åˆ—è¡¨
        metadata = getattr(session_mgr, 'session_metadata', {})
        archive_files = metadata.get("archive_files", [])
        
        if not archive_files:
            # å°è¯•è‡ªåŠ¨å‘ç°å½’æ¡£æ–‡ä»¶
            storage_path = getattr(session_mgr, 'storage_path', None)
            session_id = getattr(session_mgr, 'current_session_id', None)
            
            if storage_path and session_id:
                from pathlib import Path
                archive_pattern = f"{session_id}_archive_*.md"
                discovered = list(Path(storage_path).glob(archive_pattern))
                archive_files = [{"filename": f.name} for f in discovered]
        
        if not archive_files:
            logger.debug("ğŸ“¦ No archive files found")
            return []
        
        retrieved = []
        
        for archive_info in archive_files:
            if len(retrieved) >= max_results:
                break
            
            archive_filename = archive_info.get("filename") if isinstance(archive_info, dict) else archive_info
            storage_path = getattr(session_mgr, 'storage_path', None)
            
            if not storage_path:
                continue
            
            from pathlib import Path
            archive_path = Path(storage_path) / archive_filename
            
            if not archive_path.exists():
                logger.warning(f"ğŸ“¦ Archive file not found: {archive_path}")
                continue
            
            try:
                content = archive_path.read_text(encoding='utf-8')
                
                # è§£æå½’æ¡£æ–‡ä»¶ä¸­çš„å¯¹è¯
                json_pattern = r'<details>.*?```json\s*(\{[^`]*?"turn_number"[^`]*?\})\s*```'
                json_matches = re.findall(json_pattern, content, re.DOTALL)
                
                archived_turns = []
                for json_str in json_matches:
                    try:
                        data = json_lib.loads(json_str)
                        user_query = data.get("user_query", "")
                        agent_content = data.get("agent_response", {}).get("content", {})
                        assistant_text = agent_content.get("text", "")
                        turn_number = data.get("turn_number", 0)
                        
                        archived_turns.append({
                            "turn_number": turn_number,
                            "user_query": user_query,
                            "assistant_text": assistant_text,
                            "source": f"archive:{archive_filename}"
                        })
                    except json_lib.JSONDecodeError:
                        continue
                
                # æ ¹æ®æ£€ç´¢æ¡ä»¶ç­›é€‰
                if target_range == "earliest":
                    # è¿”å›æœ€æ—©çš„å¯¹è¯
                    archived_turns.sort(key=lambda x: x.get("turn_number", 0))
                    retrieved.extend(archived_turns[:max_results - len(retrieved)])
                
                elif target_turn:
                    # è¿”å›ç‰¹å®šè½®æ¬¡
                    for turn in archived_turns:
                        if turn.get("turn_number") == target_turn:
                            retrieved.append(turn)
                            break
                
                elif keywords:
                    # å…³é”®è¯æœç´¢
                    for turn in archived_turns:
                        if len(retrieved) >= max_results:
                            break
                        combined = turn.get("user_query", "") + turn.get("assistant_text", "")
                        for kw in keywords:
                            if kw in combined:
                                retrieved.append(turn)
                                break
                
                else:
                    # é»˜è®¤è¿”å›è¯¥å½’æ¡£çš„æ‰€æœ‰å†…å®¹
                    retrieved.extend(archived_turns[:max_results - len(retrieved)])
                
                logger.info(f"ğŸ“¦ Loaded {len(retrieved)} turns from archive: {archive_filename}")
                
            except Exception as e:
                logger.error(f"âŒ Failed to load archive {archive_filename}: {e}")
                continue
        
        return retrieved

    async def _load_context(
        self,
        session_mgr: ConversationSessionManager,
        session_id: str,
        token_usage: Dict,
        user_message: str = ""
    ) -> Dict[str, Any]:
        """
        åŠ è½½å†å²ä¸Šä¸‹æ–‡ - æ”¯æŒæ™ºèƒ½æ£€ç´¢æ—©æœŸå†…å®¹
        
        å®ç°:
        1. æ»‘åŠ¨çª—å£: åŠ è½½æœ€è¿‘ 5 è½®
        2. æ™ºèƒ½æ£€ç´¢: æ£€æµ‹ç”¨æˆ·å¼•ç”¨æ—©æœŸå†…å®¹æ—¶ï¼Œä» MD æ£€ç´¢ç›¸å…³å¯¹è¯
        """
        context_lines = []
        turns = 0
        total_chars = 0
        compressed_count = 0
        retrieved_count = 0
        all_parsed_turns = []
        
        try:
            import re
            import json as json_lib
            
            session_file = getattr(session_mgr, 'current_session_file', None)
            md_path = str(session_file) if session_file else None
            
            if md_path and os.path.exists(md_path):
                with open(md_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è§£ææ‰€æœ‰å¯¹è¯è½®æ¬¡
                json_pattern = r'<details>.*?```json\s*(\{[^`]*?"turn_number"[^`]*?\})\s*```'
                json_matches = re.findall(json_pattern, content, re.DOTALL)
                
                for json_str in json_matches:
                    try:
                        data = json_lib.loads(json_str)
                        user_query = data.get("user_query", "")
                        agent_content = data.get("agent_response", {}).get("content", {})
                        assistant_text = agent_content.get("text", "")
                        turn_number = data.get("turn_number", 0)
                        
                        all_parsed_turns.append({
                            "turn_number": turn_number,
                            "user_query": user_query,
                            "assistant_text": assistant_text
                        })
                    except json_lib.JSONDecodeError:
                        continue
                
                # ========== æ™ºèƒ½æ£€ç´¢ ==========
                reference = self._detect_history_reference(user_message)
                retrieved_turns = []
                
                if reference["has_reference"]:
                    # ğŸ†• å³ä½¿å½“å‰æ–‡ä»¶å¯¹è¯å°‘äº5è½®ï¼Œä¹Ÿå°è¯•ä»å½’æ¡£æ–‡ä»¶æ£€ç´¢
                    retrieved_turns = self._retrieve_from_history(
                        content, reference, all_parsed_turns, 
                        recent_turn_count=5,
                        session_mgr=session_mgr  # ğŸ†• ä¼ å…¥ session_mgr ä»¥æ”¯æŒå½’æ¡£æ£€ç´¢
                    )
                    
                    # æ·»åŠ æ£€ç´¢åˆ°çš„æ—©æœŸå¯¹è¯
                    if retrieved_turns:
                        context_lines.append("[ğŸ“š æ£€ç´¢åˆ°çš„æ—©æœŸå¯¹è¯]")
                        for turn in retrieved_turns:
                            context_lines.append(f"T{turn['turn_number']} ç”¨æˆ·: {turn['user_query']}")
                            context_lines.append(f"T{turn['turn_number']} åŠ©æ‰‹: {turn['assistant_text'][:100]}...")
                            context_lines.append("")
                            total_chars += len(turn['user_query']) + 100
                            retrieved_count += 1
                        context_lines.append("[å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡]")
                        logger.info(f"ğŸ” æ™ºèƒ½æ£€ç´¢: é¢å¤–åŠ è½½ {retrieved_count} è½®æ—©æœŸå¯¹è¯")
                
                # ========== æ»‘åŠ¨çª—å£: æœ€è¿‘ 5 è½® ==========
                recent_turns = all_parsed_turns[-5:] if len(all_parsed_turns) > 5 else all_parsed_turns
                
                for turn in recent_turns:
                    user_query = turn["user_query"]
                    assistant_text = turn["assistant_text"][:150]
                    
                    if user_query:
                        context_lines.append(f"ç”¨æˆ·: {user_query}")
                        context_lines.append(f"åŠ©æ‰‹: {assistant_text}...")
                        context_lines.append("")
                        
                        total_chars += len(user_query) + len(assistant_text)
                        turns += 1
                
                if turns > 0:
                    logger.info(f"ğŸ“š Loaded {turns} recent + {retrieved_count} retrieved turns")
                else:
                    logger.warning(f"âš ï¸ No conversation history found in MD")
                
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to load MD history: {e}")
        
        # ä» session_metadata è·å–è¡¥å……ä¿¡æ¯
        metadata = getattr(session_mgr, 'session_metadata', {})
        
        total_turns = getattr(session_mgr, 'turn_counter', 0)
        if total_turns == 0:
            total_turns = metadata.get("total_turns", turns)
        
        # è·å–å‹ç¼©æ‘˜è¦ï¼ˆå¦‚æœæœ‰ï¼‰
        summary = metadata.get("compressed_summary", "")
        if summary:
            context_lines.insert(0, f"[å¯¹è¯æ‘˜è¦] {summary}\n")
            compressed_count = 1
            total_chars += len(summary)
        
        context = "\n".join(context_lines)
        
        return {
            "context": context,
            "stats": {
                "turns": total_turns,
                "loaded_turns": turns,
                "retrieved_turns": retrieved_count,  # ğŸ†• æ£€ç´¢åˆ°çš„æ—©æœŸè½®æ•°
                "chars": total_chars,
                "compressed": compressed_count
            }
        }
    
    def _build_prompt(
        self,
        message: str,
        history_context: str,
        file_uris: Optional[List[str]]
    ) -> str:
        """æ„å»º LLM prompt"""
        
        # ç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å­¦ä¹ åŠ©æ‰‹ï¼Œä¸“æ³¨äºå¸®åŠ©ç”¨æˆ·å­¦ä¹ å’Œç†è§£çŸ¥è¯†ã€‚

ä½ çš„ç‰¹ç‚¹:
- å›ç­”æ¸…æ™°ã€å‡†ç¡®ã€æœ‰æ¡ç†
- å–„äºç”¨ç®€å•çš„è¯­è¨€è§£é‡Šå¤æ‚æ¦‚å¿µ
- èƒ½å¤Ÿè¯†åˆ«å’Œåˆ†æå›¾ç‰‡ã€æ–‡æ¡£å†…å®¹
- è®°ä½å¯¹è¯å†å²ï¼Œä¿æŒä¸Šä¸‹æ–‡è¿è´¯

è¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œè¯­è¨€è‡ªç„¶å‹å¥½ã€‚"""

        # å†å²ä¸Šä¸‹æ–‡
        context_section = ""
        if history_context:
            context_section = f"""
### å¯¹è¯å†å²
{history_context}
"""

        # æ–‡ä»¶è¯´æ˜
        file_section = ""
        if file_uris:
            file_names = [uri.split('/')[-1] for uri in file_uris]
            file_section = f"\n### ç”¨æˆ·é™„ä»¶\n{', '.join(file_names)}\n"

        # å®Œæ•´ prompt
        prompt = f"""{system_prompt}
{context_section}
{file_section}
### ç”¨æˆ·æ¶ˆæ¯
{message}

è¯·å›å¤:"""

        return prompt
    
    async def _generate_response(
        self,
        prompt: str,
        file_uris: Optional[List[str]],
        token_usage: Dict
    ) -> Dict[str, Any]:
        """è°ƒç”¨ LLM ç”Ÿæˆå›å¤"""
        
        try:
            result = await self.gemini.generate(
                prompt=prompt,
                model="gemini-2.5-flash",
                response_format="text",
                max_tokens=2000,
                temperature=0.7,
                file_uris=file_uris
            )
            
            # æå– token ä½¿ç”¨
            usage = result.get("usage", {})
            token_usage["llm_generation"]["input"] = usage.get("input_tokens", 0)
            token_usage["llm_generation"]["output"] = usage.get("output_tokens", 0)
            token_usage["llm_generation"]["total"] = usage.get("total_tokens", 0)
            
            return {
                "text": result.get("content", ""),
                "usage": usage
            }
            
        except Exception as e:
            logger.error(f"âŒ LLM generation failed: {e}")
            return {
                "text": "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚",
                "usage": {}
            }
    
    async def _save_turn(
        self,
        session_mgr: ConversationSessionManager,
        user_message: str,
        assistant_response: str,
        file_uris: Optional[List[str]],
        token_usage: Dict
    ):
        """ä¿å­˜å¯¹è¯è½®æ¬¡ - å¤ç”¨ç°æœ‰ MD session å­˜å‚¨é€»è¾‘"""
        
        # æ„å»º turn_dataï¼ˆå…¼å®¹ç°æœ‰æ ¼å¼ï¼‰
        turn_data = {
            "user_query": user_message,
            "agent_response": {
                "skill": "chat",
                "artifact_id": "",
                "content": {"text": assistant_response},
                "topic": ""
            },
            "response_type": "text",
            "timestamp": datetime.now(),
            "intent": {
                "intent": "chat",
                "topic": "",
                "confidence": 1.0,
                "parameters": {"file_uris": file_uris} if file_uris else {},
                "raw_text": user_message
            },
            "metadata": {
                "input_tokens": token_usage.get("llm_generation", {}).get("input", 0),
                "output_tokens": token_usage.get("llm_generation", {}).get("output", 0),
                "model": "gemini-2.5-flash",
                "has_files": bool(file_uris),
                "file_count": len(file_uris) if file_uris else 0
            }
        }
        
        # ä½¿ç”¨ç°æœ‰çš„ append_turn æ–¹æ³•ä¿å­˜åˆ° MD
        await session_mgr.append_turn(turn_data)
    
    async def _check_and_compress(
        self,
        session_mgr: ConversationSessionManager,
        token_usage: Dict
    ) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸Šä¸‹æ–‡å‹ç¼©
        
        å¤ç”¨ç°æœ‰ ConversationSessionManager çš„å‹ç¼©é€»è¾‘
        å‹ç¼©ç”± session_mgr åœ¨ append_turn æ—¶è‡ªåŠ¨è§¦å‘
        è¿™é‡Œåªæ£€æŸ¥æ˜¯å¦å‘ç”Ÿäº†å‹ç¼©ï¼Œå¹¶è®°å½• token
        """
        # ä» MemoryTokenTracker è·å–å‹ç¼© tokenï¼ˆå¦‚æœæœ‰ï¼‰
        try:
            from app.services.memory_token_tracker import MemoryTokenTracker
            tracker = MemoryTokenTracker()
            compression_usage = tracker.get_and_clear_usage()
            
            if compression_usage:
                token_usage["context_compression"]["input"] = compression_usage.get("prompt_tokens", 0)
                token_usage["context_compression"]["output"] = compression_usage.get("completion_tokens", 0)
                token_usage["context_compression"]["total"] = (
                    compression_usage.get("prompt_tokens", 0) + 
                    compression_usage.get("completion_tokens", 0)
                )
                logger.info(f"ğŸ—œï¸ Compression tokens recorded: {token_usage['context_compression']['total']}")
                return True
        except Exception as e:
            logger.debug(f"No compression this turn: {e}")
        
        return False
    
    async def _record_stats(
        self,
        user_id: str,
        session_id: str,
        message: str,
        token_usage: Dict,
        file_uris: Optional[List[str]]
    ):
        """è®°å½• Token ç»Ÿè®¡ - å¤ç”¨ç°æœ‰ TokenStatsService"""
        
        self.token_stats.record_usage(
            user_id=user_id,
            session_id=session_id,
            message=message[:50],
            intent="chat",
            content_type="text",
            token_usage={
                "intent_router": {"method": "none", "tokens": 0},
                "skill_execution": {
                    "source": "gemini",
                    "model": "gemini-2.5-flash",
                    "prompt_tokens": token_usage["llm_generation"]["input"],
                    "completion_tokens": token_usage["llm_generation"]["output"],
                    "total_tokens": token_usage["llm_generation"]["total"]
                },
                "memory_operations": {
                    "compression_input": token_usage["context_compression"]["input"],
                    "compression_output": token_usage["context_compression"]["output"],
                    "compression_tokens": token_usage["context_compression"]["total"]
                },
                "total_internal_tokens": token_usage["total"]["total"]
            },
            file_uris=file_uris
        )


# ============= API ç«¯ç‚¹ =============

# å…¨å±€æœåŠ¡å®ä¾‹
_chat_service: Optional[PureChatService] = None

def get_chat_service() -> PureChatService:
    global _chat_service
    if _chat_service is None:
        _chat_service = PureChatService()
    return _chat_service


@router.post("/send", response_model=ChatResponse)
async def send_message(request: ChatRequest):
    """
    å‘é€ Chat æ¶ˆæ¯
    
    æ”¯æŒ:
    - çº¯æ–‡æœ¬æ¶ˆæ¯
    - è¯­éŸ³è½¬æ–‡æœ¬ï¼ˆvoice_textï¼‰
    - å¤šå›¾ç‰‡é™„ä»¶ï¼ˆfile_urisï¼‰
    - å¤šæ–‡æ¡£é™„ä»¶ï¼ˆfile_urisï¼‰
    
    è¿”å›:
    - çº¯æ–‡æœ¬å›å¤
    - Token ä½¿ç”¨ç»Ÿè®¡
    - ä¸Šä¸‹æ–‡ç®¡ç†çŠ¶æ€
    """
    try:
        service = get_chat_service()
        
        result = await service.chat(
            message=request.message,
            user_id=request.user_id,
            session_id=request.session_id,
            file_uris=request.file_uris,
            voice_text=request.voice_text
        )
        
        return ChatResponse(
            code=0,
            msg="success",
            data={
                "text": result["response"],
                "session_id": result["session_id"],
                "token_usage": result["token_usage"],
                "context_stats": result["context_stats"],
                "generation_time": result["generation_time"]
            }
        )
        
    except Exception as e:
        logger.error(f"âŒ Chat API error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/session/{user_id}/{session_id}")
async def get_session_info(user_id: str, session_id: str):
    """è·å–ä¼šè¯ä¿¡æ¯"""
    try:
        service = get_chat_service()
        session_mgr = service.memory_manager.get_conversation_session_manager(user_id)
        
        # åŠ è½½æŒ‡å®šä¼šè¯
        await session_mgr.start_or_continue_session(
            user_message="get_info",
            session_id=session_id
        )
        
        history = getattr(session_mgr, 'session_history', [])
        
        return {
            "code": 0,
            "data": {
                "session_id": session_id,
                "user_id": user_id,
                "turns": len(history),
                "compressed_turns": sum(1 for t in history if t.get("compressed")),
                "total_chars": sum(
                    len(t.get("user", "")) + len(t.get("assistant", ""))
                    for t in history
                )
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/stats/today")
async def get_today_stats():
    """è·å–ä»Šæ—¥ Token ç»Ÿè®¡"""
    service = get_chat_service()
    return {
        "code": 0,
        "data": service.token_stats.get_today_summary()
    }

