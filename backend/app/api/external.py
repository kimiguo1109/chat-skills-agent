"""
External API - å¤–éƒ¨æœåŠ¡æ¥å£ï¼ˆè–„å°è£…å±‚ï¼‰

æš´éœ² Quiz å’Œ Flashcard çš„ API æ¥å£ç»™å¤–éƒ¨å‰ç«¯å¼€å‘äººå‘˜
å†…éƒ¨è°ƒç”¨å®Œæ•´çš„ skill æ¡†æ¶æµç¨‹ï¼š
  Intent Router â†’ Skill Orchestrator â†’ Memory Manager â†’ MD å­˜å‚¨

è¿™ä¸æ˜¯ç‹¬ç«‹çš„ APIï¼Œè€Œæ˜¯å¯¹ç°æœ‰ /api/agent/chat æµç¨‹çš„ç®€åŒ–å°è£…ï¼Œ
ä¸“é—¨ä¸ºéœ€è¦è·å–ç»“æ„åŒ– JSON çš„å‰ç«¯å¼€å‘äººå‘˜è®¾è®¡ã€‚

æ”¯æŒé™„ä»¶ä¸Šä¼ åˆ° GCS (gs://kimi-dev/)
"""
import logging
import time
import re
import json
import asyncio
import aiohttp
from datetime import datetime
from typing import Dict, Any, List, Optional
from fastapi import APIRouter, HTTPException, Depends, UploadFile, File, Form, Header, Query
from pydantic import BaseModel, Field

from app.core import SkillOrchestrator, MemoryManager
from app.core.intent_router import IntentRouter
from app.core.request_context import set_user_api_token, clear_user_api_token
from app.dependencies import get_memory_manager
from app.services.token_stats_service import get_token_stats_service
from app.services.memory_token_tracker import get_memory_token_tracker

logger = logging.getLogger(__name__)


# ============= ğŸ”’ å¹¶å‘æ§åˆ¶ï¼ˆApp ç«¯ï¼‰ =============

# Per-session é”ï¼Œé˜²æ­¢åŒä¸€ä¼šè¯çš„å¹¶å‘ä¿®æ”¹
_session_locks: Dict[str, asyncio.Lock] = {}
_lock_manager_lock = asyncio.Lock()


async def get_session_lock(session_id: str) -> asyncio.Lock:
    """è·å–æˆ–åˆ›å»º session çº§åˆ«çš„é”"""
    async with _lock_manager_lock:
        if session_id not in _session_locks:
            _session_locks[session_id] = asyncio.Lock()
        return _session_locks[session_id]


async def cleanup_session_lock(session_id: str):
    """æ¸…ç†ä¸å†ä½¿ç”¨çš„é”ï¼ˆå¯é€‰ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰"""
    async with _lock_manager_lock:
        if session_id in _session_locks:
            lock = _session_locks[session_id]
            if not lock.locked():
                del _session_locks[session_id]


# ============= ğŸ†• ç¯å¢ƒé…ç½® =============

# æ ¹æ® environment header é€‰æ‹© API åŸºåœ°å€
STUDYX_API_HOSTS = {
    "dev": "https://test.istudyx.com",
    "test": "https://test.istudyx.com", 
    "prod": "https://mapp.studyxapp.com",  # ç”Ÿäº§ç¯å¢ƒ (App ç«¯)
}

def get_studyx_api_host(environment: str = "test") -> str:
    """æ ¹æ® environment è·å– StudyX API åŸºåœ°å€"""
    return STUDYX_API_HOSTS.get(environment, STUDYX_API_HOSTS["test"])

def get_studyx_lang_api(environment: str = "test") -> str:
    """è·å–ç”¨æˆ·è¯­è¨€ API åœ°å€"""
    return f"{get_studyx_api_host(environment)}/api/studyx/v5/cloud/ai/getLangByUserId"

def get_studyx_question_api(environment: str = "test") -> str:
    """è·å–é¢˜ç›®è¯¦æƒ… API åœ°å€"""
    return f"{get_studyx_api_host(environment)}/api/studyx/v5/cloud/ai/newQueryQuestionInfo"

# ============= ğŸ†• ç”¨æˆ·è¯­è¨€è®¾ç½®è·å– =============

# StudyX API è·å–ç”¨æˆ·è¯­è¨€è®¾ç½®ï¼ˆé»˜è®¤æµ‹è¯•ç¯å¢ƒï¼Œå…¼å®¹æ—§ä»£ç ï¼‰
STUDYX_LANG_API = "https://test.istudyx.com/api/studyx/v5/cloud/ai/getLangByUserId"

# qLang åˆ° language code çš„æ˜ å°„
QLANG_TO_CODE = {
    # è‡ªåŠ¨æ£€æµ‹
    "Detect input": "auto",
    "Automatic": "auto",
    "Auto": "auto",
    # è‹±è¯­
    "English": "en",
    # ä¸­æ–‡ - æ”¯æŒå¤šç§å†™æ³•
    "ç®€ä½“ä¸­æ–‡": "zh",
    "Simplified Chinese": "zh",
    "Chinese": "zh",
    "Chinese (Simplified)": "zh",
    "ç¹é«”ä¸­æ–‡": "zh-TW",
    "Traditional Chinese": "zh-TW",
    "Chinese (Traditional)": "zh-TW",
    # æ—¥è¯­
    "æ—¥æœ¬èª": "ja",
    "Japanese": "ja",
    # éŸ©è¯­
    "í•œêµ­ì–´": "ko",
    "Korean": "ko",
    # æ³•è¯­
    "FranÃ§ais": "fr",
    "French": "fr",
    # è¥¿ç­ç‰™è¯­
    "EspaÃ±ol": "es",
    "Spanish": "es",
    # è‘¡è„ç‰™è¯­
    "PortuguÃªs": "pt",
    "Portuguese": "pt",
    # å¾·è¯­
    "Deutsch": "de",
    "German": "de",
    # æ„å¤§åˆ©è¯­
    "Italiano": "it",
    "Italian": "it",
    # ä¿„è¯­
    "Ğ ÑƒÑÑĞºĞ¸Ğ¹": "ru",
    "Russian": "ru",
    # è¶Šå—è¯­
    "Tiáº¿ng Viá»‡t": "vi",
    "Vietnamese": "vi",
    # æ³°è¯­
    "à¸ à¸²à¸©à¸²à¹„à¸—à¸¢": "th",
    "Thai": "th",
    # å°åœ°è¯­
    "à¤¹à¤¿à¤‚à¤¦à¥€": "hi",
    "Hindi": "hi",
    # å°å°¼è¯­
    "Bahasa Indonesia": "id",
    "Indonesian": "id",
    # é©¬æ¥è¯­
    "Melayu": "ms",
    "Malay": "ms",
    # åœŸè€³å…¶è¯­
    "TÃ¼rkÃ§e": "tr",
    "Turkish": "tr",
    # æ³¢å…°è¯­
    "Polski": "pl",
    "Polish": "pl",
    # è·å…°è¯­
    "Nederlands": "nl",
    "Dutch": "nl",
    # ç½—é©¬å°¼äºšè¯­
    "RomÃ¢nÄƒ": "ro",
    "Romanian": "ro",
    # æ·å…‹è¯­
    "ÄŒeÅ¡tina": "cs",
    "Czech": "cs",
    # æ–¯æ´›ä¼å…‹è¯­
    "SlovenÄina": "sk",
    "Slovak": "sk",
    # åŒˆç‰™åˆ©è¯­
    "Magyar": "hu",
    "Hungarian": "hu",
    # è²å¾‹å®¾è¯­
    "Tagalog/Filipino": "tl",
    "Filipino": "tl",
    "Tagalog": "tl",
    # åŒ—æ¬§è¯­è¨€
    "Norwegian": "no",
    "Danish/Dansk": "da",
    "Danish": "da",
    "Finnish/Suomi": "fi",
    "Finnish": "fi",
}


async def get_user_language_from_studyx(token: str, environment: str = "test") -> str:
    """
    ä» StudyX API è·å–ç”¨æˆ·çš„è¯­è¨€è®¾ç½®
    
    Args:
        token: ç”¨æˆ·ç™»å½• token
        environment: ç¯å¢ƒæ ‡è¯† (dev/test/prod)
    
    Returns:
        str: è¯­è¨€ä»£ç  (en, zh, ja, auto ç­‰)
    """
    if not token:
        logger.warning("âš ï¸ No token provided, using auto language detection")
        return "auto"
    
    try:
        # ğŸ†• æ ¹æ® environment é€‰æ‹© API åœ°å€
        api_url = get_studyx_lang_api(environment)
        logger.info(f"ğŸŒ Getting user language from: {api_url} (env={environment})")
        
        async with aiohttp.ClientSession() as session:
            headers = {"token": token}
            async with session.get(api_url, headers=headers, timeout=5) as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"ğŸŒ StudyX language API response: code={data.get('code')}, data={data.get('data')}, msg={data.get('msg')}")
                    
                    if data.get("code") == 0 and data.get("data"):
                        qlang = data["data"].get("qlang", "English")
                        lang_code = QLANG_TO_CODE.get(qlang, "auto")
                        logger.info(f"ğŸŒ User language from StudyX: {qlang} â†’ {lang_code}")
                        return lang_code
                    elif data.get("code") == -1 and "no user preferences" in data.get("msg", "").lower():
                        # ğŸ†• ç”¨æˆ·æ²¡æœ‰è®¾ç½®è¯­è¨€åå¥½ï¼ˆcode=-1ï¼‰ï¼Œè¿”å›é»˜è®¤è‹±è¯­
                        logger.info(f"ğŸŒ User has no language preference set (code=-1), using default: en")
                        return "en"
                    elif data.get("code") == 0 and not data.get("data"):
                        # ç”¨æˆ·æ²¡æœ‰è®¾ç½®è¯­è¨€åå¥½ï¼ˆdata ä¸ºç©ºï¼‰ï¼Œè¿”å›é»˜è®¤è‹±è¯­
                        logger.info(f"ğŸŒ User has no language preference set (empty data), using default: en")
                        return "en"
                    else:
                        logger.warning(f"âš ï¸ StudyX API returned error: code={data.get('code')}, msg={data.get('msg')}")
                else:
                    logger.warning(f"âš ï¸ StudyX API HTTP error: {response.status}")
    except asyncio.TimeoutError:
        logger.warning("âš ï¸ StudyX language API timeout, using auto")
    except Exception as e:
        logger.warning(f"âš ï¸ Failed to get user language from StudyX: {e}")
    
    return "auto"


# ============= ğŸ†• é¢˜ç›®ä¸Šä¸‹æ–‡è·å– =============

# StudyX API è·å–é¢˜ç›®è¯¦æƒ…ï¼ˆé»˜è®¤æµ‹è¯•ç¯å¢ƒï¼Œå…¼å®¹æ—§ä»£ç ï¼‰
STUDYX_QUESTION_INFO_API = "https://test.istudyx.com/api/studyx/v5/cloud/ai/newQueryQuestionInfo"


async def fetch_question_context_from_studyx(qid: str, token: str, environment: str = "test") -> Optional[str]:
    """
    ä» StudyX API è·å–é¢˜ç›®ä¸Šä¸‹æ–‡
    
    Args:
        qid: é¢˜ç›® slug (å¦‚ 96rhhg4)
        token: ç”¨æˆ·ç™»å½• token
        environment: ç¯å¢ƒæ ‡è¯† (dev/test/prod)
    
    Returns:
        str: é¢˜ç›®ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼Œæ ¼å¼ä¸º:
            Question: <é¢˜ç›®å†…å®¹>
            Answer: <ç­”æ¡ˆå†…å®¹>
            
        å¦‚æœè·å–å¤±è´¥è¿”å› None
    """
    if not qid or not token:
        logger.warning(f"âš ï¸ Missing qid or token for question context fetch")
        return None
    
    try:
        # ğŸ†• æ ¹æ® environment é€‰æ‹© API åœ°å€
        api_url = get_studyx_question_api(environment)
        logger.info(f"ğŸ“¡ Fetching question context from: {api_url} (env={environment}, qid={qid})")
        
        async with aiohttp.ClientSession() as session:
            headers = {"token": token}
            params = {"id": qid, "type": "3", "routeType": "1"}
            
            async with session.get(
                api_url, 
                headers=headers, 
                params=params,
                timeout=10
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"ğŸ“¡ StudyX question API response: code={data.get('code')}, msg={data.get('msg')}")
                    if data.get("code") == 0 and data.get("data"):
                        qnt_info = data["data"].get("qntInfo", {})
                        
                        # æå–é¢˜ç›®æ–‡æœ¬ï¼ˆä¼˜å…ˆä½¿ç”¨ questionTextï¼Œå…¶æ¬¡ imgTextï¼‰
                        question_text = qnt_info.get("questionText") or qnt_info.get("imgText") or ""
                        
                        # æå–ç­”æ¡ˆæ–‡æœ¬
                        answer_list = qnt_info.get("answerList", [])
                        answer_text = ""
                        if answer_list:
                            # è·å–ç¬¬ä¸€ä¸ªç­”æ¡ˆçš„å†…å®¹
                            first_answer = answer_list[0]
                            answer_text = first_answer.get("answerText", "")
                        
                        if question_text or answer_text:
                            context_parts = []
                            if question_text:
                                context_parts.append(f"Question:\n{question_text}")
                            if answer_text:
                                # æˆªå–ç­”æ¡ˆï¼Œé¿å…å¤ªé•¿ï¼ˆä¿ç•™å‰2000å­—ç¬¦ï¼‰
                                if len(answer_text) > 2000:
                                    answer_text = answer_text[:2000] + "...(truncated)"
                                context_parts.append(f"Answer/Solution:\n{answer_text}")
                            
                            context = "\n\n".join(context_parts)
                            logger.info(f"âœ… Fetched question context: qid={qid}, len={len(context)}")
                            return context
                        else:
                            logger.warning(f"âš ï¸ Empty question context for qid={qid}")
                    else:
                        logger.warning(f"âš ï¸ StudyX question API error: {data.get('msg')}")
                else:
                    logger.warning(f"âš ï¸ StudyX question API HTTP error: {response.status}")
    except asyncio.TimeoutError:
        logger.warning(f"âš ï¸ StudyX question API timeout for qid={qid}")
    except Exception as e:
        logger.warning(f"âš ï¸ Failed to fetch question context: {e}")
    
    return None


router = APIRouter(prefix="/api/external", tags=["external"])


# ============= æ•°é‡æå–é€»è¾‘ =============

CHINESE_NUMBERS = {
    'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5,
    'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10,
    'ä¸¤': 2, 'å‡ ': 3
}


def extract_quantity_from_text(text: str, skill_type: str = "quiz") -> Optional[int]:
    """ä»æ–‡æœ¬ä¸­æå–æ•°é‡"""
    if skill_type == "quiz":
        unit_pattern = r'[é“ä¸ªä»½é¢˜]'
    else:
        unit_pattern = r'[å¼ ä¸ªä»½å¡]'
    
    # é˜¿æ‹‰ä¼¯æ•°å­—
    arabic_match = re.search(rf'(\d+)\s*{unit_pattern}', text)
    if arabic_match:
        return int(arabic_match.group(1))
    
    # ä¸­æ–‡æ•°å­—
    chinese_match = re.search(rf'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åä¸¤å‡ ])\s*{unit_pattern}', text)
    if chinese_match:
        return CHINESE_NUMBERS.get(chinese_match.group(1))
    
    return None


# ============= Dependency =============

def get_skill_orchestrator(
    memory_manager: MemoryManager = Depends(get_memory_manager)
) -> SkillOrchestrator:
    """è·å– SkillOrchestrator å®ä¾‹"""
    return SkillOrchestrator(memory_manager=memory_manager)


# ============= Request/Response Models =============

class InputItem(BaseModel):
    """è¾“å…¥é¡¹ - æ”¯æŒæ–‡æœ¬å’Œæ–‡ä»¶ URI"""
    text: Optional[str] = Field(None, description="è¾“å…¥æ–‡æœ¬å†…å®¹")
    fileUri: Optional[str] = Field(None, description="GCS æ–‡ä»¶ URI (gs://kimi-dev/...)")


class ExternalRequest(BaseModel):
    """å¤–éƒ¨ API è¯·æ±‚æ ¼å¼ï¼ˆFlashcard/Quiz ä¸“ç”¨ï¼‰"""
    inputList: List[InputItem] = Field(..., description="è¾“å…¥åˆ—è¡¨ï¼ˆæ”¯æŒ text å’Œ fileUriï¼‰")
    cardSize: Optional[int] = Field(None, description="é—ªå¡æ•°é‡ï¼ˆå¯é€‰ï¼Œä¼šè‡ªåŠ¨ä» text ä¸­æå–ï¼‰")
    questionCount: Optional[int] = Field(None, description="é¢˜ç›®æ•°é‡ï¼ˆå¯é€‰ï¼Œä¼šè‡ªåŠ¨ä» text ä¸­æå–ï¼‰")
    outLanguage: Optional[str] = Field(None, description="è¾“å‡ºè¯­è¨€")
    user_id: Optional[str] = Field("anonymous", description="ç”¨æˆ·ID")
    session_id: Optional[str] = Field(None, description="ä¼šè¯IDï¼ˆä¸ä¼ åˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰")


class FileInfo(BaseModel):
    """
    ç»Ÿä¸€çš„æ–‡ä»¶ä¿¡æ¯ç»“æ„ - æ”¯æŒå›¾ç‰‡å’Œæ–‡æ¡£æ··åˆä¸Šä¼ 
    
    ç”¨äºè¯·æ±‚å’Œå“åº”ä¸­çš„æ–‡ä»¶ä¿¡æ¯å›æ˜¾
    """
    type: str = Field(..., description="æ–‡ä»¶ç±»å‹: image æˆ– document")
    url: Optional[str] = Field(None, description="æ–‡ä»¶çš„ HTTP URLï¼ˆå›¾ç‰‡å¿…å¡«ï¼Œæ–‡æ¡£å¯é€‰ï¼‰")
    name: Optional[str] = Field(None, description="æ–‡ä»¶åï¼ˆæ–‡æ¡£å¿…å¡«ï¼Œå›¾ç‰‡å¯é€‰ï¼‰")
    
    class Config:
        json_schema_extra = {
            "examples": [
                {"type": "image", "url": "https://cdn.studyx.com/img.jpg"},
                {"type": "document", "name": "æ•°å­¦ç¬”è®°.pdf", "url": "https://cdn.studyx.com/doc.pdf"}
            ]
        }


class ChatRequest(BaseModel):
    """
    é€šç”¨èŠå¤©è¯·æ±‚æ ¼å¼ - æ”¯æŒå¤šé™„ä»¶å’Œå¼•ç”¨æ–‡æœ¬
    
    ä¸¤ç§ä½¿ç”¨åœºæ™¯ï¼š
    
    åœºæ™¯ A - å¼•ç”¨æ–‡æœ¬æ¨¡å¼ï¼ˆç‚¹å‡»æ­¥éª¤çš„ ? æŒ‰é’®ï¼‰ï¼š
        - referenced_text: å¿…å¡«ï¼Œç”¨æˆ·é€‰ä¸­çš„æ–‡æœ¬
        - message: å¿…å¡«ï¼Œç”¨æˆ·çš„é—®é¢˜ï¼ˆUI å¼ºåˆ¶è¦æ±‚è¾“å…¥ï¼‰
        
    åœºæ™¯ B - å¿«æ·æŒ‰é’®æ¨¡å¼ï¼ˆExplain/Make simpler/Common mistakesï¼‰ï¼š
        - action_type: å¿…å¡«ï¼Œå¿«æ·æ“ä½œç±»å‹
        - message: å¯é€‰ï¼Œä¸å¡«åˆ™ä½¿ç”¨é»˜è®¤æç¤º
    
    é¢˜ç›®å…³è”ï¼š
        - question_id: é¢˜ç›® IDï¼ˆaiQuestionIdï¼‰
        - answer_id: ç­”æ¡ˆ IDï¼ˆç”¨æˆ·ç­”é¢˜è®°å½• IDï¼‰
        
    æ–‡ä»¶ä¸Šä¼ ï¼š
        - file_uris: GCS æ–‡ä»¶ URIï¼ˆAI å¤„ç†ç”¨ï¼‰
        - files: ç»Ÿä¸€çš„æ–‡ä»¶ä¿¡æ¯æ•°ç»„ï¼ˆå‰ç«¯å›æ˜¾ç”¨ï¼Œæ”¯æŒå¤šå›¾ç‰‡+å¤šæ–‡æ¡£æ··åˆï¼‰
    """
    message: str = Field("", description="ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¼•ç”¨æ–‡æœ¬æ¨¡å¼ä¸‹å¿…å¡«ï¼‰")
    file_uri: Optional[str] = Field(None, description="å•ä¸ª GCS æ–‡ä»¶ URIï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰")
    file_uris: Optional[List[str]] = Field(None, description="å¤šä¸ª GCS æ–‡ä»¶ URI æ•°ç»„ï¼ˆAI å¤„ç†ç”¨ï¼‰")
    # ğŸ†• ç»Ÿä¸€çš„æ–‡ä»¶ä¿¡æ¯æ•°ç»„ - æ”¯æŒå¤šå›¾ç‰‡+å¤šæ–‡æ¡£æ··åˆä¸Šä¼ 
    files: Optional[List[FileInfo]] = Field(None, description="æ–‡ä»¶ä¿¡æ¯æ•°ç»„ï¼ˆå‰ç«¯å›æ˜¾ç”¨ï¼‰")
    # å…¼å®¹æ—§ç‰ˆå•æ–‡ä»¶å­—æ®µï¼ˆå°†è¢« files æ›¿ä»£ï¼‰
    file_url: Optional[str] = Field(None, description="[å…¼å®¹] å•ä¸ªå›¾ç‰‡ HTTP URL")
    file_name: Optional[str] = Field(None, description="[å…¼å®¹] å•ä¸ªæ–‡æ¡£æ–‡ä»¶å")
    user_id: Optional[str] = Field("anonymous", description="ç”¨æˆ·ID")
    session_id: Optional[str] = Field(None, description="ä¼šè¯IDï¼ˆä¸ä¼ åˆ™è‡ªåŠ¨ç”Ÿæˆï¼Œä¼˜å…ˆä½¿ç”¨ question_id+answer_idï¼‰")
    # ğŸ†• é¢˜ç›®å…³è” - èŠå¤©å†å²ä¸é¢˜ç›®ç»‘å®š
    question_id: Optional[str] = Field(None, description="é¢˜ç›® ID (aiQuestionId)")
    answer_id: Optional[str] = Field(None, description="ç­”æ¡ˆ ID (answerId)")
    # ğŸ†• å¼•ç”¨æ–‡æœ¬æ”¯æŒ - ç”¨æˆ·ä»æ–‡æ¡£ä¸­é€‰ä¸­çš„å†…å®¹ï¼ˆç‚¹å‡» ? æŒ‰é’®è§¦å‘ï¼‰
    referenced_text: Optional[str] = Field(None, description="å¼•ç”¨çš„æ–‡æœ¬å†…å®¹ï¼ˆå½“æä¾›æ—¶ï¼Œmessage å¿…å¡«ï¼‰")
    # ğŸ†• å¿«æ·æ“ä½œç±»å‹ - ç‹¬ç«‹çš„å¿«æ·æŒ‰é’®åŠŸèƒ½
    action_type: Optional[str] = Field(None, description="å¿«æ·æ“ä½œ: explain_concept, make_simpler, common_mistakes")
    # ğŸ†• è¯­è¨€è®¾ç½® - æ§åˆ¶å›å¤è¯­è¨€ï¼ˆæ”¯æŒå¤šè¯­è¨€ï¼‰
    # æ”¯æŒ: auto(è‡ªåŠ¨æ£€æµ‹), en(è‹±æ–‡), zh/zh-CN(ç®€ä½“ä¸­æ–‡), zh-TW(ç¹ä½“ä¸­æ–‡), 
    # ja(æ—¥è¯­), ko(éŸ©è¯­), fr(æ³•è¯­), es(è¥¿ç­ç‰™è¯­), pt(è‘¡è„ç‰™è¯­), de(å¾·è¯­), 
    # it(æ„å¤§åˆ©è¯­), ru(ä¿„è¯­), vi(è¶Šå—è¯­), th(æ³°è¯­), hi(å°åœ°è¯­), id(å°å°¼è¯­),
    # ms(é©¬æ¥è¯­), tr(åœŸè€³å…¶è¯­), pl(æ³¢å…°è¯­), nl(è·å…°è¯­), ro(ç½—é©¬å°¼äºšè¯­),
    # cs(æ·å…‹è¯­), sk(æ–¯æ´›ä¼å…‹è¯­), hu(åŒˆç‰™åˆ©è¯­), tl(è²å¾‹å®¾è¯­), no(æŒªå¨è¯­),
    # da(ä¸¹éº¦è¯­), fi(èŠ¬å…°è¯­)
    language: Optional[str] = Field(None, description="å›å¤è¯­è¨€: ä¸ä¼ åˆ™è‡ªåŠ¨ä»ç”¨æˆ·è®¾ç½®è·å–; å¯é€‰å€¼: auto, en, zh, zh-TW, ja, ko, fr, es, pt, de, it, ru, vi, th ç­‰")
    # ğŸ†• é¢˜ç›®ä¸Šä¸‹æ–‡ - ç”¨äºæ–° session æ—¶æä¾›é¢˜ç›®å†…å®¹
    qid: Optional[str] = Field(None, description="é¢˜ç›® slugï¼ˆä» URL è·å–ï¼Œå¦‚ 96rhhg4ï¼‰ï¼Œç”¨äºè‡ªåŠ¨è·å–é¢˜ç›®ä¸Šä¸‹æ–‡")
    resource_id: Optional[str] = Field(None, description="é¢˜ç›®èµ„æº IDï¼ˆä¸ qid ä½œç”¨ç›¸åŒï¼Œå‰ç«¯å¯ç”¨æ­¤å­—æ®µï¼‰")  # ğŸ†• å…¼å®¹å‰ç«¯å­—æ®µå
    # ğŸ†• ç›´æ¥ä¼ å…¥é¢˜ç›®ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå‰ç«¯å·²æœ‰ï¼Œå¯ç›´æ¥ä¼ å…¥ï¼Œé¿å…åç«¯å†è°ƒ APIï¼‰
    question_context: Optional[str] = Field(None, description="é¢˜ç›®ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼ˆåŒ…å«é¢˜ç›®å’Œç­”æ¡ˆï¼Œå‰ç«¯ç›´æ¥ä¼ å…¥æ—¶ä¼˜å…ˆä½¿ç”¨ï¼‰")


# ============= æ ¸å¿ƒæ‰§è¡Œå‡½æ•°ï¼ˆå¤ç”¨ skill æ¡†æ¶ï¼‰ =============

async def execute_skill_pipeline(
    message: str,
    user_id: str,
    session_id: str,
    orchestrator: SkillOrchestrator,
    quantity_override: Optional[int] = None,
    skill_hint: Optional[str] = None,
    file_uris: Optional[List[str]] = None,
    referenced_text: Optional[str] = None,  # ğŸ†• å¼•ç”¨æ–‡æœ¬
    action_type: Optional[str] = None,  # ğŸ†• å¿«æ·æ“ä½œç±»å‹
    files: Optional[List[Dict[str, Any]]] = None,  # ğŸ†• ç»Ÿä¸€çš„æ–‡ä»¶ä¿¡æ¯æ•°ç»„
    # å…¼å®¹æ—§ç‰ˆå•æ–‡ä»¶å­—æ®µ
    file_url: Optional[str] = None,
    file_name: Optional[str] = None,
    # ğŸ†• è¯­è¨€è®¾ç½®
    language: str = "en",
    # ğŸ†• é¢˜ç›®ä¸Šä¸‹æ–‡ï¼ˆä» StudyX è·å–çš„åŸå§‹é¢˜ç›®å’Œç­”æ¡ˆï¼‰
    question_context: Optional[str] = None
) -> Dict[str, Any]:
    """
    æ‰§è¡Œå®Œæ•´çš„ skill æ¡†æ¶æµç¨‹
    
    è¿™æ˜¯å¯¹ /api/agent/chat æ ¸å¿ƒé€»è¾‘çš„å¤ç”¨ï¼ŒåŒ…æ‹¬ï¼š
    1. Memory æ£€ç´¢
    2. Intent Router è§£æ
    3. Skill æ‰§è¡Œ
    4. Memory æ›´æ–° & MD å­˜å‚¨
    
    Args:
        message: ç”¨æˆ·æ¶ˆæ¯
        user_id: ç”¨æˆ· ID
        session_id: ä¼šè¯ ID
        orchestrator: SkillOrchestrator å®ä¾‹
        quantity_override: è¦†ç›–æ•°é‡ï¼ˆå¦‚æœç”¨æˆ·æ˜¾å¼ä¼ äº†å‚æ•°ï¼‰
        skill_hint: æŠ€èƒ½æç¤ºï¼ˆ"quiz" æˆ– "flashcard"ï¼‰
        file_uris: GCS æ–‡ä»¶ URI åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œæ”¯æŒå¤šæ–‡ä»¶ï¼‰
        files: ç»Ÿä¸€çš„æ–‡ä»¶ä¿¡æ¯æ•°ç»„ï¼ˆç”¨äºå‰ç«¯å›æ˜¾ï¼‰
        file_url: [å…¼å®¹] å•ä¸ªå›¾ç‰‡ HTTP URL
        file_name: [å…¼å®¹] å•ä¸ªæ–‡æ¡£æ–‡ä»¶å
    
    Returns:
        æ‰§è¡Œç»“æœï¼ˆåŒ…å« token_usage ç»Ÿè®¡ï¼‰
    """
    start_time = time.time()
    
    # ğŸ†• ä¿å­˜åŸå§‹æ¶ˆæ¯ç”¨äº Intent Routerï¼ˆä¸è¢« referenced_text å¹²æ‰°ï¼‰
    original_message = message
    enhanced_message = message
    context_prefix = ""
    
    # ğŸ†• å¤„ç†å¿«æ·æ“ä½œ - å°† UI æŒ‰é’®æ˜ å°„åˆ°å…·ä½“æŒ‡ä»¤ï¼ˆæ”¯æŒå¤šè¯­è¨€ï¼‰
    if action_type:
        # å¤šè¯­è¨€ action æ˜ å°„
        action_mapping_en = {
            "explain_concept": "Please explain this concept in detail",
            "make_simpler": "Please explain this in a simpler way that's easier to understand",
            "common_mistakes": "What are the common mistakes or misconceptions about this topic? Please list and explain them",
        }
        action_mapping_zh = {
            "explain_concept": "è¯·è¯¦ç»†è§£é‡Šè¿™ä¸ªæ¦‚å¿µ",
            "make_simpler": "è¯·ç”¨æ›´ç®€å•æ˜“æ‡‚çš„æ–¹å¼è§£é‡Šè¿™ä¸ªå†…å®¹",
            "common_mistakes": "è¿™ä¸ªçŸ¥è¯†ç‚¹æœ‰å“ªäº›å¸¸è§é”™è¯¯æˆ–è¯¯åŒºï¼Ÿè¯·åˆ—ä¸¾è¯´æ˜",
        }
        
        # æ ¹æ®è¯­è¨€é€‰æ‹© action æ˜ å°„
        if language == "zh":
            action_mapping = action_mapping_zh
            default_action = "è¯·å¸®æˆ‘ç†è§£è¿™ä¸ªå†…å®¹"
        else:
            action_mapping = action_mapping_en
            default_action = "Please help me understand this content"
        
        action_prompt = action_mapping.get(action_type, default_action)
        if not message.strip():
            enhanced_message = action_prompt
            original_message = action_prompt  # å¿«æ·æ“ä½œä¹Ÿéœ€è¦æ›´æ–°åŸå§‹æ¶ˆæ¯
        else:
            enhanced_message = f"{message}, {action_prompt}" if language == "en" else f"{message}ï¼Œ{action_prompt}"
        logger.info(f"âš¡ Quick action: {action_type} (lang={language})")
    
    # ğŸ†• å¤„ç†é¢˜ç›®ä¸Šä¸‹æ–‡ - æ–° session æ—¶ä» StudyX è·å–çš„åŸå§‹é¢˜ç›®å’Œç­”æ¡ˆ
    # è¿™ä¸ªä¸Šä¸‹æ–‡å¸®åŠ© AI ç†è§£ "here" "this question" ç­‰æŒ‡ä»£è¯
    if question_context:
        context_prefix = f"[Current Question Context]\n{question_context}\n\n[User Message]\n"
        logger.info(f"ğŸ“š Question context attached: {len(question_context)} chars")
    
    # ğŸ†• å¤„ç†å¼•ç”¨æ–‡æœ¬ - å°†ç”¨æˆ·é€‰ä¸­çš„æ–‡æœ¬ä½œä¸ºä¸Šä¸‹æ–‡
    # æ³¨æ„ï¼šreferenced_text åªæ·»åŠ åˆ°æœ€ç»ˆæ‰§è¡Œæ¶ˆæ¯ï¼Œä¸å½±å“ Intent Router
    if referenced_text:
        ref_prefix = f"Based on this content:\n\"\"\"\n{referenced_text}\n\"\"\"\n\n"
        context_prefix = context_prefix + ref_prefix if context_prefix else ref_prefix
        logger.info(f"ğŸ“ Referenced text attached: {len(referenced_text)} chars")
    
    # ç»„åˆæœ€ç»ˆæ‰§è¡Œæ¶ˆæ¯ï¼ˆç”¨äº Skill æ‰§è¡Œï¼‰
    execution_message = context_prefix + enhanced_message if context_prefix else enhanced_message
    
    # Intent Router ä½¿ç”¨åŸå§‹æ¶ˆæ¯ï¼ŒSkill æ‰§è¡Œä½¿ç”¨å¢å¼ºæ¶ˆæ¯
    intent_parse_message = original_message  # ğŸ”¥ å…³é”®ï¼šIntent Router ä¸è¢« referenced_text å¹²æ‰°
    logger.info(f"ğŸ“ Intent parse message: {intent_parse_message[:50]}...")
    logger.info(f"ğŸ“ Execution message: {execution_message[:80]}...")
    
    # ğŸ†• åˆå§‹åŒ– Token ä½¿ç”¨ç»Ÿè®¡ï¼ˆæš´éœ²ç»™å¤–éƒ¨ï¼‰
    token_usage = {
        "intent_router": {
            "method": "skill_registry",  # "skill_registry" = 0 tokens, "llm_fallback" = æœ‰ tokens
            "tokens": 0
        },
        "skill_execution": {
            "source": "pending",  # "external_api" / "llm"
            "model": "pending",   # å…·ä½“æ¨¡å‹åç§°
            "thinking_mode": False,  # æ˜¯å¦ä½¿ç”¨æ€è€ƒæ¨¡å¼
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
            "thinking_tokens": 0,  # æ€è€ƒ tokenï¼ˆä»…æ€è€ƒæ¨¡å‹ï¼‰
            "content_tokens": 0,   # å†…å®¹ token
            "generation_time": 0,  # ç”Ÿæˆè€—æ—¶ï¼ˆç§’ï¼‰
            "data_source": "pending"  # "api" ç²¾ç¡® / "estimated" ä¼°ç®—
        },
        "memory_operations": {
            "compression_tokens": 0,      # å‹ç¼©æ€» token
            "compression_input": 0,       # å‹ç¼© input tokenï¼ˆå‘é€ç»™ LLMï¼‰
            "compression_output": 0,      # å‹ç¼© output tokenï¼ˆLLM ç”Ÿæˆï¼‰
            "summary_tokens": 0           # Memory summary ç”Ÿæˆæ¶ˆè€—
        },
        "total_internal_tokens": 0  # æ€»è®¡ï¼ˆä¸å«å¤–éƒ¨ APIï¼‰
    }
    
    logger.info("="*60)
    logger.info(f"ğŸ”„ External API -> Skill Pipeline")
    logger.info(f"   â€¢ User: {user_id}")
    logger.info(f"   â€¢ Session: {session_id}")
    logger.info(f"   â€¢ Message: {message}")
    logger.info(f"   â€¢ Quantity Override: {quantity_override}")
    logger.info(f"   â€¢ Skill Hint: {skill_hint}")
    logger.info(f"   â€¢ File URIs: {file_uris if file_uris else 'N/A'}")
    logger.info("="*60)
    
    # ============= STEP 1: Memory æ£€ç´¢ =============
    logger.info("ğŸ” STEP 1: Retrieving Memory Context...")
    
    memory_summary = await orchestrator.memory_manager.generate_memory_summary(
        user_id, session_id
    )
    
    # è·å– session context
    session_context = await orchestrator.memory_manager.get_session_context(
        session_id=session_id,
        user_id=user_id
    )
    
    last_artifact_summary = "No previous interaction."
    current_topic = None
    session_topics = None
    
    if session_context:
        if hasattr(session_context, 'current_topic'):
            current_topic = session_context.current_topic
        if hasattr(session_context, 'artifact_history'):
            session_topics = [a.topic for a in session_context.artifact_history if a.topic]
        if session_context.last_artifact and session_context.last_artifact_content:
            last_artifact_summary = f"Previous: {session_context.last_artifact} about {current_topic or 'unknown'}"
    
    # ğŸ”¥ å¦‚æœ session_context æ²¡æœ‰ current_topicï¼Œå°è¯•ä» MD metadata åŠ è½½
    artifact_contents = []
    if not current_topic:
        loaded_context = await _load_session_context_from_md(
            memory_manager=orchestrator.memory_manager,
            user_id=user_id,
            session_id=session_id
        )
        if loaded_context:
            current_topic = loaded_context.get("current_topic")
            session_topics = loaded_context.get("session_topics", [])
            artifact_contents = loaded_context.get("artifact_contents", [])
            if loaded_context.get("last_artifact"):
                last_artifact_summary = f"Previous: {loaded_context['last_artifact']} about {current_topic or 'unknown'}"
            logger.info(f"ğŸ“‚ Loaded context from MD: current_topic={current_topic}, topics={session_topics}, artifacts={len(artifact_contents)}")
    
    # ğŸ†• å¦‚æœä» MD åŠ è½½äº† artifact_contentsï¼Œæ³¨å…¥åˆ° session_context ä¾›å¼•ç”¨è§£æä½¿ç”¨
    if artifact_contents:
        await _inject_artifacts_to_session(
            memory_manager=orchestrator.memory_manager,
            session_id=session_id,
            artifact_contents=artifact_contents
        )
    
    logger.info(f"âœ… Memory retrieved, current_topic: {current_topic}")
    
    # ============= STEP 2: Intent Router è§£æ =============
    logger.info("ğŸ§­ STEP 2: Parsing User Intent...")
    
    # ğŸ†• æ£€æµ‹æ˜¯å¦æœ‰æ–‡ä»¶é™„ä»¶
    has_files = file_uris and len(file_uris) > 0
    
    intent_router = IntentRouter()
    intent_results = await intent_router.parse(
        message=intent_parse_message,  # ğŸ”¥ ä½¿ç”¨åŸå§‹æ¶ˆæ¯ï¼Œä¸è¢« referenced_text å¹²æ‰°
        memory_summary=memory_summary,
        last_artifact_summary=last_artifact_summary,
        current_topic=current_topic,
        session_topics=session_topics,
        has_files=has_files  # ğŸ†• ä¼ é€’æ–‡ä»¶é™„ä»¶ä¿¡æ¯
    )
    
    if not intent_results:
        return {
            "success": False,
            "error": "intent_parse_failed",
            "message": "æ— æ³•è§£æç”¨æˆ·æ„å›¾",
            "token_usage": token_usage
        }
    
    # å–ç¬¬ä¸€ä¸ª intent
    intent_result = intent_results[0]
    logger.info(f"âœ… Intent parsed: {intent_result.intent}, topic: {intent_result.topic}")
    
    # ğŸ†• æ”¶é›† Intent Router çš„ token ç»Ÿè®¡
    # ç®€å•æ–¹æ¡ˆï¼šå¦‚æœ confidence < 0.5ï¼Œè¯´æ˜å¯èƒ½ä½¿ç”¨äº† LLM fallback
    if intent_result.confidence < 0.5:
        # ä½ç½®ä¿¡åº¦å¯èƒ½ä½¿ç”¨äº† LLM fallbackï¼ˆGeminiï¼‰
        token_usage["intent_router"]["method"] = "llm_fallback"
        token_usage["intent_router"]["tokens"] = 150  # ä¼°ç®— Gemini ä½¿ç”¨
    else:
        # é«˜ç½®ä¿¡åº¦è¯´æ˜ä½¿ç”¨äº† 0-token çš„ Skill Registry
        token_usage["intent_router"]["method"] = "skill_registry"
        token_usage["intent_router"]["tokens"] = 0
    
    # ============= STEP 2.4: ğŸ†• å¤„ç† file_uris çš„ç‰¹æ®Šæƒ…å†µ =============
    # å½“æœ‰æ–‡ä»¶é™„ä»¶æ—¶ï¼Œæ ¹æ®æ„å›¾ç±»å‹å†³å®šæ˜¯å¦ override
    has_files = file_uris and len(file_uris) > 0
    if has_files:
        # ğŸ†• è¯¢é—®ç±»/è§£é‡Šç±» intent ä¸åº”è¯¥è¢« override ä¸º quiz/flashcard
        # è¿™äº› intent è¡¨ç¤ºç”¨æˆ·åœ¨è¯¢é—®/è®¨è®ºæ–‡ä»¶å†…å®¹ï¼Œè€Œä¸æ˜¯è¦æ±‚ç”Ÿæˆå­¦ä¹ å†…å®¹
        non_generation_intents = {
            "contextual", "explain", "other", "help",  # è¯¢é—®/è§£é‡Šç±»
            "explain_request",  # è§£é‡Šè¯·æ±‚ä¹Ÿå¯èƒ½åªæ˜¯è®¨è®º
        }
        
        if intent_result.intent in non_generation_intents:
            # ğŸ†• ç”¨æˆ·åœ¨è¯¢é—®æ–‡ä»¶å†…å®¹ï¼Œè½¬æ¢ä¸º "other" è®© Gemini ç›´æ¥å›ç­”
            # è€Œä¸æ˜¯è°ƒç”¨ explain_skill ç”Ÿæˆç»“æ„åŒ–è§£é‡Š
            logger.info(f"ğŸ“ File URIs provided ({len(file_uris)} files) with inquiry intent '{intent_result.intent}'")
            logger.info(f"ğŸ“ Converting '{intent_result.intent}' â†’ 'other' for direct chat response")
            intent_result.intent = "other"  # è®© Gemini ç›´æ¥å›ç­”
            intent_result.parameters['from_file'] = True
            intent_result.parameters['file_uris'] = file_uris
        else:
            # ğŸ†• å¦‚æœ intent æ˜¯ otherï¼ˆå¯¹è¯/è§£ç­”ç±»ï¼‰ï¼Œä¸è¦å¼ºåˆ¶è¦†ç›–ä¸ºç”Ÿæˆç±»
            # "solve this question" åº”è¯¥ä¿æŒä¸º otherï¼Œè®© LLM ç›´æ¥è§£ç­”
            if intent_result.intent == "other":
                logger.info(f"ğŸ“ File URIs provided ({len(file_uris)} files) with 'other' intent, keeping as chat")
                # ä¿æŒ other intentï¼Œä¸è¦†ç›–
            else:
                # ç”Ÿæˆç±» intentï¼ˆquiz/flashcard/notes ç­‰ï¼‰æˆ– clarification
                needs_override = (
                    intent_result.intent == "clarification" or
                    intent_result.intent == "clarification_needed" or
                    intent_result.parameters.get('needs_clarification') or
                    not intent_result.topic
                )
                
                if needs_override:
                    # æ ¹æ® skill_hint ç¡®å®š intentï¼Œé»˜è®¤ä¸º quiz
                    if skill_hint == "quiz":
                        intent_result.intent = "quiz_request"
                    elif skill_hint == "flashcard":
                        intent_result.intent = "flashcard_request"
                    else:
                        # æ²¡æœ‰ skill_hint æ—¶ï¼Œæ ¹æ®æ¶ˆæ¯å†…å®¹æ¨æ–­
                        if any(kw in message for kw in ['é—ªå¡', 'å¡ç‰‡', 'flashcard']):
                            intent_result.intent = "flashcard_request"
                        else:
                            intent_result.intent = "quiz_request"  # é»˜è®¤ä¸º quiz
                    
                    # ğŸ”¥ å…³é”®ï¼štopic è®¾ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œè®©å¤–éƒ¨ API ä»æ–‡ä»¶ä¸­æå–
                    intent_result.topic = ""  
                    intent_result.parameters['topic'] = ""
                    intent_result.parameters['needs_clarification'] = False
                    intent_result.parameters['from_file'] = True  # æ ‡è®°æ¥è‡ªæ–‡ä»¶
                    
                    logger.info(f"ğŸ“ File URIs provided ({len(file_uris)} files), bypassing topic check")
                    logger.info(f"ğŸ“ Override intent to: {intent_result.intent} (topic will be extracted by external API)")
    
    # ============= STEP 2.5: æ£€æŸ¥æ˜¯å¦éœ€è¦æ¾„æ¸… =============
    # å½“ä»¥ä¸‹æƒ…å†µæ—¶è§¦å‘æ¾„æ¸…æœºåˆ¶ï¼š
    # 1. confidence è¾ƒä½ä¸”æœ‰å¤šä¸ª topics
    # 2. æ£€æµ‹åˆ°æ¨¡ç³Šå¼•ç”¨ï¼ˆå¦‚ "é‚£é“é¢˜" ä½†æœ‰å¤šä¸ª quizï¼‰
    # 3. intent æ˜¯ clarificationï¼ˆä½†æœ‰æ–‡ä»¶æ—¶å·²åœ¨ä¸Šé¢å¤„ç†ï¼‰
    # ğŸ†• æœ‰ file_uris æ—¶è·³è¿‡æ¾„æ¸…
    
    if not has_files and (intent_result.intent == "clarification" or (
        intent_result.confidence < 0.7 and 
        len(session_topics) > 1 and 
        intent_result.has_reference
    )):
        logger.info(f"ğŸ¤” Clarification needed: confidence={intent_result.confidence}, topics={len(session_topics)}")
        
        # æ„å»ºå‹ç¼©ä¸Šä¸‹æ–‡å¹¶è°ƒç”¨ LLM ç”Ÿæˆæ¾„æ¸…é—®é¢˜
        clarification_response = await _generate_clarification(
            message=message,
            artifact_contents=artifact_contents,
            session_topics=session_topics,
            current_topic=current_topic
        )
        
        if clarification_response:
            # ä¿å­˜åˆ° MD
            await _save_chat_to_session(
                memory_manager=orchestrator.memory_manager,
                user_id=user_id,
                session_id=session_id,
                message=message,
                response_text=clarification_response,
                intent="clarification",
                current_topic=current_topic,
                files=files,
                referenced_text=referenced_text,
                file_url=file_url,
                file_name=file_name
            )
            
            # ğŸ†• Clarification ä½¿ç”¨ Geminiï¼ˆä¼°ç®— ~200 tokensï¼‰
            token_usage["skill_execution"]["source"] = "llm_gemini"
            token_usage["skill_execution"]["total_tokens"] = 200  # ä¼°ç®—
            token_usage["total_internal_tokens"] = token_usage["intent_router"]["tokens"] + 200
            
            return {
                "content_type": "clarification",
                "intent": "clarification",
                "topic": current_topic or "",
                "content": {"text": clarification_response},
                "token_usage": token_usage
            }
    
    # ============= STEP 2.6: å¤„ç†ç‰¹æ®Š intent =============
    
    # å¤„ç† help intent
    if intent_result.intent == "help":
        help_text = """ä½ å¥½ï¼æˆ‘æ˜¯ StudyX Agentï¼Œä½ çš„æ™ºèƒ½å­¦ä¹ åŠ©æ‰‹ ğŸ“

æˆ‘æ”¯æŒä»¥ä¸‹å­¦ä¹ åŠŸèƒ½ï¼š
â€¢ ğŸ“ ç»ƒä¹ é¢˜ï¼šã€Œç»™æˆ‘5é“å¾®ç§¯åˆ†çš„é¢˜ã€
â€¢ ğŸ“– æ¦‚å¿µè®²è§£ï¼šã€Œè§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯å…‰åˆä½œç”¨ã€
â€¢ ğŸ´ å­¦ä¹ é—ªå¡ï¼šã€Œç»™æˆ‘ä¸€äº›å…‰åˆä½œç”¨çš„é—ªå¡ã€
â€¢ ğŸ“ å­¦ä¹ ç¬”è®°ï¼šã€Œå¸®æˆ‘æ•´ç†ç‰©ç†çŸ¥è¯†ç‚¹ã€
â€¢ ğŸ—ºï¸ æ€ç»´å¯¼å›¾ï¼šã€Œç”»ä¸ªåŒ–å­¦ååº”çš„æ€ç»´å¯¼å›¾ã€

è¯•è¯•é—®æˆ‘ä¸€ä¸ªå­¦ä¹ ç›¸å…³çš„é—®é¢˜å§ï¼ğŸ˜Š"""
        
        # ğŸ”¥ ä¿å­˜åˆ° MD
        await _save_chat_to_session(
            memory_manager=orchestrator.memory_manager,
            user_id=user_id,
            session_id=session_id,
            message=message,
            response_text=help_text,
            intent="help",
            files=files,
            referenced_text=referenced_text,
            file_url=file_url,
            file_name=file_name
        )
        
        # ğŸ†• Help ä¸æ¶ˆè€— tokenï¼ˆé™æ€æ–‡æœ¬ï¼‰
        token_usage["total_internal_tokens"] = token_usage["intent_router"]["tokens"]
        
        return {
            "content_type": "text",
            "intent": "help",
            "content": {"text": help_text},
            "token_usage": token_usage
        }
    
    # ğŸ†• å¤„ç† clarification / clarification_needed intentï¼ˆéœ€è¦æ¾„æ¸…ï¼‰- è¿”å›å¼•å¯¼æ€§é—®é¢˜
    # ğŸ”¥ ä½†å¦‚æœæœ‰ referenced_textã€question_context æˆ–æœ‰ conversation historyï¼Œè·³è¿‡ clarification
    if intent_result.intent in ["clarification", "clarification_needed"]:
        # ğŸ†• å¦‚æœæœ‰ question_contextï¼ˆä» StudyX è·å–çš„é¢˜ç›®ä¸Šä¸‹æ–‡ï¼‰ï¼Œç›´æ¥è·³è¿‡ clarification
        if question_context:
            logger.info(f"ğŸ“š Has question_context, bypassing clarification and using 'other' intent for chat...")
            intent_result.intent = 'other'
            intent_result.parameters['has_question_context'] = True
            # è·³è¿‡åç»­çš„ clarification å¤„ç†
        else:
            # ğŸ†• æ£€æŸ¥æ˜¯å¦æ˜¯ follow-up é—®é¢˜ï¼ˆå¼•ç”¨ä¹‹å‰çš„ä¸Šä¸‹æ–‡ï¼‰
            followup_indicators_en = [
                'this', 'here', 'it', 'the solution', 'the problem', 'the concept',
                'the answer', 'this type', 'this kind', 'above', 'that'
            ]
            followup_indicators_zh = [
                'è¿™ä¸ª', 'è¿™é“', 'è¿™é‡Œ', 'ä¸Šé¢', 'å‰é¢', 'åˆšæ‰', 'è¿™é¢˜', 'è¿™ç±»', 'é‚£ä¸ª'
            ]
            
            msg_lower = intent_parse_message.lower()
            is_followup = any(ind in msg_lower for ind in followup_indicators_en) or \
                          any(ind in intent_parse_message for ind in followup_indicators_zh)
            
            # ğŸ†• å¦‚æœæ˜¯ follow-up é—®é¢˜ï¼Œå…ˆåŠ è½½å¯¹è¯å†å²æ£€æŸ¥æ˜¯å¦æœ‰ä¸Šä¸‹æ–‡
            has_conversation_context = False
            if is_followup and not referenced_text:
                try:
                    prev_history = await _load_conversation_history(
                        memory_manager=orchestrator.memory_manager,
                        user_id=user_id,
                        session_id=session_id,
                        max_turns=3  # åªéœ€æ£€æŸ¥æœ€è¿‘å‡ è½®
                    )
                    if prev_history and len(prev_history) > 0:
                        has_conversation_context = True
                        logger.info(f"ğŸ“ Follow-up question detected with {len(prev_history)//2} previous turns, bypassing clarification")
                        # å°† intent æ”¹ä¸º otherï¼Œè®© Gemini ä½¿ç”¨ä¸Šä¸‹æ–‡å›ç­”
                        intent_result.intent = 'other'
                        intent_result.parameters['is_followup'] = True
                        intent_result.parameters['context_turns'] = len(prev_history) // 2
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to check conversation history: {e}")
            
            if referenced_text:
                # æœ‰å¼•ç”¨æ–‡æœ¬æ—¶ï¼Œæ ¹æ®åŸå§‹æ¶ˆæ¯é‡æ–°åˆ¤æ–­ skill æ„å›¾
                logger.info(f"ğŸ“ Has referenced_text, bypassing clarification...")
                original_skill_keywords = {
                    'quiz': ['é¢˜', 'å‡ºé¢˜', 'é“é¢˜', 'é€‰æ‹©é¢˜', 'åˆ¤æ–­é¢˜', 'ç»ƒä¹ ', 'æµ‹éªŒ', 'quiz'],
                    'flashcard': ['é—ªå¡', 'å¡ç‰‡', 'åšå¡', 'flashcard', 'card'],
                    'explain': ['è®²è§£', 'è§£é‡Š', 'è¯´æ˜', 'è¯¦ç»†', 'explain'],
                }
                
                # æ£€æµ‹åŸå§‹æ¶ˆæ¯ä¸­çš„ skill ç±»å‹
                detected_skill = None
                for skill, keywords in original_skill_keywords.items():
                    if any(kw in intent_parse_message for kw in keywords):
                        detected_skill = skill
                        break
                
                if detected_skill:
                    logger.info(f"ğŸ“ Detected skill from original message: {detected_skill}")
                    # é‡å†™ intent_resultï¼Œè·³è¿‡ clarification
                    if detected_skill == 'quiz':
                        intent_result.intent = 'quiz_request'
                        intent_result.topic = "å¼•ç”¨å†…å®¹"  # ä½¿ç”¨å¼•ç”¨æ–‡æœ¬ä½œä¸ºä¸»é¢˜æ¥æº
                        intent_result.parameters['needs_clarification'] = False
                        intent_result.parameters['topic_from_reference'] = True
                    elif detected_skill == 'flashcard':
                        intent_result.intent = 'flashcard_request'
                        intent_result.topic = "å¼•ç”¨å†…å®¹"
                        intent_result.parameters['needs_clarification'] = False
                        intent_result.parameters['topic_from_reference'] = True
                    elif detected_skill == 'explain':
                        # explain ç›´æ¥ç”¨ other intent + Gemini å¯¹è¯
                        intent_result.intent = 'other'
                        intent_result.parameters['from_reference'] = True
                else:
                    # æ— æ³•æ£€æµ‹åˆ°æ˜ç¡® skillï¼Œä½¿ç”¨ "other" è®© Gemini å¤„ç†
                    logger.info(f"ğŸ“ No clear skill detected, using 'other' for direct chat")
                    intent_result.intent = 'other'
                    intent_result.parameters['from_reference'] = True
                # ğŸ”¥ è·³è¿‡ clarification å¤„ç†ï¼Œç»§ç»­æ‰§è¡Œåç»­é€»è¾‘
            elif has_conversation_context:
                # ğŸ†• æœ‰å¯¹è¯å†å²ä¸Šä¸‹æ–‡ï¼Œå·²åœ¨ä¸Šé¢å°† intent æ”¹ä¸º 'other'ï¼Œè·³è¿‡ clarification
                logger.info(f"ğŸ“ Follow-up with conversation context, skipping clarification")
                pass  # intent å·²æ”¹ä¸º 'other'ï¼Œä¼šåœ¨åç»­å¤„ç†
            else:
                # æ²¡æœ‰ referenced_textï¼Œä¹Ÿæ²¡æœ‰å¯¹è¯å†å²ï¼Œæ­£å¸¸è¿›å…¥ clarification æµç¨‹
                logger.info(f"â“ Detected '{intent_result.intent}' intent, generating clarification question...")
                
                missing = intent_result.parameters.get("missing", [])
                clarification_reason = intent_result.parameters.get("clarification_reason", "")
                
                # ğŸ†• æ›´ä¸°å¯Œçš„å¼•å¯¼æ€§é—®é¢˜æ¨¡æ¿ï¼ˆæ”¯æŒå¤šè¯­è¨€ï¼‰
                if language == "en":
                    clarification_responses = {
                        "topic": "What topic would you like to learn?\nâ€¢ Physics (Newton's laws, optics)\nâ€¢ Chemistry (chemical bonds, reactions)\nâ€¢ History (WWII, US History)\nâ€¢ Biology (cells, DNA)\n\nTell me the specific topic, and I'll help you! ğŸ˜Š",
                        "topic_missing": "What topic would you like to learn? Tell me the specific subject or concept, such as 'photosynthesis' or 'Newton's second law', and I can help you create learning materials.",
                        "subject": "Which subject would you like to make a plan for?\nâ€¢ Physics\nâ€¢ Chemistry\nâ€¢ Math\nâ€¢ English\n\nTell me the specific subject or topic!",
                        "action": "What would you like me to help you with?\n\nâ€¢ ğŸ“š **Explain concepts** - 'Explain photosynthesis'\nâ€¢ â“ **Generate practice questions** - 'Give me 5 questions about WWII'\nâ€¢ ğŸƒ **Create flashcards** - 'Make 3 flashcards about chemical bonds'\nâ€¢ ğŸ“‹ **Create study plan** - 'Help me plan physics study'\nâ€¢ ğŸ—ºï¸ **Draw mind map** - 'Draw a mind map of Newton's laws'\n\nJust tell me what you need!",
                        "multi_topic_insufficient": "Which topics would you like to include? Please tell me the specific topic names.",
                    }
                    default_clarification = "I'm not sure what you need."
                else:
                    clarification_responses = {
                        "topic": "ä½ æƒ³å­¦ä¹ ä»€ä¹ˆä¸»é¢˜å‘¢ï¼Ÿæ¯”å¦‚ï¼š\nâ€¢ ç‰©ç†ï¼ˆç‰›é¡¿å®šå¾‹ã€å…‰å­¦ï¼‰\nâ€¢ åŒ–å­¦ï¼ˆåŒ–å­¦é”®ã€åŒ–å­¦ååº”ï¼‰\nâ€¢ å†å²ï¼ˆäºŒæˆ˜ã€ä¸­å›½å†å²ï¼‰\nâ€¢ ç”Ÿç‰©ï¼ˆç»†èƒã€DNAï¼‰\n\nå‘Šè¯‰æˆ‘å…·ä½“çš„ä¸»é¢˜ï¼Œæˆ‘æ¥å¸®ä½ ï¼ğŸ˜Š",
                        "topic_missing": "ä½ æƒ³å­¦ä¹ ä»€ä¹ˆä¸»é¢˜å‘¢ï¼Ÿå‘Šè¯‰æˆ‘å…·ä½“çš„å­¦ç§‘æˆ–çŸ¥è¯†ç‚¹ï¼Œä¾‹å¦‚ã€Œå…‰åˆä½œç”¨ã€ã€Œç‰›é¡¿ç¬¬äºŒå®šå¾‹ã€ç­‰ï¼Œæˆ‘å¯ä»¥å¸®ä½ ç”Ÿæˆå­¦ä¹ ææ–™ã€‚",
                        "subject": "ä½ æƒ³é’ˆå¯¹å“ªä¸ªå­¦ç§‘åˆ¶å®šè®¡åˆ’å‘¢ï¼Ÿæ¯”å¦‚ï¼š\nâ€¢ ç‰©ç†\nâ€¢ åŒ–å­¦\nâ€¢ æ•°å­¦\nâ€¢ è‹±è¯­\n\nå‘Šè¯‰æˆ‘å…·ä½“çš„ç§‘ç›®æˆ–ä¸»é¢˜å§ï¼",
                        "action": "ä½ å¸Œæœ›æˆ‘å¸®ä½ åšä»€ä¹ˆå‘¢ï¼Ÿæˆ‘å¯ä»¥ï¼š\n\nâ€¢ ğŸ“š **è®²è§£æ¦‚å¿µ** - ã€Œè§£é‡Šä¸€ä¸‹å…‰åˆä½œç”¨ã€\nâ€¢ â“ **ç”Ÿæˆç»ƒä¹ é¢˜** - ã€Œç»™æˆ‘5é“äºŒæˆ˜çš„é¢˜ã€\nâ€¢ ğŸƒ **åˆ¶ä½œé—ªå¡** - ã€Œåš3å¼ åŒ–å­¦é”®çš„é—ªå¡ã€\nâ€¢ ğŸ“‹ **åˆ¶å®šå­¦ä¹ è®¡åˆ’** - ã€Œå¸®æˆ‘åˆ¶å®šç‰©ç†å­¦ä¹ è®¡åˆ’ã€\nâ€¢ ğŸ—ºï¸ **ç”»æ€ç»´å¯¼å›¾** - ã€Œç”»ä¸ªç‰›é¡¿å®šå¾‹çš„å¯¼å›¾ã€\n\nç›´æ¥å‘Šè¯‰æˆ‘ä½ çš„éœ€æ±‚ï¼",
                        "multi_topic_insufficient": "ä½ æƒ³è¦å“ªäº›ä¸»é¢˜çš„å†…å®¹å‘¢ï¼Ÿè¯·å‘Šè¯‰æˆ‘å…·ä½“çš„ä¸»é¢˜åç§°ã€‚",
                    }
                    default_clarification = "æˆ‘ä¸å¤ªç¡®å®šä½ çš„éœ€æ±‚ã€‚"
                
                # ğŸ†• æ ¹æ®åŸå› é€‰æ‹©åˆé€‚çš„å¼•å¯¼é—®é¢˜
                clarification_text = default_clarification
                
                if clarification_reason:
                    clarification_text = clarification_responses.get(clarification_reason, clarification_text)
                elif missing:
                    # å…¼å®¹æ—§çš„ missing å‚æ•°
                    if isinstance(missing, list) and len(missing) > 0:
                        clarification_text = clarification_responses.get(missing[0], clarification_text)
                    else:
                        clarification_text = clarification_responses.get(str(missing), clarification_text)
                else:
                    # ğŸ†• æ™ºèƒ½é»˜è®¤æ¾„æ¸…ï¼ˆåŸºäºç”¨æˆ·æ¶ˆæ¯å†…å®¹ï¼Œæ”¯æŒå¤šè¯­è¨€ï¼‰
                    if language == "en":
                        if any(kw in intent_parse_message.lower() for kw in ['learn', 'study', 'review', 'teach']):
                            clarification_text = "What would you like to learn? Tell me the specific topic, like 'physics', 'Newton's laws', or 'World War II', and I'll help you create learning materials!"
                        elif any(kw in intent_parse_message.lower() for kw in ['organize', 'summarize', 'notes']):
                            clarification_text = "What topic would you like to organize? Tell me the specific subject or content, and I'll help!"
                        elif any(kw in intent_parse_message.lower() for kw in ['plan', 'schedule', 'arrange']):
                            clarification_text = "Which subject would you like to make a study plan for? Tell me the specific subject and I'll help you plan!"
                        else:
                            clarification_text = "Hi! I'm your learning assistant. What would you like to learn?\n\nYou can:\nâ€¢ Ask me questions like 'What is photosynthesis?'\nâ€¢ Request quiz questions like 'Give me 3 questions about Newton's laws'\nâ€¢ Create flashcards like 'Make 5 flashcards about chemical bonds'\n\nTell me what you need! ğŸ˜Š"
                    else:
                        if any(kw in intent_parse_message for kw in ['å­¦ä¹ ', 'å¤ä¹ ', 'é¢„ä¹ ']):
                            clarification_text = "ä½ æƒ³å­¦ä¹ ä»€ä¹ˆå‘¢ï¼Ÿå‘Šè¯‰æˆ‘å…·ä½“çš„ä¸»é¢˜ï¼Œæ¯”å¦‚ã€Œç‰©ç†ã€ã€Œç‰›é¡¿å®šå¾‹ã€ã€ŒäºŒæˆ˜å†å²ã€ç­‰ï¼Œæˆ‘æ¥å¸®ä½ ç”Ÿæˆå­¦ä¹ ææ–™ï¼"
                        elif any(kw in intent_parse_message for kw in ['æ•´ç†', 'æ€»ç»“', 'ç¬”è®°']):
                            clarification_text = "ä½ æƒ³æ•´ç†å“ªä¸ªä¸»é¢˜çš„çŸ¥è¯†ç‚¹å‘¢ï¼Ÿå‘Šè¯‰æˆ‘å…·ä½“çš„å­¦ç§‘æˆ–å†…å®¹ï¼Œæˆ‘æ¥å¸®ä½ æ•´ç†ï¼"
                        elif any(kw in intent_parse_message for kw in ['è®¡åˆ’', 'è§„åˆ’', 'å®‰æ’']):
                            clarification_text = "ä½ æƒ³åˆ¶å®šå“ªä¸ªå­¦ç§‘çš„å­¦ä¹ è®¡åˆ’å‘¢ï¼Ÿå‘Šè¯‰æˆ‘å…·ä½“çš„ç§‘ç›®ï¼Œæˆ‘æ¥å¸®ä½ è§„åˆ’ï¼"
                        else:
                            clarification_text = "ä½ å¥½ï¼æˆ‘æ˜¯å­¦ä¹ åŠ©æ‰‹ã€‚ä½ æƒ³å­¦ä¹ ä»€ä¹ˆå‘¢ï¼Ÿ\n\nä½ å¯ä»¥ï¼š\nâ€¢ ç›´æ¥é—®æˆ‘é—®é¢˜ï¼Œå¦‚ã€Œä»€ä¹ˆæ˜¯å…‰åˆä½œç”¨ã€\nâ€¢ è®©æˆ‘å‡ºé¢˜ï¼Œå¦‚ã€Œç»™æˆ‘3é“ç‰›é¡¿å®šå¾‹çš„é¢˜ã€\nâ€¢ è®©æˆ‘åšé—ªå¡ï¼Œå¦‚ã€Œåš5å¼ åŒ–å­¦é”®çš„é—ªå¡ã€\n\nå‘Šè¯‰æˆ‘ä½ çš„éœ€æ±‚ï¼ğŸ˜Š"
                
                # ğŸ”¥ ä¿å­˜ clarification åˆ° MD æ–‡ä»¶
                await _save_chat_to_session(
                    memory_manager=orchestrator.memory_manager,
                    user_id=user_id,
                    session_id=session_id,
                    message=message,
                    response_text=clarification_text,
                    intent="clarification",
                    current_topic=current_topic,
                    files=files,
                    referenced_text=referenced_text,
                    file_url=file_url,
                    file_name=file_name
                )
                
                token_usage["total_internal_tokens"] = token_usage["intent_router"]["tokens"]
                
                return {
                    "content_type": "clarification_needed",
                    "intent": "clarification",
                    "content": {"text": clarification_text},
                    "token_usage": token_usage
                }
    
    # å¤„ç† other intentï¼ˆé—²èŠ/æœªè¯†åˆ«ï¼‰- ä½¿ç”¨ Gemini å¯¹è¯
    if intent_result.intent == "other":
        logger.info("ğŸ’¬ Detected 'other' intent, using Gemini for conversation...")
        
        try:
            # ğŸ†• åŠ è½½å¯¹è¯å†å²ï¼ˆå®ç°ä¸Šä¸‹æ–‡å…³è”ï¼‰
            conversation_history = await _load_conversation_history(
                memory_manager=orchestrator.memory_manager,
                user_id=user_id,
                session_id=session_id,
                max_turns=6  # åŠ è½½æœ€è¿‘6è½®å¯¹è¯
            )
            
            chat_response = await _handle_chat_conversation(
                message=execution_message,  # ğŸ”¥ ä½¿ç”¨å¢å¼ºæ¶ˆæ¯ï¼ˆåŒ…å« referenced_textï¼‰
                current_topic=current_topic,
                session_topics=session_topics,
                file_uris=file_uris,
                conversation_history=conversation_history,  # ğŸ†• ä¼ é€’å¯¹è¯å†å²
                language=language  # ğŸ†• ä¼ é€’è¯­è¨€è®¾ç½®
            )
            
            # ğŸ”¥ ä¿å­˜åˆ° MDï¼ˆä½¿ç”¨åŸå§‹æ¶ˆæ¯ä¾¿äºé˜…è¯»ï¼‰
            await _save_chat_to_session(
                memory_manager=orchestrator.memory_manager,
                user_id=user_id,
                session_id=session_id,
                message=intent_parse_message,  # ä¿å­˜åŸå§‹æ¶ˆæ¯
                response_text=chat_response,
                intent="other",
                current_topic=current_topic,
                files=files,
                referenced_text=referenced_text,
                file_url=file_url,
                file_name=file_name
            )
            
            # ğŸ†• Other intent ä½¿ç”¨ Geminiï¼ˆä¼°ç®— ~500 tokensï¼‰
            token_usage["skill_execution"]["source"] = "llm_gemini"
            token_usage["skill_execution"]["total_tokens"] = 500  # ä¼°ç®—å¯¹è¯ token
            token_usage["total_internal_tokens"] = token_usage["intent_router"]["tokens"] + 500
            
            # ğŸ†• æ„å»ºä¸Šä¸‹æ–‡ç»Ÿè®¡ä¿¡æ¯
            context_stats = {
                "loaded_turns": len(conversation_history) // 2 if conversation_history else 0,
                "retrieved_turns": 0,
                "session_turns": len(conversation_history) // 2 if conversation_history else 0,
                "context_source": "conversation_history"
            }
            
            return {
                "content_type": "text",
                "intent": "other",
                "content": {"text": chat_response},
                "token_usage": token_usage,
                "context_stats": context_stats  # ğŸ†• æ·»åŠ ä¸Šä¸‹æ–‡ç»Ÿè®¡
            }
        except Exception as e:
            logger.error(f"âŒ Chat conversation failed: {e}")
            fallback_text = "æŠ±æ­‰ï¼Œæˆ‘ç›®å‰ä¸“æ³¨äºå­¦ä¹ è¾…åŠ©åŠŸèƒ½ã€‚è¯•è¯•é—®æˆ‘ä¸€ä¸ªå­¦ä¹ ç›¸å…³çš„é—®é¢˜å§ï¼ğŸ˜Š"
            
            # ğŸ”¥ ä¿å­˜åˆ° MDï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè®°å½•ï¼Œä½¿ç”¨åŸå§‹æ¶ˆæ¯ï¼‰
            await _save_chat_to_session(
                memory_manager=orchestrator.memory_manager,
                user_id=user_id,
                session_id=session_id,
                message=intent_parse_message,  # ä¿å­˜åŸå§‹æ¶ˆæ¯
                response_text=fallback_text,
                intent="other",
                current_topic=current_topic,
                files=files,
                referenced_text=referenced_text,
                file_url=file_url,
                file_name=file_name
            )
            
            # ğŸ†• Fallback ä¸æ¶ˆè€— tokenï¼ˆé™æ€æ–‡æœ¬ï¼‰
            token_usage["total_internal_tokens"] = token_usage["intent_router"]["tokens"]
            
            return {
                "content_type": "text",
                "intent": "other",
                "content": {"text": fallback_text},
                "token_usage": token_usage
            }
    
    # å¦‚æœç”¨æˆ·æ˜¾å¼ä¼ äº†æ•°é‡ï¼Œè¦†ç›– intent ä¸­çš„å‚æ•°
    if quantity_override is not None:
        if skill_hint == "quiz":
            intent_result.parameters['num_questions'] = quantity_override
        elif skill_hint == "flashcard":
            intent_result.parameters['num_cards'] = quantity_override
        logger.info(f"ğŸ“Š Quantity override applied: {quantity_override}")
    
    # ğŸ†• æ·»åŠ  file_uris åˆ°å‚æ•°ä¸­ï¼ˆå¦‚æœæä¾›äº†é™„ä»¶ï¼‰
    if file_uris:
        intent_result.parameters['file_uris'] = file_uris
        # ä¿æŒå‘åå…¼å®¹ï¼šç¬¬ä¸€ä¸ªæ–‡ä»¶ä¹Ÿå­˜åˆ° file_uri
        intent_result.parameters['file_uri'] = file_uris[0]
        logger.info(f"ğŸ“ File URIs attached: {file_uris} ({len(file_uris)} files)")
    
    # ğŸ†• æ·»åŠ  referenced_text åˆ°å‚æ•°ä¸­ï¼ˆå¦‚æœæœ‰å¼•ç”¨æ–‡æœ¬ï¼‰
    if referenced_text:
        intent_result.parameters['referenced_text'] = referenced_text
        intent_result.parameters['execution_message'] = execution_message
        logger.info(f"ğŸ“ Referenced text attached to intent_result: {len(referenced_text)} chars")
    
    # ============= STEP 3: Skill æ‰§è¡Œ =============
    logger.info(f"ğŸ¯ STEP 3: Executing Skill ({intent_result.intent})...")
    
    orchestrator_response = await orchestrator.execute(
        intent_result=intent_result,
        user_id=user_id,
        session_id=session_id,
        additional_params={"language": language}  # ğŸ†• ä¼ é€’è¯­è¨€è®¾ç½®
    )
    
    # ğŸ†• ä¿å­˜ attachments åˆ° session metadataï¼ˆorchestrator å†…éƒ¨ä¿å­˜ turnï¼Œè¿™é‡Œè¡¥å…… attachmentsï¼‰
    if files or referenced_text:
        await _update_last_turn_attachments(
            memory_manager=orchestrator.memory_manager,
            user_id=user_id,
            session_id=session_id,
            files=files,
            referenced_text=referenced_text,
            file_url=file_url,
            file_name=file_name
        )
    
    # ğŸ†• æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å®šå‘åˆ° "other" å¤„ç†
    # å½“ contextual intent ä¸­æ£€æµ‹åˆ°è¯¢é—®/è§£é‡Šè¯·æ±‚æ—¶ï¼Œorchestrator ä¼šè¿”å› redirect
    if orchestrator_response.get("redirect"):
        logger.info("ğŸ”„ Redirecting contextual explain request to 'other' intent handler...")
        original_message = orchestrator_response.get("original_message", message)
        redirect_topic = orchestrator_response.get("topic", current_topic)
        
        try:
            # ğŸ†• åŠ è½½å¯¹è¯å†å²
            conversation_history = await _load_conversation_history(
                memory_manager=orchestrator.memory_manager,
                user_id=user_id,
                session_id=session_id,
                max_turns=6
            )
            
            chat_response = await _handle_chat_conversation(
                message=original_message,
                current_topic=redirect_topic,
                session_topics=session_topics,
                file_uris=file_uris,
                conversation_history=conversation_history,  # ğŸ†• ä¼ é€’å¯¹è¯å†å²
                language=language  # ğŸ†• ä¼ é€’è¯­è¨€è®¾ç½®
            )
            
            # ä¿å­˜åˆ° MD
            await _save_chat_to_session(
                memory_manager=orchestrator.memory_manager,
                user_id=user_id,
                session_id=session_id,
                message=original_message,
                response_text=chat_response,
                intent="other",
                current_topic=redirect_topic,
                files=files,
                referenced_text=referenced_text,
                file_url=file_url,
                file_name=file_name
            )
            
            # Token ç»Ÿè®¡ï¼ˆLLM å¯¹è¯ï¼‰
            token_usage["skill_execution"] = {
                "source": "llm_gemini",
                "model": "gemini-2.5-flash",
                "thinking_mode": False,
                "total_tokens": 500  # ä¼°ç®—
            }
            token_usage["total_internal_tokens"] = token_usage["intent_router"]["tokens"] + 500
            
            return {
                "content_type": "text",
                "intent": "other",
                "topic": redirect_topic,
                "content": {"text": chat_response},
                "token_usage": token_usage
            }
        except Exception as chat_error:
            logger.error(f"âŒ Redirect chat failed: {chat_error}")
            # ç»§ç»­åŸæ¥çš„æµç¨‹
    
    processing_time = time.time() - start_time
    logger.info(f"âœ… Skill executed in {processing_time:.2f}s")
    
    # ğŸ†• æ”¶é›† Skill æ‰§è¡Œçš„ token ç»Ÿè®¡
    usage_summary = orchestrator_response.get("usage_summary", {})
    if usage_summary:
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¤–éƒ¨ API è°ƒç”¨ï¼ˆä¸è®¡ tokenï¼‰
        if usage_summary.get("external_api"):
            token_usage["skill_execution"] = {
                "source": "external_api",
                "model": "studyx_api",
                "thinking_mode": False,
                "prompt_tokens": 0,
                "completion_tokens": 0,
                "total_tokens": 0,
                "generation_time": 0
            }
        else:
            # å†…éƒ¨ LLM è°ƒç”¨ï¼ˆè®¡ tokenï¼‰- è¯¦ç»†è®°å½•æ¨¡å‹ä¿¡æ¯
            model_name = usage_summary.get("model", "unknown")
            is_thinking_model = "thinking" in model_name.lower() or "kimi-k2" in model_name.lower()
            
            # Token è®¡ç®—è¯´æ˜ï¼š
            # - total_tokens = prompt_tokens + completion_tokens
            # - thinking_tokens æ˜¯ completion_tokens çš„å­é›†ï¼ˆä¼°ç®—å€¼ï¼‰
            # - content_tokens = completion_tokens - thinking_tokensï¼ˆä¼°ç®—ï¼‰
            prompt_tokens = usage_summary.get("prompt_tokens", 0)
            completion_tokens = usage_summary.get("completion_tokens", 0)
            total_tokens = usage_summary.get("total_tokens", 0)
            thinking_tokens = usage_summary.get("thinking_tokens", 0)
            
            # ğŸ†• è®¡ç®— content_tokensï¼ˆä» thinking_chars å’Œ content_chars ä¼°ç®—ï¼‰
            thinking_chars = usage_summary.get("thinking_chars", 0)
            content_chars = usage_summary.get("content_chars", 0)
            # å¦‚æœæœ‰ thinking_tokensï¼Œcontent_tokens = completion - thinking
            content_tokens = max(0, completion_tokens - thinking_tokens) if thinking_tokens > 0 else completion_tokens
            
            token_usage["skill_execution"] = {
                "source": "llm",
                "model": model_name,
                "thinking_mode": is_thinking_model,
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,  # åŒ…å« thinking + content
                "total_tokens": total_tokens,            # = prompt + completion
                # ğŸ†• Completion ç»†åˆ†ï¼ˆthinking_tokens + content_tokens â‰ˆ completion_tokensï¼‰
                "completion_breakdown": {
                    "thinking_tokens": thinking_tokens,  # æ€è€ƒéƒ¨åˆ†ï¼ˆä¼°ç®—ï¼‰
                    "content_tokens": content_tokens,    # å†…å®¹éƒ¨åˆ†ï¼ˆä¼°ç®—ï¼‰
                    "thinking_chars": thinking_chars,    # æ€è€ƒå­—ç¬¦æ•°
                    "content_chars": content_chars       # å†…å®¹å­—ç¬¦æ•°
                },
                "generation_time": usage_summary.get("generation_time", 0),
                "data_source": usage_summary.get("source", "unknown")  # "api" ç²¾ç¡® or "estimated" ä¼°ç®—
            }
    
    # ğŸ†• è·å– Memory Operations çš„ token ç»Ÿè®¡ï¼ˆæ¥è‡ªåå°å¼‚æ­¥å‹ç¼©ä»»åŠ¡ï¼‰
    # æ³¨æ„ï¼šè¿™äº›æ˜¯ä¸Šä¸€æ¬¡è¯·æ±‚è§¦å‘çš„å‹ç¼©ä»»åŠ¡çš„ tokenï¼Œå› ä¸ºå‹ç¼©æ˜¯å¼‚æ­¥çš„
    try:
        memory_tracker = get_memory_token_tracker()
        memory_tokens = memory_tracker.get_and_clear_tokens(user_id, session_id)
        token_usage["memory_operations"]["compression_tokens"] = memory_tokens.get("compression_tokens", 0)
        token_usage["memory_operations"]["compression_input"] = memory_tokens.get("compression_input", 0)
        token_usage["memory_operations"]["compression_output"] = memory_tokens.get("compression_output", 0)
        token_usage["memory_operations"]["summary_tokens"] = memory_tokens.get("summary_tokens", 0)
        if memory_tokens.get("total_memory_tokens", 0) > 0:
            comp_in = memory_tokens.get("compression_input", 0)
            comp_out = memory_tokens.get("compression_output", 0)
            logger.info(f"ğŸ“Š Memory operations tokens: input={comp_in:,}, output={comp_out:,}, total={memory_tokens.get('total_memory_tokens', 0):,}")
    except Exception as e:
        logger.warning(f"âš ï¸ Failed to get memory tokens: {e}")
    
    # ğŸ†• è®¡ç®—æ€»å†…éƒ¨ token æ¶ˆè€—
    token_usage["total_internal_tokens"] = (
        token_usage["intent_router"]["tokens"] +
        token_usage["skill_execution"]["total_tokens"] +
        token_usage["memory_operations"]["compression_tokens"] +
        token_usage["memory_operations"]["summary_tokens"]
    )
    
    # ğŸ†• è®°å½• token ç»Ÿè®¡æ—¥å¿—
    model_info = token_usage['skill_execution'].get('model', 'unknown')
    thinking_info = " (thinking)" if token_usage['skill_execution'].get('thinking_mode') else ""
    logger.info(f"ğŸ“Š Token Usage Summary:")
    logger.info(f"   â€¢ Intent Router: {token_usage['intent_router']['tokens']} tokens ({token_usage['intent_router']['method']})")
    logger.info(f"   â€¢ Skill Execution: {token_usage['skill_execution']['total_tokens']} tokens ({model_info}{thinking_info})")
    logger.info(f"   â€¢ Memory Ops: {token_usage['memory_operations']['compression_tokens'] + token_usage['memory_operations']['summary_tokens']} tokens")
    logger.info(f"   â€¢ Total Internal: {token_usage['total_internal_tokens']} tokens")
    
    # ğŸ†• å°† token_usage æ·»åŠ åˆ°è¿”å›ç»“æœ
    orchestrator_response["token_usage"] = token_usage
    
    # ğŸ†• ç¡®ä¿æ‰€æœ‰ skill æ‰§è¡Œéƒ½è¿”å› context_stats
    if "context_stats" not in orchestrator_response:
        # è·å–å¯¹è¯å†å²é•¿åº¦
        try:
            conversation_history = await _load_conversation_history(
                orchestrator.memory_manager,
                user_id,
                session_id,
                max_turns=6
            )
            orchestrator_response["context_stats"] = {
                "loaded_turns": len(conversation_history) // 2 if conversation_history else 0,
                "retrieved_turns": 0,
                "session_turns": len(conversation_history) // 2 if conversation_history else 0,
                "context_source": "conversation_history"
            }
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to get context_stats: {e}")
            orchestrator_response["context_stats"] = {}
    
    # ğŸ†• ä¿å­˜é™„ä»¶ä¿¡æ¯åˆ° session metadataï¼ˆç”¨äºå†å²è®°å½•å›æ˜¾ï¼‰
    if file_url or file_name or referenced_text:
        try:
            attachments_data = {}
            if file_url:
                attachments_data["file_url"] = file_url
            if file_name:
                attachments_data["file_name"] = file_name
            if referenced_text:
                attachments_data["referenced_text"] = referenced_text
            
            # ä¿å­˜åˆ° session metadata
            session_mgr = orchestrator.memory_manager.get_conversation_session_manager(user_id)
            await session_mgr.start_or_continue_session(original_message, session_id=session_id)
            
            # æ›´æ–°æœ€åä¸€è½®çš„ attachments
            if hasattr(session_mgr, 'session_metadata') and session_mgr.session_metadata:
                if 'last_turn_attachments' not in session_mgr.session_metadata:
                    session_mgr.session_metadata['last_turn_attachments'] = {}
                
                turn_key = str(session_mgr.turn_counter)
                session_mgr.session_metadata['last_turn_attachments'][turn_key] = attachments_data
                
                # ä¿å­˜æ›´æ–°åçš„ metadata
                metadata_file = session_mgr.storage_path / f"{session_id}_metadata.json"
                import json
                with open(metadata_file, 'w', encoding='utf-8') as f:
                    json.dump(session_mgr.session_metadata, f, ensure_ascii=False, indent=2, default=str)
                
                logger.info(f"ğŸ“ Saved attachments to metadata: turn={turn_key}, data={attachments_data}")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to save attachments metadata: {e}")
    
    return orchestrator_response


async def _handle_chat_conversation(
    message: str,
    current_topic: Optional[str] = None,
    session_topics: Optional[List[str]] = None,
    file_uris: Optional[List[str]] = None,
    conversation_history: Optional[List[Dict[str, str]]] = None,
    language: str = "en"  # ğŸ†• è¯­è¨€è®¾ç½®
) -> str:
    """
    ä½¿ç”¨ Gemini 2.0 Flash Exp å¤„ç†é—²èŠ/å¯¹è¯ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ï¼‰
    
    Args:
        message: ç”¨æˆ·æ¶ˆæ¯
        current_topic: å½“å‰å­¦ä¹ ä¸»é¢˜
        session_topics: å†å²å­¦ä¹ ä¸»é¢˜
        file_uris: é™„ä»¶æ–‡ä»¶åˆ—è¡¨
        conversation_history: å¯¹è¯å†å²åˆ—è¡¨ [{"role": "user/assistant", "content": "..."}]
        language: å›å¤è¯­è¨€ (en/zh/auto)
    
    Returns:
        å¯¹è¯å“åº”æ–‡æœ¬
    """
    from app.services.gemini import GeminiClient
    
    gemini = GeminiClient()
    
    # ğŸ†• è¯­è¨€ä»£ç æ˜ å°„åˆ°è¯­è¨€åç§°ï¼ˆç”¨äº prompt æŒ‡ä»¤ï¼‰
    LANGUAGE_NAMES = {
        "auto": None,  # è‡ªåŠ¨æ£€æµ‹
        "en": "English",
        "zh": "Simplified Chinese (ç®€ä½“ä¸­æ–‡)",
        "zh-CN": "Simplified Chinese (ç®€ä½“ä¸­æ–‡)",
        "zh-TW": "Traditional Chinese (ç¹é«”ä¸­æ–‡)",
        "ja": "Japanese (æ—¥æœ¬èª)",
        "ko": "Korean (í•œêµ­ì–´)",
        "fr": "French (FranÃ§ais)",
        "es": "Spanish (EspaÃ±ol)",
        "pt": "Portuguese (PortuguÃªs)",
        "de": "German (Deutsch)",
        "it": "Italian (Italiano)",
        "ru": "Russian (Ğ ÑƒÑÑĞºĞ¸Ğ¹)",
        "vi": "Vietnamese (Tiáº¿ng Viá»‡t)",
        "th": "Thai (à¸ à¸²à¸©à¸²à¹„à¸—à¸¢)",
        "hi": "Hindi (à¤¹à¤¿à¤‚à¤¦à¥€)",
        "id": "Indonesian (Bahasa Indonesia)",
        "ms": "Malay (Melayu)",
        "tr": "Turkish (TÃ¼rkÃ§e)",
        "pl": "Polish (Polski)",
        "nl": "Dutch (Nederlands)",
        "ro": "Romanian (RomÃ¢nÄƒ)",
        "cs": "Czech (ÄŒeÅ¡tina)",
        "sk": "Slovak (SlovenÄina)",
        "hu": "Hungarian (Magyar)",
        "tl": "Tagalog/Filipino",
        "no": "Norwegian (Norsk)",
        "da": "Danish (Dansk)",
        "fi": "Finnish (Suomi)",
    }
    
    # ğŸ†• è·å–è¯­è¨€åç§°
    target_language = LANGUAGE_NAMES.get(language, None)
    is_chinese = language in ["zh", "zh-CN", "zh-TW"]
    
    # æ„å»ºä¸Šä¸‹æ–‡æç¤ºï¼ˆä½¿ç”¨ä¸­æ€§æ ¼å¼ï¼‰
    context_info = ""
    if current_topic:
        context_info = f"\nCurrent topic: {current_topic}"
    if session_topics:
        recent = session_topics[-3:]  # æœ€è¿‘3ä¸ªä¸»é¢˜
        context_info += f"\nRecent topics: {', '.join(recent)}"
    
    # ğŸ†• æ„å»ºå¯¹è¯å†å²ä¸Šä¸‹æ–‡
    history_context = ""
    if conversation_history and len(conversation_history) > 0:
        history_context = "\n\n## Previous conversation:\n"
        for turn in conversation_history[-6:]:  # æœ€è¿‘6è½®å¯¹è¯
            role = turn.get("role", "user")
            content = turn.get("content", "")[:200]  # é™åˆ¶æ¯è½®é•¿åº¦
            if role == "user":
                history_context += f"User: {content}\n"
            else:
                history_context += f"Assistant: {content}\n"
        history_context += "\n---\n"
        logger.info(f"ğŸ“œ Loaded {len(conversation_history[-6:])} turns of conversation history")
    
    # ğŸ†• å¤„ç†æ–‡ä»¶é™„ä»¶
    file_context = ""
    if file_uris:
        file_names = []
        for uri in file_uris:
            # æå–æ–‡ä»¶åï¼ˆå»æ‰ gs://kimi-dev/ å‰ç¼€ï¼‰
            name = uri.split('/')[-1] if '/' in uri else uri
            file_names.append(name)
        file_context = f"\nUploaded files: {', '.join(file_names)}"
        logger.info(f"ğŸ“ Chat with files: {file_names}")
    
    # ğŸ†• æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡æ–‡ä»¶ï¼ˆå›¾ç‰‡å¯ä»¥è¢« Gemini ç›´æ¥è¯†åˆ«ï¼‰
    image_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.webp')
    has_images = file_uris and any(uri.lower().endswith(image_extensions) for uri in file_uris)
    
    # ğŸ†• è¯­è¨€æŒ‡ä»¤ï¼ˆæ”¯æŒ 30+ è¯­è¨€ + è‡ªåŠ¨æ£€æµ‹ï¼‰
    lang_instruction = ""
    if language == "auto" or target_language is None:
        # è‡ªåŠ¨æ£€æµ‹ï¼šæ ¹æ®ç”¨æˆ·è¾“å…¥è¯­è¨€å›å¤
        # ğŸ†• å¢å¼ºï¼šæ˜ç¡®å¼ºè°ƒæ ¹æ®ç”¨æˆ·æ¶ˆæ¯è¯­è¨€å›å¤ï¼Œä¸å—æ–‡ä»¶å†…å®¹è¯­è¨€å½±å“
        lang_instruction = "\n\n**CRITICAL LANGUAGE RULE: You MUST respond in THE SAME LANGUAGE as the user's message (the 'User message:' field above), NOT the language of any uploaded files or documents. If the user writes in English (e.g., 'Please help me analyze...'), you MUST respond in English, even if the uploaded file is in Chinese/Japanese/other languages. Match the user's message language exactly.**"
    else:
        # æŒ‡å®šè¯­è¨€
        lang_instruction = f"\n\n**IMPORTANT: You MUST respond in {target_language} only. This is critical - do not use any other language, regardless of the content in uploaded files.**"
    
    # æ ¹æ®æ˜¯å¦æœ‰æ–‡ä»¶é€‰æ‹©ä¸åŒçš„ promptï¼ˆç»Ÿä¸€ä½¿ç”¨è‹±æ–‡æ¨¡æ¿ + è¯­è¨€æŒ‡ä»¤ï¼‰
    if file_uris:
        # æœ‰æ–‡ä»¶æ—¶çš„ prompt
        prompt = f"""You are StudyX Agent, an intelligent learning assistant.

The user has uploaded files (images/documents) and asked a question.
{file_context}
{context_info}
{history_context}
User message: {message}

Please answer the user's question based on the uploaded images/files.
- If it's an image, describe the content and answer the question
- If it's a document, analyze its content and provide a detailed answer
- If it's a math/physics problem, provide a **COMPLETE step-by-step solution with all calculations**
- Be friendly, clear, and helpful
- **DO NOT truncate or cut off your response. Complete all steps.**
{lang_instruction}
Please respond directly and completely (no length limit for math problems, otherwise within 800 words)."""
    else:
        # æ— æ–‡ä»¶æ—¶çš„ prompt
        if history_context:
            # æœ‰å¯¹è¯å†å²
            prompt = f"""You are StudyX Agent, an intelligent learning assistant. You are having a continuous conversation with the user.

**IMPORTANT** You MUST base your response on the previous conversation history, maintaining context continuity. If the user asks about something discussed earlier, refer to the previous responses.

Your main functions include:
- Generating practice questions (when user explicitly asks)
- Explaining concepts (when user asks "what is X" or "explain X")
- Creating flashcards (when user explicitly asks)
- Organizing notes
- Drawing mind maps
- Creating study plans (when user explicitly asks)

{context_info}
{history_context}

Current user message: {message}

Please respond based on conversation history.
- If user follows up on previous content, reference and explain in detail
- If user asks about "what we discussed earlier", find relevant content from history
- If it's a math/physics problem, provide a **COMPLETE step-by-step solution**
- Be friendly, clear, and helpful
- Don't proactively recommend generating quizzes/flashcards unless explicitly asked
- **DO NOT truncate or cut off your response. Complete all explanations.**
{lang_instruction}
Please respond directly and completely (within 800 words, no limit for math problems)."""
        else:
            # æ— å¯¹è¯å†å²
            prompt = f"""You are StudyX Agent, an intelligent learning assistant.

Your main functions include:
- Generating practice questions (when user explicitly asks for "quiz/test/questions")
- Explaining concepts (when user asks "what is X" or "explain X")
- Creating flashcards (when user explicitly asks)
- Organizing notes
- Drawing mind maps
- Creating study plans (when user explicitly asks)

When user sends a message, you should:
1. Respond friendly and directly answer their question
2. If user asks about a concept, explain it directly
3. Don't proactively recommend generating quizzes/flashcards unless explicitly asked

{context_info}

User message: {message}
{lang_instruction}
Please respond directly and completely (within 500 words)."""
    
    try:
        # ğŸ†• ä¼ é€’ file_uris ç»™ Geminiï¼ˆæ”¯æŒå¤šæ¨¡æ€è¯†åˆ«ï¼‰
        # ğŸ†• å¢åŠ  max_tokens åˆ° 8192ï¼Œç¡®ä¿å¤æ‚æ•°å­¦é¢˜è§£ç­”æœ‰è¶³å¤Ÿç©ºé—´
        # ğŸ†• ç¦ç”¨ thinking æ¨¡å¼ï¼ˆthinking_budget=0ï¼‰ï¼Œè®©æ›´å¤š tokens ç•™ç»™å®é™…è¾“å‡º
        response = await gemini.generate(
            prompt=prompt,
            model="gemini-2.5-flash",
            response_format="text",
            temperature=0.7,
            max_tokens=8192,  # ğŸ†• å¢åŠ åˆ° 8192ï¼Œé¿å…å¤æ‚æ•°å­¦é¢˜å›ç­”è¢«æˆªæ–­
            thinking_budget=0,  # ğŸ†• ç¦ç”¨ thinkingï¼Œé¿å…æ€è€ƒ tokens æ¶ˆè€—è¾“å‡ºé…é¢
            file_uris=file_uris if file_uris else None  # ä¼ é€’æ–‡ä»¶ URI
        )
        
        # å¤„ç†å“åº”
        if isinstance(response, dict):
            return response.get("content", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›å¤ã€‚")
        return str(response)
        
    except Exception as e:
        logger.error(f"âŒ Gemini chat failed: {e}")
        
        # æ„å»ºåŸºäºä¸Šä¸‹æ–‡çš„é»˜è®¤å›å¤
        if current_topic:
            return f"æˆ‘çœ‹åˆ°ä½ æ­£åœ¨å­¦ä¹ ã€Œ{current_topic}ã€ï¼Œæœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ è§£ç­”çš„å—ï¼ŸğŸ˜Š"
        else:
            return "ä½ å¥½ï¼æˆ‘æ˜¯å­¦ä¹ åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå­¦ä¹ é—®é¢˜æˆ‘å¯ä»¥å¸®ä½ è§£ç­”å—ï¼Ÿ"


async def _generate_clarification(
    message: str,
    artifact_contents: List[Dict[str, Any]],
    session_topics: List[str],
    current_topic: Optional[str] = None
) -> Optional[str]:
    """
    ğŸ†• åŸºäºå‹ç¼©ä¸Šä¸‹æ–‡ç”Ÿæˆæ¾„æ¸…é—®é¢˜
    
    å½“ç”¨æˆ·çš„è¯·æ±‚æ¨¡ç³Šæ—¶ï¼ˆå¦‚"é‚£é“é¢˜"ä½†æœ‰å¤šä¸ª quizï¼‰ï¼Œ
    ä½¿ç”¨ LLM ç”Ÿæˆå‹å¥½çš„æ¾„æ¸…é—®é¢˜å¸®åŠ©ç”¨æˆ·æ˜ç¡®éœ€æ±‚
    """
    from app.services.gemini import GeminiClient
    
    if not artifact_contents:
        return None
    
    try:
        gemini = GeminiClient()
        
        # æ„å»ºå‹ç¼©çš„ä¸Šä¸‹æ–‡æ‘˜è¦
        context_summary = _build_compressed_context_summary(artifact_contents, session_topics)
        
        prompt = f"""ä½ æ˜¯ StudyX Agent çš„æ¾„æ¸…åŠ©æ‰‹ã€‚ç”¨æˆ·å‘é€äº†ä¸€æ¡æ¶ˆæ¯ï¼Œä½†æ„å›¾ä¸å¤Ÿæ˜ç¡®ã€‚

## ç”¨æˆ·æ¶ˆæ¯
{message}

## å­¦ä¹ å†å²æ‘˜è¦
{context_summary}

## å½“å‰ä¸»é¢˜
{current_topic or "æ— "}

## ä»»åŠ¡
è¯·ç”Ÿæˆä¸€ä¸ªå‹å¥½ã€ç®€æ´çš„æ¾„æ¸…é—®é¢˜ï¼Œå¸®åŠ©ç”¨æˆ·æ˜ç¡®ä»–ä»¬æƒ³è¦çš„å†…å®¹ã€‚

æ¾„æ¸…é—®é¢˜åº”è¯¥ï¼š
1. å‹å¥½ä¸”ä¸æ‰“æ–­ç”¨æˆ·æ€è·¯
2. åˆ—å‡ºå¯èƒ½çš„é€‰é¡¹ï¼ˆå¦‚æœæœ‰å¤šä¸ª topic æˆ– artifactï¼‰
3. ä½¿ç”¨ç¼–å·è®©ç”¨æˆ·æ–¹ä¾¿å›å¤
4. ä¸è¶…è¿‡ 150 å­—

ç¤ºä¾‹æ ¼å¼ï¼š
"æ‚¨å¥½ï¼æˆ‘æ³¨æ„åˆ°æ‚¨ä¹‹å‰å­¦ä¹ äº†å¤šä¸ªä¸»é¢˜ã€‚è¯·é—®æ‚¨æƒ³è¦çš„æ˜¯ï¼š
1. å…³äºã€Œå‡¡å°”èµ›æ¡çº¦ã€çš„ç¬¬ä¸€é“é¢˜çš„è§£é‡Š
2. å…³äºã€Œç»æµå¤§è§æ¡ã€çš„ç¬¬äºŒé“é¢˜çš„è§£é‡Š
è¯·å›å¤æ•°å­—é€‰æ‹©ï¼Œæˆ–ç›´æ¥å‘Šè¯‰æˆ‘å…·ä½“éœ€æ±‚ ğŸ˜Š"

è¯·ç›´æ¥è¾“å‡ºæ¾„æ¸…é—®é¢˜ï¼Œä¸éœ€è¦å…¶ä»–è§£é‡Šã€‚"""

        response = await gemini.generate(
            prompt=prompt,
            model="gemini-2.5-flash",
            response_format="text",
            temperature=0.5
        )
        
        if isinstance(response, dict):
            return response.get("content", None)
        return str(response)
        
    except Exception as e:
        logger.error(f"âŒ Failed to generate clarification: {e}")
        return None


def _build_compressed_context_summary(
    artifact_contents: List[Dict[str, Any]],
    session_topics: List[str]
) -> str:
    """
    ğŸ†• æ„å»ºå‹ç¼©çš„ä¸Šä¸‹æ–‡æ‘˜è¦ï¼Œç”¨äº LLM æ¾„æ¸…
    """
    lines = []
    
    # ä¸»é¢˜æ‘˜è¦
    if session_topics:
        unique_topics = list(dict.fromkeys(session_topics))
        lines.append(f"ğŸ“š å­¦ä¹ è¿‡çš„ä¸»é¢˜ï¼š{', '.join(unique_topics[:5])}")
    
    # Artifacts æ‘˜è¦ï¼ˆæŒ‰ turn_number æ’åºï¼‰
    sorted_artifacts = sorted(artifact_contents, key=lambda x: x.get('turn_number', 0))
    
    for artifact in sorted_artifacts[-5:]:  # åªå–æœ€è¿‘ 5 ä¸ª
        turn = artifact.get('turn_number', '?')
        a_type = artifact.get('artifact_type', 'unknown')
        topic = artifact.get('topic', 'unknown')
        content = artifact.get('content', {})
        
        # æ ¹æ®ç±»å‹ç”Ÿæˆæ‘˜è¦
        if a_type == 'quiz_set' or 'questions' in content:
            q_count = len(content.get('questions', []))
            questions_preview = []
            for i, q in enumerate(content.get('questions', [])[:3], 1):
                q_text = q.get('question', q.get('question_text', ''))[:30]
                questions_preview.append(f"Q{i}: {q_text}...")
            lines.append(f"Turn {turn} - ğŸ“ ç»ƒä¹ é¢˜ ({topic}): {q_count}é“é¢˜")
            if questions_preview:
                lines.append(f"   é¢„è§ˆ: {'; '.join(questions_preview)}")
                
        elif a_type == 'flashcard_set' or 'cardList' in content:
            cards = content.get('cardList', content.get('cards', []))
            lines.append(f"Turn {turn} - ğŸ´ é—ªå¡ ({topic}): {len(cards)}å¼ ")
            
        elif a_type == 'explanation' or 'examples' in content:
            examples = content.get('examples', [])
            examples_preview = []
            for i, ex in enumerate(examples[:3], 1):
                ex_text = ex.get('example', '')[:25]
                examples_preview.append(f"ä¾‹{i}: {ex_text}...")
            lines.append(f"Turn {turn} - ğŸ“– è®²è§£ ({topic}): {len(examples)}ä¸ªä¾‹å­")
            if examples_preview:
                lines.append(f"   é¢„è§ˆ: {'; '.join(examples_preview)}")
        else:
            lines.append(f"Turn {turn} - {a_type} ({topic})")
    
    return "\n".join(lines) if lines else "æ— å†å²è®°å½•"


async def _update_last_turn_attachments(
    memory_manager,
    user_id: str,
    session_id: str,
    files: Optional[List[Dict[str, Any]]] = None,
    referenced_text: Optional[str] = None,
    file_url: Optional[str] = None,
    file_name: Optional[str] = None
):
    """
    æ›´æ–°æœ€åä¸€è½®å¯¹è¯çš„ attachmentsï¼ˆç”¨äº orchestrator æ‰§è¡Œåè¡¥å……é™„ä»¶ä¿¡æ¯ï¼‰
    
    Args:
        memory_manager: MemoryManager å®ä¾‹
        user_id: ç”¨æˆ· ID
        session_id: ä¼šè¯ ID
        files: ç»Ÿä¸€çš„æ–‡ä»¶ä¿¡æ¯æ•°ç»„
        referenced_text: å¼•ç”¨æ–‡æœ¬
        file_url: [å…¼å®¹] å•ä¸ªå›¾ç‰‡ URL
        file_name: [å…¼å®¹] å•ä¸ªæ–‡æ¡£å
    """
    try:
        session_mgr = memory_manager.get_conversation_session_manager(user_id)
        
        # æ„å»º attachments
        attachments = {}
        
        # ä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€çš„ files æ•°ç»„
        if files:
            attachments["files"] = files
        else:
            # å…¼å®¹æ—§ç‰ˆå•æ–‡ä»¶å­—æ®µ
            legacy_files = []
            if file_url:
                legacy_files.append({"type": "image", "url": file_url})
            if file_name:
                legacy_files.append({"type": "document", "name": file_name})
            if legacy_files:
                attachments["files"] = legacy_files
        
        if referenced_text:
            attachments["referenced_text"] = referenced_text
        
        if not attachments:
            return  # æ— é™„ä»¶ä¿¡æ¯ï¼Œè·³è¿‡
        
        # è·å–å½“å‰ turn æ•°
        turn_key = str(session_mgr.turn_counter) if hasattr(session_mgr, 'turn_counter') else "1"
        
        # æ›´æ–° session metadata
        if hasattr(session_mgr, 'session_metadata') and session_mgr.session_metadata:
            if 'last_turn_attachments' not in session_mgr.session_metadata:
                session_mgr.session_metadata['last_turn_attachments'] = {}
            
            session_mgr.session_metadata['last_turn_attachments'][turn_key] = attachments
            
            # ä¿å­˜æ›´æ–°åçš„ metadata
            from pathlib import Path
            metadata_file = session_mgr.storage_path / f"{session_id}_metadata.json"
            import json as json_module
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json_module.dump(session_mgr.session_metadata, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"ğŸ“ Updated attachments for turn {turn_key}: {list(attachments.keys())}")
    except Exception as e:
        logger.warning(f"âš ï¸ Failed to update turn attachments: {e}")


async def _save_chat_to_session(
    memory_manager,
    user_id: str,
    session_id: str,
    message: str,
    response_text: str,
    intent: str,
    current_topic: Optional[str] = None,
    files: Optional[List[Dict[str, Any]]] = None,  # ğŸ†• ç»Ÿä¸€çš„æ–‡ä»¶ä¿¡æ¯æ•°ç»„
    referenced_text: Optional[str] = None,
    # å…¼å®¹æ—§ç‰ˆå•æ–‡ä»¶å­—æ®µ
    file_url: Optional[str] = None,
    file_name: Optional[str] = None
):
    """
    ä¿å­˜èŠå¤©å¯¹è¯åˆ°ä¼šè¯ MD æ–‡ä»¶
    
    Args:
        memory_manager: MemoryManager å®ä¾‹
        user_id: ç”¨æˆ· ID
        session_id: ä¼šè¯ ID
        message: ç”¨æˆ·æ¶ˆæ¯
        response_text: AI å›å¤
        intent: æ„å›¾ç±»å‹ï¼ˆhelp/otherï¼‰
        current_topic: å½“å‰ä¸»é¢˜ï¼ˆå¯é€‰ï¼‰
        files: ç»Ÿä¸€çš„æ–‡ä»¶ä¿¡æ¯æ•°ç»„ [{"type": "image", "url": "..."}, {"type": "document", "name": "..."}]
        referenced_text: å¼•ç”¨æ–‡æœ¬å†…å®¹
        file_url: [å…¼å®¹] å•ä¸ªå›¾ç‰‡ HTTP URL
        file_name: [å…¼å®¹] å•ä¸ªæ–‡æ¡£æ–‡ä»¶å
    """
    try:
        session_mgr = memory_manager.get_conversation_session_manager(user_id)
        await session_mgr.start_or_continue_session(message, session_id=session_id)
        
        # ğŸ†• æ„å»ºé™„ä»¶ä¿¡æ¯ï¼ˆç”¨äºå†å²è®°å½•å›æ˜¾ï¼‰
        attachments = {}
        
        # ä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€çš„ files æ•°ç»„
        if files:
            attachments["files"] = files
        else:
            # å…¼å®¹æ—§ç‰ˆå•æ–‡ä»¶å­—æ®µ - è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            legacy_files = []
            if file_url:
                legacy_files.append({"type": "image", "url": file_url})
            if file_name:
                legacy_files.append({"type": "document", "name": file_name})
            if legacy_files:
                attachments["files"] = legacy_files
        
        if referenced_text:
            attachments["referenced_text"] = referenced_text
        
        await session_mgr.append_turn({
            "user_query": message,
            "agent_response": {
                "skill": "chat",
                "artifact_id": "",
                "content": {"text": response_text}
            },
            "response_type": "text",
            "timestamp": datetime.now(),
            "intent": {
                "intent": intent,
                "topic": current_topic,
                "raw_text": message
            },
            "metadata": {
                "model": "gemini-2.5-flash",
                "source": "/api/external/chat"
            },
            "attachments": attachments if attachments else None  # ğŸ†• é™„ä»¶ä¿¡æ¯
        })
        
        # ğŸ†• ä¿å­˜é™„ä»¶ä¿¡æ¯åˆ° session metadataï¼ˆç”¨äºå†å²è®°å½•å›æ˜¾ï¼‰
        if attachments:
            try:
                if hasattr(session_mgr, 'session_metadata') and session_mgr.session_metadata:
                    if 'last_turn_attachments' not in session_mgr.session_metadata:
                        session_mgr.session_metadata['last_turn_attachments'] = {}
                    
                    turn_key = str(session_mgr.turn_counter)
                    session_mgr.session_metadata['last_turn_attachments'][turn_key] = attachments
                    
                    # ä¿å­˜æ›´æ–°åçš„ metadata
                    metadata_file = session_mgr.storage_path / f"{session_id}_metadata.json"
                    import json as json_module
                    with open(metadata_file, 'w', encoding='utf-8') as f:
                        json_module.dump(session_mgr.session_metadata, f, ensure_ascii=False, indent=2, default=str)
                    
                    logger.info(f"ğŸ“ Saved attachments to metadata: turn={turn_key}")
            except Exception as attach_err:
                logger.warning(f"âš ï¸ Failed to save attachments metadata: {attach_err}")
        
        logger.info(f"âœ… Saved chat to MD: intent={intent}, user={user_id}, attachments={bool(attachments)}")
    except Exception as e:
        logger.error(f"âŒ Failed to save chat to MD: {e}")


async def _load_session_context_from_md(
    memory_manager,
    user_id: str,
    session_id: str
) -> Optional[Dict[str, Any]]:
    """
    ä» MD metadata æ–‡ä»¶åŠ è½½ session ä¸Šä¸‹æ–‡
    
    Args:
        memory_manager: MemoryManager å®ä¾‹
        user_id: ç”¨æˆ· ID
        session_id: ä¼šè¯ ID
    
    Returns:
        Dict with current_topic, session_topics, last_artifact, etc.
    """
    from pathlib import Path
    
    try:
        # æ„å»º metadata æ–‡ä»¶è·¯å¾„
        artifacts_dir = memory_manager.artifact_storage.base_dir / user_id
        metadata_file = artifacts_dir / f"{session_id}_metadata.json"
        
        if not metadata_file.exists():
            logger.debug(f"ğŸ“‚ No metadata file found: {metadata_file}")
            return None
        
        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        # æå–ä¸Šä¸‹æ–‡ä¿¡æ¯ - ä¼˜å…ˆä½¿ç”¨ last_topicï¼Œå…¶æ¬¡æ˜¯ current_topic
        current_topic = metadata.get("last_topic") or metadata.get("current_topic")
        topics = metadata.get("topics", [])
        
        # ä» artifact_history æ„å»º session_topics
        artifact_history = metadata.get("artifact_history", [])
        session_topics = [a.get("topic") for a in artifact_history if a.get("topic")]
        
        # å¦‚æœ topics åˆ—è¡¨ä¸ä¸ºç©ºï¼Œåˆå¹¶åˆ° session_topics
        if topics:
            for t in topics:
                if t not in session_topics:
                    session_topics.append(t)
        
        # è·å–æœ€åä¸€ä¸ª artifact
        last_artifact = None
        if artifact_history:
            last = artifact_history[-1]
            last_artifact = last.get("artifact_type")
        
        logger.info(f"ğŸ“‚ Loaded session metadata: topic={current_topic}, artifacts={len(artifact_history)}")
        
        # ğŸ†• å°è¯•ä» MD æ–‡ä»¶åŠ è½½ artifact contentsï¼ˆç”¨äºå¼•ç”¨è§£æï¼‰
        artifact_contents = await _load_artifacts_from_md(
            artifacts_dir / f"{session_id}.md"
        )
        
        return {
            "current_topic": current_topic,
            "session_topics": session_topics,
            "last_artifact": last_artifact,
            "artifact_contents": artifact_contents  # ğŸ†• æ·»åŠ å®Œæ•´å†…å®¹
        }
        
    except Exception as e:
        logger.error(f"âŒ Failed to load session context from MD: {e}")
        return None


async def _load_artifacts_from_md(md_file_path) -> List[Dict[str, Any]]:
    """
    ğŸ†• ä» MD æ–‡ä»¶ä¸­æå– artifact contentsï¼ˆç”¨äºå¼•ç”¨è§£æï¼‰
    
    è§£æ MD æ–‡ä»¶ä¸­çš„ JSON ä»£ç å—ï¼Œæå– agent_response.content
    """
    from pathlib import Path
    
    artifacts = []
    
    try:
        md_path = Path(md_file_path)
        if not md_path.exists():
            return artifacts
        
        content = md_path.read_text(encoding='utf-8')
        
        # æŸ¥æ‰¾æ‰€æœ‰ JSON ä»£ç å—
        json_pattern = r'```json\s*\n(.*?)\n```'
        matches = re.findall(json_pattern, content, re.DOTALL)
        
        for json_str in matches:
            try:
                data = json.loads(json_str)
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å« agent_response
                if 'agent_response' in data and 'content' in data['agent_response']:
                    topic = data.get('intent', {}).get('topic', '')
                    artifact_content = data['agent_response']['content']
                    turn_number = data.get('turn_number', 0)
                    skill = data['agent_response'].get('skill', '')
                    
                    # ğŸ”¥ ä» skill æ¨æ–­ artifact_type
                    # skill: explain_skill â†’ explanation
                    # skill: quiz_skill â†’ quiz_set
                    # skill: flashcard_skill â†’ flashcard_set
                    skill_to_type = {
                        'explain_skill': 'explanation',
                        'quiz_skill': 'quiz_set',
                        'flashcard_skill': 'flashcard_set',
                        'notes_skill': 'notes',
                        'mindmap_skill': 'mindmap',
                        'learning_plan_skill': 'learning_bundle'
                    }
                    artifact_type = skill_to_type.get(skill, 'unknown')
                    
                    # ğŸ”¥ ä¹Ÿå¯ä»¥ä» content ç»“æ„æ¨æ–­
                    if artifact_type == 'unknown':
                        if 'questions' in artifact_content:
                            artifact_type = 'quiz_set'
                        elif 'cardList' in artifact_content or 'cards' in artifact_content:
                            artifact_type = 'flashcard_set'
                        elif 'examples' in artifact_content or 'intuition' in artifact_content:
                            artifact_type = 'explanation'
                    
                    artifacts.append({
                        'artifact_type': artifact_type,
                        'topic': topic,
                        'content': artifact_content,
                        'turn_number': turn_number
                    })
                    
                    logger.debug(f"ğŸ“„ Loaded artifact: turn={turn_number}, type={artifact_type}, skill={skill}")
                    
            except json.JSONDecodeError:
                continue
        
        logger.info(f"ğŸ“¦ Loaded {len(artifacts)} artifacts from MD file")
        return artifacts
        
    except Exception as e:
        logger.error(f"âŒ Failed to load artifacts from MD: {e}")
        return []


async def _inject_artifacts_to_session(
    memory_manager,
    session_id: str,
    artifact_contents: List[Dict[str, Any]]
):
    """
    ğŸ†• å°†ä» MD åŠ è½½çš„ artifact contents æ³¨å…¥åˆ° session_context
    
    ç”¨äºå¼•ç”¨è§£ææ—¶è·å–å†å² artifact å†…å®¹
    """
    from app.models.memory import ArtifactRecord
    from datetime import datetime
    
    try:
        session_context = await memory_manager.get_session_context(session_id)
        
        # å¦‚æœ artifact_history å·²ç»æœ‰å†…å®¹ï¼Œè·³è¿‡
        if session_context.artifact_history:
            logger.debug(f"ğŸ“¦ Session already has {len(session_context.artifact_history)} artifacts, skipping injection")
            return
        
        # æ³¨å…¥ artifacts
        for artifact in artifact_contents:
            turn_num = artifact.get('turn_number', 0)
            record = ArtifactRecord(
                artifact_id=f"loaded_{turn_num}_{artifact.get('artifact_type', 'unknown')}",
                artifact_type=artifact.get('artifact_type', 'unknown'),
                topic=artifact.get('topic', ''),
                content=artifact.get('content', {}),
                summary=str(artifact.get('content', {}))[:100],
                storage_type='inline',
                content_reference=None,
                timestamp=datetime.now(),
                turn_number=turn_num  # ğŸ”¥ æ·»åŠ  turn_number
            )
            session_context.artifact_history.append(record)
        
        logger.info(f"ğŸ“¦ Injected {len(artifact_contents)} artifacts to session_context")
        
    except Exception as e:
        logger.error(f"âŒ Failed to inject artifacts to session: {e}")


async def _load_conversation_history(
    memory_manager,
    user_id: str,
    session_id: str,
    max_turns: int = 6
) -> List[Dict[str, str]]:
    """
    ğŸ†• ä» MD æ–‡ä»¶åŠ è½½å¯¹è¯å†å²ï¼ˆç”¨äºå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ï¼‰
    
    Args:
        memory_manager: MemoryManager å®ä¾‹
        user_id: ç”¨æˆ· ID
        session_id: ä¼šè¯ ID
        max_turns: æœ€å¤§è¿”å›è½®æ•°
    
    Returns:
        å¯¹è¯å†å²åˆ—è¡¨ [{"role": "user/assistant", "content": "..."}]
    """
    from pathlib import Path
    
    history = []
    
    try:
        # æ„å»º MD æ–‡ä»¶è·¯å¾„
        artifacts_dir = memory_manager.artifact_storage.base_dir / user_id
        md_file = artifacts_dir / f"{session_id}.md"
        
        if not md_file.exists():
            logger.debug(f"ğŸ“‚ No MD file found: {md_file}")
            return history
        
        content = md_file.read_text(encoding='utf-8')
        
        # æŸ¥æ‰¾æ‰€æœ‰ JSON ä»£ç å—ï¼Œæå–å¯¹è¯å†…å®¹
        json_pattern = r'```json\s*\n(.*?)\n```'
        matches = re.findall(json_pattern, content, re.DOTALL)
        
        for json_str in matches:
            try:
                data = json.loads(json_str)
                
                # æå–ç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹å›å¤
                user_query = data.get('user_query', '')
                agent_response = data.get('agent_response', {})
                
                if user_query:
                    history.append({
                        "role": "user",
                        "content": user_query
                    })
                
                # æå–åŠ©æ‰‹å›å¤å†…å®¹
                response_content = agent_response.get('content', {})
                if isinstance(response_content, dict):
                    # å°è¯•æå–æ–‡æœ¬å†…å®¹
                    if 'text' in response_content:
                        history.append({
                            "role": "assistant",
                            "content": response_content['text']
                        })
                    elif 'concept' in response_content:
                        # Explain ç±»å‹çš„å“åº”
                        concept = response_content.get('concept', '')
                        intuition = response_content.get('intuition', '')
                        history.append({
                            "role": "assistant",
                            "content": f"å…³äº {concept}ï¼š{intuition[:200]}..."
                        })
                    elif 'questions' in response_content:
                        # Quiz ç±»å‹
                        q_count = len(response_content.get('questions', []))
                        history.append({
                            "role": "assistant",
                            "content": f"[ç”Ÿæˆäº† {q_count} é“ç»ƒä¹ é¢˜]"
                        })
                    elif 'cardList' in response_content:
                        # Flashcard ç±»å‹
                        c_count = len(response_content.get('cardList', []))
                        history.append({
                            "role": "assistant",
                            "content": f"[ç”Ÿæˆäº† {c_count} å¼ é—ªå¡]"
                        })
                elif isinstance(response_content, str):
                    history.append({
                        "role": "assistant",
                        "content": response_content
                    })
                    
            except json.JSONDecodeError:
                continue
        
        # åªè¿”å›æœ€è¿‘çš„ N è½®
        if len(history) > max_turns * 2:
            history = history[-(max_turns * 2):]
        
        logger.info(f"ğŸ“œ Loaded {len(history)//2} turns of conversation history from {session_id}")
        return history
        
    except Exception as e:
        logger.error(f"âŒ Failed to load conversation history: {e}")
        return []


# ============= å“åº”æ ¼å¼è½¬æ¢ï¼ˆä¸´æ—¶é™åˆ¶ï¼šåªè¾“å‡ºæ–‡æœ¬ï¼‰ =============


def _convert_to_text_format(content_type: str, content: Any, topic: str = "") -> tuple:
    """
    ğŸ”¥ ä¸´æ—¶é™åˆ¶ï¼šå°†æ‰€æœ‰éæ–‡æœ¬æ ¼å¼è½¬æ¢ä¸ºçº¯æ–‡æœ¬è¾“å‡º
    
    å‰ç«¯ç›®å‰åªæ”¯æŒæ–‡æœ¬æ¸²æŸ“ï¼Œåç»­æ”¯æŒ Quiz/Flashcard ç­‰æ ¼å¼åå¯ç§»é™¤æ­¤å‡½æ•°
    
    Args:
        content_type: åŸå§‹å†…å®¹ç±»å‹ (quiz_set, flashcard_set, explanation, etc.)
        content: åŸå§‹å†…å®¹
        topic: ä¸»é¢˜
    
    Returns:
        (new_content_type, new_content): è½¬æ¢åçš„ç±»å‹å’Œå†…å®¹
    """
    # å·²ç»æ˜¯æ–‡æœ¬æ ¼å¼ï¼Œç›´æ¥è¿”å›
    if content_type in ["text", "clarification_needed", "onboarding"]:
        return content_type, content
    
    # å¦‚æœ content ä¸æ˜¯ dictï¼Œç›´æ¥è¿”å›
    if not isinstance(content, dict):
        return "text", {"text": str(content)}
    
    # è½¬æ¢ Quiz ä¸ºæ–‡æœ¬
    if content_type == "quiz_set":
        text_lines = []
        title = content.get("title", topic or "æµ‹éªŒ")
        text_lines.append(f"ğŸ“ **{title}**\n")
        
        questions = content.get("questions", [])
        for i, q in enumerate(questions, 1):
            text_lines.append(f"**ç¬¬ {i} é¢˜ï¼š** {q.get('question', '')}\n")
            
            options = q.get("answer_options", [])
            for j, opt in enumerate(options):
                letter = chr(65 + j)  # A, B, C, D
                is_correct = "âœ“" if opt.get("is_correct") else ""
                text_lines.append(f"  {letter}. {opt.get('text', '')} {is_correct}")
            
            # æ‰¾å‡ºæ­£ç¡®ç­”æ¡ˆ
            correct_opts = [chr(65 + j) for j, opt in enumerate(options) if opt.get("is_correct")]
            if correct_opts:
                text_lines.append(f"\n  **ç­”æ¡ˆï¼š{', '.join(correct_opts)}**")
            
            # æ·»åŠ è§£æ
            for j, opt in enumerate(options):
                if opt.get("is_correct") and opt.get("rationale"):
                    text_lines.append(f"  **è§£æï¼š** {opt.get('rationale')}")
                    break
            
            text_lines.append("")
        
        return "text", {"text": "\n".join(text_lines)}
    
    # è½¬æ¢ Flashcard ä¸ºæ–‡æœ¬
    if content_type == "flashcard_set":
        text_lines = []
        title = content.get("title", topic or "é—ªå¡")
        text_lines.append(f"ğŸ—‚ï¸ **{title}**\n")
        
        cards = content.get("cardList", [])
        for i, card in enumerate(cards, 1):
            text_lines.append(f"**å¡ç‰‡ {i}**")
            text_lines.append(f"  ğŸ“Œ æ­£é¢ï¼š{card.get('front', '')}")
            text_lines.append(f"  ğŸ“ èƒŒé¢ï¼š{card.get('back', '')}")
            text_lines.append("")
        
        return "text", {"text": "\n".join(text_lines)}
    
    # è½¬æ¢ Explanation ä¸ºæ–‡æœ¬
    if content_type == "explanation":
        text_lines = []
        concept = content.get("concept", topic or "æ¦‚å¿µè®²è§£")
        text_lines.append(f"ğŸ“– **{concept}**\n")
        
        if content.get("intuition"):
            text_lines.append(f"**ç›´è§‚ç†è§£ï¼š** {content['intuition']}\n")
        
        if content.get("formal_definition"):
            text_lines.append(f"**å®šä¹‰ï¼š** {content['formal_definition']}\n")
        
        if content.get("why_it_matters"):
            text_lines.append(f"**é‡è¦æ€§ï¼š** {content['why_it_matters']}\n")
        
        examples = content.get("examples", [])
        if examples:
            text_lines.append("**ä¾‹å­ï¼š**")
            for ex in examples:
                if isinstance(ex, dict):
                    text_lines.append(f"  â€¢ {ex.get('description', ex)}")
                else:
                    text_lines.append(f"  â€¢ {ex}")
            text_lines.append("")
        
        mistakes = content.get("common_mistakes", [])
        if mistakes:
            text_lines.append("**å¸¸è§é”™è¯¯ï¼š**")
            for m in mistakes:
                if isinstance(m, dict):
                    text_lines.append(f"  âš ï¸ {m.get('mistake', m)}")
                else:
                    text_lines.append(f"  âš ï¸ {m}")
            text_lines.append("")
        
        return "text", {"text": "\n".join(text_lines)}
    
    # è½¬æ¢ Learning Bundle ä¸ºæ–‡æœ¬
    if content_type == "learning_bundle":
        text_lines = []
        text_lines.append(f"ğŸ“š **å­¦ä¹ åŒ…ï¼š{topic or 'ç»¼åˆå­¦ä¹ '}**\n")
        
        components = content.get("components", [])
        for comp in components:
            comp_type = comp.get("type", "unknown")
            comp_content = comp.get("content", {})
            
            if comp_type == "explanation":
                text_lines.append("ğŸ“– **è®²è§£éƒ¨åˆ†**")
                text_lines.append(comp_content.get("text", str(comp_content)[:200]))
            elif comp_type == "quiz_set":
                text_lines.append("ğŸ“ **ç»ƒä¹ é¢˜**")
                # é€’å½’è½¬æ¢
                _, quiz_text = _convert_to_text_format("quiz_set", comp_content, "")
                text_lines.append(quiz_text.get("text", ""))
            elif comp_type == "flashcard_set":
                text_lines.append("ğŸ—‚ï¸ **é—ªå¡**")
                _, card_text = _convert_to_text_format("flashcard_set", comp_content, "")
                text_lines.append(card_text.get("text", ""))
            
            text_lines.append("")
        
        return "text", {"text": "\n".join(text_lines)}
    
    # å…¶ä»–æœªçŸ¥æ ¼å¼ï¼Œå°è¯•æå– text å­—æ®µæˆ–è½¬ä¸ºå­—ç¬¦ä¸²
    if "text" in content:
        return "text", {"text": content["text"]}
    
    # æœ€åå…œåº•ï¼šJSON è½¬å­—ç¬¦ä¸²
    import json
    return "text", {"text": json.dumps(content, ensure_ascii=False, indent=2)}


# ============= API Endpoints =============


@router.post("/chat", response_model=Dict[str, Any])
async def chat(
    request: ChatRequest,
    orchestrator: SkillOrchestrator = Depends(get_skill_orchestrator),
    token: Optional[str] = Header(None, description="ç”¨æˆ·è®¤è¯ Tokenï¼ˆç”¨äºå¤–éƒ¨ API è°ƒç”¨ï¼‰"),
    environment: Optional[str] = Header("test", description="ç¯å¢ƒæ ‡è¯† (dev/test/prod)")
):
    """
    é€šç”¨èŠå¤©æ¥å£ - æ”¯æŒæ‰€æœ‰ skill å’Œé™„ä»¶ä¸Šä¼ 
    
    å†…éƒ¨æµç¨‹ï¼š
    1. Intent Router è‡ªåŠ¨è¯†åˆ«æ„å›¾ï¼ˆquiz/flashcard/explain/notes/mindmap ç­‰ï¼‰
    2. Skill Orchestrator æ‰§è¡Œå¯¹åº” skill
    3. Memory Manager æ›´æ–°ä¸Šä¸‹æ–‡ & å­˜å‚¨ MD
    
    è¾“å…¥æ ¼å¼:
    ```json
    {
        "message": "å¸®æˆ‘å‡º5é“é¢˜",
        "file_uri": "gs://kimi-dev/user_xxx/xxx.txt",  // å¯é€‰ï¼Œé™„ä»¶
        "user_id": "user_kimi",  // å¯é€‰
        "session_id": "session_123"  // å¯é€‰
    }
    ```
    
    è¾“å‡ºæ ¼å¼:
    ```json
    {
        "code": 0,
        "msg": "Request succeeded",
        "data": {
            "content_type": "quiz_set",
            "intent": "quiz_request",
            "topic": "å…‰åˆä½œç”¨",
            "content": {...}
        }
    }
    ```
    
    é™„ä»¶ä½¿ç”¨æµç¨‹ï¼š
    1. å…ˆè°ƒç”¨ /api/external/upload ä¸Šä¼ æ–‡ä»¶ï¼Œè·å– file_uri
    2. å°† file_uri ä¼ å…¥æ­¤æ¥å£
    
    æ”¯æŒçš„æ„å›¾ç±»å‹ï¼š
    - quiz_request: ç”Ÿæˆæµ‹éªŒé¢˜ç›®
    - flashcard_request: ç”Ÿæˆé—ªå¡
    - explain_request: æ¦‚å¿µè®²è§£
    - notes: ç”Ÿæˆç¬”è®°
    - mindmap: ç”Ÿæˆæ€ç»´å¯¼å›¾
    - learning_bundle: ç”Ÿæˆå­¦ä¹ åŒ…
    - help: å¸®åŠ©ä¿¡æ¯
    - other: å…¶ä»–å¯¹è¯
    """
    try:
        # ğŸ†• è®¾ç½®ç”¨æˆ· token åˆ°è¯·æ±‚ä¸Šä¸‹æ–‡ï¼ˆç”¨äºå¤–éƒ¨ API è°ƒç”¨ï¼‰
        if token:
            set_user_api_token(token)
            logger.info(f"ğŸ”‘ User token set from headers")
        
        message = request.message.strip()
        
        # ============= æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ä¸Šä¼  =============
        has_files = bool(request.file_uri or request.file_uris)
        
        # ============= ğŸ†• è·å–ç”¨æˆ·è¯­è¨€è®¾ç½® =============
        # ä¼˜å…ˆçº§: 1. è¯·æ±‚å‚æ•° â†’ 2. StudyX ç”¨æˆ·è®¾ç½® â†’ 3. auto
        env = environment or "test"  # é»˜è®¤æµ‹è¯•ç¯å¢ƒ
        logger.info(f"ğŸŒ Environment: {env}")
        
        if request.language:
            language = request.language
            logger.info(f"ğŸŒ Using language from request: {language}")
        elif token:
            # ä» StudyX API è·å–ç”¨æˆ·è¯­è¨€è®¾ç½®ï¼ˆæ ¹æ®ç¯å¢ƒé€‰æ‹© APIï¼‰
            language = await get_user_language_from_studyx(token, env)
        else:
            language = "auto"
            logger.info(f"ğŸŒ No token, using auto language detection")
        
        # åœºæ™¯ A: å¿«æ·æŒ‰é’®æ¨¡å¼ï¼ˆaction_typeï¼‰- ä¸éœ€è¦è¾“å…¥æ–‡å­—
        if not message and request.action_type:
            # æ ¹æ®è¯­è¨€è®¾ç½®é€‰æ‹©é»˜è®¤æç¤ºï¼ˆç®€åŒ–ä¸ºä¸­è‹±åŒè¯­ï¼Œå…¶ä»–è¯­è¨€ç”¨è‹±è¯­ï¼‰
            if language in ["zh", "zh-CN", "zh-TW"]:
                action_default_messages = {
                    "explain_concept": "è¯·è¯¦ç»†è§£é‡Šè¿™ä¸ªæ¦‚å¿µ",
                    "make_simpler": "è¯·ç”¨æ›´ç®€å•çš„æ–¹å¼è§£é‡Š",
                    "common_mistakes": "è¿™ä¸ªçŸ¥è¯†ç‚¹æœ‰å“ªäº›å¸¸è§é”™è¯¯",
                }
                default_msg = "è¯·å¸®æˆ‘ç†è§£è¿™ä¸ªå†…å®¹"
            else:
                action_default_messages = {
                    "explain_concept": "Please explain this concept in detail",
                    "make_simpler": "Please explain this in a simpler way",
                    "common_mistakes": "What are the common mistakes for this topic",
                }
                default_msg = "Please help me understand this content"
            message = action_default_messages.get(request.action_type, default_msg)
        
        # åœºæ™¯ B: æ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼ˆå›¾ç‰‡/æ–‡æ¡£ï¼‰- ä¸éœ€è¦è¾“å…¥æ–‡å­—
        # ğŸ†• å…è®¸åªä¸Šä¼ å›¾ç‰‡/æ–‡ä»¶ï¼Œä¸è¾“å…¥æ–‡å­—
        if not message and has_files:
            # æ ¹æ®è¯­è¨€è®¾ç½®é»˜è®¤æç¤º
            if language in ["zh", "zh-CN", "zh-TW"]:
                message = "è¯·å¸®æˆ‘åˆ†æè¿™ä¸ªå›¾ç‰‡/æ–‡ä»¶çš„å†…å®¹"
            else:
                message = "Please help me analyze this image/file"
            logger.info(f"ğŸ“ File upload without message, using default: {message}")
        
        # åœºæ™¯ C: å¼•ç”¨æ–‡æœ¬æ¨¡å¼ï¼ˆæ—  action_type ä¸”æ— æ–‡ä»¶ï¼‰- å¿…é¡»è¾“å…¥æ–‡å­—
        if request.referenced_text and not message and not request.action_type and not has_files:
            return {
                "code": 400, 
                "msg": "Message is required when referenced_text is provided (unless using action_type or file upload)", 
                "data": None
            }
        
        # åœºæ™¯ D: æ™®é€šèŠå¤©ï¼ˆæ— æ–‡ä»¶ã€æ—  action_typeï¼‰- å¿…é¡»æœ‰æ¶ˆæ¯
        if not message and not has_files:
            return {"code": 400, "msg": "Message is empty", "data": None}
        
        # ä½¿ç”¨ä¼ å…¥çš„ session_idï¼Œæˆ–ç”Ÿæˆä¸ç™»å½•æ¥å£ä¸€è‡´çš„æ ¼å¼
        user_id = request.user_id or "anonymous"
        
        # ğŸ†• ä¼˜å…ˆä½¿ç”¨ question_id + answer_id ä½œä¸º session_idï¼ˆé¢˜ç›®å…³è”æ¨¡å¼ï¼‰
        if request.question_id and request.answer_id:
            session_id = f"q{request.question_id}_a{request.answer_id}"
            logger.info(f"ğŸ“ Using question-bound session: {session_id}")
        elif request.question_id:
            session_id = f"q{request.question_id}"
            logger.info(f"ğŸ“ Using question session: {session_id}")
        elif request.session_id:
            session_id = request.session_id
        else:
            session_id = f"{user_id}_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        logger.info("="*60)
        
        # ğŸ†• æ”¯æŒå¤šæ–‡ä»¶ï¼šåˆå¹¶ file_uri å’Œ file_uris
        file_uris = []
        if request.file_uri:
            file_uris.append(request.file_uri)
        if request.file_uris:
            file_uris.extend(request.file_uris)
        
        # å»é‡
        file_uris = list(dict.fromkeys(file_uris))
        
        # ğŸ†• æ„å»ºç»Ÿä¸€çš„ files æ•°ç»„ï¼ˆä¼˜å…ˆä½¿ç”¨ request.filesï¼Œå…¶æ¬¡è½¬æ¢æ—§ç‰ˆå­—æ®µï¼‰
        files = None
        if request.files:
            # ä½¿ç”¨æ–°ç‰ˆç»Ÿä¸€çš„ files æ•°ç»„
            files = [f.model_dump() for f in request.files]
        else:
            # å…¼å®¹æ—§ç‰ˆå•æ–‡ä»¶å­—æ®µ - è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            legacy_files = []
            if request.file_url:
                legacy_files.append({"type": "image", "url": request.file_url})
            if request.file_name:
                legacy_files.append({"type": "document", "name": request.file_name})
            if legacy_files:
                files = legacy_files
        
        logger.info(f"ğŸ“¥ /api/external/chat")
        logger.info(f"   â€¢ User: {user_id}")
        logger.info(f"   â€¢ Session: {session_id}")
        logger.info(f"   â€¢ Question ID: {request.question_id or 'N/A'}")
        logger.info(f"   â€¢ Answer ID: {request.answer_id or 'N/A'}")
        logger.info(f"   â€¢ Message: {message[:100]}...")
        logger.info(f"   â€¢ File URIs: {file_uris if file_uris else 'N/A'} ({len(file_uris)} files)")
        logger.info(f"   â€¢ Files: {files if files else 'N/A'}")
        logger.info(f"   â€¢ Referenced Text: {'Yes (' + str(len(request.referenced_text)) + ' chars)' if request.referenced_text else 'N/A'}")
        logger.info(f"   â€¢ Action Type: {request.action_type or 'N/A'}")
        # ğŸ†• æ”¯æŒ qid å’Œ resource_id ä¸¤ç§å­—æ®µå
        effective_qid = request.qid or request.resource_id
        logger.info(f"   â€¢ QID/Resource ID: {effective_qid or 'N/A'}")
        logger.info("="*60)
        
        # ğŸ†• æ£€æŸ¥æ˜¯å¦éœ€è¦è·å–é¢˜ç›®ä¸Šä¸‹æ–‡
        # ä¼˜å…ˆçº§: 1. request.question_context (å‰ç«¯ç›´æ¥ä¼ å…¥) â†’ 2. ä» StudyX API è·å– (éœ€è¦ qid/resource_id)
        question_context = None
        
        # æ£€æŸ¥ session æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆåˆ¤æ–­æ˜¯å¦ä¸ºæ–° sessionï¼‰
        from pathlib import Path
        artifacts_dir = Path("artifacts")
        if not artifacts_dir.exists():
            artifacts_dir = Path("backend/artifacts")
        if not artifacts_dir.exists():
            artifacts_dir = Path("/root/usr/skill_agent_demo/backend/artifacts")
        
        session_file = artifacts_dir / user_id / f"{session_id}.md"
        is_new_session = not session_file.exists()
        
        # ğŸ†• å¿«æ·é—®ç­”ï¼ˆaction_typeï¼‰ä¹Ÿéœ€è¦ question_contextï¼Œå³ä½¿ session å·²å­˜åœ¨
        # è¿™æ · AI æ‰èƒ½ç†è§£ "this solution"ã€"this concept" ç­‰æŒ‡ä»£è¯
        needs_question_context = is_new_session or request.action_type
        
        if needs_question_context:
            # æ–¹å¼ 1: å‰ç«¯ç›´æ¥ä¼ å…¥ question_context
            if request.question_context:
                question_context = request.question_context
                logger.info(f"âœ… Using question context from request: {len(question_context)} chars")
            # æ–¹å¼ 2: é€šè¿‡ qid/resource_id ä» StudyX è·å–
            elif effective_qid and token:
                # ğŸ†• æ£€æŸ¥ qid æ ¼å¼ï¼šStudyX API éœ€è¦ slug æ ¼å¼ï¼ˆå¦‚ 4merhtgï¼‰ï¼Œä¸èƒ½æ˜¯çº¯æ•°å­—
                if effective_qid.isdigit():
                    logger.warning(f"âš ï¸ qid '{effective_qid}' is numeric format (question_id), not slug format. Skipping API call.")
                    logger.warning(f"ğŸ’¡ Frontend should pass slug format qid/resource_id (e.g., '4merhtg'), not question_id")
                else:
                    reason = "new session" if is_new_session else f"quick action '{request.action_type}'"
                    logger.info(f"ğŸ“¡ Fetching question context ({reason}) from StudyX (qid={effective_qid}, env={env})...")
                    question_context = await fetch_question_context_from_studyx(effective_qid, token, env)
                    if question_context:
                        logger.info(f"âœ… Question context fetched: {len(question_context)} chars")
                    else:
                        logger.warning(f"âš ï¸ Failed to fetch question context for qid={effective_qid} (API permission issue?)")
        else:
            logger.info(f"ğŸ“‚ Existing session without action_type, skipping question context fetch")
        
        # ğŸ”’ è·å– session é”ï¼ˆé˜²æ­¢åŒä¸€ä¼šè¯çš„å¹¶å‘ä¿®æ”¹ï¼‰
        lock = await get_session_lock(session_id)
        
        async with lock:
            logger.info(f"ğŸ”’ Acquired lock for session: {session_id}")
            
            # ğŸ”¥ è°ƒç”¨å®Œæ•´çš„ skill æ¡†æ¶æµç¨‹ï¼ˆä¼ é€’å®Œæ•´çš„ file_uris æ•°ç»„ï¼‰
            result = await execute_skill_pipeline(
                message=message,
                user_id=user_id,
                session_id=session_id,
                orchestrator=orchestrator,
                quantity_override=None,
                skill_hint=None,
                file_uris=file_uris if file_uris else None,  # ğŸ†• ä¼ é€’å¤šæ–‡ä»¶ URI åˆ—è¡¨
                referenced_text=request.referenced_text,  # ğŸ†• ä¼ é€’å¼•ç”¨æ–‡æœ¬
                action_type=request.action_type,  # ğŸ†• ä¼ é€’å¿«æ·æ“ä½œç±»å‹
                files=files,  # ğŸ†• ç»Ÿä¸€çš„æ–‡ä»¶ä¿¡æ¯æ•°ç»„ï¼ˆç”¨äºå›æ˜¾ï¼‰
                file_url=request.file_url,  # å…¼å®¹æ—§ç‰ˆ
                file_name=request.file_name,  # å…¼å®¹æ—§ç‰ˆ
                language=language,  # ğŸ†• ä¼ é€’è¯­è¨€è®¾ç½®
                question_context=question_context  # ğŸ†• ä¼ é€’é¢˜ç›®ä¸Šä¸‹æ–‡
            )
            
            logger.info(f"ğŸ”“ Released lock for session: {session_id}")
        
        # æ£€æŸ¥æ‰§è¡Œç»“æœ
        if result.get("success") == False:
            return {
                "code": 500,
                "msg": result.get("message", "Skill execution failed"),
                "data": None
            }
        
        # æ„å»ºå“åº”
        original_content_type = result.get("content_type", "unknown")
        intent = result.get("intent", "unknown")
        # ğŸ†• å…¼å®¹ content å’Œ response_contentï¼ˆPlan Skill ä½¿ç”¨ response_contentï¼‰
        original_content = result.get("content") or result.get("response_content") or {}
        
        # ğŸ†• æå– topicï¼ˆä¼˜å…ˆä» result ç›´æ¥è·å–ï¼Œå…¶æ¬¡ä» content ä¸­ï¼‰
        # orchestrator å·²ç»å°† actual_topic æ”¾å…¥ result["topic"]
        topic = result.get("topic") or ""
        if not topic and isinstance(original_content, dict):
            topic = original_content.get("title") or original_content.get("topic") or original_content.get("concept") or ""
        
        # ğŸ”¥ ä¸´æ—¶é™åˆ¶ï¼šå°†æ‰€æœ‰éæ–‡æœ¬æ ¼å¼è½¬æ¢ä¸ºçº¯æ–‡æœ¬è¾“å‡º
        # å‰ç«¯ç›®å‰åªæ”¯æŒæ–‡æœ¬æ¸²æŸ“ï¼Œåç»­æ”¯æŒå…¶ä»–æ ¼å¼åå¯ç§»é™¤æ­¤é™åˆ¶
        content_type, content = _convert_to_text_format(original_content_type, original_content, topic)
        
        # ğŸ†• æå– token_usage
        token_usage = result.get("token_usage", {})
        
        # ğŸ†• è®°å½• token ä½¿ç”¨åˆ°æ–‡ä»¶ï¼ˆæŒ‰å¤©åˆ‡åˆ†ï¼‰
        try:
            token_stats = get_token_stats_service()
            token_stats.record_usage(
                user_id=user_id,
                session_id=session_id,
                message=message,
                intent=intent,
                content_type=content_type,
                token_usage=token_usage,
                file_uris=file_uris if file_uris else None
            )
        except Exception as stats_error:
            logger.warning(f"âš ï¸ Failed to record token stats: {stats_error}")
        
        # ğŸ†• æå– context_statsï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        context_stats = result.get("context_stats", {})
        
        return {
            "code": 0,
            "msg": "Request succeeded",
            "data": {
                "session_id": session_id,  # ğŸ†• è¿”å› session_id ä¾›å‰ç«¯ä½¿ç”¨
                "content_type": content_type,
                "intent": intent,
                "topic": topic,
                "content": content,
                "token_usage": token_usage,  # ğŸ†• æš´éœ² token ç»Ÿè®¡
                "context_stats": context_stats  # ğŸ†• æš´éœ²ä¸Šä¸‹æ–‡ç»Ÿè®¡
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ chat error: {e}", exc_info=True)
        return {"code": 500, "msg": str(e), "data": None}
    finally:
        # ğŸ†• æ¸…é™¤è¯·æ±‚ä¸Šä¸‹æ–‡ä¸­çš„ç”¨æˆ· token
        clear_user_api_token()


# ============= Token ç»Ÿè®¡æ¥å£ =============

@router.get("/token-stats/today", response_model=Dict[str, Any])
async def get_today_token_stats():
    """
    è·å–ä»Šå¤©çš„ Token ä½¿ç”¨æ±‡æ€»
    
    è¿”å›æ ¼å¼:
    ```json
    {
        "code": 0,
        "msg": "Request succeeded",
        "data": {
            "date": "2025-11-27",
            "summary": {
                "total_requests": 100,
                "total_internal_tokens": 50000,
                "intent_router_tokens": 1500,
                "skill_execution_tokens": 48000,
                "memory_operation_tokens": 500,
                "external_api_calls": 30,
                "llm_calls": 70
            }
        }
    }
    ```
    """
    try:
        token_stats = get_token_stats_service()
        summary = token_stats.get_today_summary()
        
        return {
            "code": 0,
            "msg": "Request succeeded",
            "data": summary
        }
    except Exception as e:
        logger.error(f"âŒ get_today_token_stats error: {e}", exc_info=True)
        return {"code": 500, "msg": str(e), "data": None}


@router.get("/token-stats/records", response_model=Dict[str, Any])
async def get_token_stats_records(limit: int = 100):
    """
    è·å–ä»Šå¤©çš„ Token ä½¿ç”¨è¯¦ç»†è®°å½•
    
    Args:
        limit: è¿”å›è®°å½•æ•°é‡é™åˆ¶ï¼ˆé»˜è®¤100ï¼‰
    
    è¿”å›æ ¼å¼:
    ```json
    {
        "code": 0,
        "msg": "Request succeeded",
        "data": {
            "records": [
                {
                    "timestamp": "2025-11-27T10:30:00",
                    "user_id": "user_kimi",
                    "session_id": "session_xxx",
                    "message": "ç»™æˆ‘3é“é¢˜...",
                    "intent": "quiz_request",
                    "content_type": "quiz_set",
                    "token_usage": {...}
                }
            ]
        }
    }
    ```
    """
    try:
        token_stats = get_token_stats_service()
        records = token_stats.get_today_records(limit=limit)
        
        return {
            "code": 0,
            "msg": "Request succeeded",
            "data": {
                "date": datetime.now().strftime("%Y-%m-%d"),
                "count": len(records),
                "records": records
            }
        }
    except Exception as e:
        logger.error(f"âŒ get_token_stats_records error: {e}", exc_info=True)
        return {"code": 500, "msg": str(e), "data": None}


@router.get("/token-stats/dates", response_model=Dict[str, Any])
async def list_token_stats_dates():
    """
    åˆ—å‡ºæ‰€æœ‰æœ‰ç»Ÿè®¡æ•°æ®çš„æ—¥æœŸ
    
    è¿”å›æ ¼å¼:
    ```json
    {
        "code": 0,
        "msg": "Request succeeded",
        "data": {
            "dates": ["2025-11-27", "2025-11-26", "2025-11-25"]
        }
    }
    ```
    """
    try:
        token_stats = get_token_stats_service()
        dates = token_stats.list_available_dates()
        
        return {
            "code": 0,
            "msg": "Request succeeded",
            "data": {
                "dates": dates
            }
        }
    except Exception as e:
        logger.error(f"âŒ list_token_stats_dates error: {e}", exc_info=True)
        return {"code": 500, "msg": str(e), "data": None}


@router.get("/token-stats/{target_date}", response_model=Dict[str, Any])
async def get_token_stats_by_date(target_date: str):
    """
    è·å–æŒ‡å®šæ—¥æœŸçš„ Token ç»Ÿè®¡
    
    Args:
        target_date: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ YYYY-MM-DD
    
    è¿”å›æ ¼å¼:
    ```json
    {
        "code": 0,
        "msg": "Request succeeded",
        "data": {
            "date": "2025-11-26",
            "summary": {...},
            "records": [...]
        }
    }
    ```
    """
    try:
        token_stats = get_token_stats_service()
        stats = token_stats.get_stats_by_date(target_date)
        
        if stats is None:
            return {
                "code": 404,
                "msg": f"No stats found for {target_date}",
                "data": None
            }
        
        return {
            "code": 0,
            "msg": "Request succeeded",
            "data": stats
        }
    except Exception as e:
        logger.error(f"âŒ get_token_stats_by_date error: {e}", exc_info=True)
        return {"code": 500, "msg": str(e), "data": None}


# ============= é¢˜ç›®èŠå¤©å†å²æ¥å£ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰ =============


@router.get("/chat/history", response_model=Dict[str, Any])
async def get_homework_chat_history(
    question_id: str = Query(..., alias="aiQuestionId", description="é¢˜ç›® ID"),
    answer_id: str = Query(..., alias="answerId", description="ç­”æ¡ˆ ID")
):
    """
    è·å–é¢˜ç›®ä¸‹çš„èŠå¤©å†å²ï¼ˆå…¼å®¹æ—§æ¥å£ /chat/getHomeworkChatListV2ï¼‰
    
    å‚æ•°:
    - aiQuestionId: é¢˜ç›® ID
    - answerId: ç­”æ¡ˆ ID
    
    è¿”å›:
    ```json
    {
        "code": 0,
        "msg": "success",
        "data": {
            "question_id": "Q123",
            "answer_id": "A456",
            "chat_list": [
                {
                    "turn": 1,
                    "timestamp": "2025-12-15T10:30:00",
                    "user_message": "è¿™æ­¥æ€ä¹ˆç†è§£",
                    "assistant_message": "è¿™ä¸€æ­¥æ˜¯...",
                    "referenced_text": "8x-31=-29"
                }
            ],
            "total": 5
        }
    }
    ```
    """
    import os
    import re
    from pathlib import Path
    
    try:
        # æ ¹æ® question_id å’Œ answer_id æ„å»º session_id
        session_id = f"q{question_id}_a{answer_id}"
        
        logger.info(f"ğŸ“œ Getting chat history for question={question_id}, answer={answer_id}")
        
        # æŸ¥æ‰¾å¯¹åº”çš„ MD æ–‡ä»¶ï¼ˆä»é¡¹ç›®æ ¹ç›®å½•çš„ backend/artifactsï¼‰
        # æ”¯æŒä» backend ç›®å½•è¿è¡Œæˆ–ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
        artifacts_dir = Path("artifacts")
        if not artifacts_dir.exists():
            artifacts_dir = Path("backend/artifacts")
        if not artifacts_dir.exists():
            artifacts_dir = Path("/root/usr/skill_agent_demo/backend/artifacts")
        
        chat_list = []
        
        # ğŸ†• éå†æ‰€æœ‰ç”¨æˆ·ç›®å½•ï¼Œæ‰¾æœ€è¿‘ä¿®æ”¹çš„ session æ–‡ä»¶
        session_file = None
        latest_mtime = 0
        selected_user_dir = None
        
        for user_dir in artifacts_dir.iterdir():
            if not user_dir.is_dir():
                continue
            
            potential_file = user_dir / f"{session_id}.md"
            if potential_file.exists():
                mtime = potential_file.stat().st_mtime
                if mtime > latest_mtime:
                    latest_mtime = mtime
                    session_file = potential_file
                    selected_user_dir = user_dir
        
        # å¤„ç†æ‰¾åˆ°çš„æ–‡ä»¶
        if session_file and selected_user_dir:
            user_dir = selected_user_dir
            logger.info(f"ğŸ“„ Found session file: {session_file} (user={user_dir.name})")
            
            # è§£æ MD æ–‡ä»¶
            content = session_file.read_text(encoding='utf-8')
            
            # ä½¿ç”¨æ­£åˆ™è§£ææ¯ä¸€è½®å¯¹è¯
            # æ ¼å¼: ## Turn 1 - 07:25:17
            #       ### ğŸ‘¤ User Query
            #       ç”¨æˆ·æ¶ˆæ¯
            #       ### ğŸ¤– Agent Response
            #       ...
            turn_pattern = r'## Turn (\d+) - (\d{2}:\d{2}:\d{2})\s*\n+### ğŸ‘¤ User Query\s*\n(.*?)### ğŸ¤– Agent Response\s*\n(.*?)(?=## Turn |\Z)'
            matches = re.findall(turn_pattern, content, re.DOTALL)
            
            logger.info(f"ğŸ“Š Found {len(matches)} turns in MD file")
            
            # ğŸ†• åŠ è½½åé¦ˆæ•°æ®
            feedback_map = {}
            feedback_dir = Path("feedback")
            if not feedback_dir.exists():
                feedback_dir = Path("backend/feedback")
            if not feedback_dir.exists():
                feedback_dir = Path("/root/usr/skill_agent_demo/backend/feedback")
            
            # æŸ¥æ‰¾è¯¥ç”¨æˆ·çš„åé¦ˆæ–‡ä»¶
            user_id = user_dir.name
            user_feedback_file = feedback_dir / f"{user_id}_feedback.json"
            if user_feedback_file.exists():
                try:
                    with open(user_feedback_file, 'r', encoding='utf-8') as f:
                        feedback_list = json.load(f)
                        for fb in feedback_list:
                            if fb.get("session_id") == session_id:
                                turn_key = fb.get("turn_number")
                                feedback_map[turn_key] = {
                                    "type": fb.get("feedback_type"),
                                    "reason": fb.get("report_reason"),
                                    "timestamp": fb.get("timestamp")
                                }
                except Exception as fb_err:
                    logger.warning(f"âš ï¸ Failed to load feedback: {fb_err}")
            
            # ğŸ†• åŠ è½½é™„ä»¶æ•°æ®ï¼ˆä» session metadataï¼‰
            attachments_map = {}
            metadata_file = user_dir / f"{session_id}_metadata.json"
            if metadata_file.exists():
                try:
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                        last_turn_attachments = metadata.get("last_turn_attachments", {})
                        for turn_key, attach_data in last_turn_attachments.items():
                            attachments_map[int(turn_key)] = attach_data
                except Exception as meta_err:
                    logger.warning(f"âš ï¸ Failed to load attachments metadata: {meta_err}")
                
            for match in matches:
                turn_num = int(match[0])
                timestamp = match[1]
                user_section = match[2].strip()
                assistant_section = match[3].strip()
                
                # ç”¨æˆ·æ¶ˆæ¯å°±æ˜¯ User Query ä¸‹é¢çš„å†…å®¹
                user_message = user_section.split('\n')[0] if user_section else ""
                
                # ğŸ†• æå–é™„ä»¶ä¿¡æ¯ï¼ˆä» JSON attachments å­—æ®µæå–ï¼‰
                files = None
                referenced_text = None
                
                # å°è¯•ä» attachments å­—æ®µæå– files æ•°ç»„
                attachments_match = re.search(r'"attachments":\s*(\{[^}]*\})', assistant_section)
                if attachments_match:
                    try:
                        attachments_data = json.loads(attachments_match.group(1))
                        files = attachments_data.get("files")
                        referenced_text = attachments_data.get("referenced_text")
                    except json.JSONDecodeError:
                        # æ—§æ ¼å¼å…¼å®¹ï¼šä½¿ç”¨æ­£åˆ™æå–
                        attachments_str = attachments_match.group(1)
                        # æå– file_urlï¼ˆæ—§æ ¼å¼ï¼‰
                        file_url_match = re.search(r'"file_url":\s*"([^"]*)"', attachments_str)
                        # æå– file_nameï¼ˆæ—§æ ¼å¼ï¼‰
                        file_name_match = re.search(r'"file_name":\s*"([^"]*)"', attachments_str)
                        # è½¬æ¢ä¸ºæ–°çš„ files æ ¼å¼
                        if file_url_match or file_name_match:
                            files = []
                            if file_url_match:
                                files.append({"type": "image", "url": file_url_match.group(1)})
                            if file_name_match:
                                files.append({"type": "document", "name": file_name_match.group(1)})
                        # æå– referenced_text
                        ref_text_match = re.search(r'"referenced_text":\s*"([^"]*)"', attachments_str)
                        if ref_text_match:
                            referenced_text = ref_text_match.group(1)
                
                # å…¼å®¹æ—§æ ¼å¼ï¼šç›´æ¥ä» assistant_section æå– referenced_text
                if not referenced_text:
                    ref_text_match = re.search(r'"referenced_text":\s*"([^"]*)"', assistant_section)
                    referenced_text = ref_text_match.group(1) if ref_text_match else None
                
                # æå–åŠ©æ‰‹å›å¤çš„æ‘˜è¦ï¼ˆä» JSON ä»£ç å—æˆ– text å­—æ®µæå–ï¼‰
                assistant_message = ""
                
                # æ–¹æ³•1: å°è¯•ä» JSON ä»£ç å—ä¸­è§£æ text å­—æ®µ
                json_block_match = re.search(r'```json\s*\n(\{[\s\S]*?\})\s*\n```', assistant_section)
                if json_block_match:
                    try:
                        json_content = json.loads(json_block_match.group(1))
                        if isinstance(json_content, dict) and "text" in json_content:
                            assistant_message = json_content["text"]
                            logger.debug(f"ğŸ“ Method 1 succeeded for turn {turn_num}, text length: {len(assistant_message)}")
                    except json.JSONDecodeError as e:
                        logger.debug(f"ğŸ“ Method 1 JSON parse failed for turn {turn_num}: {e}")
                    
                # æ–¹æ³•2: ä» details å—ä¸­çš„ JSON è§£æï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰
                if not assistant_message:
                    # ä½¿ç”¨æ›´å¯é çš„æ­£åˆ™ï¼šåŒ¹é…åˆ° \n} ç»“å°¾çš„å®Œæ•´ JSON å¯¹è±¡
                    details_match = re.search(r'<details>[\s\S]*?```json\s*\n(\{[\s\S]+?\n\})\s*\n```', assistant_section)
                    if details_match:
                        try:
                            structured_json = json.loads(details_match.group(1))
                            # ä¼˜å…ˆä» agent_response.content.text è·å–
                            agent_resp = structured_json.get("agent_response", {})
                            content = agent_resp.get("content", {})
                            skill = agent_resp.get("skill", "")
                            
                            if isinstance(content, dict):
                                if "text" in content:
                                    # æ™®é€š chat å“åº”
                                    assistant_message = content["text"]
                                    logger.debug(f"ğŸ“ Method 2 (details.text) succeeded for turn {turn_num}")
                                elif "intuition" in content:
                                    # explain_skill å“åº”ï¼šç»„åˆå¤šä¸ªå­—æ®µ
                                    parts = []
                                    if content.get("concept"):
                                        parts.append(f"**{content['concept']}**\n")
                                    if content.get("intuition"):
                                        parts.append(f"ğŸ“š **ç›´è§‰ç†è§£**: {content['intuition']}\n")
                                    if content.get("formal_definition"):
                                        parts.append(f"ğŸ“– **æ­£å¼å®šä¹‰**: {content['formal_definition']}\n")
                                    if content.get("why_it_matters"):
                                        parts.append(f"ğŸ’¡ **ä¸ºä»€ä¹ˆé‡è¦**: {content['why_it_matters']}\n")
                                    # æ·»åŠ ç¤ºä¾‹ï¼ˆæœ€å¤š2ä¸ªï¼‰
                                    examples = content.get("examples", [])
                                    if examples:
                                        parts.append("ğŸŒŸ **å®ä¾‹**:\n")
                                        for i, ex in enumerate(examples[:2], 1):
                                            if isinstance(ex, dict):
                                                parts.append(f"  {i}. {ex.get('example', '')}: {ex.get('explanation', '')}\n")
                                    assistant_message = "\n".join(parts)
                                    logger.debug(f"ğŸ“ Method 2 (details.explain_skill) succeeded for turn {turn_num}")
                                elif "flashcards" in content:
                                    # flashcard_skill å“åº”
                                    flashcards = content.get("flashcards", [])
                                    assistant_message = f"å·²ç”Ÿæˆ {len(flashcards)} å¼ é—ªå¡"
                                    if flashcards and isinstance(flashcards[0], dict):
                                        first_card = flashcards[0]
                                        front = first_card.get("front", first_card.get("question", ""))
                                        assistant_message += f"\n\n**ç¬¬1å¼ **: {front[:100]}..."
                                    logger.debug(f"ğŸ“ Method 2 (details.flashcard_skill) succeeded for turn {turn_num}")
                                elif "questions" in content:
                                    # quiz_skill å“åº”
                                    questions = content.get("questions", [])
                                    assistant_message = f"å·²ç”Ÿæˆ {len(questions)} é“ç»ƒä¹ é¢˜"
                                    if questions and isinstance(questions[0], dict):
                                        first_q = questions[0]
                                        q_text = first_q.get("question", first_q.get("text", ""))
                                        assistant_message += f"\n\n**ç¬¬1é¢˜**: {q_text[:100]}..."
                                    logger.debug(f"ğŸ“ Method 2 (details.quiz_skill) succeeded for turn {turn_num}")
                        except json.JSONDecodeError as e:
                            logger.debug(f"ğŸ“ Method 2 (details) JSON parse failed for turn {turn_num}: {e}")
                    
                # æ–¹æ³•3: ä½¿ç”¨æ”¹è¿›çš„æ­£åˆ™ï¼ˆæ”¯æŒè½¬ä¹‰å­—ç¬¦ï¼‰
                if not assistant_message:
                    # åŒ¹é… "text": "..." åŒ…æ‹¬è½¬ä¹‰å­—ç¬¦
                    text_match = re.search(r'"text":\s*"((?:[^"\\]|\\.)*)"', assistant_section)
                    if text_match:
                        assistant_message = text_match.group(1)
                        # åªå¤„ç†å¸¸è§çš„ JSON è½¬ä¹‰å­—ç¬¦ï¼Œä¿ç•™ LaTeX åæ–œæ 
                        assistant_message = assistant_message.replace('\\n', '\n').replace('\\r', '\r').replace('\\"', '"')
                
                # æ–¹æ³•4: æå– ç›´è§‰ç†è§£
                if not assistant_message:
                    intuition_match = re.search(r'#### ğŸ“š ç›´è§‰ç†è§£\s*\n(.+?)(?=\n####|\n##|\Z)', assistant_section, re.DOTALL)
                    if intuition_match:
                        assistant_message = intuition_match.group(1).strip()
                
                # æ–¹æ³•5: å–å‰ 500 å­—ç¬¦ä½œä¸ºæ‘˜è¦
                if not assistant_message:
                    assistant_message = assistant_section[:500].replace('\n', ' ')
                
                # ğŸ†• è·å–è¯¥è½®çš„åé¦ˆçŠ¶æ€
                feedback = feedback_map.get(turn_num)
                
                # ğŸ†• ä» attachments_map è·å–é™„ä»¶ä¿¡æ¯ï¼ˆä¼˜å…ˆçº§é«˜äº MD æ–‡ä»¶è§£æï¼‰
                turn_attachments = attachments_map.get(turn_num, {})
                if turn_attachments:
                    # ä¼˜å…ˆä½¿ç”¨ metadata ä¸­çš„ files æ•°ç»„
                    if turn_attachments.get("files"):
                        files = turn_attachments.get("files")
                    # å…¼å®¹æ—§æ ¼å¼
                    elif turn_attachments.get("file_url") or turn_attachments.get("file_name"):
                        files = []
                        if turn_attachments.get("file_url"):
                            files.append({"type": "image", "url": turn_attachments.get("file_url")})
                        if turn_attachments.get("file_name"):
                            files.append({"type": "document", "name": turn_attachments.get("file_name")})
                    
                    referenced_text = turn_attachments.get("referenced_text") or referenced_text
                
                chat_list.append({
                    "turn": turn_num,
                    "timestamp": timestamp,
                    "user_message": user_message,
                    "assistant_message": assistant_message,  # JSON è§£æå·²å¤„ç†è½¬ä¹‰
                    "referenced_text": referenced_text,
                    "files": files,  # ğŸ†• ç»Ÿä¸€çš„æ–‡ä»¶ä¿¡æ¯æ•°ç»„
                    "feedback": feedback  # ğŸ†• åé¦ˆçŠ¶æ€
                })
            
            logger.info(f"ğŸ“‹ Parsed {len(chat_list)} chat entries")
        
        return {
            "code": 0,
            "msg": "success",
            "data": {
                "question_id": question_id,
                "answer_id": answer_id,
                "session_id": session_id,
                "chat_list": chat_list,
                "total": len(chat_list)
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ get_homework_chat_history error: {e}", exc_info=True)
        return {"code": 500, "msg": str(e), "data": None}

