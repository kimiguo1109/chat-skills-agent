"""
External Web API - Web ä¸“ç”¨èŠå¤©æ¥å£ï¼ˆSSE æµå¼ + Edit/Regenerateï¼‰

ä¸ /api/external/chat (Appç«¯) å…±äº«ç›¸åŒçš„æ ¸å¿ƒåŠŸèƒ½ï¼š
- Intent Routerï¼ˆæ„å›¾è¯†åˆ«ï¼‰
- Skill Orchestratorï¼ˆæŠ€èƒ½æ‰§è¡Œï¼‰
- Memory Managerï¼ˆä¸Šä¸‹æ–‡ç®¡ç†ï¼‰
- MD æŒä¹…åŒ–

Web ç«¯ä¸“å±åŠŸèƒ½ï¼š
- SSE æµå¼è¾“å‡º
- Edit/Regenerate æ”¯æŒï¼ˆä¿ç•™å†å²ç‰ˆæœ¬ï¼‰
- Clear Session æ”¯æŒ
- å¹¶å‘å®‰å…¨ï¼ˆper-session é”ï¼‰

ç«¯ç‚¹:
- POST /api/external/chat/web - æµå¼èŠå¤©ï¼ˆæ”¯æŒæ‰€æœ‰ Skillï¼‰
- POST /api/external/chat/web/clear - æ¸…é™¤ä¼šè¯
- GET /api/external/chat/web/versions - è·å–å†å²ç‰ˆæœ¬
- GET /api/external/chat/web/status - è·å–ä¼šè¯çŠ¶æ€
"""
import logging
import asyncio
import json
import time
import re
from datetime import datetime
from typing import Dict, Any, List, Optional, AsyncGenerator, Literal
from fastapi import APIRouter, HTTPException, Depends, Header, Query
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from enum import Enum

from app.core import SkillOrchestrator, MemoryManager
from app.core.intent_router import IntentRouter
from app.core.request_context import set_user_api_token, clear_user_api_token
from app.dependencies import get_memory_manager
from app.services.gemini import GeminiClient
from app.config import settings

# ğŸ”¥ å¤ç”¨ external.py çš„æ ¸å¿ƒåŠŸèƒ½
from app.api.external import (
    execute_skill_pipeline,
    get_skill_orchestrator,
    get_user_language_from_studyx,
    fetch_question_context_from_studyx,  # ğŸ†• è·å–é¢˜ç›®ä¸Šä¸‹æ–‡
    _load_conversation_history,
    _save_chat_to_session,
    _convert_to_text_format,
)

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/external/chat/web", tags=["external-web"])


# ============= ğŸ”’ å¹¶å‘æ§åˆ¶ =============

_session_locks: Dict[str, asyncio.Lock] = {}
_lock_manager_lock = asyncio.Lock()


async def get_session_lock(session_id: str) -> asyncio.Lock:
    """è·å–æˆ–åˆ›å»º session çº§åˆ«çš„é”"""
    async with _lock_manager_lock:
        if session_id not in _session_locks:
            _session_locks[session_id] = asyncio.Lock()
        return _session_locks[session_id]


# ============= è¯·æ±‚/å“åº”æ¨¡å‹ =============

class ActionType(str, Enum):
    SEND = "send"
    EDIT = "edit"
    REGENERATE = "regenerate"


class FileInfo(BaseModel):
    type: Literal["image", "document"] = Field(..., description="æ–‡ä»¶ç±»å‹")
    url: Optional[str] = Field(None, description="å›¾ç‰‡ HTTP URL")
    name: Optional[str] = Field(None, description="æ–‡æ¡£æ–‡ä»¶å")


class WebChatRequest(BaseModel):
    message: str = Field("", description="ç”¨æˆ·æ¶ˆæ¯")
    user_id: str = Field(..., description="ç”¨æˆ· ID")
    question_id: str = Field(..., description="é¢˜ç›® ID (aiQuestionId)")
    answer_id: str = Field(..., description="ç­”æ¡ˆ ID (answerId)")
    
    # Web ä¸“ç”¨å‚æ•°
    action: ActionType = Field(ActionType.SEND, description="æ“ä½œç±»å‹: send/edit/regenerate")
    turn_id: Optional[int] = Field(None, description="Edit/Regenerate æ—¶æŒ‡å®šçš„è½®æ¬¡å·")
    
    # é€šç”¨å‚æ•°ï¼ˆä¸ App ç«¯ä¸€è‡´ï¼‰
    file_uri: Optional[str] = Field(None, description="å•ä¸ª GCS æ–‡ä»¶ URI")
    file_uris: Optional[List[str]] = Field(None, description="å¤šä¸ª GCS æ–‡ä»¶ URI")
    files: Optional[List[FileInfo]] = Field(None, description="æ–‡ä»¶ä¿¡æ¯æ•°ç»„")
    referenced_text: Optional[str] = Field(None, description="å¼•ç”¨çš„æ–‡æœ¬å†…å®¹")
    action_type: Optional[str] = Field(None, description="å¿«æ·æ“ä½œ: explain_concept, make_simpler, common_mistakes")
    language: Optional[str] = Field(None, description="å›å¤è¯­è¨€")
    # ğŸ†• é¢˜ç›®ä¸Šä¸‹æ–‡æ”¯æŒï¼ˆä¸ App ç«¯ä¸€è‡´ï¼‰
    qid: Optional[str] = Field(None, description="é¢˜ç›® slugï¼ˆä» URL è·å–ï¼Œå¦‚ 96rhhg4ï¼‰ï¼Œç”¨äºè‡ªåŠ¨è·å–é¢˜ç›®ä¸Šä¸‹æ–‡")
    resource_id: Optional[str] = Field(None, description="é¢˜ç›®èµ„æº IDï¼ˆä¸ qid ä½œç”¨ç›¸åŒï¼Œå‰ç«¯å¯ç”¨æ­¤å­—æ®µï¼‰")  # ğŸ†• å…¼å®¹å‰ç«¯å­—æ®µå
    question_context: Optional[str] = Field(None, description="é¢˜ç›®ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼ˆå‰ç«¯ç›´æ¥ä¼ å…¥æ—¶ä¼˜å…ˆä½¿ç”¨ï¼‰")


class ClearSessionRequest(BaseModel):
    user_id: str = Field(..., description="ç”¨æˆ· ID")
    question_id: str = Field(..., description="é¢˜ç›® ID")
    answer_id: str = Field(..., description="ç­”æ¡ˆ ID")


# ============= SSE æµå¼ç”Ÿæˆ =============

async def generate_sse_stream(
    message: str,
    user_id: str,
    session_id: str,
    action: ActionType,
    turn_id: Optional[int],
    orchestrator: SkillOrchestrator,
    file_uris: Optional[List[str]] = None,
    files: Optional[List[Dict]] = None,
    referenced_text: Optional[str] = None,
    action_type_hint: Optional[str] = None,
    language: str = "en",
    # ğŸ†• é¢˜ç›®ä¸Šä¸‹æ–‡
    qid: Optional[str] = None,
    question_context: Optional[str] = None,
    token: Optional[str] = None,
    environment: str = "test"  # ğŸ†• ç¯å¢ƒæ ‡è¯†
) -> AsyncGenerator[str, None]:
    """
    ç”Ÿæˆ SSE äº‹ä»¶æµï¼ˆä½¿ç”¨å®Œæ•´çš„ Skill Pipelineï¼‰
    
    Events:
    - start: å¼€å§‹ç”Ÿæˆ
    - intent: æ„å›¾è¯†åˆ«ç»“æœ
    - chunk: å†…å®¹å—ï¼ˆæµå¼è¾“å‡ºï¼‰
    - done: å®Œæˆï¼Œè¿”å›å®Œæ•´å“åº”
    - error: é”™è¯¯
    """
    start_time = time.time()
    
    try:
        # 1. å‘é€å¼€å§‹äº‹ä»¶
        yield f"data: {json.dumps({'type': 'start', 'action': action.value, 'turn_id': turn_id, 'timestamp': datetime.now().isoformat()})}\n\n"
        
        # 2. å¤„ç† Edit/Regenerate
        if action == ActionType.EDIT:
            if not turn_id:
                yield f"data: {json.dumps({'type': 'error', 'message': 'turn_id is required for edit action'})}\n\n"
                return
            
            # æˆªæ–­å¹¶ä¿å­˜ç‰ˆæœ¬
            await _truncate_and_save_version(
                orchestrator.memory_manager,
                user_id,
                session_id,
                turn_id,
                action="edit",
                new_message=message
            )
            
        elif action == ActionType.REGENERATE:
            if not turn_id:
                # ğŸ†• æ²¡æœ‰ turn_id æ—¶ï¼Œè½¬æ¢ä¸º send action
                logger.info(f"âš ï¸ Regenerate without turn_id, converting to send action")
                action = ActionType.SEND
            else:
                # è·å–åŸå§‹æ¶ˆæ¯
                original_message = await _get_turn_message(
                    orchestrator.memory_manager,
                    user_id,
                    session_id,
                    turn_id
                )
                
                if not original_message:
                    # ğŸ†• æ‰¾ä¸åˆ°å†å²æ¶ˆæ¯æ—¶ï¼Œä½¿ç”¨ä¼ å…¥çš„ message ä½œä¸ºæ–°æ¶ˆæ¯ï¼ˆè½¬æ¢ä¸º sendï¼‰
                    logger.info(f"âš ï¸ Turn {turn_id} not found, converting to send action with message: {message[:50]}...")
                    action = ActionType.SEND
                else:
                    message = original_message
                    
                    # æˆªæ–­å¹¶ä¿å­˜ç‰ˆæœ¬
                    await _truncate_and_save_version(
                        orchestrator.memory_manager,
                        user_id,
                        session_id,
                        turn_id,
                        action="regenerate"
                    )
        
        # 2.5 ğŸ†• å¤„ç†é¢˜ç›®ä¸Šä¸‹æ–‡
        # æ¯æ¬¡å¿«æ·é—®ç­”éƒ½åº”è¯¥åŸºäºé¢˜ç›®ä¸Šä¸‹æ–‡ï¼Œä¸ä»…é™äºæ–° session
        final_question_context = question_context
        logger.info(f"ğŸ“š Question context check: qid={qid}, token={'present' if token else 'missing'}, existing_context={'yes' if question_context else 'no'}")
        
        if not final_question_context and qid:
            if token:
                logger.info(f"ğŸ“š Fetching question context from StudyX (qid={qid}, env={environment})...")
                final_question_context = await fetch_question_context_from_studyx(qid, token, environment)
                if final_question_context:
                    logger.info(f"âœ… Question context fetched: {len(final_question_context)} chars")
                else:
                    logger.warning(f"âš ï¸ Failed to fetch question context for qid={qid}")
            else:
                logger.warning(f"âš ï¸ Cannot fetch question context: token is missing (qid={qid})")
        
        # 3. ğŸ”¥ è°ƒç”¨å®Œæ•´çš„ Skill Pipelineï¼ˆä¸ App ç«¯ä¸€è‡´ï¼‰
        result = await execute_skill_pipeline(
            message=message,
            user_id=user_id,
            session_id=session_id,
            orchestrator=orchestrator,
            quantity_override=None,
            skill_hint=None,
            file_uris=file_uris,
            referenced_text=referenced_text,
            action_type=action_type_hint,
            files=files,
            language=language,
            question_context=final_question_context  # ğŸ†• ä¼ é€’é¢˜ç›®ä¸Šä¸‹æ–‡
        )
        
        # 4. å‘é€æ„å›¾è¯†åˆ«ç»“æœ
        intent = result.get("intent", "other")
        content_type = result.get("content_type", "text")
        topic = result.get("topic", "")
        
        yield f"data: {json.dumps({'type': 'intent', 'intent': intent, 'content_type': content_type, 'topic': topic})}\n\n"
        
        # 5. æå–å†…å®¹å¹¶æµå¼å‘é€
        content = result.get("content") or result.get("response_content") or {}
        
        # ğŸ†• æ ¹æ® content_type æå–æ–‡æœ¬å†…å®¹
        text = ""
        if isinstance(content, dict):
            if "text" in content:
                # æ™®é€š chat å“åº”
                text = content.get("text", "")
            elif "intuition" in content:
                # explain_skill å“åº”ï¼šç»„åˆå¤šä¸ªå­—æ®µä¸ºå®Œæ•´æ–‡æœ¬
                parts = []
                if content.get("concept"):
                    parts.append(f"**{content['concept']}**\n")
                if content.get("intuition"):
                    parts.append(f"ğŸ“š **ç›´è§‰ç†è§£**\n{content['intuition']}\n")
                if content.get("formal_definition"):
                    parts.append(f"ğŸ“– **æ­£å¼å®šä¹‰**\n{content['formal_definition']}\n")
                if content.get("why_it_matters"):
                    parts.append(f"ğŸ’¡ **ä¸ºä»€ä¹ˆé‡è¦**\n{content['why_it_matters']}\n")
                # ç¤ºä¾‹
                examples = content.get("examples", [])
                if examples:
                    parts.append("ğŸŒŸ **å®ä¾‹**\n")
                    for i, ex in enumerate(examples, 1):
                        if isinstance(ex, dict):
                            parts.append(f"{i}. **{ex.get('example', '')}**\n   {ex.get('explanation', '')}\n")
                # å¸¸è§è¯¯åŒº
                mistakes = content.get("common_mistakes", [])
                if mistakes:
                    parts.append("âš ï¸ **å¸¸è§è¯¯åŒº**\n")
                    for i, m in enumerate(mistakes, 1):
                        if isinstance(m, dict):
                            parts.append(f"{i}. âŒ {m.get('mistake', '')}\n   âœ… {m.get('correction', '')}\n")
                # ç›¸å…³æ¦‚å¿µ
                related = content.get("related_concepts", [])
                if related:
                    parts.append(f"ğŸ”— **ç›¸å…³æ¦‚å¿µ**: {', '.join(related)}\n")
                text = "\n".join(parts)
            elif "flashcards" in content:
                # flashcard_skill å“åº”
                flashcards = content.get("flashcards", [])
                parts = [f"ğŸ“š å·²ç”Ÿæˆ {len(flashcards)} å¼ é—ªå¡\n"]
                for i, card in enumerate(flashcards[:5], 1):  # æœ€å¤šæ˜¾ç¤º5å¼ 
                    if isinstance(card, dict):
                        front = card.get("front", card.get("question", ""))
                        back = card.get("back", card.get("answer", ""))
                        parts.append(f"\n**å¡ç‰‡ {i}**\nğŸ”¹ æ­£é¢: {front}\nğŸ”¸ èƒŒé¢: {back}\n")
                if len(flashcards) > 5:
                    parts.append(f"\n... è¿˜æœ‰ {len(flashcards) - 5} å¼ å¡ç‰‡")
                text = "\n".join(parts)
            elif "questions" in content:
                # quiz_skill å“åº”
                questions = content.get("questions", [])
                parts = [f"ğŸ“ å·²ç”Ÿæˆ {len(questions)} é“ç»ƒä¹ é¢˜\n"]
                for i, q in enumerate(questions[:3], 1):  # æœ€å¤šæ˜¾ç¤º3é¢˜
                    if isinstance(q, dict):
                        q_text = q.get("question", q.get("text", ""))
                        parts.append(f"\n**é¢˜ç›® {i}**: {q_text}\n")
                        options = q.get("options", [])
                        if options:
                            for opt in options:
                                if isinstance(opt, dict):
                                    parts.append(f"   {opt.get('label', '')}) {opt.get('text', '')}\n")
                if len(questions) > 3:
                    parts.append(f"\n... è¿˜æœ‰ {len(questions) - 3} é“é¢˜ç›®")
                text = "\n".join(parts)
            else:
                # å°è¯•å°†æ•´ä¸ª content è½¬ä¸ºå­—ç¬¦ä¸²
                text = json.dumps(content, ensure_ascii=False, indent=2)
        elif isinstance(content, str):
            text = content
        else:
            text = str(content) if content else ""
        
        # æµå¼å‘é€å†…å®¹ï¼ˆåˆ†å—ï¼‰
        if text:
            chunk_size = 50  # æ¯å—å­—ç¬¦æ•°
            for i in range(0, len(text), chunk_size):
                chunk = text[i:i+chunk_size]
                yield f"data: {json.dumps({'type': 'chunk', 'content': chunk})}\n\n"
                await asyncio.sleep(0.01)  # æ¨¡æ‹Ÿæµå¼æ•ˆæœ
        else:
            # ğŸ†• å³ä½¿æ²¡æœ‰æ–‡æœ¬ï¼Œä¹Ÿå‘é€ä¸€ä¸ªç©º chunk è¡¨ç¤ºå¤„ç†å®Œæˆ
            yield f"data: {json.dumps({'type': 'chunk', 'content': 'å¤„ç†å®Œæˆ'})}\n\n"
        
        # 6. è·å–å®é™…è½®æ¬¡
        actual_turn_id = await _get_current_turn_count(
            orchestrator.memory_manager,
            user_id,
            session_id
        )
        
        # 7. å‘é€å®Œæˆäº‹ä»¶
        elapsed_time = time.time() - start_time
        token_usage = result.get("token_usage", {})
        context_stats = result.get("context_stats", {})
        
        yield f"data: {json.dumps({'type': 'done', 'turn_id': actual_turn_id, 'intent': intent, 'content_type': content_type, 'topic': topic, 'full_response': text, 'elapsed_time': round(elapsed_time, 2), 'token_usage': token_usage, 'context_stats': context_stats, 'action': action.value})}\n\n"
        
    except Exception as e:
        logger.error(f"âŒ SSE generation error: {e}", exc_info=True)
        yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"


# ============= ç‰ˆæœ¬ç®¡ç† =============

async def _truncate_and_save_version(
    memory_manager: MemoryManager,
    user_id: str,
    session_id: str,
    turn_id: int,
    action: str,
    new_message: Optional[str] = None
) -> bool:
    """æˆªæ–­ä¼šè¯å†å²å¹¶ä¿å­˜ç‰ˆæœ¬"""
    from pathlib import Path
    
    try:
        artifacts_dir = memory_manager.artifact_storage.base_dir / user_id
        md_file = artifacts_dir / f"{session_id}.md"
        versions_file = artifacts_dir / f"{session_id}_versions.json"
        
        if not md_file.exists():
            logger.warning(f"âš ï¸ MD file not found: {md_file}")
            return False
        
        content = md_file.read_text(encoding='utf-8')
        
        # è§£æ turns
        turn_pattern = r'## Turn (\d+) - (\d{2}:\d{2}:\d{2})'
        turns = list(re.finditer(turn_pattern, content))
        
        if not turns:
            return False
        
        # æ‰¾åˆ°è¦æˆªæ–­çš„ä½ç½®
        truncate_idx = None
        for i, match in enumerate(turns):
            if int(match.group(1)) == turn_id:
                truncate_idx = i
                break
        
        if truncate_idx is None:
            logger.warning(f"âš ï¸ Turn {turn_id} not found")
            return False
        
        # æå–è¦ä¿å­˜çš„ç‰ˆæœ¬å†…å®¹
        truncate_pos = turns[truncate_idx].start()
        version_content = content[truncate_pos:]
        header_content = content[:truncate_pos]
        
        # åŠ è½½æˆ–åˆ›å»ºç‰ˆæœ¬å†å²
        versions = []
        if versions_file.exists():
            try:
                versions = json.loads(versions_file.read_text(encoding='utf-8'))
            except:
                versions = []
        
        # ä¿å­˜ç‰ˆæœ¬
        versions.append({
            "version_id": len(versions) + 1,
            "action": action,
            "turn_id": turn_id,
            "timestamp": datetime.now().isoformat(),
            "content": version_content,
            "new_message": new_message
        })
        
        versions_file.write_text(json.dumps(versions, ensure_ascii=False, indent=2), encoding='utf-8')
        
        # æˆªæ–­ MD æ–‡ä»¶
        md_file.write_text(header_content, encoding='utf-8')
        
        logger.info(f"âœ… Truncated session at turn {turn_id}, saved version {len(versions)}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Failed to truncate and save version: {e}")
        return False


async def _get_turn_message(
    memory_manager: MemoryManager,
    user_id: str,
    session_id: str,
    turn_id: int
) -> Optional[str]:
    """è·å–æŒ‡å®šè½®æ¬¡çš„ç”¨æˆ·æ¶ˆæ¯"""
    from pathlib import Path
    
    try:
        artifacts_dir = memory_manager.artifact_storage.base_dir / user_id
        md_file = artifacts_dir / f"{session_id}.md"
        
        if not md_file.exists():
            return None
        
        content = md_file.read_text(encoding='utf-8')
        
        # æŸ¥æ‰¾ turn çš„ JSON æ•°æ®
        json_pattern = r'```json\s*\n(\{[^`]+\})\s*\n```'
        matches = list(re.finditer(json_pattern, content, re.DOTALL))
        
        for match in matches:
            try:
                data = json.loads(match.group(1))
                if data.get("turn_number") == turn_id:
                    return data.get("user_query", "")
            except:
                continue
        
        return None
        
    except Exception as e:
        logger.error(f"âŒ Failed to get turn message: {e}")
        return None


async def _get_current_turn_count(
    memory_manager: MemoryManager,
    user_id: str,
    session_id: str
) -> int:
    """è·å–å½“å‰ä¼šè¯çš„è½®æ¬¡æ•°"""
    from pathlib import Path
    
    try:
        artifacts_dir = memory_manager.artifact_storage.base_dir / user_id
        md_file = artifacts_dir / f"{session_id}.md"
        
        if not md_file.exists():
            return 0
        
        content = md_file.read_text(encoding='utf-8')
        turn_pattern = r'## Turn (\d+)'
        matches = re.findall(turn_pattern, content)
        
        if matches:
            return max(int(m) for m in matches)
        return 0
        
    except:
        return 0


async def _get_chat_tree(
    memory_manager: MemoryManager,
    user_id: str,
    session_id: str
) -> Dict[str, Any]:
    """
    è·å–èŠå¤©æ ‘ç»“æ„ï¼ˆåŒ…å«ç‰ˆæœ¬å†å²ï¼‰
    
    è¿”å›ç»“æ„ï¼š
    {
        "current": [turn1, turn2, ...],
        "versions": [
            {"version_id": 1, "action": "edit", "turn_id": 3, "branches": [turn3_v1, turn4_v1, ...]},
            ...
        ]
    }
    """
    from pathlib import Path
    
    try:
        artifacts_dir = memory_manager.artifact_storage.base_dir / user_id
        md_file = artifacts_dir / f"{session_id}.md"
        versions_file = artifacts_dir / f"{session_id}_versions.json"
        
        result = {
            "current": [],
            "versions": []
        }
        
        # è§£æå½“å‰ä¼šè¯
        if md_file.exists():
            content = md_file.read_text(encoding='utf-8')
            json_pattern = r'```json\s*\n(\{[^`]+\})\s*\n```'
            
            for match in re.finditer(json_pattern, content, re.DOTALL):
                try:
                    data = json.loads(match.group(1))
                    turn_data = {
                        "turn_number": data.get("turn_number"),
                        "timestamp": data.get("timestamp"),
                        "user_query": data.get("user_query"),
                        "intent": data.get("intent", {}).get("intent"),
                        "response_preview": str(data.get("agent_response", {}).get("content", {}).get("text", ""))[:100]
                    }
                    result["current"].append(turn_data)
                except:
                    continue
        
        # è§£æç‰ˆæœ¬å†å²
        if versions_file.exists():
            try:
                versions = json.loads(versions_file.read_text(encoding='utf-8'))
                for v in versions:
                    version_data = {
                        "version_id": v.get("version_id"),
                        "action": v.get("action"),
                        "turn_id": v.get("turn_id"),
                        "timestamp": v.get("timestamp"),
                        "new_message": v.get("new_message"),
                        "branches": []
                    }
                    
                    # è§£æç‰ˆæœ¬å†…çš„ turns
                    version_content = v.get("content", "")
                    for match in re.finditer(r'```json\s*\n(\{[^`]+\})\s*\n```', version_content, re.DOTALL):
                        try:
                            data = json.loads(match.group(1))
                            branch_turn = {
                                "turn_number": data.get("turn_number"),
                                "user_query": data.get("user_query"),
                                "response_preview": str(data.get("agent_response", {}).get("content", {}).get("text", ""))[:100]
                            }
                            version_data["branches"].append(branch_turn)
                        except:
                            continue
                    
                    result["versions"].append(version_data)
            except:
                pass
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ Failed to get chat tree: {e}")
        return {"current": [], "versions": []}


# ============= API ç«¯ç‚¹ =============

@router.post("", response_class=StreamingResponse)
async def web_chat_stream(
    request: WebChatRequest,
    orchestrator: SkillOrchestrator = Depends(get_skill_orchestrator),
    token: Optional[str] = Header(None, description="ç”¨æˆ·è®¤è¯ Token"),
    environment: Optional[str] = Header("test", description="ç¯å¢ƒæ ‡è¯† (dev/test/prod)")
):
    """
    ğŸŒ Web æµå¼èŠå¤©æ¥å£ï¼ˆSSEï¼‰
    
    åŠŸèƒ½ï¼š
    - å®Œæ•´çš„ Intent è¯†åˆ«ï¼ˆä¸ App ç«¯ä¸€è‡´ï¼‰
    - å®Œæ•´çš„ Skill æ‰§è¡Œï¼ˆQuiz/Flashcard/Explain/Plan ç­‰ï¼‰
    - SSE æµå¼è¾“å‡º
    - Edit/Regenerate æ”¯æŒ
    
    Actions:
    - send: å‘é€æ–°æ¶ˆæ¯
    - edit: ç¼–è¾‘æŸè½®å¹¶é‡æ–°ç”Ÿæˆ
    - regenerate: é‡æ–°ç”ŸæˆæŸè½®å›å¤
    """
    # è®¾ç½® token
    if token:
        set_user_api_token(token)
    
    try:
        # æ„å»º session_idï¼ˆä½¿ç”¨æ•°å­—æ ¼å¼çš„ question_idï¼‰
        session_id = f"q{request.question_id}_a{request.answer_id}"
        
        # ğŸ”§ å…³é”®åŒºåˆ†ï¼š
        # - question_idï¼ˆæ•°å­—æ ¼å¼ï¼Œå¦‚ 20000003451ï¼‰ï¼šç”¨äº session_id
        # - resource_id / qidï¼ˆslug æ ¼å¼ï¼Œå¦‚ 96rhh58ï¼‰ï¼šç”¨äºè·å–é¢˜ç›®ä¸Šä¸‹æ–‡
        # StudyX çš„ newQueryQuestionInfo API éœ€è¦ slug æ ¼å¼çš„ ID
        effective_qid_for_context = request.resource_id or request.qid  # ä¼˜å…ˆä½¿ç”¨ slug æ ¼å¼
        logger.info(f"   â€¢ Question ID: {request.question_id}, QID: {request.qid}, Resource ID: {request.resource_id}")
        logger.info(f"   â€¢ QID for context: {effective_qid_for_context or 'N/A (will skip context fetch)'}")
        
        # æ—¥å¿—è®°å½•
        logger.info("="*60)
        logger.info(f"ğŸ“¥ [Web] /api/external/chat/web")
        logger.info(f"   â€¢ User: {request.user_id}")
        logger.info(f"   â€¢ Session: {session_id}")
        logger.info(f"   â€¢ Action: {request.action}")
        logger.info(f"   â€¢ QID/Resource ID: {effective_qid_for_context or 'N/A'}")
        logger.info("="*60)
        
        # ğŸ†• ç¯å¢ƒæ ‡è¯†
        env = environment or "test"
        logger.info(f"   â€¢ Environment: {env}")
        
        # è·å–è¯­è¨€è®¾ç½®
        language = request.language
        if not language and token:
            language = await get_user_language_from_studyx(token, env)
        language = language or "en"
        
        logger.info(f"   â€¢ Language: {language}")
        
        # åˆå¹¶ file_uris
        file_uris = []
        if request.file_uri:
            file_uris.append(request.file_uri)
        if request.file_uris:
            file_uris.extend(request.file_uris)
        
        # ğŸ†• æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ä¸Šä¼ 
        has_files = bool(file_uris or request.files)
        
        # ğŸ†• åŒæ­¥ App ç«¯é€»è¾‘ï¼šå¤„ç†æ¶ˆæ¯
        message = request.message.strip() if request.message else ""
        
        # åœºæ™¯ A: å¿«æ·æŒ‰é’®æ¨¡å¼ï¼ˆaction_typeï¼‰- ä¸éœ€è¦è¾“å…¥æ–‡å­—
        if not message and request.action_type:
            # æ ¹æ®è¯­è¨€è®¾ç½®é€‰æ‹©é»˜è®¤æç¤º
            if language in ["zh", "zh-CN", "zh-TW"]:
                action_default_messages = {
                    "explain_concept": "è¯·è¯¦ç»†è§£é‡Šè¿™ä¸ªæ¦‚å¿µ",
                    "make_simpler": "è¯·ç”¨æ›´ç®€å•çš„æ–¹å¼è§£é‡Š",
                    "common_mistakes": "è¿™ä¸ªçŸ¥è¯†ç‚¹æœ‰å“ªäº›å¸¸è§é”™è¯¯",
                    "step_by_step": "è¯·ä¸€æ­¥ä¸€æ­¥è§£é‡Šè§£é¢˜è¿‡ç¨‹",
                    "why_important": "ä¸ºä»€ä¹ˆè¿™ä¸ªçŸ¥è¯†ç‚¹å¾ˆé‡è¦",
                }
                default_msg = "è¯·å¸®æˆ‘ç†è§£è¿™ä¸ªå†…å®¹"
            elif language == "ja":
                action_default_messages = {
                    "explain_concept": "ã“ã®æ¦‚å¿µã‚’è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„",
                    "make_simpler": "ã‚‚ã£ã¨ç°¡å˜ã«èª¬æ˜ã—ã¦ãã ã•ã„",
                    "common_mistakes": "ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã§ã‚ˆãã‚ã‚‹é–“é•ã„ã¯ä½•ã§ã™ã‹",
                    "step_by_step": "è§£ãæ–¹ã‚’ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§èª¬æ˜ã—ã¦ãã ã•ã„",
                    "why_important": "ãªãœã“ã®çŸ¥è­˜ç‚¹ãŒé‡è¦ã§ã™ã‹",
                }
                default_msg = "ã“ã®å†…å®¹ã‚’ç†è§£ã™ã‚‹ã®ã‚’æ‰‹ä¼ã£ã¦ãã ã•ã„"
            elif language == "ko":
                action_default_messages = {
                    "explain_concept": "ì´ ê°œë…ì„ ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”",
                    "make_simpler": "ë” ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”",
                    "common_mistakes": "ì´ ì£¼ì œì—ì„œ í”íˆ í•˜ëŠ” ì‹¤ìˆ˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”",
                    "step_by_step": "í’€ì´ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”",
                    "why_important": "ì™œ ì´ ì§€ì‹ì´ ì¤‘ìš”í•œê°€ìš”",
                }
                default_msg = "ì´ ë‚´ìš©ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ì„¸ìš”"
            else:
                action_default_messages = {
                    "explain_concept": "Please explain this concept in detail",
                    "make_simpler": "Please explain this in a simpler way",
                    "common_mistakes": "What are the common mistakes for this topic",
                    "step_by_step": "Please explain the solution step by step",
                    "why_important": "Why is this concept important",
                }
                default_msg = "Please help me understand this content"
            message = action_default_messages.get(request.action_type, default_msg)
            logger.info(f"   â€¢ ğŸ¯ Action Type: {request.action_type} -> Default message: {message}")
        
        # åœºæ™¯ B: æ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼ˆå›¾ç‰‡/æ–‡æ¡£ï¼‰- ä¸éœ€è¦è¾“å…¥æ–‡å­—
        if not message and has_files:
            if language in ["zh", "zh-CN", "zh-TW"]:
                message = "è¯·å¸®æˆ‘åˆ†æè¿™ä¸ªå›¾ç‰‡/æ–‡ä»¶çš„å†…å®¹"
            elif language == "ja":
                message = "ã“ã®ç”»åƒ/ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’åˆ†æã—ã¦ãã ã•ã„"
            elif language == "ko":
                message = "ì´ ì´ë¯¸ì§€/íŒŒì¼ì˜ ë‚´ìš©ì„ ë¶„ì„í•´ ì£¼ì„¸ìš”"
            else:
                message = "Please help me analyze this image/file"
            logger.info(f"   â€¢ ğŸ“ File upload without message, using default: {message}")
        
        # è½¬æ¢ files
        files = None
        if request.files:
            files = [f.model_dump() for f in request.files]
        
        # ğŸ”’ è·å– session é”
        lock = await get_session_lock(session_id)
        
        async def locked_generator():
            """å¸¦é”çš„ç”Ÿæˆå™¨"""
            async with lock:
                logger.info(f"ğŸ”’ [Web] Acquired lock for session: {session_id}")
                async for event in generate_sse_stream(
                    message=message,  # ğŸ†• ä½¿ç”¨å¤„ç†åçš„ messageï¼ˆæ”¯æŒå¿«æ·æŒ‰é’®/æ–‡ä»¶ä¸Šä¼ é»˜è®¤æ¶ˆæ¯ï¼‰
                    user_id=request.user_id,
                    session_id=session_id,
                    action=request.action,
                    turn_id=request.turn_id,
                    orchestrator=orchestrator,
                    file_uris=file_uris if file_uris else None,
                    files=files,
                    referenced_text=request.referenced_text,
                    action_type_hint=request.action_type,
                    language=language,
                    # ğŸ”§ ä½¿ç”¨ slug æ ¼å¼çš„ qid è·å–é¢˜ç›®ä¸Šä¸‹æ–‡ï¼ˆresource_id æˆ– qidï¼‰
                    qid=effective_qid_for_context,
                    question_context=request.question_context,
                    token=token,
                    environment=env  # ğŸ†• ç¯å¢ƒæ ‡è¯†
                ):
                    yield event
                logger.info(f"ğŸ”“ [Web] Released lock for session: {session_id}")
        
        return StreamingResponse(
            locked_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
        
    except Exception as e:
        logger.error(f"âŒ Web chat error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        clear_user_api_token()


@router.post("/clear")
async def clear_session(
    request: ClearSessionRequest,
    orchestrator: SkillOrchestrator = Depends(get_skill_orchestrator)
):
    """
    ğŸ—‘ï¸ æ¸…é™¤å½“å‰é¢˜ç›®çš„ä¼šè¯
    
    ä¼šå°†å½“å‰ä¼šè¯å½’æ¡£ï¼Œå¹¶ä¸ºç”¨æˆ·åˆ›å»ºæ–°çš„ç©ºç™½ä¼šè¯ã€‚
    """
    from pathlib import Path
    import shutil
    
    session_id = f"q{request.question_id}_a{request.answer_id}"
    
    lock = await get_session_lock(session_id)
    
    async with lock:
        try:
            artifacts_dir = orchestrator.memory_manager.artifact_storage.base_dir / request.user_id
            md_file = artifacts_dir / f"{session_id}.md"
            versions_file = artifacts_dir / f"{session_id}_versions.json"
            
            previous_turns = 0
            
            if md_file.exists():
                content = md_file.read_text(encoding='utf-8')
                turn_pattern = r'## Turn (\d+)'
                matches = re.findall(turn_pattern, content)
                previous_turns = len(matches)
                
                # å½’æ¡£æ—§æ–‡ä»¶
                archive_name = f"{session_id}_archived_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
                archive_file = artifacts_dir / archive_name
                shutil.move(str(md_file), str(archive_file))
                logger.info(f"ğŸ“¦ Archived session to: {archive_file}")
                
                # å½’æ¡£ç‰ˆæœ¬æ–‡ä»¶
                if versions_file.exists():
                    archive_versions = artifacts_dir / f"{session_id}_archived_{datetime.now().strftime('%Y%m%d_%H%M%S')}_versions.json"
                    shutil.move(str(versions_file), str(archive_versions))
            
            return {
                "code": 0,
                "msg": "Session cleared successfully",
                "data": {
                    "session_id": session_id,
                    "previous_turns": previous_turns,
                    "archived": True,
                    "new_session_ready": True
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ Failed to clear session: {e}")
            return {
                "code": 500,
                "msg": f"Failed to clear session: {str(e)}",
                "data": None
            }


@router.get("/versions")
async def get_turn_versions(
    user_id: str = Query(..., description="ç”¨æˆ· ID"),
    question_id: str = Query(..., description="é¢˜ç›® ID"),
    answer_id: str = Query(..., description="ç­”æ¡ˆ ID"),
    turn_id: Optional[int] = Query(None, description="æŒ‡å®šè½®æ¬¡ï¼ˆä¸ä¼ åˆ™è¿”å›æ‰€æœ‰ç‰ˆæœ¬ï¼‰"),
    orchestrator: SkillOrchestrator = Depends(get_skill_orchestrator)
):
    """
    ğŸ“œ è·å– Edit/Regenerate çš„å†å²ç‰ˆæœ¬
    """
    session_id = f"q{question_id}_a{answer_id}"
    
    try:
        artifacts_dir = orchestrator.memory_manager.artifact_storage.base_dir / user_id
        versions_file = artifacts_dir / f"{session_id}_versions.json"
        
        if not versions_file.exists():
            return {
                "code": 0,
                "msg": "No versions found",
                "data": {
                    "session_id": session_id,
                    "versions": []
                }
            }
        
        versions = json.loads(versions_file.read_text(encoding='utf-8'))
        
        if turn_id is not None:
            versions = [v for v in versions if v.get("turn_id") == turn_id]
        
        return {
            "code": 0,
            "msg": "Success",
            "data": {
                "session_id": session_id,
                "total_versions": len(versions),
                "versions": versions
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ Failed to get versions: {e}")
        return {
            "code": 500,
            "msg": f"Failed to get versions: {str(e)}",
            "data": None
        }


@router.get("/status")
async def get_session_status(
    user_id: str = Query(..., description="ç”¨æˆ· ID"),
    question_id: str = Query(..., description="é¢˜ç›® ID"),
    answer_id: str = Query(..., description="ç­”æ¡ˆ ID"),
    orchestrator: SkillOrchestrator = Depends(get_skill_orchestrator)
):
    """
    ğŸ“Š è·å–ä¼šè¯çŠ¶æ€
    """
    session_id = f"q{question_id}_a{answer_id}"
    
    try:
        lock = _session_locks.get(session_id)
        is_locked = lock.locked() if lock else False
        
        turn_count = await _get_current_turn_count(
            orchestrator.memory_manager,
            user_id,
            session_id
        )
        
        artifacts_dir = orchestrator.memory_manager.artifact_storage.base_dir / user_id
        versions_file = artifacts_dir / f"{session_id}_versions.json"
        version_count = 0
        if versions_file.exists():
            try:
                versions = json.loads(versions_file.read_text(encoding='utf-8'))
                version_count = len(versions)
            except:
                pass
        
        return {
            "code": 0,
            "msg": "Success",
            "data": {
                "session_id": session_id,
                "turn_count": turn_count,
                "version_count": version_count,
                "is_processing": is_locked,
                "exists": turn_count > 0
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ Failed to get session status: {e}")
        return {
            "code": 500,
            "msg": f"Failed: {str(e)}",
            "data": None
        }


@router.get("/tree")
async def get_chat_tree(
    user_id: str = Query(..., description="ç”¨æˆ· ID"),
    question_id: str = Query(..., description="é¢˜ç›® ID"),
    answer_id: str = Query(..., description="ç­”æ¡ˆ ID"),
    orchestrator: SkillOrchestrator = Depends(get_skill_orchestrator)
):
    """
    ğŸŒ³ è·å–èŠå¤©æ ‘ç»“æ„ï¼ˆåŒ…å«ç‰ˆæœ¬å†å²åˆ†æ”¯ï¼‰
    
    è¿”å›å½“å‰ä¼šè¯å’Œæ‰€æœ‰å†å²ç‰ˆæœ¬åˆ†æ”¯ï¼Œæ”¯æŒå‰ç«¯å±•ç¤º"æŸ¥çœ‹å…¶ä»–ç‰ˆæœ¬"åŠŸèƒ½ã€‚
    """
    session_id = f"q{question_id}_a{answer_id}"
    
    try:
        tree = await _get_chat_tree(
            orchestrator.memory_manager,
            user_id,
            session_id
        )
        
        return {
            "code": 0,
            "msg": "Success",
            "data": {
                "session_id": session_id,
                "current_turns": len(tree.get("current", [])),
                "version_count": len(tree.get("versions", [])),
                "tree": tree
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ Failed to get chat tree: {e}")
        return {
            "code": 500,
            "msg": f"Failed: {str(e)}",
            "data": None
        }


# ============= ğŸ†• ä¼šè¯åˆ—è¡¨æ¥å£ =============

@router.get("/sessions")
async def get_user_sessions(
    user_id: str = Query(..., description="ç”¨æˆ· ID"),
    page: int = Query(1, ge=1, description="é¡µç "),
    limit: int = Query(20, ge=1, le=50, description="æ¯é¡µæ•°é‡"),
    orchestrator: SkillOrchestrator = Depends(get_skill_orchestrator)
):
    """
    ğŸ“‹ è·å–ç”¨æˆ·çš„ä¼šè¯åˆ—è¡¨
    
    è¿”å›ç”¨æˆ·æ‰€æœ‰çš„èŠå¤©ä¼šè¯ï¼ŒåŒ…å« session_idã€åˆ›å»ºæ—¶é—´ã€è½®æ¬¡æ•°ç­‰ä¿¡æ¯ã€‚
    """
    from pathlib import Path
    import os
    
    try:
        # æŸ¥æ‰¾ç”¨æˆ·ç›®å½•
        artifacts_dir = Path("artifacts")
        if not artifacts_dir.exists():
            artifacts_dir = Path("backend/artifacts")
        if not artifacts_dir.exists():
            artifacts_dir = Path("/root/usr/skill_agent_demo/backend/artifacts")
        
        user_dir = artifacts_dir / user_id
        
        if not user_dir.exists():
            return {
                "code": 0,
                "msg": "No sessions found",
                "data": {
                    "user_id": user_id,
                    "sessions": [],
                    "total": 0,
                    "page": page,
                    "limit": limit
                }
            }
        
        # è·å–æ‰€æœ‰ .md æ–‡ä»¶ï¼ˆæ’é™¤ _versions.jsonï¼‰
        md_files = list(user_dir.glob("*.md"))
        
        sessions = []
        for md_file in md_files:
            session_id = md_file.stem
            
            # è§£æ session_id è·å– question_id å’Œ answer_id
            question_id = None
            answer_id = None
            if session_id.startswith("q") and "_a" in session_id:
                parts = session_id.split("_a")
                question_id = parts[0][1:]  # å»æ‰å‰ç¼€ 'q'
                answer_id = parts[1] if len(parts) > 1 else None
            
            # è·å–æ–‡ä»¶ä¿¡æ¯
            stat = md_file.stat()
            
            # è¯»å–æ–‡ä»¶è·å– turn_count
            turn_count = 0
            first_timestamp = None
            try:
                content = md_file.read_text()
                turn_count = content.count("## Turn ")
                
                # æå–ç¬¬ä¸€ä¸ªæ—¶é—´æˆ³
                import re
                timestamp_match = re.search(r'## Turn \d+ - (\d{2}:\d{2}:\d{2})', content)
                if timestamp_match:
                    first_timestamp = timestamp_match.group(1)
            except:
                pass
            
            sessions.append({
                "session_id": session_id,
                "question_id": question_id,
                "answer_id": answer_id,
                "turn_count": turn_count,
                "created_at": datetime.fromtimestamp(stat.st_ctime).isoformat(),
                "updated_at": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "first_timestamp": first_timestamp
            })
        
        # æŒ‰æ›´æ–°æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        sessions.sort(key=lambda x: x["updated_at"], reverse=True)
        
        # åˆ†é¡µ
        total = len(sessions)
        start_idx = (page - 1) * limit
        end_idx = start_idx + limit
        paginated_sessions = sessions[start_idx:end_idx]
        
        return {
            "code": 0,
            "msg": "Success",
            "data": {
                "user_id": user_id,
                "sessions": paginated_sessions,
                "total": total,
                "page": page,
                "limit": limit,
                "has_more": end_idx < total
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ Failed to get user sessions: {e}")
        return {
            "code": 500,
            "msg": f"Failed: {str(e)}",
            "data": None
        }


@router.get("/history")
async def get_chat_history(
    question_id: str = Query(..., alias="aiQuestionId", description="é¢˜ç›® ID"),
    answer_id: str = Query(..., alias="answerId", description="ç­”æ¡ˆ ID"),
    orchestrator: SkillOrchestrator = Depends(get_skill_orchestrator)
):
    """
    ğŸ“œ è·å–å•ä¸ªä¼šè¯çš„èŠå¤©å†å²
    
    ä¸ App ç«¯ /api/external/chat/history åŠŸèƒ½ä¸€è‡´ï¼Œæä¾› Web ç«¯è·¯å¾„ã€‚
    """
    from pathlib import Path
    import re
    
    session_id = f"q{question_id}_a{answer_id}"
    
    try:
        # æŸ¥æ‰¾ MD æ–‡ä»¶
        artifacts_dir = Path("artifacts")
        if not artifacts_dir.exists():
            artifacts_dir = Path("backend/artifacts")
        if not artifacts_dir.exists():
            artifacts_dir = Path("/root/usr/skill_agent_demo/backend/artifacts")
        
        # æœç´¢æ‰€æœ‰ç”¨æˆ·ç›®å½•ï¼Œæ‰¾æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶
        md_file = None
        user_id = None
        latest_mtime = 0
        
        for user_dir in artifacts_dir.iterdir():
            if user_dir.is_dir():
                potential_file = user_dir / f"{session_id}.md"
                if potential_file.exists():
                    # ğŸ†• é€‰æ‹©æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶
                    mtime = potential_file.stat().st_mtime
                    if mtime > latest_mtime:
                        latest_mtime = mtime
                        md_file = potential_file
                        user_id = user_dir.name
        
        if md_file:
            logger.info(f"ğŸ“„ Found session file: {md_file} (user={user_id})")
        
        if not md_file:
            return {
                "code": 0,
                "msg": "No chat history found",
                "data": {
                    "question_id": question_id,
                    "answer_id": answer_id,
                    "session_id": session_id,
                    "chat_list": [],
                    "total": 0
                }
            }
        
        # è§£æ MD æ–‡ä»¶
        content = md_file.read_text()
        chat_list = []
        
        # åŒ¹é…æ¯ä¸ª Turn
        turn_pattern = r'## Turn (\d+) - (\d{2}:\d{2}:\d{2})\n\n### ğŸ‘¤ User Query\n(.*?)\n\n### ğŸ¤– Agent Response\n\*\*Type\*\*: (\w+)'
        
        # ç®€åŒ–åŒ¹é… - æŒ‰ Turn åˆ†å‰²
        turns = content.split("## Turn ")[1:]  # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºå…ƒç´ 
        
        for turn_text in turns:
            try:
                # æå– turn number å’Œ timestamp
                header_match = re.match(r'(\d+) - (\d{2}:\d{2}:\d{2})', turn_text)
                if not header_match:
                    continue
                
                turn_num = int(header_match.group(1))
                timestamp = header_match.group(2)
                
                # æå–ç”¨æˆ·æ¶ˆæ¯
                user_match = re.search(r'### ğŸ‘¤ User Query\n(.*?)\n\n### ğŸ¤–', turn_text, re.DOTALL)
                user_message = user_match.group(1).strip() if user_match else ""
                
                # æå– assistant æ¶ˆæ¯ï¼ˆä» JSON å—ä¸­è§£æï¼‰
                assistant_message = ""
                
                # æ–¹æ³•1: å°è¯•ä» JSON ä»£ç å—ä¸­è§£æ text å­—æ®µï¼ˆç®€å• chatï¼‰
                json_block_match = re.search(r'```json\s*\n(\{[\s\S]*?\})\s*\n```', turn_text)
                if json_block_match:
                    try:
                        json_content = json.loads(json_block_match.group(1))
                        if isinstance(json_content, dict) and "text" in json_content:
                            assistant_message = json_content["text"]
                    except json.JSONDecodeError:
                        pass
                
                # ğŸ†• æ–¹æ³•2: ä» details å—ä¸­çš„ JSON è§£æï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰
                if not assistant_message:
                    details_match = re.search(r'<details>[\s\S]*?```json\s*\n(\{[\s\S]+?\n\})\s*\n```', turn_text)
                    if details_match:
                        try:
                            structured_json = json.loads(details_match.group(1))
                            agent_resp = structured_json.get("agent_response", {})
                            content = agent_resp.get("content", {})
                            
                            if isinstance(content, dict):
                                if "text" in content:
                                    # æ™®é€š chat å“åº”
                                    assistant_message = content["text"]
                                elif "intuition" in content:
                                    # explain_skill å“åº”ï¼šç»„åˆå¤šä¸ªå­—æ®µ
                                    parts = []
                                    if content.get("concept"):
                                        parts.append(f"**{content['concept']}**\n")
                                    if content.get("intuition"):
                                        parts.append(f"ğŸ“š **ç›´è§‰ç†è§£**: {content['intuition']}\n")
                                    if content.get("formal_definition"):
                                        parts.append(f"ğŸ“– **æ­£å¼å®šä¹‰**: {content['formal_definition']}\n")
                                    if content.get("why_it_matters"):
                                        parts.append(f"ğŸ’¡ **ä¸ºä»€ä¹ˆé‡è¦**: {content['why_it_matters']}\n")
                                    # æ·»åŠ ç¤ºä¾‹ï¼ˆæœ€å¤š2ä¸ªï¼‰
                                    examples = content.get("examples", [])
                                    if examples:
                                        parts.append("ğŸŒŸ **å®ä¾‹**:\n")
                                        for i, ex in enumerate(examples[:2], 1):
                                            if isinstance(ex, dict):
                                                parts.append(f"  {i}. {ex.get('example', '')}: {ex.get('explanation', '')}\n")
                                    assistant_message = "\n".join(parts)
                                elif "flashcards" in content:
                                    # flashcard_skill å“åº”
                                    flashcards = content.get("flashcards", [])
                                    assistant_message = f"å·²ç”Ÿæˆ {len(flashcards)} å¼ é—ªå¡"
                                    if flashcards and isinstance(flashcards[0], dict):
                                        first_card = flashcards[0]
                                        front = first_card.get("front", first_card.get("question", ""))
                                        assistant_message += f"\n\n**ç¬¬1å¼ **: {front[:100]}..."
                                elif "questions" in content:
                                    # quiz_skill å“åº”
                                    questions = content.get("questions", [])
                                    assistant_message = f"å·²ç”Ÿæˆ {len(questions)} é“ç»ƒä¹ é¢˜"
                                    if questions and isinstance(questions[0], dict):
                                        first_q = questions[0]
                                        q_text = first_q.get("question", first_q.get("text", ""))
                                        assistant_message += f"\n\n**ç¬¬1é¢˜**: {q_text[:100]}..."
                        except json.JSONDecodeError:
                            pass
                
                # æ–¹æ³•3: ä½¿ç”¨æ”¹è¿›çš„æ­£åˆ™ï¼ˆæ”¯æŒè½¬ä¹‰å­—ç¬¦ï¼‰
                if not assistant_message:
                    text_match = re.search(r'"text":\s*"((?:[^"\\]|\\.)*)"', turn_text)
                    if text_match:
                        assistant_message = text_match.group(1)
                        # åªå¤„ç†å¸¸è§çš„ JSON è½¬ä¹‰å­—ç¬¦ï¼Œä¿ç•™ LaTeX åæ–œæ 
                        assistant_message = assistant_message.replace('\\n', '\n').replace('\\r', '\r').replace('\\"', '"')
                
                # æ–¹æ³•4: æå– ç›´è§‰ç†è§£ï¼ˆmarkdown æ ¼å¼çš„ explain_skillï¼‰
                if not assistant_message:
                    intuition_match = re.search(r'#### ğŸ“š ç›´è§‰ç†è§£\s*\n(.+?)(?=\n####|\n##|\Z)', turn_text, re.DOTALL)
                    if intuition_match:
                        assistant_message = intuition_match.group(1).strip()
                
                # æ–¹æ³•5: å–å‰ 500 å­—ç¬¦ä½œä¸ºæ‘˜è¦
                if not assistant_message:
                    # ä» Agent Response ä¹‹åå¼€å§‹æå–
                    response_match = re.search(r'### ğŸ¤– Agent Response\s*\n(.*)', turn_text, re.DOTALL)
                    if response_match:
                        assistant_message = response_match.group(1)[:500].replace('\n', ' ')
                
                # æå– referenced_text
                referenced_text = None
                ref_match = re.search(r'"referenced_text":\s*"([^"]*)"', turn_text)
                if ref_match and ref_match.group(1):
                    referenced_text = ref_match.group(1)
                
                # æå– feedback
                feedback = None
                feedback_match = re.search(r'"feedback":\s*(\{[^}]+\}|null)', turn_text)
                if feedback_match and feedback_match.group(1) != "null":
                    try:
                        feedback = json.loads(feedback_match.group(1))
                    except:
                        pass
                
                chat_list.append({
                    "turn": turn_num,
                    "timestamp": timestamp,
                    "user_message": user_message,
                    "assistant_message": assistant_message,
                    "referenced_text": referenced_text,
                    "files": None,
                    "feedback": feedback
                })
                
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to parse turn: {e}")
                continue
        
        return {
            "code": 0,
            "msg": "Success",
            "data": {
                "question_id": question_id,
                "answer_id": answer_id,
                "session_id": session_id,
                "user_id": user_id,
                "chat_list": chat_list,
                "total": len(chat_list)
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ Failed to get chat history: {e}")
        return {
            "code": 500,
            "msg": f"Failed: {str(e)}",
            "data": None
        }


# ============= ğŸ†• StudyX å…¼å®¹æ¥å£ =============
# è¿™äº›æ¥å£å…¼å®¹ StudyX åŸç”Ÿæ ¼å¼ï¼Œæ–¹ä¾¿å‰ç«¯è°ƒç”¨

# åˆ›å»º StudyX å…¼å®¹è·¯ç”±
studyx_router = APIRouter(prefix="/api/studyx/v5/cloud/chat", tags=["studyx-compat"])


async def generate_studyx_sse_stream(
    message: str,
    user_id: str,
    session_id: str,
    msg_id: str,
    orchestrator: SkillOrchestrator,
    language: str = "en",
    file_uris: Optional[List[str]] = None,
    files: Optional[List[Dict]] = None,
    referenced_text: Optional[str] = None,
    action_type_hint: Optional[str] = None,
    qid: Optional[str] = None,
    token: Optional[str] = None,
    environment: str = "test"  # ğŸ†• ç¯å¢ƒæ ‡è¯†
) -> AsyncGenerator[str, None]:
    """
    ğŸ”„ ç”Ÿæˆ StudyX å…¼å®¹æ ¼å¼çš„ SSE äº‹ä»¶æµ
    
    æ ¼å¼ï¼š
    data: {"code":0,"msg":"Request succeeded","data":{"contents":[{"content":"xxx","contentType":"text","role":"assistant"}],"msgId":"xxx","sessionId":"xxx"}}
    """
    import uuid
    
    # ç”Ÿæˆå”¯ä¸€çš„ sessionId
    studyx_session_id = str(uuid.uuid4().int)[:19]  # æ¨¡æ‹Ÿ StudyX çš„ sessionId æ ¼å¼
    
    def make_chunk_event(content: str) -> str:
        """ç”Ÿæˆ StudyX æ ¼å¼çš„ chunk äº‹ä»¶"""
        event_data = {
            "code": 0,
            "msg": "Request succeeded",
            "eventId": None,
            "source": None,
            "data": {
                "contents": [{
                    "content": content,
                    "title": None,
                    "contentType": "text",
                    "msgId": None,
                    "role": "assistant",
                    "msgType": None,
                    "replaceFlag": None
                }],
                "msgId": msg_id,
                "sessionId": studyx_session_id,
                "data": None
            }
        }
        return f"data: {json.dumps(event_data, ensure_ascii=False)}\n\n"
    
    def make_end_event() -> str:
        """ç”Ÿæˆ StudyX æ ¼å¼çš„ç»“æŸäº‹ä»¶"""
        event_data = {
            "code": 200,
            "msg": "success",
            "eventId": None,
            "source": None,
            "data": None
        }
        return f"data: {json.dumps(event_data)}\n\n"
    
    try:
        # ğŸ†• è·å–é¢˜ç›®ä¸Šä¸‹æ–‡ï¼ˆç”¨äºå¿«é€Ÿé—®é¢˜æŒ‰é’®ï¼‰
        # å¯¹äºå¿«æ·é—®é¢˜ï¼ˆaction_type_hint å­˜åœ¨ï¼‰ï¼Œå§‹ç»ˆå°è¯•è·å–é¢˜ç›®ä¸Šä¸‹æ–‡
        question_context = None
        if qid and token:
            from pathlib import Path
            artifacts_dir = Path("/root/usr/skill_agent_demo/backend/artifacts")
            if not artifacts_dir.exists():
                artifacts_dir = Path("backend/artifacts")
            if not artifacts_dir.exists():
                artifacts_dir = Path("artifacts")
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ session æ–‡ä»¶åŠå…¶ turn æ•°
            existing_turns = 0
            for user_dir in artifacts_dir.iterdir():
                if user_dir.is_dir():
                    md_file = user_dir / f"{session_id}.md"
                    if md_file.exists():
                        content = md_file.read_text(encoding='utf-8')
                        existing_turns = content.count("## Turn ")
                        break
            
            # ğŸ†• æ¡ä»¶ï¼šæ–° session æˆ–è€…æœ‰å¿«æ·æ“ä½œç±»å‹ (action_type_hint)
            # å¿«æ·é—®é¢˜éœ€è¦é¢˜ç›®ä¸Šä¸‹æ–‡æ¥ç†è§£ "this concept", "this problem" ç­‰æŒ‡ä»£
            should_fetch_context = (existing_turns == 0) or action_type_hint
            
            if should_fetch_context:
                logger.info(f"ğŸ†• [StudyX SSE] Fetching question context (qid={qid}, action={action_type_hint}, turns={existing_turns}, env={environment})...")
                from app.api.external import fetch_question_context_from_studyx
                question_context = await fetch_question_context_from_studyx(qid, token, environment)
                if question_context:
                    logger.info(f"âœ… [StudyX SSE] Question context fetched: {len(question_context)} chars")
                else:
                    logger.warning(f"âš ï¸ [StudyX SSE] Failed to fetch question context")
        
        # 1. è°ƒç”¨å®Œæ•´çš„ Skill Pipeline
        result = await execute_skill_pipeline(
            message=message,
            user_id=user_id,
            session_id=session_id,
            orchestrator=orchestrator,
            quantity_override=None,
            skill_hint=None,
            file_uris=file_uris,
            referenced_text=referenced_text,
            action_type=action_type_hint,
            files=files,
            language=language,
            question_context=question_context  # ğŸ†• ä¼ é€’é¢˜ç›®ä¸Šä¸‹æ–‡
        )
        
        # 2. æå–å†…å®¹
        content = result.get("content") or result.get("response_content") or {}
        
        # æ ¹æ® content_type æå–æ–‡æœ¬å†…å®¹
        text = ""
        if isinstance(content, dict):
            if "text" in content:
                text = content.get("text", "")
            elif "intuition" in content:
                # explain_skill å“åº”
                parts = []
                if content.get("concept"):
                    parts.append(f"**{content['concept']}**\n\n")
                if content.get("intuition"):
                    parts.append(f"ğŸ“š **ç›´è§‰ç†è§£**\n{content['intuition']}\n\n")
                if content.get("formal_definition"):
                    parts.append(f"ğŸ“– **æ­£å¼å®šä¹‰**\n{content['formal_definition']}\n\n")
                if content.get("why_it_matters"):
                    parts.append(f"ğŸ’¡ **ä¸ºä»€ä¹ˆé‡è¦**\n{content['why_it_matters']}\n\n")
                examples = content.get("examples", [])
                if examples:
                    parts.append("ğŸŒŸ **å®ä¾‹**\n")
                    for i, ex in enumerate(examples, 1):
                        if isinstance(ex, dict):
                            parts.append(f"{i}. **{ex.get('example', '')}**\n   {ex.get('explanation', '')}\n\n")
                text = "".join(parts)
            elif "flashcards" in content:
                flashcards = content.get("flashcards", [])
                parts = [f"ğŸ“š å·²ç”Ÿæˆ {len(flashcards)} å¼ é—ªå¡\n\n"]
                for i, card in enumerate(flashcards[:5], 1):
                    if isinstance(card, dict):
                        front = card.get("front", card.get("question", ""))
                        back = card.get("back", card.get("answer", ""))
                        parts.append(f"**å¡ç‰‡ {i}**\nğŸ”¹ æ­£é¢: {front}\nğŸ”¸ èƒŒé¢: {back}\n\n")
                text = "".join(parts)
            elif "questions" in content:
                questions = content.get("questions", [])
                parts = [f"ğŸ“ å·²ç”Ÿæˆ {len(questions)} é“ç»ƒä¹ é¢˜\n\n"]
                for i, q in enumerate(questions, 1):
                    if isinstance(q, dict):
                        q_text = q.get("question", q.get("text", ""))
                        parts.append(f"**é¢˜ç›® {i}**: {q_text}\n")
                        options = q.get("options", [])
                        for opt in options:
                            if isinstance(opt, dict):
                                parts.append(f"   {opt.get('label', '')}) {opt.get('text', '')}\n")
                        parts.append("\n")
                text = "".join(parts)
            else:
                text = json.dumps(content, ensure_ascii=False, indent=2)
        elif isinstance(content, str):
            text = content
        else:
            text = str(content) if content else "å¤„ç†å®Œæˆ"
        
        # 3. æµå¼å‘é€å†…å®¹ï¼ˆæ¨¡æ‹Ÿ StudyX çš„å°å—è¾“å‡ºï¼‰
        if text:
            # StudyX æ ¼å¼æ˜¯éå¸¸å°çš„å—ï¼ˆçº¦ 1-5 ä¸ªå­—ç¬¦ï¼‰
            chunk_size = 5
            for i in range(0, len(text), chunk_size):
                chunk = text[i:i+chunk_size]
                # æ›¿æ¢ç©ºæ ¼ä¸º &nbsp; ä»¥åŒ¹é… StudyX æ ¼å¼
                # chunk = chunk.replace(' ', '&nbsp;')
                yield make_chunk_event(chunk)
                await asyncio.sleep(0.02)  # æ¨¡æ‹Ÿæµå¼æ•ˆæœ
        else:
            yield make_chunk_event("å¤„ç†å®Œæˆ")
        
        # 4. å‘é€ç»“æŸäº‹ä»¶
        yield make_end_event()
        
    except Exception as e:
        logger.error(f"âŒ StudyX SSE generation error: {e}", exc_info=True)
        error_event = {
            "code": 500,
            "msg": str(e),
            "eventId": None,
            "source": None,
            "data": None
        }
        yield f"data: {json.dumps(error_event)}\n\n"


class StudyXChatRequest(BaseModel):
    """StudyX å‘é€æ¶ˆæ¯è¯·æ±‚æ ¼å¼"""
    promptInput: str = Field(default="", description="ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¿«æ·æŒ‰é’®æ—¶å¯ä¸ºç©ºï¼‰")
    aiId: int = Field(default=21, description="AI ID")
    channelId: Optional[int] = Field(None, description="é¢‘é“ ID")
    aiQuestionId: str = Field(..., description="é¢˜ç›® IDï¼ˆæ•°å­—æ ¼å¼ï¼Œç”¨äº session_idï¼‰")
    aiAnswerId: str = Field(..., description="ç­”æ¡ˆ ID")
    chatType: int = Field(default=2, description="èŠå¤©ç±»å‹")
    lastAnswerId: Optional[str] = Field(None, description="ä¸Šä¸€æ¡å›å¤ IDï¼ˆç”¨äº regenerateï¼‰")
    # ğŸ†• æ”¯æŒå¿«æ·æŒ‰é’®å’Œæ–‡ä»¶ä¸Šä¼ 
    actionType: Optional[str] = Field(None, description="å¿«æ·æŒ‰é’®ç±»å‹ï¼ˆexplain_concept/make_simpler/common_mistakes ç­‰ï¼‰")
    fileUris: Optional[List[str]] = Field(None, description="æ–‡ä»¶ URI åˆ—è¡¨")
    files: Optional[List[Dict[str, Any]]] = Field(None, description="æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨")
    referencedText: Optional[str] = Field(None, description="å¼•ç”¨çš„æ–‡æœ¬")
    # ğŸ†• é¢˜ç›®ä¸Šä¸‹æ–‡æ”¯æŒï¼ˆslug æ ¼å¼çš„ resource_id ç”¨äºè·å–é¢˜ç›®è¯¦æƒ…ï¼‰
    resourceId: Optional[str] = Field(None, description="é¢˜ç›® slugï¼ˆå¦‚ 96rhh58ï¼‰ï¼Œç”¨äºè·å–é¢˜ç›®ä¸Šä¸‹æ–‡")


class StudyXRefreshRequest(BaseModel):
    """StudyX é‡æ–°ç”Ÿæˆè¯·æ±‚æ ¼å¼"""
    promptInput: str = Field(..., description="åŸå§‹æ¶ˆæ¯")
    aiId: int = Field(default=21, description="AI ID")
    channelId: Optional[int] = Field(None, description="é¢‘é“ ID")
    aiQuestionId: str = Field(..., description="é¢˜ç›® ID")
    aiAnswerId: str = Field(..., description="ç­”æ¡ˆ ID")
    chatType: int = Field(default=2, description="èŠå¤©ç±»å‹")
    lastAnswerId: str = Field(..., description="è¦é‡æ–°ç”Ÿæˆçš„å›å¤ ID")


@studyx_router.post("/newHomeChatQuestionV2", response_class=StreamingResponse)
async def studyx_new_chat_question(
    request: StudyXChatRequest,
    orchestrator: SkillOrchestrator = Depends(get_skill_orchestrator),
    token: Optional[str] = Header(None, description="ç”¨æˆ·è®¤è¯ Token"),
    environment: Optional[str] = Header("test", description="ç¯å¢ƒæ ‡è¯† (dev/test/prod)")
):
    """
    ğŸ”„ StudyX å…¼å®¹æ¥å£ - å‘é€æ–°æ¶ˆæ¯
    
    å°† StudyX æ ¼å¼è½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼å¹¶è°ƒç”¨ SSE æµ
    æ”¯æŒï¼šå¿«æ·æŒ‰é’®ã€æ–‡ä»¶ä¸Šä¼ ã€è¯­è¨€åå¥½
    """
    if token:
        set_user_api_token(token)
    
    try:
        # è½¬æ¢å‚æ•°
        session_id = f"q{request.aiQuestionId}_a{request.aiAnswerId}"
        
        # ğŸ†• ç¯å¢ƒæ ‡è¯†
        env = environment or "test"
        logger.info(f"ğŸŒ Environment: {env}")
        
        # è·å–è¯­è¨€è®¾ç½®
        language = "en"
        if token:
            language = await get_user_language_from_studyx(token, env) or "en"
        
        # å¤„ç†æ–‡ä»¶
        file_uris = request.fileUris or []
        has_files = bool(file_uris or request.files)
        
        # ğŸ†• åŒæ­¥ App ç«¯é€»è¾‘ï¼šå¤„ç†æ¶ˆæ¯
        message = request.promptInput.strip() if request.promptInput else ""
        
        # åœºæ™¯ A: å¿«æ·æŒ‰é’®æ¨¡å¼ï¼ˆactionTypeï¼‰
        if not message and request.actionType:
            if language in ["zh", "zh-CN", "zh-TW"]:
                action_default_messages = {
                    "explain_concept": "è¯·è¯¦ç»†è§£é‡Šè¿™ä¸ªæ¦‚å¿µ",
                    "make_simpler": "è¯·ç”¨æ›´ç®€å•çš„æ–¹å¼è§£é‡Š",
                    "common_mistakes": "è¿™ä¸ªçŸ¥è¯†ç‚¹æœ‰å“ªäº›å¸¸è§é”™è¯¯",
                    "step_by_step": "è¯·ä¸€æ­¥ä¸€æ­¥è§£é‡Šè§£é¢˜è¿‡ç¨‹",
                    "why_important": "ä¸ºä»€ä¹ˆè¿™ä¸ªçŸ¥è¯†ç‚¹å¾ˆé‡è¦",
                }
                default_msg = "è¯·å¸®æˆ‘ç†è§£è¿™ä¸ªå†…å®¹"
            elif language == "ja":
                action_default_messages = {
                    "explain_concept": "ã“ã®æ¦‚å¿µã‚’è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„",
                    "make_simpler": "ã‚‚ã£ã¨ç°¡å˜ã«èª¬æ˜ã—ã¦ãã ã•ã„",
                    "common_mistakes": "ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã§ã‚ˆãã‚ã‚‹é–“é•ã„ã¯ä½•ã§ã™ã‹",
                }
                default_msg = "ã“ã®å†…å®¹ã‚’ç†è§£ã™ã‚‹ã®ã‚’æ‰‹ä¼ã£ã¦ãã ã•ã„"
            elif language == "ko":
                action_default_messages = {
                    "explain_concept": "ì´ ê°œë…ì„ ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”",
                    "make_simpler": "ë” ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”",
                    "common_mistakes": "ì´ ì£¼ì œì—ì„œ í”íˆ í•˜ëŠ” ì‹¤ìˆ˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”",
                }
                default_msg = "ì´ ë‚´ìš©ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ì„¸ìš”"
            else:
                action_default_messages = {
                    "explain_concept": "Please explain this concept in detail",
                    "make_simpler": "Please explain this in a simpler way",
                    "common_mistakes": "What are the common mistakes for this topic",
                    "step_by_step": "Please explain the solution step by step",
                    "why_important": "Why is this concept important",
                }
                default_msg = "Please help me understand this content"
            message = action_default_messages.get(request.actionType, default_msg)
        
        # åœºæ™¯ B: æ–‡ä»¶ä¸Šä¼ æ¨¡å¼
        if not message and has_files:
            if language in ["zh", "zh-CN", "zh-TW"]:
                message = "è¯·å¸®æˆ‘åˆ†æè¿™ä¸ªå›¾ç‰‡/æ–‡ä»¶çš„å†…å®¹"
            elif language == "ja":
                message = "ã“ã®ç”»åƒ/ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’åˆ†æã—ã¦ãã ã•ã„"
            elif language == "ko":
                message = "ì´ ì´ë¯¸ì§€/íŒŒì¼ì˜ ë‚´ìš©ì„ ë¶„ì„í•´ ì£¼ì„¸ìš”"
            else:
                message = "Please help me analyze this image/file"
        
        logger.info("="*60)
        logger.info(f"ğŸ“¥ [StudyX] /newHomeChatQuestionV2")
        logger.info(f"   â€¢ Session: {session_id}")
        logger.info(f"   â€¢ Language: {language}")
        logger.info(f"   â€¢ Action Type: {request.actionType or 'N/A'}")
        logger.info(f"   â€¢ Files: {len(file_uris)} URIs, {len(request.files or [])} files")
        logger.info(f"   â€¢ Message: {message[:50]}...")
        logger.info("="*60)
        
        # ä» token è·å– user_id
        user_id = "unknown"
        if token:
            try:
                import base64
                parts = token.split('.')
                if len(parts) >= 2:
                    payload = base64.b64decode(parts[1] + '==')
                    payload_data = json.loads(payload)
                    user_id = payload_data.get('userguid', 'unknown')
            except:
                pass
        
        # è·å– session é”
        lock = await get_session_lock(session_id)
        
        # ğŸ”§ å…³é”®åŒºåˆ†ï¼šä½¿ç”¨ resourceIdï¼ˆslug æ ¼å¼ï¼‰è·å–é¢˜ç›®ä¸Šä¸‹æ–‡
        qid_for_context = request.resourceId  # ä¼˜å…ˆä½¿ç”¨ slug æ ¼å¼çš„ resourceId
        logger.info(f"   â€¢ QID for context: {qid_for_context or 'N/A (will skip context fetch)'}")
        
        async def locked_generator():
            async with lock:
                logger.info(f"ğŸ”’ [StudyX] Acquired lock for session: {session_id}")
                # ğŸ†• ä½¿ç”¨ StudyX å…¼å®¹æ ¼å¼çš„ SSE æµç”Ÿæˆå™¨
                async for event in generate_studyx_sse_stream(
                    message=message,
                    user_id=user_id,
                    session_id=session_id,
                    msg_id=request.aiQuestionId,  # ä½¿ç”¨é¢˜ç›® ID ä½œä¸º msgId
                    orchestrator=orchestrator,
                    language=language,
                    file_uris=file_uris if file_uris else None,
                    files=request.files,
                    referenced_text=request.referencedText,
                    action_type_hint=request.actionType,
                    qid=qid_for_context,  # ğŸ”§ ä½¿ç”¨ slug æ ¼å¼çš„ resourceId è·å–é¢˜ç›®ä¸Šä¸‹æ–‡
                    token=token,
                    environment=env  # ğŸ†• ç¯å¢ƒæ ‡è¯†
                ):
                    yield event
                logger.info(f"ğŸ”“ [StudyX] Released lock for session: {session_id}")
        
        return StreamingResponse(
            locked_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
        
    except Exception as e:
        logger.error(f"âŒ [StudyX] newHomeChatQuestionV2 error: {e}")
        error_event = f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
        return StreamingResponse(
            iter([error_event]),
            media_type="text/event-stream"
        )


@studyx_router.post("/newHwRefreshAnswer", response_class=StreamingResponse)
async def studyx_refresh_answer(
    request: StudyXRefreshRequest,
    orchestrator: SkillOrchestrator = Depends(get_skill_orchestrator),
    token: Optional[str] = Header(None, description="ç”¨æˆ·è®¤è¯ Token"),
    environment: Optional[str] = Header("test", description="ç¯å¢ƒæ ‡è¯† (dev/test/prod)")
):
    """
    ğŸ”„ StudyX å…¼å®¹æ¥å£ - é‡æ–°ç”Ÿæˆå›å¤
    
    å°† StudyX æ ¼å¼è½¬æ¢ä¸ºå†…éƒ¨ regenerate æ“ä½œ
    """
    if token:
        set_user_api_token(token)
    
    try:
        session_id = f"q{request.aiQuestionId}_a{request.aiAnswerId}"
        
        # ğŸ†• ç¯å¢ƒæ ‡è¯†
        env = environment or "test"
        
        logger.info("="*60)
        logger.info(f"ğŸ“¥ [StudyX] /newHwRefreshAnswer")
        logger.info(f"   â€¢ Session: {session_id}")
        logger.info(f"   â€¢ LastAnswerId: {request.lastAnswerId}")
        logger.info(f"   â€¢ Environment: {env}")
        logger.info("="*60)
        
        # è·å–è¯­è¨€è®¾ç½®
        language = "en"
        if token:
            language = await get_user_language_from_studyx(token, env) or "en"
        
        # ä» token è·å– user_id
        user_id = "unknown"
        if token:
            try:
                import base64
                parts = token.split('.')
                if len(parts) >= 2:
                    payload = base64.b64decode(parts[1] + '==')
                    payload_data = json.loads(payload)
                    user_id = payload_data.get('userguid', 'unknown')
            except:
                pass
        
        # ğŸ†• ä» lastAnswerId æ¨æ–­ turn_id
        # lastAnswerId æ ¼å¼å¯èƒ½æ˜¯æ•°å­—å­—ç¬¦ä¸²ï¼Œéœ€è¦æ˜ å°„åˆ° turn_id
        # ç®€åŒ–å¤„ç†ï¼šä½¿ç”¨æœ€åä¸€è½®ä½œä¸º regenerate ç›®æ ‡
        turn_id = None
        try:
            # è¯»å– session æ–‡ä»¶è·å–æœ€æ–° turn
            from pathlib import Path
            artifacts_dir = Path("/root/usr/skill_agent_demo/backend/artifacts")
            
            for user_dir in artifacts_dir.iterdir():
                if not user_dir.is_dir():
                    continue
                session_file = user_dir / f"{session_id}.md"
                if session_file.exists():
                    content = session_file.read_text()
                    # æ‰¾åˆ°æœ€åä¸€ä¸ª Turn å·
                    turns = re.findall(r'## Turn (\d+)', content)
                    if turns:
                        turn_id = int(turns[-1])
                    break
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to get last turn: {e}")
        
        if turn_id is None:
            turn_id = 1  # é»˜è®¤é‡æ–°ç”Ÿæˆç¬¬ä¸€è½®
        
        logger.info(f"   â€¢ Regenerate Turn: {turn_id}")
        
        # è·å– session é”
        lock = await get_session_lock(session_id)
        
        # ğŸ†• StudyX å…¼å®¹æ ¼å¼çš„ regenerate SSE æµ
        import uuid
        studyx_session_id = str(uuid.uuid4().int)[:19]
        
        def make_studyx_chunk(content: str) -> str:
            return f"data: {json.dumps({'code': 0, 'msg': 'Request succeeded', 'eventId': None, 'source': None, 'data': {'contents': [{'content': content, 'title': None, 'contentType': 'text', 'msgId': None, 'role': 'assistant', 'msgType': None, 'replaceFlag': None}], 'msgId': request.aiQuestionId, 'sessionId': studyx_session_id, 'data': None}}, ensure_ascii=False)}\n\n"
        
        async def locked_generator():
            async with lock:
                logger.info(f"ğŸ”’ [StudyX] Acquired lock for session: {session_id}")
                
                full_text = ""
                async for event in generate_sse_stream(
                    message=request.promptInput,
                    user_id=user_id,
                    session_id=session_id,
                    action="regenerate",
                    turn_id=turn_id,
                    orchestrator=orchestrator,
                    language=language,
                    file_uris=None,
                    files=None,
                    referenced_text=None,
                    action_type_hint=None,
                    qid=request.aiQuestionId,
                    token=token,
                    environment=env  # ğŸ†• ç¯å¢ƒæ ‡è¯†
                ):
                    # è§£æå†…éƒ¨ SSE äº‹ä»¶å¹¶è½¬æ¢ä¸º StudyX æ ¼å¼
                    if event.startswith("data: "):
                        try:
                            event_data = json.loads(event[6:].strip())
                            event_type = event_data.get("type")
                            
                            if event_type == "chunk":
                                chunk_content = event_data.get("content", "")
                                full_text += chunk_content
                                # åˆ†å°å—å‘é€ï¼ˆæ¯ 5 ä¸ªå­—ç¬¦ï¼‰
                                for i in range(0, len(chunk_content), 5):
                                    yield make_studyx_chunk(chunk_content[i:i+5])
                                    await asyncio.sleep(0.02)
                            elif event_type == "done":
                                # å¦‚æœæ²¡æœ‰ chunkï¼Œä» done äº‹ä»¶è·å–å®Œæ•´å“åº”
                                if not full_text:
                                    done_text = event_data.get("full_response", "")
                                    for i in range(0, len(done_text), 5):
                                        yield make_studyx_chunk(done_text[i:i+5])
                                        await asyncio.sleep(0.02)
                        except json.JSONDecodeError:
                            pass
                
                # å‘é€ç»“æŸäº‹ä»¶
                yield f"data: {json.dumps({'code': 200, 'msg': 'success', 'eventId': None, 'source': None, 'data': None})}\n\n"
                logger.info(f"ğŸ”“ [StudyX] Released lock for session: {session_id}")
        
        return StreamingResponse(
            locked_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
        
    except Exception as e:
        logger.error(f"âŒ [StudyX] newHwRefreshAnswer error: {e}")
        error_event = f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
        return StreamingResponse(
            iter([error_event]),
            media_type="text/event-stream"
        )


@studyx_router.get("/getHomeworkChatListV2")
async def studyx_get_chat_list(
    aiQuestionId: str,
    answerId: str,
    token: Optional[str] = Header(None, description="ç”¨æˆ·è®¤è¯ Token")
):
    """
    ğŸ”„ StudyX å…¼å®¹æ¥å£ - è·å–èŠå¤©å†å²åˆ—è¡¨
    
    è¿”å›æ ¼å¼ä¸ StudyX åŸç”Ÿæ¥å£å®Œå…¨å…¼å®¹ï¼š
    {
        "code": 0,
        "msg": "Request succeeded",
        "data": {
            "lastAnswerId": "xxx",
            "resultList": [
                {
                    "question": {...},
                    "answerList": [{...}]
                }
            ]
        }
    }
    """
    import uuid
    from datetime import datetime, timezone
    from pathlib import Path
    
    try:
        session_id = f"q{aiQuestionId}_a{answerId}"
        
        logger.info("="*60)
        logger.info(f"ğŸ“¥ [StudyX] /getHomeworkChatListV2")
        logger.info(f"   â€¢ Question ID: {aiQuestionId}")
        logger.info(f"   â€¢ Answer ID: {answerId}")
        logger.info(f"   â€¢ Session: {session_id}")
        logger.info("="*60)
        
        # æŸ¥æ‰¾ session æ–‡ä»¶
        artifacts_dir = Path("/root/usr/skill_agent_demo/backend/artifacts")
        if not artifacts_dir.exists():
            artifacts_dir = Path("backend/artifacts")
        if not artifacts_dir.exists():
            artifacts_dir = Path("artifacts")
        
        # æœç´¢æ‰€æœ‰ç”¨æˆ·ç›®å½•ï¼Œæ‰¾åˆ°æœ€æ–°ä¿®æ”¹çš„ session æ–‡ä»¶
        md_file = None
        user_id = None
        latest_mtime = 0
        
        for user_dir in artifacts_dir.iterdir():
            if user_dir.is_dir():
                potential_file = user_dir / f"{session_id}.md"
                if potential_file.exists():
                    current_mtime = potential_file.stat().st_mtime
                    if current_mtime > latest_mtime:
                        latest_mtime = current_mtime
                        md_file = potential_file
                        user_id = user_dir.name
        
        if not md_file:
            logger.info(f"ğŸ“„ No session file found for session={session_id}")
            return {
                "code": 0,
                "msg": "Request succeeded",
                "eventId": None,
                "source": None,
                "data": {
                    "lastAnswerId": None,
                    "resultList": []
                }
            }
        
        logger.info(f"ğŸ“„ Found session file: {md_file} (user={user_id})")
        content = md_file.read_text(encoding='utf-8')
        
        # è§£æ MD æ–‡ä»¶ä¸­çš„ turns
        turn_pattern = re.compile(r'## Turn (\d+).*?(?=## Turn \d+|\Z)', re.DOTALL)
        turns = turn_pattern.findall(content)
        turn_sections = turn_pattern.finditer(content)
        
        result_list = []
        last_answer_id = None
        
        for match in turn_sections:
            turn_text = match.group(0)
            turn_num = int(re.search(r'## Turn (\d+)', turn_text).group(1))
            
            try:
                # æå–æ—¶é—´æˆ³
                time_match = re.search(r'\*\*Time\*\*:\s*(\d{2}:\d{2}:\d{2})', turn_text)
                timestamp = time_match.group(1) if time_match else "00:00:00"
                
                # åˆ›å»ºæ—¶é—´ï¼ˆä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸï¼‰
                today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
                create_time = f"{today}T{timestamp}.000+00:00"
                
                # ç”Ÿæˆå”¯ä¸€çš„ chatId
                base_id = int(uuid.uuid4().int % (10**19))
                question_chat_id = str(base_id + turn_num * 2)
                answer_chat_id = str(base_id + turn_num * 2 + 1)
                
                # æå–ç”¨æˆ·æ¶ˆæ¯
                user_match = re.search(r'"user_query":\s*"((?:[^"\\]|\\.)*)"', turn_text)
                user_message = user_match.group(1) if user_match else ""
                if user_message:
                    user_message = user_message.replace('\\n', '\n').replace('\\r', '\r').replace('\\"', '"')
                
                # æå– AI å“åº”
                assistant_message = ""
                
                # æ–¹æ³•1: ä» JSON å—è§£æ
                details_match = re.search(r'<details>.*?```json\s*(.*?)\s*```.*?</details>', turn_text, re.DOTALL)
                if details_match:
                    try:
                        json_content = json.loads(details_match.group(1))
                        if isinstance(json_content, dict):
                            assistant_message = json_content.get("text", "")
                    except:
                        pass
                
                # æ–¹æ³•2: ä» "text" å­—æ®µæå–
                if not assistant_message:
                    text_match = re.search(r'"text":\s*"((?:[^"\\]|\\.)*)"', turn_text)
                    if text_match:
                        assistant_message = text_match.group(1)
                        assistant_message = assistant_message.replace('\\n', '\n').replace('\\r', '\r').replace('\\"', '"')
                
                # æ–¹æ³•3: å– Agent Response éƒ¨åˆ†
                if not assistant_message:
                    response_match = re.search(r'### ğŸ¤– Agent Response\s*\n(.*?)(?=\n###|\n##|\Z)', turn_text, re.DOTALL)
                    if response_match:
                        assistant_message = response_match.group(1).strip()[:1000]
                
                # æ„å»º StudyX æ ¼å¼çš„ question
                question_obj = {
                    "chatId": question_chat_id,
                    "messageId": None,
                    "sessionId": answerId,
                    "userId": user_id,
                    "messageType": None,
                    "messageOrigin": 1,  # 1 = ç”¨æˆ·æ¶ˆæ¯
                    "message": user_message,
                    "messageText": user_message,
                    "searchQnts": None,
                    "searchWeb": None,
                    "searchContent": None,
                    "sources": None,
                    "createTime": create_time,
                    "aiTypeId": 21,
                    "hasWebAccess": None,
                    "modelType": None,
                    "parentId": "0",
                    "likeType": None,
                    "aiName": None
                }
                
                # æ„å»º StudyX æ ¼å¼çš„ answer
                answer_obj = {
                    "chatId": answer_chat_id,
                    "messageId": None,
                    "sessionId": answerId,
                    "userId": user_id,
                    "messageType": None,
                    "messageOrigin": 2,  # 2 = AI å“åº”
                    "message": assistant_message,
                    "messageText": None,
                    "searchQnts": None,
                    "searchWeb": None,
                    "searchContent": None,
                    "sources": None,
                    "createTime": create_time,
                    "aiTypeId": 21,
                    "hasWebAccess": None,
                    "modelType": None,
                    "parentId": question_chat_id,
                    "likeType": 0,
                    "aiName": None
                }
                
                result_list.append({
                    "question": question_obj,
                    "answerList": [answer_obj]
                })
                
                # æ›´æ–° lastAnswerId
                last_answer_id = answer_chat_id
                
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to parse turn {turn_num}: {e}")
                continue
        
        logger.info(f"âœ… Parsed {len(result_list)} turns for StudyX format")
        
        return {
            "code": 0,
            "msg": "Request succeeded",
            "eventId": None,
            "source": None,
            "data": {
                "lastAnswerId": last_answer_id,
                "resultList": result_list
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ [StudyX] getHomeworkChatListV2 error: {e}", exc_info=True)
        return {
            "code": 500,
            "msg": str(e),
            "eventId": None,
            "source": None,
            "data": None
        }
