# ğŸ—ï¸ System Architecture

æœ¬æ–‡æ¡£æ•´åˆäº†ç³»ç»Ÿçš„æ ¸å¿ƒæ¶æ„è®¾è®¡ã€‚

---

## ğŸ“‹ ç›®å½•

1. [Context Engineeringï¼ˆä¸Šä¸‹æ–‡å·¥ç¨‹ï¼‰](#context-engineering)
2. [Thinking Mode Selectionï¼ˆæ€è€ƒæ¨¡å¼é€‰æ‹©ï¼‰](#thinking-mode-selection)
3. [Plan Skillï¼ˆè®¡åˆ’æŠ€èƒ½ï¼‰](#plan-skill)

---


<a name="context-engineering"></a>
# ğŸ”§ Context Engineering


**å®Œæˆæ—¶é—´**: 2024-11-24  
**æœ€åæ›´æ–°**: 2024-12-22  
**çŠ¶æ€**: âœ… æ ¸å¿ƒåŠŸèƒ½å·²å®ç°  
**æ¶æ„ç‰ˆæœ¬**: Phase 4 (Skill Registry + Context Engineering)  
**ä¸»è¦ LLM**: Gemini 2.5 Flash (Kimi ä½œä¸ºå¤‡é€‰)

---

## ğŸ“Š å®ç°çŠ¶æ€æ€»è§ˆ

| åŠŸèƒ½æ”¯æŸ± | çŠ¶æ€ | å®ç°åº¦ | è¯´æ˜ |
|---------|------|--------|------|
| **Context Offloading** (ä¸Šä¸‹æ–‡å¸è½½) | âœ… å·²å®ç° | 100% | å¤§å†…å®¹è‡ªåŠ¨ä¿å­˜åˆ°æ–‡ä»¶/S3ï¼Œåªä¿ç•™å¼•ç”¨ |
| **Context Reduction** (ä¸Šä¸‹æ–‡ç¼©å‡) | âœ… å·²å®ç° | 100% | LLM æ™ºèƒ½å‹ç¼© + å¼‚æ­¥æ‰§è¡Œ |
| **Context Retrieval** (æŒ‰éœ€æ£€ç´¢) | âš ï¸ éƒ¨åˆ†å®ç° | 60% | å·¥å…·å·²å¼€å‘ï¼Œæœªé›†æˆåˆ° Agent |

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### ç³»ç»Ÿæ¶æ„å…¨æ™¯å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend (React)                             â”‚
â”‚                     â€¢ ç”¨æˆ·ç•Œé¢                                      â”‚
â”‚                     â€¢ WebSocket å®æ—¶æ›´æ–°                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ HTTP/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FastAPI Backend                             â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              Intent Router (Phase 4)                       â”‚    â”‚
â”‚  â”‚  â€¢ Skill Registry (0-token å…³é”®è¯åŒ¹é…)                    â”‚    â”‚
â”‚  â”‚  â€¢ æ··åˆæ„å›¾æ£€æµ‹                                            â”‚    â”‚
â”‚  â”‚  â€¢ æ—  LLM fallback                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚            Skill Orchestrator (æ ¸å¿ƒç¼–æ’å™¨)                 â”‚    â”‚
â”‚  â”‚  â€¢ æŠ€èƒ½è°ƒåº¦å’Œæ‰§è¡Œ                                          â”‚    â”‚
â”‚  â”‚  â€¢ Context æ„å»º (åªåŠ è½½å‹ç¼© summary)                       â”‚    â”‚
â”‚  â”‚  â€¢ LLM è°ƒç”¨å’Œå“åº”è§£æ                                      â”‚    â”‚
â”‚  â”‚  â€¢ æµå¼è¾“å‡ºæ”¯æŒ                                            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              Memory Manager (è®°å¿†ç®¡ç†)                     â”‚    â”‚
â”‚  â”‚  â€¢ ç”¨æˆ·å­¦ä¹ ç”»åƒ (User Profile)                            â”‚    â”‚
â”‚  â”‚  â€¢ ä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç† (Session Context)                       â”‚    â”‚
â”‚  â”‚  â€¢ Artifact ä¿å­˜ (å¼‚æ­¥å‹ç¼©)                               â”‚    â”‚
â”‚  â”‚  â€¢ ä¸Šä¸‹æ–‡ç»§æ‰¿ (Session åˆ‡æ¢æ—¶)                            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚    Context Engineering Modules (ä¸Šä¸‹æ–‡å·¥ç¨‹æ¨¡å—)            â”‚    â”‚
â”‚  â”‚                                                             â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚  ContextArtifactManager (ä¸Šä¸‹æ–‡å¸è½½)               â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ å¤§å†…å®¹ä¿å­˜åˆ°æ–‡ä»¶/S3 (> 500 tokens)              â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ è½»é‡çº§ç´¢å¼•ç»´æŠ¤ (artifact_index.json)            â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ æŒ‰éœ€è¯»å– API                                     â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚                                                             â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚  ContextMemoryManager (ä¸Šä¸‹æ–‡ç¼©å‡)                 â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Pruning: ä¿®å‰ªå†—é•¿çš„ tool calls                  â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Condensation: é€’å½’æ‘˜è¦æ—©æœŸå¯¹è¯                  â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ 70% ä½¿ç”¨ç‡è‡ªåŠ¨è§¦å‘                              â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚                                                             â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚  RetrievalTools (æŒ‰éœ€æ£€ç´¢) âš ï¸ 60% å®ç°             â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ read_artifact(artifact_id)                       â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ search_artifacts(query)                          â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ list_artifacts(session_id)                       â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      Conversation Session Manager (ä¼šè¯ç®¡ç†)              â”‚    â”‚
â”‚  â”‚  â€¢ æ™ºèƒ½åˆ†æ®µ (åŸºäºé•¿åº¦å’Œè¯­ä¹‰æ–­ç‚¹)                          â”‚    â”‚
â”‚  â”‚  â€¢ MD æ—¥å¿—ç”Ÿæˆå’Œ S3 ä¸Šä¼                                   â”‚    â”‚
â”‚  â”‚  â€¢ Session Metadata æŒä¹…åŒ–                                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚          Plan Skill Executor (è®¡åˆ’æŠ€èƒ½æ‰§è¡Œå™¨)             â”‚    â”‚
â”‚  â”‚  â€¢ å¤šæ­¥éª¤ä»»åŠ¡ç¼–æ’                                          â”‚    â”‚
â”‚  â”‚  â€¢ {context.previous} é“¾å¼ä¼ é€’                            â”‚    â”‚
â”‚  â”‚  â€¢ æ­¥éª¤é—´æ™ºèƒ½å‹ç¼©                                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                           â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   AWS S3 Storage  â”‚       â”‚   Gemini LLM    â”‚
     â”‚  â€¢ MD æ–‡ä»¶         â”‚       â”‚  â€¢ 2.5-flash    â”‚
     â”‚  â€¢ Metadata JSON  â”‚       â”‚  â€¢ ç”Ÿæˆ + å‹ç¼©  â”‚
     â”‚  â€¢ å¤§å‹ Artifacts â”‚       â”‚  (Kimi å¤‡é€‰)    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è¯·æ±‚å¤„ç†æ•°æ®æµå›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User: "è®²è®²å…‰åˆä½œç”¨"                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Intent Router (Skill Registry åŒ¹é…)                             â”‚
â”‚     â€¢ å…³é”®è¯: "è®²è®²", "å…‰åˆä½œç”¨"                                    â”‚
â”‚     â€¢ åŒ¹é…ç»“æœ: intent="explain", topic="å…‰åˆä½œç”¨"                  â”‚
â”‚     â€¢ è€—æ—¶: < 1ms (0 tokens)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Skill Orchestrator ç¼–æ’                                         â”‚
â”‚     a) åŠ è½½ explain_skill prompt (3.5K chars)                       â”‚
â”‚     b) æ„å»º Context:                                                â”‚
â”‚        â€¢ ç”¨æˆ·ç”»åƒ: 20 chars                                         â”‚
â”‚        â€¢ æœ€è¿‘ 2 ä¸ª artifacts (compressed): 150-300 chars            â”‚
â”‚        â€¢ æœ€è¿‘ 3 è½®å¯¹è¯: 500 chars                                   â”‚
â”‚     c) è°ƒç”¨ Kimi LLM                                                â”‚
â”‚        Prompt: ~2,450 tokens (vs 5,255 before)                      â”‚
â”‚     d) è§£æ JSON å“åº” (LaTeX escape å¤„ç†)                           â”‚
â”‚     â€¢ è€—æ—¶: ~60s                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Memory Manager ä¿å­˜ Artifact                                    â”‚
â”‚     a) Fallback å‹ç¼© (å¿«é€Ÿè§„åˆ™å‹ç¼©):                                â”‚
â”‚        â€¢ åŸå§‹: 1,773 chars                                          â”‚
â”‚        â€¢ å‹ç¼©: 388 chars                                            â”‚
â”‚        â€¢ è€—æ—¶: < 1ms                                                â”‚
â”‚     b) åˆ›å»º ArtifactRecord:                                         â”‚
â”‚        â€¢ artifact_id: artifact_explanation_å…‰åˆä½œç”¨_xxx             â”‚
â”‚        â€¢ content: {fallback_summary}                                â”‚
â”‚        â€¢ content_reference: null (å®Œæ•´å†…å®¹åœ¨ MD)                    â”‚
â”‚     c) æ›´æ–° Session Context                                         â”‚
â”‚     d) ğŸš€ å¯åŠ¨å¼‚æ­¥ä»»åŠ¡: _compress_artifact_async()                 â”‚
â”‚     â€¢ è€—æ—¶: < 1s (ä¸é˜»å¡)                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚                    â”‚
                           â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4a. Conversation Session       â”‚  â”‚  4b. åå°å¼‚æ­¥ä»»åŠ¡ (Background)â”‚
â”‚      Manager                    â”‚  â”‚                               â”‚
â”‚  â€¢ Append to MD log             â”‚  â”‚  â€¢ LLM æ™ºèƒ½å‹ç¼©:              â”‚
â”‚  â€¢ Upload to S3:                â”‚  â”‚    1,773 â†’ 245 chars (-86%)   â”‚
â”‚    - session_xxx.md             â”‚  â”‚  â€¢ ä½¿ç”¨ summary_skill prompt  â”‚
â”‚    - session_xxx_metadata.json  â”‚  â”‚  â€¢ æ›´æ–° ArtifactRecord.contentâ”‚
â”‚  â€¢ æ£€æŸ¥æ˜¯å¦éœ€è¦æ–° session       â”‚  â”‚  â€¢ è€—æ—¶: ~260s (ä¸å½±å“ç”¨æˆ·)   â”‚
â”‚  â€¢ è€—æ—¶: < 1s                   â”‚  â”‚                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. âœ… è¿”å›ç»™ç”¨æˆ·                                                   â”‚
â”‚     â€¢ æ€»è€—æ—¶: ~61s (ç”Ÿæˆ 60s + ä¿å­˜ 1s)                             â”‚
â”‚     â€¢ ç”¨æˆ·ä½“éªŒ: ä¸å—å¼‚æ­¥å‹ç¼©å½±å“                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Turn 2: "ç»™æˆ‘3é“é¢˜"
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Intent Router: intent="quiz", topic="å…‰åˆä½œç”¨", num_questions=3 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Skill Orchestrator ç¼–æ’                                         â”‚
â”‚     a) åŠ è½½ quiz_skill prompt (5.1K chars)                          â”‚
â”‚     b) æ„å»º Context:                                                â”‚
â”‚        â€¢ æœ€è¿‘ 2 ä¸ª artifacts (compressed):                          â”‚
â”‚          - explanation: 245 chars â† LLM å‹ç¼©åï¼                    â”‚
â”‚        â€¢ æœ€è¿‘ 3 è½®å¯¹è¯: 800 chars                                   â”‚
â”‚     c) è°ƒç”¨ Kimi LLM                                                â”‚
â”‚        Prompt: ~1,300 tokens (vs 3,949 before) â† èŠ‚çœ 67%!          â”‚
â”‚     â€¢ è€—æ—¶: ~50s                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Memory Manager ä¿å­˜ Quiz Artifact                               â”‚
â”‚     â€¢ Fallback å‹ç¼©: 1,200 â†’ 160 chars                             â”‚
â”‚     â€¢ ğŸš€ å¯åŠ¨å¼‚æ­¥ LLM å‹ç¼©                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. âœ… è¿”å›ç»™ç”¨æˆ·                                                   â”‚
â”‚     â€¢ æ€»è€—æ—¶: ~51s                                                  â”‚
â”‚     â€¢ Token èŠ‚çœ: 3,949 â†’ 1,300 (-67%)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Context Engineering ç”Ÿå‘½å‘¨æœŸ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Artifact ç”Ÿå‘½å‘¨æœŸ: ä»ç”Ÿæˆåˆ°å‹ç¼©åˆ°æ£€ç´¢                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Time    Action                                     State
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
T0      LLM ç”Ÿæˆ artifact                          ğŸ“„ Raw (1,773 chars)
        |
        â–¼
T1      Fallback å¿«é€Ÿå‹ç¼©                          ğŸ“¦ Fallback (388 chars)
        â€¢ è§„åˆ™æå–å…³é”®å­—æ®µ
        â€¢ æˆªæ–­é•¿æ–‡æœ¬
        â€¢ < 1ms
        |
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        |                                      |
        â–¼                                      â–¼
T2      ç”¨æˆ·æ”¶åˆ°å“åº”                           ğŸ”„ å¯åŠ¨åå°ä»»åŠ¡
        â€¢ å®Œæ•´å†…å®¹åœ¨ MD ä¸­                     â€¢ _compress_artifact_async()
        â€¢ Context åªæœ‰ fallback summary
        |                                      |
        |                                      â–¼
        |                                     T3 (å¼‚æ­¥) LLM æ™ºèƒ½å‹ç¼©
        |                                      â€¢ è°ƒç”¨ summary_skill
        |                                      â€¢ Kimi k2-thinking
        |                                      â€¢ ~260s
        |                                      |
        |                                      â–¼
        |                                     T4 (å¼‚æ­¥) æ›´æ–° Session Context
        |                                      â€¢ æ›¿æ¢ fallback â†’ LLM summary
        |                                      â€¢ ğŸ“¦ Compressed (245 chars)
        |                                      â€¢ -86% å‹ç¼©æ¯”
        â–¼                                      |
T5      ç”¨æˆ·å‘èµ· Turn 2                        â–¼
        "ç»™æˆ‘3é“é¢˜"                            åŠ è½½ LLM å‹ç¼©åçš„ summary
        |                                      â€¢ 245 chars (è€Œé 1,773)
        â–¼                                      â€¢ Token å¤§å¹…èŠ‚çœ
        
        Prompt: 1,300 tokens (vs 3,949 before)
        
        âœ… Context Engineering æˆåŠŸï¼
```

### æ¨¡å—äº¤äº’æ—¶åºå›¾

```
ç”¨æˆ·è¯·æ±‚ "è®²è®²å…‰åˆä½œç”¨" â†’ ç³»ç»Ÿå†…éƒ¨è°ƒç”¨é“¾

â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User â”‚    â”‚ Intent      â”‚    â”‚ Skill        â”‚    â”‚ Memory      â”‚
â”‚      â”‚    â”‚ Router      â”‚    â”‚ Orchestrator â”‚    â”‚ Manager     â”‚
â””â”€â”€â”€â”¬â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
    â”‚              â”‚                   â”‚                   â”‚
    â”‚ "è®²è®²å…‰åˆä½œç”¨"â”‚                   â”‚                   â”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚ 1. match_message()â”‚                   â”‚
    â”‚              â”‚   (Skill Registry)â”‚                   â”‚
    â”‚              â”‚   â†’ explain       â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚ 2. dispatch(explain, topic="å…‰åˆä½œç”¨")â”‚
    â”‚              â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚ 3. get_session_context()
    â”‚              â”‚                   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚ 4. session_contextâ”‚
    â”‚              â”‚                   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚              â”‚                   â”‚   (åŒ…å«å‹ç¼©çš„     â”‚
    â”‚              â”‚                   â”‚    artifact_history)
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚ 5. _build_context()
    â”‚              â”‚                   â”‚   â€¢ åªåŠ è½½æœ€è¿‘2ä¸ª  â”‚
    â”‚              â”‚                   â”‚     compressed    â”‚
    â”‚              â”‚                   â”‚     summaries     â”‚
    â”‚              â”‚                   â”‚   â€¢ è·³è¿‡ > 1000   â”‚
    â”‚              â”‚                   â”‚     chars çš„æ—§æ•°æ®â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚ 6. kimi.generate()â”‚
    â”‚              â”‚                   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
    â”‚              â”‚                   â”‚        â”‚ ~60s    â”‚
    â”‚              â”‚                   â”‚<â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
    â”‚              â”‚                   â”‚   (1,773 chars)   â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚ 7. save_artifact()â”‚
    â”‚              â”‚                   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚ 8. _fallback_compression()
    â”‚              â”‚                   â”‚                   â”‚    (1,773â†’388 chars)
    â”‚              â”‚                   â”‚                   â”‚    < 1ms
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚ 9. create ArtifactRecord
    â”‚              â”‚                   â”‚                   â”‚    content: fallback_summary
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚ 10. asyncio.create_task()
    â”‚              â”‚                   â”‚                   â”‚     _compress_artifact_async()
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚ 11. artifact savedâ”‚
    â”‚              â”‚                   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚              â”‚                   â”‚    (ä¸ç­‰å¾…LLMå‹ç¼©)â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚ 12. response_data â”‚                   â”‚
    â”‚              â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚ 13. è¿”å›ç»“æœ â”‚                   â”‚                   â”‚
    â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                   â”‚                   â”‚
    â”‚ (æ€»è€—æ—¶ ~61s)â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚ [åå°å¼‚æ­¥çº¿ç¨‹]
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚ 14. _create_context_summary()
    â”‚              â”‚                   â”‚                   â”‚     â€¢ summary_skill prompt
    â”‚              â”‚                   â”‚                   â”‚     â€¢ kimi.generate()
    â”‚              â”‚                   â”‚                   â”‚       ~260s
    â”‚              â”‚                   â”‚                   â”‚     â€¢ 1,773 â†’ 245 chars
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚ 15. update ArtifactRecord
    â”‚              â”‚                   â”‚                   â”‚     content: LLM_summary
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚ 16. update_session_context()
    â”‚              â”‚                   â”‚                   â”‚     âœ… åå°å‹ç¼©å®Œæˆ
    â”‚              â”‚                   â”‚                   â”‚


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Turn 2: "ç»™æˆ‘3é“é¢˜" (æ­¤æ—¶ LLM å‹ç¼©å·²å®Œæˆ)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    â”‚ "ç»™æˆ‘3é“é¢˜"  â”‚                   â”‚                   â”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚ quiz, topic="å…‰åˆä½œç”¨", num=3         â”‚
    â”‚              â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                   â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚ get_session_context()
    â”‚              â”‚                   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚ session_context   â”‚
    â”‚              â”‚                   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚              â”‚                   â”‚  (artifact_historyâ”‚
    â”‚              â”‚                   â”‚   åŒ…å« LLM å‹ç¼©çš„ â”‚
    â”‚              â”‚                   â”‚   245 chars summary)
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚ _build_context()  â”‚
    â”‚              â”‚                   â”‚ â€¢ Load 245 chars  â”‚
    â”‚              â”‚                   â”‚   (è€Œé 1,773!)   â”‚
    â”‚              â”‚                   â”‚                   â”‚
    â”‚              â”‚                   â”‚ kimi.generate()   â”‚
    â”‚              â”‚                   â”‚ Prompt: ~1,300 tokens
    â”‚              â”‚                   â”‚ (vs 3,949 before) â”‚
    â”‚              â”‚                   â”‚ èŠ‚çœ 67%! âœ…      â”‚
```

### å…³é”®æ¨¡å—èŒè´£

| æ¨¡å— | ä¸»è¦èŒè´£ | è¾“å…¥ | è¾“å‡º | æ€§èƒ½æŒ‡æ ‡ |
|------|---------|------|------|----------|
| **IntentRouter** | 0-token æ„å›¾è¯†åˆ« | ç”¨æˆ·æ¶ˆæ¯ | intent + params | < 1ms, 0 tokens |
| **SkillOrchestrator** | æŠ€èƒ½ç¼–æ’å’Œæ‰§è¡Œ | intent + context | LLM response | ~50-60s |
| **MemoryManager** | è®°å¿†å’Œä¸Šä¸‹æ–‡ç®¡ç† | artifact + session | ArtifactRecord | < 1s (åŒæ­¥éƒ¨åˆ†) |
| **ContextArtifactManager** | ä¸Šä¸‹æ–‡å¸è½½ | large artifacts | lightweight refs | 97.5% å‹ç¼© |
| **ContextMemoryManager** | ä¸Šä¸‹æ–‡ç¼©å‡ | session history | condensed history | 73% å‹ç¼© |
| **ConversationSessionManager** | ä¼šè¯ç®¡ç†å’Œæ—¥å¿— | turn data | MD + S3 upload | < 1s |
| **PlanSkillExecutor** | å¤šæ­¥éª¤ä»»åŠ¡ç¼–æ’ | plan + steps | aggregated result | å¤šæ­¥ç´¯åŠ  |

---

## ğŸ’¾ Context Offloading (ä¸Šä¸‹æ–‡å¸è½½)

### æ ¸å¿ƒåŸç†

å°†å¤§å‹ artifacts çš„**å®Œæ•´å†…å®¹**ä¿å­˜åˆ°å¤–éƒ¨å­˜å‚¨ï¼ˆæ–‡ä»¶ç³»ç»Ÿ/S3ï¼‰ï¼Œåœ¨ Context ä¸­åªä¿ç•™**è½»é‡çº§å¼•ç”¨**å’Œ**å‹ç¼©æ‘˜è¦**ã€‚

### å®ç°ä½ç½®

**æ–‡ä»¶**: `backend/app/core/memory_manager.py`

### ä»£ç ç¤ºä¾‹

#### 1. ä¿å­˜ Artifact (å¿«é€Ÿè¿”å› + å¼‚æ­¥å‹ç¼©)

```python
async def save_artifact(
    self,
    session_id: str,
    artifact: Dict[str, Any],
    artifact_type: str,
    topic: str,
    user_id: str
) -> ArtifactRecord:
    """
    ä¿å­˜ artifactï¼ˆè‡ªåŠ¨å¸è½½åˆ° S3/æœ¬åœ°ï¼‰
    
    ç­–ç•¥ï¼š
    1. å…ˆç”¨ fallback å‹ç¼©åˆ›å»ºè®°å½•ï¼ˆå¿«é€Ÿè¿”å›ç»™ç”¨æˆ·ï¼‰
    2. å¯åŠ¨åå°ä»»åŠ¡è¿›è¡Œ LLM æ™ºèƒ½å‹ç¼©ï¼ˆä¸é˜»å¡ï¼‰
    """
    artifact_id = self._generate_artifact_id(artifact_type, topic)
    
    # å¿«é€Ÿç”Ÿæˆ summary
    summary_text = self._generate_summary(artifact, artifact_type)
    
    # ğŸ”¥ å…ˆç”¨ fallback å‹ç¼©ï¼ˆå¿«é€Ÿï¼‰
    context_summary_placeholder = self._fallback_compression(artifact, artifact_type, topic)
    
    # åˆ›å»ºè®°å½•
    record = ArtifactRecord(
        artifact_id=artifact_id,
        turn_number=self._get_turn_number(session_id),
        artifact_type=artifact_type,
        topic=topic,
        summary=summary_text,
        content=context_summary_placeholder,  # å…ˆç”¨ fallback
        content_reference=None  # å®Œæ•´å†…å®¹åœ¨ MD æ–‡ä»¶
    )
    
    # æ·»åŠ åˆ° session context
    session_context = await self.get_session_context(session_id)
    session_context.artifact_history.append(record)
    await self.update_session_context(session_id, session_context)
    
    # ğŸš€ å¯åŠ¨åå°ä»»åŠ¡è¿›è¡Œ LLM æ™ºèƒ½å‹ç¼©ï¼ˆä¸é˜»å¡ï¼‰
    asyncio.create_task(
        self._compress_artifact_async(artifact_id, artifact, artifact_type, topic, session_id)
    )
    logger.debug(f"ğŸ”„ Started background LLM compression for {artifact_id}")
    
    return record  # ç«‹å³è¿”å›ï¼Œä¸ç­‰å¾… LLM å‹ç¼©
```

#### 2. åå°å¼‚æ­¥å‹ç¼©

```python
async def _compress_artifact_async(
    self,
    artifact_id: str,
    artifact: Dict[str, Any],
    artifact_type: str,
    topic: str,
    session_id: str
):
    """
    åå°å¼‚æ­¥ä»»åŠ¡ï¼šä½¿ç”¨ LLM æ™ºèƒ½å‹ç¼© artifact
    
    æ‰§è¡Œæµç¨‹ï¼š
    1. è°ƒç”¨ LLM è¿›è¡Œæ™ºèƒ½å‹ç¼© (~260sï¼Œä½†ä¸é˜»å¡ç”¨æˆ·)
    2. æ›´æ–° session_context ä¸­çš„ artifact record
    3. åç»­è¯·æ±‚ä¼šä½¿ç”¨ LLM å‹ç¼©åçš„ summary
    """
    try:
        logger.info(f"ğŸ”„ Background compression started for {artifact_id}")
        
        # è°ƒç”¨ LLM è¿›è¡Œæ™ºèƒ½å‹ç¼©
        compressed_summary = await self._create_context_summary(artifact, artifact_type, topic)
        
        # æ›´æ–° session context ä¸­çš„ artifact record
        session_context = await self.get_session_context(session_id)
        
        for record in session_context.artifact_history:
            if record.artifact_id == artifact_id:
                # æ›¿æ¢ fallback summary ä¸º LLM compressed summary
                record.content = compressed_summary
                logger.info(f"âœ… Background compression complete for {artifact_id}")
                break
        
        # ä¿å­˜æ›´æ–°åçš„ session context
        await self.update_session_context(session_id, session_context)
        
    except Exception as e:
        logger.warning(f"âš ï¸  Background compression failed for {artifact_id}: {e}")
        # Fallback summary ç»§ç»­ä½¿ç”¨
```

#### 3. åŠ è½½ Artifact (åªåŠ è½½å‹ç¼©çš„ Summary)

**æ–‡ä»¶**: `backend/app/core/skill_orchestrator.py`

```python
async def _build_context(self, skill, user_id, session_id):
    """æ„å»ºæŠ€èƒ½æ‰§è¡Œæ‰€éœ€çš„ä¸Šä¸‹æ–‡"""
    
    # åŠ è½½æœ€è¿‘çš„ artifacts
    if session_context.artifact_history:
        logger.info(f"ğŸ” Total artifacts in history: {len(session_context.artifact_history)}")
        
        # åªå–æœ€è¿‘ 2 ä¸ª
        recent_artifact_records = session_context.artifact_history[-2:]
        
        for artifact_record in recent_artifact_records:
            if artifact_record.content:
                content_str = str(artifact_record.content)
                content_size = len(content_str)
                
                # ğŸ›¡ï¸ å®‰å…¨æ£€æŸ¥ï¼šè·³è¿‡æœªå‹ç¼©çš„æ—§æ•°æ®
                if content_size > 1000:
                    logger.warning(f"âš ï¸  Artifact content too large ({content_size} chars), skipping")
                    continue
                
                # âœ… åªåŠ è½½å‹ç¼©åçš„ summary
                recent_artifacts.append({
                    "artifact_id": artifact_record.artifact_id,
                    "topic": artifact_record.topic,
                    "type": artifact_record.artifact_type,
                    "summary": artifact_record.summary,
                    "content": artifact_record.content  # å‹ç¼©çš„æ‘˜è¦ (~150-300 chars)
                })
                logger.info(f"ğŸ“„ Loaded artifact: {artifact_record.topic} ({content_size} chars)")
        
        context["recent_artifacts"] = recent_artifacts
        logger.info(f"ğŸ“š Loaded {len(recent_artifacts)} recent artifacts for context")
```

### å‹ç¼©æ•ˆæœ

| Artifact ç±»å‹ | åŸå§‹å¤§å° | å‹ç¼©åå¤§å° | å‹ç¼©æ¯” |
|--------------|----------|-----------|--------|
| explanation  | ~1,500 chars | ~200 chars | **-87%** |
| quiz_set     | ~1,500 chars | ~160 chars | **-89%** |
| flashcard_set | ~1,000 chars | ~150 chars | **-85%** |

---

## ğŸ”¥ Context Reduction (ä¸Šä¸‹æ–‡ç¼©å‡)

### æ ¸å¿ƒåŸç†

ä½¿ç”¨ LLM (Kimi k2-thinking) å¯¹ artifact è¿›è¡Œ**ç»“æ„åŒ–è¯­ä¹‰å‹ç¼©**ï¼Œä¿ç•™é€»è¾‘å…³ç³»ï¼Œä¸¢å¼ƒå†—ä½™æè¿°ã€‚

### å®ç°ä½ç½®

**æ–‡ä»¶**: `backend/app/core/memory_manager.py`

### ä»£ç ç¤ºä¾‹

#### 1. LLM æ™ºèƒ½å‹ç¼©

```python
async def _create_context_summary(
    self, 
    artifact: Dict[str, Any], 
    artifact_type: str, 
    topic: str
) -> Dict[str, Any]:
    """
    ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½å‹ç¼©
    
    ç›®æ ‡ï¼š
    - å‹ç¼©æ¯” > 85% (2000 tokens â†’ < 300 tokens)
    - ä¿ç•™é€»è¾‘å…³ç³»ï¼Œä¸¢å¼ƒå†—ä½™æè¿°
    - ä½¿ç”¨ Kimi k2-thinking è¿›è¡Œæ·±åº¦ç†è§£
    """
    try:
        import json
        from pathlib import Path
        
        # åŠ è½½ summary_skill prompt
        summary_prompt_path = Path(__file__).parent.parent / "prompts" / "summary_skill.txt"
        
        if not summary_prompt_path.exists():
            logger.warning(f"âš ï¸ summary_skill.txt not found, using fallback")
            return self._fallback_compression(artifact, artifact_type, topic)
        
        with open(summary_prompt_path, 'r', encoding='utf-8') as f:
            summary_prompt = f.read()
        
        # æ„é€ å‹ç¼©è¯·æ±‚
        compression_input = {
            "interaction_type": self._map_artifact_type_to_interaction(artifact_type),
            "topic": topic,
            "ai_response": json.dumps(artifact, ensure_ascii=False),
            "artifact_type": artifact_type
        }
        
        params_json = json.dumps(compression_input, ensure_ascii=False, indent=2)
        full_prompt = f"{summary_prompt}\n\n## Input Parameters (JSON)\n\n```json\n{params_json}\n```"
        
        # è°ƒç”¨ Kimi LLM è¿›è¡Œå‹ç¼©
        from app.services.kimi import KimiClient
        kimi = KimiClient()
        
        response = await kimi.generate(
            prompt=full_prompt,
            response_format="json",
            temperature=0.3  # ä½æ¸©åº¦ï¼Œä¿è¯ç¡®å®šæ€§
        )
        
        # è§£æå‹ç¼©ç»“æœ
        if isinstance(response, dict) and "content" in response:
            content = response["content"]
            
            # content å¯èƒ½æ˜¯ str æˆ– dict
            if isinstance(content, str):
                compressed = json.loads(content)
            elif isinstance(content, dict):
                compressed = content
            else:
                return self._fallback_compression(artifact, artifact_type, topic)
            
            original_size = len(json.dumps(artifact, ensure_ascii=False))
            compressed_size = len(json.dumps(compressed, ensure_ascii=False))
            compression_ratio = (1 - compressed_size / original_size) * 100
            
            logger.info(f"âœ… LLM compressed {artifact_type}: {original_size} â†’ {compressed_size} chars (-{compression_ratio:.1f}%)")
            return compressed
        else:
            logger.warning("âš ï¸ LLM compression failed, using fallback")
            return self._fallback_compression(artifact, artifact_type, topic)
    
    except Exception as e:
        logger.error(f"âŒ Error during LLM compression: {e}")
        return self._fallback_compression(artifact, artifact_type, topic)
```

#### 2. Fallback å‹ç¼©ï¼ˆå¿«é€Ÿä½†ç®€å•ï¼‰

```python
def _fallback_compression(
    self, 
    artifact: Dict[str, Any], 
    artifact_type: str, 
    topic: str
) -> Dict[str, Any]:
    """
    Fallback: ç®€å•çš„åŸºäºè§„åˆ™çš„å‹ç¼©ï¼ˆå½“ LLM ä¸å¯ç”¨æ—¶ï¼‰
    
    ç­–ç•¥ï¼šåªä¿ç•™å…³é”®å­—æ®µï¼Œæˆªæ–­é•¿æ–‡æœ¬
    """
    if artifact_type == "explanation":
        return {
            "summary_type": "concept_snapshot",
            "topic": topic,
            "key_concepts": [artifact.get("concept", "")],
            "mental_model": artifact.get("intuition", "")[:100],
            "examples_used": [ex.get("example", "")[:50] for ex in artifact.get("examples", [])[:2]],
            "user_state": {"understanding": "medium"},
            "next_suggestion": "practice"
        }
    
    elif artifact_type == "quiz_set":
        questions = artifact.get("questions", [])
        return {
            "summary_type": "assessment_log",
            "topic": topic,
            "stats": f"{len(questions)} questions generated",
            "weak_points": [],
            "strong_points": [],
            "mistakes_detail": []
        }
    
    # ... å…¶ä»–ç±»å‹
```

### Prompt è®¾è®¡

**æ–‡ä»¶**: `backend/app/prompts/summary_skill.txt`

```markdown
You are a Context Summarization Skill (The "Compressor").
Your goal is to compress verbose conversation turns into highly structured, token-efficient JSON summaries.

## âš¡ æ ¸å¿ƒçº¦æŸ (CRITICAL CONSTRAINTS)
1. **Compression Ratio:** Target < 10% of original length (e.g., 2000 tokens â†’ < 200 tokens).
2. **Format:** Output ONLY valid JSON.
3. **No Repetition:** Do not copy full sentences. Use keywords, short phrases, and references.
4. **Lossless Logic:** Preserve the *logic* (causality, rules, user state), discard the *prose*.

## ğŸ“ è¾“å‡ºæ¨¡å¼ (Output Schemas)

### Mode A: Concept Explanation
{
  "summary_type": "concept_snapshot",
  "topic": "æ ¸å¿ƒè¯é¢˜",
  "key_concepts": ["æ¦‚å¿µ1:å®šä¹‰å…³é”®è¯", "æ¦‚å¿µ2:å®šä¹‰å…³é”®è¯"],
  "mental_model": "ä½¿ç”¨çš„ç±»æ¯”",
  "examples_used": ["ä¾‹å­1å…³é”®è¯", "ä¾‹å­2å…³é”®è¯"],
  "user_state": {
    "understanding": "weak|medium|strong",
    "confusions": ["å›°æƒ‘ç‚¹1"]
  }
}

### Mode B: Assessment (Quiz/Flashcard)
{
  "summary_type": "assessment_log",
  "topic": "æµ‹è¯•è¯é¢˜",
  "stats": "Score: 3/5",
  "weak_points": ["é”™é¢˜çŸ¥è¯†ç‚¹1"],
  "mistakes_detail": [
    {"q": "é—®é¢˜å…³é”®è¯", "err": "é”™è¯¯é€‰é¡¹", "fix": "æ ¸å¿ƒä¿®æ­£ç‚¹"}
  ]
}
```

---

## ğŸ” Context Retrieval (æŒ‰éœ€æ£€ç´¢)

### æ ¸å¿ƒåŸç†

Agent ä¸»åŠ¨è°ƒç”¨å·¥å…·æ£€ç´¢è¢«å¸è½½çš„å†…å®¹ï¼Œå®ç° "æŒ‰éœ€åŠ è½½ = æŒ‰éœ€ä»˜è´¹"ã€‚

### å®ç°çŠ¶æ€

âš ï¸ **éƒ¨åˆ†å®ç° (60%)**

- âœ… å·¥å…·å·²å¼€å‘ï¼š`read_artifact`, `search_artifacts`, `list_artifacts`
- âš ï¸ æœªé›†æˆåˆ° Agent å·¥å…·é“¾
- âš ï¸ Agent å°šæœªæ”¯æŒ multi-turn tool calling

### å·²å¼€å‘çš„å·¥å…·

**æ–‡ä»¶**: `backend/app/tools/retrieval_tools.py`

```python
def read_artifact(artifact_id: str, lines: Optional[Tuple[int, int]] = None) -> str:
    """
    è¯»å– artifact çš„å®Œæ•´å†…å®¹
    
    Args:
        artifact_id: Artifact ID
        lines: å¯é€‰ï¼Œåªè¯»å–æŒ‡å®šè¡ŒèŒƒå›´ (start, end)
    
    Returns:
        Artifact å†…å®¹ (JSON string æˆ– markdown)
    """
    # ä»æ–‡ä»¶ç³»ç»Ÿæˆ– S3 è¯»å–
    artifact_manager = ContextArtifactManager()
    return artifact_manager.read_artifact(artifact_id, lines)


def search_artifacts(
    query: str, 
    artifact_type: Optional[str] = None
) -> List[Dict[str, Any]]:
    """
    è¯­ä¹‰æœç´¢ artifacts
    
    Args:
        query: æœç´¢æŸ¥è¯¢ï¼ˆå¦‚ "å…‰åˆä½œç”¨çš„å…¬å¼"ï¼‰
        artifact_type: å¯é€‰ï¼Œé™åˆ¶ç±»å‹ (explanation/quiz_set/flashcard_set)
    
    Returns:
        åŒ¹é…çš„ artifacts åˆ—è¡¨ï¼ˆè½»é‡çº§ç´¢å¼•ï¼‰
    """
    artifact_manager = ContextArtifactManager()
    return artifact_manager.search_artifacts(query, artifact_type)


def list_artifacts(session_id: str) -> List[Dict[str, Any]]:
    """
    åˆ—å‡ºä¼šè¯ä¸­çš„æ‰€æœ‰ artifacts (è½»é‡çº§ç´¢å¼•)
    
    Returns:
        [
            {
                "artifact_id": "...",
                "topic": "å…‰åˆä½œç”¨",
                "type": "explanation",
                "size": 1500,
                "summary": "..."
            }
        ]
    """
    artifact_manager = ContextArtifactManager()
    return artifact_manager.get_artifact_index(session_id)
```

### OpenAI Function Calling æ ¼å¼

```json
{
  "name": "read_artifact",
  "description": "Read the full content of a specific artifact that was offloaded to storage",
  "parameters": {
    "type": "object",
    "properties": {
      "artifact_id": {
        "type": "string",
        "description": "The unique ID of the artifact to read"
      },
      "lines": {
        "type": "object",
        "properties": {
          "start": {"type": "integer"},
          "end": {"type": "integer"}
        },
        "description": "Optional: only read specific line range"
      }
    },
    "required": ["artifact_id"]
  }
}
```

---

## ğŸ“Š æ•ˆæœéªŒè¯

### Token æ¶ˆè€—å¯¹æ¯”

| Turn | Before (å®Œæ•´åŠ è½½) | After (æ™ºèƒ½å‹ç¼©) | æ”¹å–„ |
|------|-------------------|------------------|------|
| Turn 1 | 1,002 tokens | 1,002 tokens | Baseline |
| Turn 2 | 3,949 tokens | ~1,300 tokens | **-67%** |
| Turn 3 | 6,500 tokens | ~1,500 tokens | **-77%** |
| Turn 10 | ~35,000 tokens | ~5,000 tokens | **-86%** |

### å…³é”®çªç ´

âœ… **Context ä¸å†çº¿æ€§å¢é•¿**  
âœ… **ç”¨æˆ·å“åº”æ—¶é—´ä¸å—å‹ç¼©å½±å“** (å¼‚æ­¥æ‰§è¡Œ)  
âœ… **æ”¯æŒé•¿å¯¹è¯åœºæ™¯** (10+ turns)

### æ—¥å¿—ç¤ºä¾‹

```
# Turn 1: ç”Ÿæˆ explanation
âœ… Generation complete: 1773 chars, 3331 tokens
ğŸ“ Artifact recorded (context summary: 388 chars)  â† Fallback å‹ç¼©
ğŸ”„ Started background LLM compression  â† å¼‚æ­¥ä»»åŠ¡å¯åŠ¨

# åå°ï¼ˆç”¨æˆ·å·²æ”¶åˆ°å“åº”ï¼‰
ğŸ”„ Background compression started for artifact_explanation_...
âœ… LLM compressed explanation: 1773 â†’ 245 chars (-86.2%)  â† LLM å‹ç¼©å®Œæˆ
âœ… Background compression complete, updated in session context

# Turn 2: ç”Ÿæˆ quiz (æ­¤æ—¶ä½¿ç”¨ LLM å‹ç¼©åçš„ summary)
ğŸ“„ Loaded artifact: å…‰åˆä½œç”¨ (explanation, 245 chars)  â† åªåŠ è½½ 245 chars!
ğŸ“š Loaded 1 recent artifacts for context
ğŸ“¦ Added 1 artifact summaries to prompt (~245 chars)  â† Context å¤§å¹…å‡å°‘
```

---

## ğŸ”„ å®Œæ•´æµç¨‹ç¤ºä¾‹

### åœºæ™¯ï¼š3 è½®å¯¹è¯

```
User: è®²è®²å…‰åˆä½œç”¨
  â†“
[Turn 1] Explain Skill
  â€¢ LLM ç”Ÿæˆ explanation (~1500 chars, 60s)
  â€¢ ä¿å­˜ artifact (fallback å‹ç¼© â†’ 388 chars, <1s)
  â€¢ âœ… ç”¨æˆ·æ”¶åˆ°å“åº” (æ€»è€—æ—¶ ~61s)
  â€¢ åå°å¼‚æ­¥ LLM å‹ç¼© (1500 â†’ 245 chars, 260s)
  
User: ç»™æˆ‘3é“é¢˜
  â†“
[Turn 2] Quiz Skill
  â€¢ åŠ è½½ context (explanation: 245 chars)  â† ä½¿ç”¨ LLM å‹ç¼©åçš„
  â€¢ LLM ç”Ÿæˆ quiz (~1200 chars, 50s)
  â€¢ ä¿å­˜ artifact (fallback å‹ç¼© â†’ 160 chars, <1s)
  â€¢ âœ… ç”¨æˆ·æ”¶åˆ°å“åº” (æ€»è€—æ—¶ ~51s)
  â€¢ åå°å¼‚æ­¥ LLM å‹ç¼© (1200 â†’ 160 chars, 240s)

User: å†æ¥5é“é¢˜
  â†“
[Turn 3] Quiz Skill
  â€¢ åŠ è½½ context (explanation: 245 chars + quiz: 160 chars = 405 chars)
  â€¢ LLM ç”Ÿæˆ quiz (~2000 chars, 60s)
  â€¢ âœ… ç”¨æˆ·æ”¶åˆ°å“åº” (æ€»è€—æ—¶ ~61s)
  
Token æ¶ˆè€—ï¼š
  Turn 1: 1,002 tokens (baseline)
  Turn 2: 1,300 tokens (+298, vs 3,949 before)  â† èŠ‚çœ 67%
  Turn 3: 1,500 tokens (+200, vs 6,500 before)  â† èŠ‚çœ 77%
```

---

## ğŸš€ ä¸‹ä¸€æ­¥ä¼˜åŒ–æ–¹å‘

### 1. é›†æˆ Context Retrieval âš ï¸

**ä¼˜å…ˆçº§**: High

**ä»»åŠ¡**:
- å°† retrieval_tools æ³¨å†Œåˆ° Agent å·¥å…·é“¾
- å®ç° multi-turn tool calling
- è®© Agent ä¸»åŠ¨å†³å®šä½•æ—¶éœ€è¦åŠ è½½å®Œæ•´å†…å®¹

**é¢„æœŸæ•ˆæœ**:
- Context è¿›ä¸€æ­¥ç¼©å‡ (åªåŠ è½½ç´¢å¼•ï¼Œä¸åŠ è½½ summary)
- Turn 2 Prompt: 1,300 â†’ ~1,000 tokens (-23%)

### 2. å‘é‡æ£€ç´¢

**ä¼˜å…ˆçº§**: Medium

**ä»»åŠ¡**:
- ä¸º artifacts å»ºç«‹ embedding ç´¢å¼•
- æ”¯æŒè¯­ä¹‰æœç´¢ï¼ˆè€Œéä»…å…³é”®è¯ï¼‰

### 3. æ™ºèƒ½é¢„åŠ è½½

**ä¼˜å…ˆçº§**: Low

**ä»»åŠ¡**:
- åŸºäºç”¨æˆ·æ„å›¾é¢„æµ‹å¯èƒ½éœ€è¦çš„ artifacts
- åœ¨åå°é¢„å…ˆåŠ è½½

---

## ğŸ“ æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒæ¨¡å—

1. **memory_manager.py** (945 lines)
   - `save_artifact()` - å¿«é€Ÿä¿å­˜ + å¼‚æ­¥å‹ç¼©
   - `_compress_artifact_async()` - åå° LLM å‹ç¼©
   - `_create_context_summary()` - LLM æ™ºèƒ½å‹ç¼©
   - `_fallback_compression()` - å¿«é€Ÿè§„åˆ™å‹ç¼©

2. **skill_orchestrator.py**
   - `_build_context()` - åªåŠ è½½å‹ç¼©çš„ summary
   - è·³è¿‡æœªå‹ç¼©çš„æ—§æ•°æ® (> 1000 chars)

3. **context_artifact_manager.py** (304 lines)
   - `save_with_offload()` - ä¿å­˜åˆ°æ–‡ä»¶/S3
   - `get_artifact_index()` - è½»é‡çº§ç´¢å¼•
   - `read_artifact()` - è¯»å–å®Œæ•´å†…å®¹

4. **context_memory_manager.py** (261 lines)
   - `condense_history()` - å†å²å‹ç¼©
   - `build_lightweight_context()` - è½»é‡çº§ä¸Šä¸‹æ–‡

5. **retrieval_tools.py**
   - `read_artifact()` - Agent å·¥å…·
   - `search_artifacts()` - Agent å·¥å…·
   - `list_artifacts()` - Agent å·¥å…·

### Prompt

- **summary_skill.txt** (81 lines)
  - Mode A: Concept Explanation
  - Mode B: Assessment
  - Mode C: General Chat

---

## âœ… æ€»ç»“

### å·²å®ç° (100%)

1. âœ… **Context Offloading**: å®Œæ•´å†…å®¹ä¿å­˜åˆ°å¤–éƒ¨ï¼ŒContext åªä¿ç•™å¼•ç”¨
2. âœ… **Context Reduction**: LLM æ™ºèƒ½å‹ç¼© (å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡ç”¨æˆ·)
3. âœ… **Fallback æœºåˆ¶**: LLM å¤±è´¥æ—¶è‡ªåŠ¨ä½¿ç”¨è§„åˆ™å‹ç¼©
4. âœ… **æ—§æ•°æ®è¿‡æ»¤**: è·³è¿‡æœªå‹ç¼©çš„å†å²æ•°æ®
5. âœ… **S3 æŒä¹…åŒ–**: MD + metadata è‡ªåŠ¨ä¸Šä¼ äº‘ç«¯

### éƒ¨åˆ†å®ç° (60%)

1. âš ï¸ **Context Retrieval**: å·¥å…·å·²å¼€å‘ï¼Œæœªé›†æˆåˆ° Agent

### æ ¸å¿ƒæˆæœ

- **Token èŠ‚çœ**: 67-86% (é•¿å¯¹è¯åœºæ™¯)
- **ç”¨æˆ·ä½“éªŒ**: å“åº”æ—¶é—´ä¸å—å½±å“ (å¼‚æ­¥å‹ç¼©)
- **å¯æ‰©å±•æ€§**: æ”¯æŒ 10+ è½®é•¿å¯¹è¯
- **æˆæœ¬ä¼˜åŒ–**: æ¯ä¸ª session èŠ‚çœ $0.05-0.15

### æŠ€æœ¯äº®ç‚¹

1. **å¼‚æ­¥æ¶æ„**: å‹ç¼©ä¸é˜»å¡ç”¨æˆ·å“åº”
2. **åŒé‡å‹ç¼©**: Fallback (å¿«é€Ÿ) + LLM (æ™ºèƒ½)
3. **è‡ªé€‚åº”åŠ è½½**: è‡ªåŠ¨è·³è¿‡è¿‡å¤§çš„æ—§æ•°æ®
4. **é›¶ token åˆ†ç±»**: Skill Registry (Phase 4)

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2024-11-24 06:10  
**æœ€åæ›´æ–°**: 2024-12-22  
**ç‰ˆæœ¬**: v1.1



---

<a name="thinking-mode-selection"></a>
# ğŸ§  Thinking Mode Selection


## ğŸ“‹ æ¶æ„æ¦‚è§ˆ

```
ç”¨æˆ·è¾“å…¥
    â†“
Intent Router (Phase 4 - 0 Token)
    â†“
Thinking Mode Selector â­ [NEW]
    â†“
    â”œâ”€â†’ çœŸæ€è€ƒ (Real Thinking)
    â”‚   â€¢ æ¨¡å‹: Gemini 2.5 Flash (ä¸») / Kimi k2-thinking (å¤‡)
    â”‚   â€¢ åœºæ™¯: å¤šä¸»é¢˜ã€å¼€æ”¾æ€§ã€é«˜éš¾åº¦
    â”‚   â€¢ æˆæœ¬: 1x (åŸºå‡†)
    â”‚   â€¢ ç¤ºä¾‹: å­¦ä¹ åŒ…è§„åˆ’ã€è¯¾ç¨‹è®¾è®¡
    â”‚
    â””â”€â†’ ä¼ªæ€è€ƒ (Fake Thinking)
        â€¢ æ¨¡å‹: Gemini 2.5 Flash
        â€¢ åœºæ™¯: å•ä¸€ topic follow-up
        â€¢ æˆæœ¬: 0.1x (~1/10)
        â€¢ ç¤ºä¾‹: è§£é¢˜æ­¥éª¤ã€å˜å¼ç”Ÿæˆ

```

---

## ğŸ¯ æ ¸å¿ƒè®¾è®¡ç†å¿µ

### ä»€ä¹ˆæ˜¯ä¼ªæ€è€ƒï¼Ÿ

> **ç”¨ä¾¿å®œçš„æ¨¡å‹ + é«˜è´¨é‡ä¸Šä¸‹æ–‡ + å±€éƒ¨æ¨ç†æ¡†æ¶ â†’ æ¨¡æ‹Ÿ Thinking èƒ½åŠ›**

**å…³é”®ç‰¹ç‚¹**ï¼š
- âœ… é—®é¢˜èŒƒå›´é™åˆ¶å¾—éå¸¸å°
- âœ… åªåŠ è½½è¯¥ topic çš„ç›¸å…³ä¸Šä¸‹æ–‡
- âœ… æ‰§è¡Œç»“æ„åŒ–æ­¥éª¤ï¼ˆæ¨¡æ¿å¼æ¨ç†ï¼‰
- âœ… ä¸è§¦å‘æ·±åº¦ chain-of-thought
- âœ… æˆæœ¬ä»…ä¸ºçœŸæ€è€ƒçš„ 1/10ï½1/20

---

## ğŸ“Š çœŸæ€è€ƒ vs ä¼ªæ€è€ƒå¯¹æ¯”

| ç»´åº¦ | çœŸæ€è€ƒ (Gemini/Kimi) | ä¼ªæ€è€ƒ (Gemini Flash) |
|------|----------------------|----------------------|
| **é€‚ç”¨åœºæ™¯** | å¤šä¸»é¢˜ã€å¼€æ”¾æ€§ã€é«˜éš¾åº¦ | å•ä¸€ topic follow-up |
| **æ¨ç†ç±»å‹** | æ·±åº¦ chain-of-thought | æ¨¡æ¿å¼æµç¨‹æ¨ç† |
| **ä¸Šä¸‹æ–‡é‡** | å¤§ / å…¨å±€ä¸»é¢˜ | å° / å±€éƒ¨ topic |
| **æˆæœ¬** | é«˜ (1x) | ä½ (0.1x) |
| **é€Ÿåº¦** | è¾ƒæ…¢ (~30s) | å¿« (~5-10s) |
| **ç¤ºä¾‹** | è®¾è®¡è¯¾ç¨‹ã€è§„åˆ’å­¦ä¹ åŒ… | è§£æŸé¢˜ã€å˜å¼ç»ƒä¹  |

> **æ³¨æ„**: å½“å‰é»˜è®¤ä½¿ç”¨ Gemini 2.5 Flash å¤„ç†æ‰€æœ‰è¯·æ±‚ï¼ŒKimi ä½œä¸ºå¤‡é€‰ã€‚

---

## ğŸ” æ™ºèƒ½é€‰æ‹©é€»è¾‘

### è§¦å‘çœŸæ€è€ƒçš„æ¡ä»¶ï¼š

1. **Intent ç±»å‹**ï¼š
   - `learning_bundle`ï¼ˆå­¦ä¹ åŒ…ï¼‰
   - `plan_skill`ï¼ˆè§„åˆ’ç±»ï¼‰
   - `mindmap`ï¼ˆæ€ç»´å¯¼å›¾ï¼‰

2. **å¤šæŠ€èƒ½ç»„åˆ**ï¼š
   - `required_steps` åŒ…å« 2+ ä¸ªæŠ€èƒ½

3. **å…¨æ–° Topic**ï¼š
   - `topic` ä¸åœ¨ `artifact_history` ä¸­
   - ä¸æ˜¯ `current_topic` çš„å»¶ç»­

4. **ä¿å®ˆç­–ç•¥**ï¼š
   - æ— æ³•åˆ¤æ–­æ—¶ï¼Œé»˜è®¤çœŸæ€è€ƒ

---

### è§¦å‘ä¼ªæ€è€ƒçš„æ¡ä»¶ï¼š

1. **Follow-up é—®é¢˜**ï¼š
   - `topic == current_topic`
   - `topic` åœ¨æœ€è¿‘ 5 ä¸ª artifacts ä¸­

2. **å¼•ç”¨ç‰¹å®šå†…å®¹**ï¼š
   - `use_last_artifact = true`
   - `reference_index` å­˜åœ¨ï¼ˆå¦‚ "ç¬¬3é¢˜"ï¼‰

3. **å•ä¸€æŠ€èƒ½**ï¼š
   - Intent æ˜¯ `explain_request`, `quiz_request`, `flashcard_request`
   - æ— å¤šæŠ€èƒ½ç»„åˆ

---

## ğŸ’¡ å…¸å‹ä½¿ç”¨åœºæ™¯

### çœŸæ€è€ƒåœºæ™¯ï¼š

**ç”¨æˆ·**: "ç»™æˆ‘ä¸€ä¸ªå…³äºå…‰åˆä½œç”¨çš„å­¦ä¹ åŒ…ï¼ŒåŒ…å«è®²è§£ã€5å¼ é—ªå¡å’Œ3é“é¢˜"

```
åˆ¤æ–­ä¾æ®:
  âœ“ Intent = learning_bundle
  âœ“ required_steps = ["explain", "flashcard", "quiz"]
  âœ“ éœ€è¦å…¨å±€è§„åˆ’
  
é€‰æ‹©: çœŸæ€è€ƒ (Kimi k2-thinking)
åŸå› : å¤šæŠ€èƒ½ç»„åˆï¼Œéœ€è¦æ·±åº¦è§„åˆ’
æˆæœ¬: 1x
```

---

### ä¼ªæ€è€ƒåœºæ™¯ï¼š

**ç”¨æˆ·**: "ä¸Šæ¬¡é‚£é“å‡½æ•°é¢˜ï¼Œç¬¬3æ­¥çš„å¯¼æ•°ä¸º0æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ"

```
åˆ¤æ–­ä¾æ®:
  âœ“ Follow-up = true (topic = "å‡½æ•°å•è°ƒæ€§")
  âœ“ reference_index = 3
  âœ“ å±€éƒ¨æ¨ç†ï¼ˆæŸä¸ªæ­¥éª¤ï¼‰
  
é€‰æ‹©: ä¼ªæ€è€ƒ (Gemini 2.0 Flash Exp)
åŸå› : Follow-up é—®é¢˜ï¼Œå±€éƒ¨æ¨ç†å³å¯
æˆæœ¬: 0.05x (~1/20)
```

---

## ğŸ› ï¸ æŠ€æœ¯å®ç°

### æ ¸å¿ƒæ¨¡å—ï¼š`ThinkingModeSelector`

**ä½ç½®**: `backend/app/core/thinking_mode_selector.py`

**API**:
```python
selector = ThinkingModeSelector()

result = selector.select_mode(
    intent_result=intent_result,
    session_context=session_context
)

# result = {
#     "mode": "real_thinking" | "fake_thinking",
#     "model": "moonshotai/kimi-k2-thinking" | "gemini-2.0-flash-exp",
#     "reasoning": "é€‰æ‹©åŸå› ",
#     "thinking_budget": 32 | None,
#     "estimated_cost_multiplier": 1.0 | 0.05
# }
```

---

### é›†æˆåˆ° SkillOrchestrator

**ä¿®æ”¹ç‚¹**: `backend/app/core/skill_orchestrator.py`

```python
# åœ¨ execute() æ–¹æ³•ä¸­æ·»åŠ 
from .thinking_mode_selector import ThinkingModeSelector

selector = ThinkingModeSelector()
thinking_config = selector.select_mode(
    intent_result=intent_result,
    session_context=session_context
)

# æ ¹æ® thinking_config.model é€‰æ‹©å®¢æˆ·ç«¯
if thinking_config["mode"] == "real_thinking":
    client = KimiClient()
else:
    client = GeminiClient()
```

---

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### æˆæœ¬ä¼˜åŒ–ï¼š

**Beforeï¼ˆå…¨éƒ¨çœŸæ€è€ƒï¼‰**:
```
10 ä¸ªè¯·æ±‚ Ã— 1x = 10x æˆæœ¬
```

**Afterï¼ˆæ™ºèƒ½æ··åˆï¼‰**:
```
2 ä¸ªè¯·æ±‚ Ã— 1x (çœŸæ€è€ƒ) = 2x
8 ä¸ªè¯·æ±‚ Ã— 0.05x (ä¼ªæ€è€ƒ) = 0.4x
æ€»æˆæœ¬: 2.4x

èŠ‚çœ: 76% ğŸ’°
```

---

### é€Ÿåº¦ä¼˜åŒ–ï¼š

**ä¼ªæ€è€ƒå“åº”æ—¶é—´**: ~10s
**çœŸæ€è€ƒå“åº”æ—¶é—´**: ~60s

**Follow-up é—®é¢˜åŠ é€Ÿ 6 å€ï¼** âš¡

---

## ğŸ”„ åç»­ä¼˜åŒ–æ–¹å‘

1. **åŠ¨æ€ Thinking Budget è°ƒæ•´**ï¼š
   - ç®€å•é—®é¢˜ï¼šbudget = 16
   - ä¸­ç­‰é—®é¢˜ï¼šbudget = 32
   - å¤æ‚é—®é¢˜ï¼šbudget = 64

2. **Context Retrieval ä¼˜åŒ–**ï¼š
   - ä¼ªæ€è€ƒåªåŠ è½½ topic-level ä¸Šä¸‹æ–‡
   - å‡å°‘æ— å…³ artifacts åŠ è½½

3. **Template-based Reasoning**ï¼š
   - ä¸ºä¼ªæ€è€ƒè®¾è®¡æ¨ç†æ¨¡æ¿
   - å¦‚ï¼šè§£é¢˜æ¨¡æ¿ã€å˜å¼æ¨¡æ¿ã€æ­¥éª¤è®²è§£æ¨¡æ¿

4. **A/B Testing**ï¼š
   - å¯¹æ¯”çœŸæ€è€ƒ vs ä¼ªæ€è€ƒçš„ç”¨æˆ·æ»¡æ„åº¦
   - ä¼˜åŒ–åˆ‡æ¢é˜ˆå€¼

---

## ğŸ“ æ€»ç»“

âœ… **æ™ºèƒ½è·¯ç”±**ï¼šè‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„æ€è€ƒæ¨¡å¼
âœ… **æˆæœ¬ä¼˜åŒ–**ï¼šèŠ‚çœ 70-80% çš„ LLM æˆæœ¬
âœ… **é€Ÿåº¦æå‡**ï¼šFollow-up é—®é¢˜å¿« 6 å€
âœ… **è´¨é‡ä¿è¯**ï¼šå¤æ‚ä»»åŠ¡ä»ç”¨çœŸæ€è€ƒ

**æ ¸å¿ƒä»·å€¼**ï¼šåœ¨ä¿è¯è´¨é‡çš„å‰æä¸‹ï¼Œæœ€å¤§åŒ–æˆæœ¬æ•ˆç›Šï¼ğŸ’ª



---

<a name="plan-skill"></a>
# ğŸ“‹ Plan Skill


## ğŸ” é—®é¢˜åˆ†æ (åŸºäº backend.log)

### é—®é¢˜ 1: ä¾èµ–æ­¥éª¤ä¸å­˜åœ¨æ—¶ä¼ é€’ None âŒ

**æ—¥å¿—ä½ç½®**: Line 284-285, 309-311

```
âš ï¸  ä¾èµ–çš„ step explain ä¸å­˜åœ¨æˆ–æœªæ‰§è¡Œï¼ˆå¯èƒ½è¢«åŠ¨æ€è·³è¿‡ï¼‰ï¼Œä¼ é€’ None
```

**é—®é¢˜æ ¹æº**:
1. ç”¨æˆ·è¯·æ±‚: "ç»™æˆ‘4é“quiz å’Œ 4å¼ é—ªå¡"
2. ç³»ç»Ÿè¯†åˆ«ä¸º `learning_plan_skill`ï¼Œ`required_steps=['quiz', 'flashcard']`
3. ä½† Plan Skill é…ç½®ä¸­ï¼Œ`flashcard` å’Œ `quiz` çš„ `input_mapping` ä»ç„¶ç¡¬ç¼–ç ä¾èµ– `explain` æ­¥éª¤
4. ç”±äºç”¨æˆ·æ²¡æœ‰è¯·æ±‚ `explain`ï¼Œæ‰€ä»¥ `explain` è¢«è·³è¿‡
5. ä¸‹æ¸¸æ­¥éª¤ (flashcard/quiz) è·å– `reference_explanation=None`
6. LLM æ— æ³•ç”Ÿæˆæœ‰æ•ˆå†…å®¹ï¼Œè¿”å›é JSON å“åº”

**ä»£ç ä½ç½®**: `plan_skill_executor.py:665-668`

### é—®é¢˜ 2: Flashcard ç”Ÿæˆå¤±è´¥ âŒ

**æ—¥å¿—ä½ç½®**: Line 295-296

```
âŒ Failed to parse JSON: Expecting value: line 1 column 1 (char 0)
ğŸ“Š Final content: 86 chars
ğŸ§  Final reasoning: 4292 chars
```

**é—®é¢˜æ ¹æº**:
- `reference_explanation=None` å¯¼è‡´ LLM æ— æ³•ç”Ÿæˆ flashcard
- LLM è¿”å›äº†ä¸€ä¸ªé”™è¯¯æ¶ˆæ¯ (86 chars) è€Œä¸æ˜¯æœ‰æ•ˆçš„ JSON
- å¯èƒ½çš„å“åº”: "æ— æ³•ç”Ÿæˆé—ªå¡ï¼Œå› ä¸ºæ²¡æœ‰æä¾›å‚è€ƒè®²è§£å†…å®¹"

### é—®é¢˜ 3: é‡å¤è¯·æ±‚å¤„ç† ğŸ”„

**æ—¥å¿—ä½ç½®**: Line 106-157

- åŒä¸€ä¸ªè¯·æ±‚è¢«å¤„ç†äº†ä¸¤æ¬¡
- å¯èƒ½æ˜¯å‰ç«¯é‡å¤å‘é€æˆ–åç«¯æ²¡æœ‰å»é‡

---

## ğŸ› ï¸ ä¿®å¤æ–¹æ¡ˆ

### ä¿®å¤ 1: æ™ºèƒ½ä¾èµ–æŸ¥æ‰¾ (ä» Session Context)

**ç­–ç•¥**: å½“æ­¥éª¤ä¾èµ–ä¸å­˜åœ¨æ—¶ï¼Œä» `session_context` çš„ `artifact_history` ä¸­æŸ¥æ‰¾æœ€è¿‘çš„ç›¸å…³ artifactã€‚

```python
# åœ¨ plan_skill_executor.py çš„ _build_step_input æ–¹æ³•ä¸­

elif value_template.startswith("{context."):
    parts = value_template[9:-1].split(".", 1)
    step_id = parts[0]
    field_path = parts[1] if len(parts) > 1 else None
    
    # ... (existing code for "previous") ...
    
    else:
        # æ£€æŸ¥ä¾èµ–æ­¥éª¤æ˜¯å¦å­˜åœ¨äºå½“å‰ Plan çš„æ‰§è¡Œä¸Šä¸‹æ–‡ä¸­
        if step_id in step_contexts:
            context_value = step_contexts[step_id]
            if field_path:
                step_input[key] = self._get_nested_value(context_value, field_path)
            else:
                step_input[key] = context_value
        else:
            # ğŸ†• ä» session_context.artifact_history æŸ¥æ‰¾ç›¸å…³ artifact
            fallback_value = self._find_artifact_from_session(
                session_context=session_context,  # éœ€è¦ä¼ å…¥
                artifact_type=step_id,  # ä¾‹å¦‚ "explain"
                topic=user_input.get("topic")
            )
            
            if fallback_value:
                logger.info(f"âœ… ä» session_context æ‰¾åˆ° {step_id} çš„ fallback artifact")
                step_input[key] = fallback_value
            else:
                logger.warning(f"âš ï¸  ä¾èµ–çš„ step {step_id} ä¸å­˜åœ¨ï¼Œä¸” session ä¸­æ— ç›¸å…³ artifactï¼Œè·³è¿‡è¯¥å‚æ•°")
                # ä¸è®¾ç½®è¯¥å‚æ•°ï¼Œè€Œä¸æ˜¯ä¼ é€’ None
```

**æ–°å¢æ–¹æ³•**:

```python
def _find_artifact_from_session(
    self,
    session_context: Any,
    artifact_type: str,
    topic: Optional[str] = None
) -> Optional[Dict[str, Any]]:
    """
    ä» session_context.artifact_history ä¸­æŸ¥æ‰¾ç›¸å…³ artifact
    
    Args:
        session_context: ä¼šè¯ä¸Šä¸‹æ–‡
        artifact_type: Artifact ç±»å‹ (e.g., "explain", "quiz")
        topic: å¯é€‰ä¸»é¢˜ï¼Œç”¨äºè¿‡æ»¤
    
    Returns:
        æ‰¾åˆ°çš„ artifact contentï¼Œæˆ– None
    """
    if not session_context or not hasattr(session_context, 'artifact_history'):
        return None
    
    # ä»åå¾€å‰æŸ¥æ‰¾ (æœ€æ–°çš„ä¼˜å…ˆ)
    for artifact_record in reversed(session_context.artifact_history):
        # åŒ¹é…ç±»å‹
        if artifact_record.artifact_type == artifact_type:
            # å¦‚æœæŒ‡å®šäº† topicï¼Œè¿›ä¸€æ­¥åŒ¹é…
            if topic and artifact_record.topic != topic:
                continue
            
            # è¿”å› artifact çš„ content (å‹ç¼©çš„ summary)
            if artifact_record.content:
                logger.info(f"ğŸ“¦ Found {artifact_type} artifact from session: {artifact_record.artifact_id}")
                return artifact_record.content
    
    return None
```

### ä¿®å¤ 2: æ›´æ–° execute_plan_stream æ–¹æ³•ç­¾å

```python
async def execute_plan_stream(
    self,
    plan_config: Dict[str, Any],
    user_input: Dict[str, Any],
    user_profile: Any,
    session_context: Any  # ğŸ†• ç¡®ä¿ä¼ å…¥
):
    # ...
    
    # åœ¨è°ƒç”¨ _build_step_input æ—¶ä¼ å…¥ session_context
    step_input = self._build_step_input(
        step=step,
        user_input=user_input,
        step_contexts=step_contexts,
        session_context=session_context  # ğŸ†•
    )
```

### ä¿®å¤ 3: æ›´æ–° _build_step_input æ–¹æ³•ç­¾å

```python
def _build_step_input(
    self,
    step: Dict[str, Any],
    user_input: Dict[str, Any],
    step_contexts: Dict[str, Any],
    session_context: Optional[Any] = None  # ğŸ†•
) -> Dict[str, Any]:
    # ... (existing code) ...
```

### ä¿®å¤ 4: Prompt å¢å¼º (å‘ŠçŸ¥ LLM å¯ä»¥ä½¿ç”¨ session context)

åœ¨ `flashcard_skill.txt` å’Œ `quiz_generation_skill.txt` ä¸­æ·»åŠ :

```markdown
## ğŸ”„ Context Fallback

å¦‚æœ `reference_explanation` ä¸ºç©ºæˆ– Noneï¼Œä½† `context.recent_artifacts` ä¸­åŒ…å«ç›¸å…³çš„ explanationï¼Œ
ä½ åº”è¯¥ä»ä¸­æå–ä¿¡æ¯æ¥ç”Ÿæˆ flashcards/quizzesã€‚

ç¤ºä¾‹:
```json
{
  "context": {
    "recent_artifacts": [
      {
        "artifact_id": "artifact_explanation_...",
        "topic": "äºŒæˆ˜ èµ·å› ",
        "type": "explanation",
        "content": {
          "summary_type": "concept_snapshot",
          "key_concepts": ["å‡¡å°”èµ›æ¡çº¦", "ç»æµå¤§è§æ¡"],
          "examples_used": ["æ…•å°¼é»‘åå®š", "è½´å¿ƒå›½è”ç›Ÿ"]
        }
      }
    ]
  }
}
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ åº”è¯¥ä½¿ç”¨ `context.recent_artifacts` ä¸­çš„ä¿¡æ¯ç”Ÿæˆå†…å®¹ã€‚
```

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### Before (æœ‰ Bug):
```
User: "ç»™æˆ‘4é“quiz å’Œ 4å¼ é—ªå¡"
  â†“
Plan Skill: ['quiz', 'flashcard']
  â†“
Flashcard Skill:
  â€¢ reference_explanation: None âŒ
  â€¢ LLM è¿”å›é”™è¯¯æ¶ˆæ¯
  â€¢ JSON è§£æå¤±è´¥ âŒ
  
Quiz Skill:
  â€¢ reference_explanation: None âŒ
  â€¢ å‹‰å¼ºç”Ÿæˆï¼Œä½†å†…å®¹ä¸è¿è´¯
```

### After (ä¿®å¤å):
```
User: "ç»™æˆ‘4é“quiz å’Œ 4å¼ é—ªå¡"
  â†“
Plan Skill: ['quiz', 'flashcard']
  â†“
_build_step_input æ£€æµ‹åˆ° explain æ­¥éª¤è¢«è·³è¿‡
  â†“
ä» session_context.artifact_history æŸ¥æ‰¾æœ€è¿‘çš„ explanation artifact
  â†“
æ‰¾åˆ°: artifact_explanation_äºŒæˆ˜_èµ·å›  (Turn 1/2)
  â†“
Flashcard Skill:
  â€¢ reference_explanation: {compressed_summary} âœ…
  â€¢ LLM æˆåŠŸç”Ÿæˆ 4 å¼ é—ªå¡ âœ…
  
Quiz Skill:
  â€¢ reference_explanation: {compressed_summary} âœ…
  â€¢ reference_flashcards: {flashcard_result} âœ…
  â€¢ LLM æˆåŠŸç”Ÿæˆ 4 é“é¢˜ âœ…
```

---

## ğŸš€ å®æ–½æ­¥éª¤

1. âœ… åˆ†æé—®é¢˜ (å·²å®Œæˆ)
2. â³ ä¿®æ”¹ `plan_skill_executor.py`:
   - æ·»åŠ  `_find_artifact_from_session` æ–¹æ³•
   - æ›´æ–° `_build_step_input` æ–¹æ³•
   - æ›´æ–° `execute_plan_stream` æ–¹æ³•ç­¾å
3. â³ æ›´æ–° Prompt æ¨¡æ¿ (å¯é€‰ä¼˜åŒ–)
4. â³ æµ‹è¯•éªŒè¯

---

**ä¼˜å…ˆçº§**: ğŸ”´ High  
**é¢„è®¡æ—¶é—´**: 30 åˆ†é’Ÿ  
**é£é™©è¯„ä¼°**: Low (å‘åå…¼å®¹ï¼Œfallback æœºåˆ¶)

